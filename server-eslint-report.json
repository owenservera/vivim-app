[{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\ai\\agent-pipeline.js","messages":[{"ruleId":"no-unused-vars","severity":1,"message":"'z' is defined but never used.","line":15,"column":10,"nodeType":"Identifier","messageId":"unusedVar","endLine":15,"endColumn":11,"suggestions":[{"messageId":"removeVar","data":{"varName":"z"},"fix":{"range":[635,659],"text":""},"desc":"Remove unused variable 'z'."}]},{"ruleId":"no-unused-vars","severity":1,"message":"'onStepStart' is assigned a value but never used. Allowed unused args must match /^_/u.","line":73,"column":5,"nodeType":"Identifier","messageId":"unusedVar","endLine":73,"endColumn":16,"suggestions":[{"messageId":"removeVar","data":{"varName":"onStepStart"},"fix":{"range":[2012,2036],"text":""},"desc":"Remove unused variable 'onStepStart'."}]}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":2,"fixableErrorCount":0,"fixableWarningCount":0,"source":"// apps/server/src/ai/agent-pipeline.js\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// AI AGENT PIPELINE - Multi-Step Autonomous Agent using Vercel AI SDK\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n//\n// This pipeline enables the AI to perform multi-step autonomous tasks:\n// 1. Understand the user's intent\n// 2. Plan a sequence of tool calls\n// 3. Execute tools iteratively\n// 4. Synthesize results into a coherent response\n//\n// Uses Vercel AI SDK's `maxSteps` for automatic tool call loops.\n\nimport { generateText, streamText, Output, stepCountIs } from 'ai';\nimport { z } from 'zod';\nimport { buildToolkit, getToolkitDescriptions } from './tools/index.js';\nimport { systemPromptManager } from './system-prompts.js';\nimport { logger } from '../lib/logger.js';\n\n/**\n * Agent execution modes\n */\nexport const AGENT_MODES = {\n  /**\n   * Single-shot: One LLM call, may include tool use\n   * Best for: Simple questions with potential knowledge lookup\n   */\n  singleShot: 'single-shot',\n\n  /**\n   * Multi-step: Multiple LLM calls with tool use\n   * Best for: Complex queries requiring multiple knowledge lookups\n   */\n  multiStep: 'multi-step',\n\n  /**\n   * Researcher: Deep analysis with structured output\n   * Best for: Research questions, analysis tasks\n   */\n  researcher: 'researcher',\n\n  /**\n   * Conversational: Lightweight, fast responses\n   * Best for: Quick chat, casual conversation\n   */\n  conversational: 'conversational',\n};\n\n/**\n * AgentPipeline - Multi-step autonomous agent\n */\nexport class AgentPipeline {\n  constructor() {\n    this.logger = logger.child({ module: 'AgentPipeline' });\n  }\n\n  /**\n   * Execute an agent task with tool access\n   */\n  async execute({\n    model,\n    messages,\n    userId,\n    conversationId = null,\n    mode = 'multi-step',\n    personaId = 'default',\n    contextBundles = [],\n    secondBrainStats = null,\n    customInstructions = '',\n    maxSteps = 8,\n    toolSet = 'full',\n    enableSocial = true,\n    onStepStart = null,\n    onStepComplete = null,\n  }) {\n    const startTime = Date.now();\n    const log = this.logger.child({ userId, mode, personaId });\n\n    // Build tools\n    const tools = buildToolkit({ userId, conversationId, toolSet, enableSocial });\n    const toolDescriptions = getToolkitDescriptions(toolSet);\n\n    // Build system prompt\n    const systemPrompt = systemPromptManager.buildPrompt({\n      mode: conversationId ? 'continuation' : 'fresh',\n      personaId,\n      userId,\n      contextBundles,\n      availableTools: toolDescriptions,\n      secondBrainStats,\n      customInstructions,\n      enableSocial,\n    });\n\n    // Determine max steps based on mode\n    const stepLimits = {\n      'single-shot': 2,\n      'multi-step': maxSteps,\n      researcher: 12,\n      conversational: 1,\n    };\n\n    const effectiveMaxSteps = stepLimits[mode] || maxSteps;\n    const shouldUseTools = mode !== 'conversational';\n\n    // Get persona settings for temperature\n    const personaSettings = systemPromptManager.getPersonaSettings(personaId);\n\n    log.info(\n      {\n        toolCount: Object.keys(tools).length,\n        maxSteps: effectiveMaxSteps,\n        messageCount: messages.length,\n      },\n      'Agent pipeline starting'\n    );\n\n    try {\n      const result = await generateText({\n        model,\n        system: systemPrompt,\n        messages,\n        tools: shouldUseTools ? tools : undefined,\n        maxSteps: effectiveMaxSteps,\n        temperature: personaSettings.temperature,\n        onStepFinish: (step) => {\n          log.debug(\n            {\n              stepType: step.stepType,\n              toolCalls: step.toolCalls?.length || 0,\n              tokensUsed: step.usage?.totalTokens || 0,\n            },\n            'Agent step complete'\n          );\n\n          if (onStepComplete) {\n            onStepComplete(step);\n          }\n        },\n      });\n\n      const duration = Date.now() - startTime;\n\n      log.info(\n        {\n          duration,\n          totalTokens: result.usage?.totalTokens,\n          steps: result.steps?.length || 1,\n          toolCalls: result.steps?.reduce((sum, s) => sum + (s.toolCalls?.length || 0), 0) || 0,\n          finishReason: result.finishReason,\n        },\n        'Agent pipeline complete'\n      );\n\n      return {\n        text: result.text,\n        usage: result.usage,\n        finishReason: result.finishReason,\n        steps: result.steps?.map((s) => ({\n          type: s.stepType,\n          toolCalls: s.toolCalls?.map((tc) => ({\n            name: tc.toolName,\n            args: tc.args,\n            result: tc.result,\n          })),\n          text: s.text,\n          tokens: s.usage?.totalTokens,\n        })),\n        metadata: {\n          mode,\n          personaId,\n          duration,\n          toolsAvailable: Object.keys(tools),\n          toolsUsed:\n            result.steps\n              ?.flatMap((s) => s.toolCalls?.map((tc) => tc.toolName) || [])\n              .filter((v, i, a) => a.indexOf(v) === i) || [],\n        },\n      };\n    } catch (error) {\n      const duration = Date.now() - startTime;\n      log.error({ error: error.message, duration }, 'Agent pipeline failed');\n      throw error;\n    }\n  }\n\n  /**\n   * Execute an agent task with streaming output\n   */\n  async executeStream({\n    model,\n    messages,\n    res,\n    userId,\n    conversationId = null,\n    mode = 'multi-step',\n    personaId = 'default',\n    contextBundles = [],\n    secondBrainStats = null,\n    customInstructions = '',\n    maxSteps = 8,\n    toolSet = 'full',\n    enableSocial = true,\n  }) {\n    const log = this.logger.child({ userId, mode, personaId });\n\n    // Build tools\n    const tools = buildToolkit({ userId, conversationId, toolSet, enableSocial });\n    const toolDescriptions = getToolkitDescriptions(toolSet);\n\n    // Build system prompt\n    const systemPrompt = systemPromptManager.buildPrompt({\n      mode: conversationId ? 'continuation' : 'fresh',\n      personaId,\n      userId,\n      contextBundles,\n      availableTools: toolDescriptions,\n      secondBrainStats,\n      customInstructions,\n      enableSocial,\n    });\n\n    // Mode config\n    const stepLimits = {\n      'single-shot': 2,\n      'multi-step': maxSteps,\n      researcher: 12,\n      conversational: 1,\n    };\n    const effectiveMaxSteps = stepLimits[mode] || maxSteps;\n    const shouldUseTools = mode !== 'conversational';\n    const personaSettings = systemPromptManager.getPersonaSettings(personaId);\n\n    log.info(\n      {\n        toolCount: Object.keys(tools).length,\n        maxSteps: effectiveMaxSteps,\n        streaming: true,\n      },\n      'Agent stream pipeline starting'\n    );\n\n    const result = streamText({\n      model,\n      system: systemPrompt,\n      messages,\n      tools: shouldUseTools ? tools : undefined,\n      maxSteps: effectiveMaxSteps,\n      temperature: personaSettings.temperature,\n      onStepFinish: (step) => {\n        log.debug(\n          {\n            stepType: step.stepType,\n            toolCalls: step.toolCalls?.length || 0,\n          },\n          'Agent stream step complete'\n        );\n      },\n      onFinish: (result) => {\n        log.info(\n          {\n            totalTokens: result.usage?.totalTokens,\n            finishReason: result.finishReason,\n          },\n          'Agent stream pipeline complete'\n        );\n      },\n    });\n\n    // Pipe to Express response using Vercel SDK's built-in method\n    result.pipeDataStreamToResponse(res);\n  }\n\n  /**\n   * Generate structured output using agent + tools + schema\n   */\n  async generateStructured({\n    model,\n    prompt,\n    schema,\n    userId,\n    conversationId = null,\n    toolSet = 'minimal',\n    maxSteps = 5,\n  }) {\n    const tools = buildToolkit({ userId, conversationId, toolSet, enableSocial: false });\n\n    const result = await generateText({\n      model,\n      tools,\n      output: Output.object({ schema }),\n      stopWhen: stepCountIs(maxSteps),\n      prompt,\n    });\n\n    return {\n      output: result.output,\n      usage: result.usage,\n      steps: result.steps?.length || 1,\n    };\n  }\n}\n\n// Singleton\nexport const agentPipeline = new AgentPipeline();\nexport default agentPipeline;\n","usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\ai\\errors.js","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\ai\\middleware\\telemetry.js","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\ai\\providers\\base.js","messages":[{"ruleId":"no-unused-vars","severity":1,"message":"'messages' is defined but never used. Allowed unused args must match /^_/u.","line":28,"column":18,"nodeType":"Identifier","messageId":"unusedVar","endLine":28,"endColumn":26,"suggestions":[{"messageId":"removeVar","data":{"varName":"messages"},"fix":{"range":[767,776],"text":""},"desc":"Remove unused variable 'messages'."}]},{"ruleId":"no-unused-vars","severity":1,"message":"'options' is defined but never used. Allowed unused args must match /^_/u.","line":28,"column":28,"nodeType":"Identifier","messageId":"unusedVar","endLine":28,"endColumn":35,"suggestions":[{"messageId":"removeVar","data":{"varName":"options"},"fix":{"range":[775,784],"text":""},"desc":"Remove unused variable 'options'."}]},{"ruleId":"no-unused-vars","severity":1,"message":"'messages' is defined but never used. Allowed unused args must match /^_/u.","line":36,"column":16,"nodeType":"Identifier","messageId":"unusedVar","endLine":36,"endColumn":24,"suggestions":[{"messageId":"removeVar","data":{"varName":"messages"},"fix":{"range":[944,953],"text":""},"desc":"Remove unused variable 'messages'."}]},{"ruleId":"no-unused-vars","severity":1,"message":"'options' is defined but never used. Allowed unused args must match /^_/u.","line":36,"column":26,"nodeType":"Identifier","messageId":"unusedVar","endLine":36,"endColumn":33,"suggestions":[{"messageId":"removeVar","data":{"varName":"options"},"fix":{"range":[952,961],"text":""},"desc":"Remove unused variable 'options'."}]},{"ruleId":"no-unused-vars","severity":1,"message":"'onChunk' is defined but never used. Allowed unused args must match /^_/u.","line":36,"column":35,"nodeType":"Identifier","messageId":"unusedVar","endLine":36,"endColumn":42,"suggestions":[{"messageId":"removeVar","data":{"varName":"onChunk"},"fix":{"range":[961,970],"text":""},"desc":"Remove unused variable 'onChunk'."}]}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":5,"fixableErrorCount":0,"fixableWarningCount":0,"source":"// apps/server/src/ai/providers/base.js\n\nimport { logger } from '../../lib/logger.js';\nimport { AIError, RateLimitError, AuthenticationError } from '../errors.js';\n\n/**\n * Abstract base class for all AI providers\n * All provider implementations must extend this class\n */\nexport class BaseAIProvider {\n  /**\n   * @param {string} providerType - Provider type identifier\n   * @param {object} config - Provider configuration\n   */\n  constructor(providerType, config) {\n    this.providerType = providerType;\n    this.config = config;\n    this.baseURL = config.baseURL;\n    this.apiKey = config.apiKey;\n    this.defaultModel = config.defaultModel;\n    this.models = config.models;\n  }\n\n  /**\n   * Must be implemented by each provider\n   * @abstract\n   */\n  async complete(messages, options) {\n    throw new Error('complete() must be implemented by subclass');\n  }\n\n  /**\n   * Must be implemented by each provider\n   * @abstract\n   */\n  async stream(messages, options, onChunk) {\n    throw new Error('stream() must be implemented by subclass');\n  }\n\n  /**\n   * Format request headers\n   * Can be overridden by providers\n   */\n  getHeaders() {\n    return {\n      'Content-Type': 'application/json',\n    };\n  }\n\n  /**\n   * Transform messages to provider-specific format\n   * Can be overridden by providers\n   */\n  transformMessages(messages) {\n    return messages;\n  }\n\n  /**\n   * Parse provider response to standard format\n   * Can be overridden by providers\n   */\n  parseResponse(response) {\n    return {\n      content: response.content,\n      model: response.model,\n      usage: response.usage,\n      finishReason: response.finishReason,\n    };\n  }\n\n  /**\n   * Handle provider-specific errors\n   */\n  handleAPIError(error, response) {\n    logger.error(\n      {\n        provider: this.providerType,\n        error: error.message,\n        status: response?.status,\n      },\n      'API request failed'\n    );\n\n    if (response?.status === 401 || response?.status === 403) {\n      throw new AuthenticationError(\n        `Authentication failed for ${this.providerType}. Check API key.`,\n        { provider: this.providerType }\n      );\n    }\n\n    if (response?.status === 429) {\n      throw new RateLimitError(`Rate limit exceeded for ${this.providerType}`, {\n        provider: this.providerType,\n        retryAfter: response.headers?.get('retry-after'),\n      });\n    }\n\n    throw new AIError(`${this.providerType} API error: ${error.message}`, {\n      provider: this.providerType,\n      originalError: error,\n    });\n  }\n\n  /**\n   * Check if provider is healthy\n   */\n  async healthCheck() {\n    // Basic health check: try to fetch models or just return true if baseURL is set\n    // In a real app, we might want a more robust check\n    return !!this.apiKey;\n  }\n}\n","usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\ai\\providers\\zai-provider.js","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\ai\\providers\\zai.js","messages":[{"ruleId":"no-unused-vars","severity":1,"message":"'e' is defined but never used.","line":108,"column":22,"nodeType":"Identifier","messageId":"unusedVar","endLine":108,"endColumn":23},{"ruleId":"no-empty","severity":2,"message":"Empty block statement.","line":108,"column":25,"nodeType":"BlockStatement","messageId":"unexpected","endLine":108,"endColumn":27,"suggestions":[{"messageId":"suggestComment","data":{"type":"block"},"fix":{"range":[2927,2927],"text":" /* empty */ "},"desc":"Add comment inside empty block statement."}]}],"suppressedMessages":[],"errorCount":1,"fatalErrorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":"// apps/server/src/ai/providers/zai.js\n// Z.AI (æ™ºè°±AI) Provider - FREE DEFAULT using centralized config\n\nimport { BaseAIProvider } from './base.js';\nimport { logger } from '../../lib/logger.js';\nimport { ProviderConfig } from '../../types/ai.js';\n\nconst ZAI = ProviderConfig.zai;\n\nexport class ZAIProvider extends BaseAIProvider {\n  constructor() {\n    super('zai', {\n      baseURL: ZAI.baseURL,\n      apiKey: ZAI.apiKey,\n      defaultModel: ZAI.defaultModel,\n    });\n  }\n\n  getHeaders() {\n    return {\n      'Content-Type': 'application/json',\n      Authorization: `Bearer ${this.apiKey}`,\n      'Accept-Language': 'en-US,en',\n    };\n  }\n\n  transformMessages(messages) {\n    return messages.map((msg) => ({ role: msg.role, content: msg.content }));\n  }\n\n  async complete(messages, options = {}) {\n    const {\n      model = this.defaultModel,\n      max_tokens = 4096,\n      temperature = 0.7,\n      thinking_type = 'disabled',\n    } = options;\n\n    logger.info({ model, messageCount: messages.length }, 'ZAI request');\n\n    const response = await fetch(`${this.baseURL}/chat/completions`, {\n      method: 'POST',\n      headers: this.getHeaders(),\n      body: JSON.stringify({\n        model,\n        messages: this.transformMessages(messages),\n        max_tokens,\n        temperature,\n        thinking: { type: thinking_type },\n      }),\n    });\n\n    if (!response.ok) {\n      const error = await response.text();\n      throw new Error(`ZAI ${response.status}: ${error}`);\n    }\n\n    const data = await response.json();\n    return this.parseResponse(data);\n  }\n\n  async stream(messages, options = {}, onChunk) {\n    const {\n      model = this.defaultModel,\n      max_tokens = 4096,\n      temperature = 0.7,\n      thinking_type = 'disabled',\n    } = options;\n\n    const response = await fetch(`${this.baseURL}/chat/completions`, {\n      method: 'POST',\n      headers: this.getHeaders(),\n      body: JSON.stringify({\n        model,\n        messages: this.transformMessages(messages),\n        max_tokens,\n        temperature,\n        stream: true,\n        thinking: { type: thinking_type },\n      }),\n    });\n\n    if (!response.ok) {\n      const error = await response.text();\n      throw new Error(`ZAI ${response.status}: ${error}`);\n    }\n\n    const reader = response.body.getReader();\n    const decoder = new TextDecoder();\n    let buffer = '';\n\n    while (true) {\n      const { done, value } = await reader.read();\n      if (done) {\n        break;\n      }\n      buffer += decoder.decode(value, { stream: true });\n      for (const line of buffer.split('\\n')) {\n        if (line.startsWith('data: ')) {\n          const data = line.slice(6);\n          if (data !== '[DONE]') {\n            try {\n              const parsed = JSON.parse(data);\n              const content = parsed.choices?.[0]?.delta?.content;\n              if (content) {\n                onChunk({ content, done: false });\n              }\n            } catch (e) {}\n          }\n        }\n      }\n    }\n    onChunk({ done: true });\n  }\n\n  parseResponse(data) {\n    const choice = data.choices?.[0];\n    return {\n      content: choice?.message?.content || '',\n      model: data.model,\n      usage: {\n        promptTokens: data.usage?.prompt_tokens || 0,\n        completionTokens: data.usage?.completion_tokens || 0,\n        totalTokens: data.usage?.total_tokens || 0,\n      },\n      finishReason: choice?.finish_reason || 'unknown',\n    };\n  }\n}\n","usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\ai\\system-prompts.js","messages":[{"ruleId":"no-unused-vars","severity":1,"message":"'config' is assigned a value but never used. Allowed unused args must match /^_/u.","line":165,"column":15,"nodeType":"Identifier","messageId":"unusedVar","endLine":165,"endColumn":21,"suggestions":[{"messageId":"removeVar","data":{"varName":"config"},"fix":{"range":[6578,6589],"text":""},"desc":"Remove unused variable 'config'."}]},{"ruleId":"no-unused-vars","severity":1,"message":"'userId' is defined but never used. Allowed unused args must match /^_/u.","line":176,"column":5,"nodeType":"Identifier","messageId":"unusedVar","endLine":176,"endColumn":11,"suggestions":[{"messageId":"removeVar","data":{"varName":"userId"},"fix":{"range":[6869,6881],"text":""},"desc":"Remove unused variable 'userId'."}]}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":2,"fixableErrorCount":0,"fixableWarningCount":0,"source":"// apps/server/src/ai/system-prompts.js\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// SYSTEM PROMPT MANAGER - State-of-the-Art AI Identity & Persona System\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nimport { logger } from '../lib/logger.js';\n\n/**\n * Built-in Persona Templates\n * Users can create custom personas; these are intelligent defaults.\n */\nexport const PERSONAS = {\n  default: {\n    id: 'default',\n    name: 'OpenScroll AI',\n    emoji: 'ðŸ§ ',\n    description: 'Your intelligent second brain assistant',\n    systemPrompt: `You are OpenScroll AI â€” an intelligent second brain assistant that helps users capture, organize, and evolve their knowledge. You have deep context about the user's conversations, knowledge base, and interests.\n\nCORE PRINCIPLES:\n- Be genuinely helpful, not performative\n- Connect dots between the user's existing knowledge\n- Surface relevant context proactively\n- Respect the user's communication style\n- Be concise unless depth is requested`,\n    temperature: 0.7,\n    traits: ['helpful', 'contextual', 'proactive'],\n  },\n\n  researcher: {\n    id: 'researcher',\n    name: 'Research Mode',\n    emoji: 'ðŸ”¬',\n    description: 'Deep analysis and research assistant',\n    systemPrompt: `You are operating in Research Mode â€” a deep analytical assistant focused on thorough investigation, source evaluation, and structured analysis.\n\nRESEARCH PRINCIPLES:\n- Provide well-structured, evidence-based responses\n- Distinguish between facts, analysis, and speculation\n- Cross-reference with the user's existing knowledge base\n- Suggest follow-up research directions\n- Use proper citations and source attribution when available\n- Break complex topics into digestible sections`,\n    temperature: 0.3,\n    traits: ['analytical', 'thorough', 'structured'],\n  },\n\n  creative: {\n    id: 'creative',\n    name: 'Creative Studio',\n    emoji: 'ðŸŽ¨',\n    description: 'Creative ideation and brainstorming',\n    systemPrompt: `You are operating in Creative Studio Mode â€” an imaginative collaborator focused on generating novel ideas, exploring possibilities, and pushing creative boundaries.\n\nCREATIVE PRINCIPLES:\n- Embrace unconventional thinking\n- Build on and remix the user's existing ideas\n- Explore multiple directions before converging\n- Use analogies and metaphors freely\n- Connect disparate concepts from the user's knowledge base\n- Encourage experimentation and iteration`,\n    temperature: 0.9,\n    traits: ['imaginative', 'explorative', 'divergent'],\n  },\n\n  coder: {\n    id: 'coder',\n    name: 'Code Partner',\n    emoji: 'ðŸ’»',\n    description: 'Technical coding and architecture assistant',\n    systemPrompt: `You are operating in Code Partner Mode â€” a senior engineering collaborator with deep expertise across the full stack.\n\nENGINEERING PRINCIPLES:\n- Write clean, idiomatic, production-ready code\n- Explain architectural decisions and trade-offs\n- Consider performance, security, and maintainability\n- Reference relevant patterns from the user's codebase\n- Suggest tests and edge cases\n- Use proper error handling and logging`,\n    temperature: 0.4,\n    traits: ['precise', 'systematic', 'pragmatic'],\n  },\n\n  coach: {\n    id: 'coach',\n    name: 'Strategic Coach',\n    emoji: 'ðŸŽ¯',\n    description: 'Goal-oriented strategic thinking partner',\n    systemPrompt: `You are operating in Strategic Coach Mode â€” a thinking partner focused on clarity, goal-setting, and actionable strategies.\n\nCOACHING PRINCIPLES:\n- Ask clarifying questions before providing solutions\n- Help the user think through problems systematically\n- Break goals into actionable steps with clear milestones\n- Reference past decisions and learnings from knowledge base\n- Challenge assumptions constructively\n- Focus on outcomes over processes`,\n    temperature: 0.5,\n    traits: ['strategic', 'outcome-focused', 'challenging'],\n  },\n};\n\n/**\n * Context-aware system prompt sections\n * These are dynamically composed based on the conversation state\n */\nconst PROMPT_SECTIONS = {\n  /**\n   * Second Brain awareness section - injected when context bundles are present\n   */\n  secondBrainAwareness: (stats) => `\n## Your Knowledge Access\nYou have access to the user's second brain â€” their personal knowledge system containing:\n${stats.topicCount ? `- ${stats.topicCount} tracked topics they care about` : ''}\n${stats.entityCount ? `- ${stats.entityCount} recognized entities (people, projects, tools)` : ''}\n${stats.conversationCount ? `- ${stats.conversationCount} past conversations for reference` : ''}\n${stats.memoryCount ? `- ${stats.memoryCount} extracted knowledge units (ACUs)` : ''}\n\nWhen relevant context from the second brain is provided below, use it naturally in your responses. Reference specific knowledge when it adds value, but don't force connections.`,\n\n  /**\n   * Tool awareness section - injected when tools are available\n   */\n  toolAwareness: (availableTools) => `\n## Available Tools\nYou have access to the following tools. Use them proactively when they would enhance your response:\n${availableTools.map((t) => `- **${t.name}**: ${t.description}`).join('\\n')}\n\nTOOL USAGE GUIDELINES:\n- Use tools when they add genuine value, not performatively\n- You can chain multiple tool calls to build comprehensive answers\n- Always explain what you found and how it connects to the user's question`,\n\n  /**\n   * Conversation continuation context\n   */\n  continuationContext: (convStats) => `\n## Conversation Context\nThis is a continuation of an existing conversation:\n- Messages so far: ${convStats.messageCount || 0}\n- Topics discussed: ${convStats.topics?.join(', ') || 'general'}\n${convStats.summary ? `\\nConversation summary: ${convStats.summary}` : ''}\n\nBuild on the established context naturally. Don't repeat information already covered.`,\n\n  /**\n   * Social/sharing awareness\n   */\n  socialAwareness: () => `\n## Social Sharing\nThe user may choose to share insights from this conversation to their feed. Structure your responses to be shareable â€” use clear formatting, include key takeaways, and create content that others might find valuable.`,\n\n  /**\n   * Fresh chat context\n   */\n  freshChat: () => `\n## Fresh Conversation\nThis is a new conversation with no prior context loaded. Focus on understanding the user's intent and providing immediate value. If you detect they're asking about something that might be in their knowledge base, suggest using the knowledge search tools.`,\n};\n\n/**\n * SystemPromptManager - Composes intelligent system prompts\n */\nexport class SystemPromptManager {\n  constructor(config = {}) {\n    this.customPersonas = new Map();\n    this.logger = logger.child({ module: 'SystemPromptManager' });\n  }\n\n  /**\n   * Build a complete system prompt for a given context\n   */\n  buildPrompt({\n    mode = 'fresh', // 'fresh' | 'continuation' | 'agent'\n    personaId = 'default',\n    userId,\n    contextBundles = [], // Compiled context from DynamicContextAssembler\n    availableTools = [],\n    conversationStats = null,\n    secondBrainStats = null,\n    customInstructions = '',\n    enableSocial = false,\n  }) {\n    const sections = [];\n\n    // 1. Base persona prompt\n    const persona = this.getPersona(personaId);\n    sections.push(persona.systemPrompt);\n\n    // 2. Mode-specific sections\n    if (mode === 'fresh') {\n      sections.push(PROMPT_SECTIONS.freshChat());\n    } else if (mode === 'continuation' && conversationStats) {\n      sections.push(PROMPT_SECTIONS.continuationContext(conversationStats));\n    }\n\n    // 3. Second brain awareness (if user has data)\n    if (secondBrainStats && (secondBrainStats.topicCount > 0 || secondBrainStats.memoryCount > 0)) {\n      sections.push(PROMPT_SECTIONS.secondBrainAwareness(secondBrainStats));\n    }\n\n    // 4. Tool awareness (if tools are available)\n    if (availableTools.length > 0) {\n      sections.push(PROMPT_SECTIONS.toolAwareness(availableTools));\n    }\n\n    // 5. Compiled context bundles (from DynamicContextAssembler)\n    for (const bundle of contextBundles) {\n      if (bundle.compiledPrompt) {\n        sections.push(bundle.compiledPrompt);\n      }\n    }\n\n    // 6. Social sharing awareness\n    if (enableSocial) {\n      sections.push(PROMPT_SECTIONS.socialAwareness());\n    }\n\n    // 7. Custom user instructions (highest priority, goes last)\n    if (customInstructions) {\n      sections.push(`## Custom Instructions\\n${customInstructions}`);\n    }\n\n    const fullPrompt = sections.filter(Boolean).join('\\n\\n---\\n\\n');\n\n    this.logger.debug(\n      {\n        personaId,\n        mode,\n        sectionCount: sections.length,\n        promptLength: fullPrompt.length,\n      },\n      'System prompt composed'\n    );\n\n    return fullPrompt;\n  }\n\n  /**\n   * Get a persona by ID (built-in or custom)\n   */\n  getPersona(id) {\n    if (this.customPersonas.has(id)) {\n      return this.customPersonas.get(id);\n    }\n    return PERSONAS[id] || PERSONAS.default;\n  }\n\n  /**\n   * Register a custom persona\n   */\n  registerPersona(persona) {\n    if (!persona.id || !persona.systemPrompt) {\n      throw new Error('Persona must have id and systemPrompt');\n    }\n    this.customPersonas.set(persona.id, {\n      ...PERSONAS.default,\n      ...persona,\n    });\n    this.logger.info({ personaId: persona.id }, 'Custom persona registered');\n  }\n\n  /**\n   * Get all available personas\n   */\n  getAllPersonas() {\n    const builtIn = Object.values(PERSONAS).map((p) => ({\n      ...p,\n      isBuiltIn: true,\n    }));\n    const custom = Array.from(this.customPersonas.values()).map((p) => ({\n      ...p,\n      isBuiltIn: false,\n    }));\n    return [...builtIn, ...custom];\n  }\n\n  /**\n   * Get persona-specific model settings\n   */\n  getPersonaSettings(personaId) {\n    const persona = this.getPersona(personaId);\n    return {\n      temperature: persona.temperature || 0.7,\n      traits: persona.traits || [],\n      name: persona.name,\n    };\n  }\n}\n\n// Singleton\nexport const systemPromptManager = new SystemPromptManager();\nexport default systemPromptManager;\n","usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\ai\\tools\\index.js","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\ai\\tools\\second-brain-tools.js","messages":[{"ruleId":"no-unused-vars","severity":1,"message":"'depth' is defined but never used. Allowed unused args must match /^_/u.","line":326,"column":30,"nodeType":"Identifier","messageId":"unusedVar","endLine":326,"endColumn":35,"suggestions":[{"messageId":"removeVar","data":{"varName":"depth"},"fix":{"range":[10814,10821],"text":""},"desc":"Remove unused variable 'depth'."}]},{"ruleId":"no-undef","severity":2,"message":"'deep' is not defined.","line":342,"column":19,"nodeType":"Identifier","messageId":"undef","endLine":342,"endColumn":23}],"suppressedMessages":[],"errorCount":1,"fatalErrorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":"// apps/server/src/ai/tools/second-brain-tools.js\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// SECOND BRAIN AI TOOLS - Vercel AI SDK Tool Definitions\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n//\n// These tools give the AI direct access to the user's knowledge system,\n// turning it from a stateless chat into an intelligent second brain.\n\nimport { tool } from 'ai';\nimport { z } from 'zod';\nimport { getPrismaClient } from '../../lib/database.js';\nimport { logger } from '../../lib/logger.js';\n\nconst prisma = getPrismaClient();\n\n/**\n * Search the user's knowledge base (ACUs, memories, conversations)\n */\nexport const searchKnowledge = tool({\n  description:\n    \"Search the user's knowledge base for relevant information. Use this when the user asks about something they might have discussed before, or when you need additional context. Returns relevant knowledge units (ACUs) and conversation snippets.\",\n  parameters: z.object({\n    query: z.string().describe('The search query â€” what to look for in the knowledge base'),\n    type: z\n      .enum(['all', 'conversations', 'acus', 'memories'])\n      .default('all')\n      .describe('Type of knowledge to search'),\n    limit: z.number().min(1).max(20).default(5).describe('Maximum number of results to return'),\n  }),\n  execute: async ({ query, type, limit }, { userId }) => {\n    const log = logger.child({ tool: 'searchKnowledge', userId, query });\n    log.info('Searching knowledge base');\n\n    try {\n      const results = [];\n\n      // Search conversations by title and message content\n      if (type === 'all' || type === 'conversations') {\n        const conversations = await prisma.conversation.findMany({\n          where: {\n            ownerId: userId,\n            OR: [\n              { title: { contains: query, mode: 'insensitive' } },\n              {\n                messages: {\n                  some: {\n                    parts: { path: [], string_contains: query },\n                  },\n                },\n              },\n            ],\n          },\n          select: {\n            id: true,\n            title: true,\n            provider: true,\n            model: true,\n            messageCount: true,\n            createdAt: true,\n            updatedAt: true,\n          },\n          take: Math.min(limit, 5),\n          orderBy: { updatedAt: 'desc' },\n        });\n\n        for (const conv of conversations) {\n          results.push({\n            type: 'conversation',\n            id: conv.id,\n            title: conv.title,\n            messageCount: conv.messageCount,\n            lastActive: conv.updatedAt,\n            source: `${conv.provider}/${conv.model}`,\n          });\n        }\n      }\n\n      // Search ACUs (Atomic Content Units)\n      if (type === 'all' || type === 'acus') {\n        const acus = await prisma.atomicContentUnit.findMany({\n          where: {\n            conversation: { ownerId: userId },\n            OR: [\n              { content: { contains: query, mode: 'insensitive' } },\n              { category: { contains: query, mode: 'insensitive' } },\n            ],\n          },\n          select: {\n            id: true,\n            content: true,\n            type: true,\n            category: true,\n            createdAt: true,\n          },\n          take: Math.min(limit, 10),\n          orderBy: { createdAt: 'desc' },\n        });\n\n        for (const acu of acus) {\n          results.push({\n            type: 'knowledge_unit',\n            id: acu.id,\n            content: acu.content?.substring(0, 300),\n            category: acu.category,\n            unitType: acu.type,\n            createdAt: acu.createdAt,\n          });\n        }\n      }\n\n      // Search topic profiles\n      if (type === 'all' || type === 'memories') {\n        const topics = await prisma.topicProfile.findMany({\n          where: {\n            userId,\n            OR: [\n              { label: { contains: query, mode: 'insensitive' } },\n              { slug: { contains: query, mode: 'insensitive' } },\n            ],\n          },\n          select: {\n            id: true,\n            label: true,\n            slug: true,\n            domain: true,\n            importanceScore: true,\n            totalConversations: true,\n            lastEngagedAt: true,\n          },\n          take: Math.min(limit, 5),\n        });\n\n        for (const topic of topics) {\n          results.push({\n            type: 'topic',\n            id: topic.id,\n            label: topic.label,\n            domain: topic.domain,\n            importance: topic.importanceScore,\n            totalConversations: topic.totalConversations,\n            lastEngaged: topic.lastEngagedAt,\n          });\n        }\n      }\n\n      log.info({ resultCount: results.length }, 'Knowledge search complete');\n\n      return {\n        query,\n        resultCount: results.length,\n        results,\n        suggestion:\n          results.length === 0\n            ? 'No matching knowledge found. This might be a new topic for the user.'\n            : undefined,\n      };\n    } catch (error) {\n      log.error({ error: error.message }, 'Knowledge search failed');\n      return { query, resultCount: 0, results: [], error: error.message };\n    }\n  },\n});\n\n/**\n * Recall full context from a specific conversation\n */\nexport const recallConversation = tool({\n  description:\n    'Recall the full context from a specific past conversation. Use this when you need detailed information from a conversation that was found via search.',\n  parameters: z.object({\n    conversationId: z.string().describe('The conversation ID to recall'),\n    messageLimit: z.number().min(1).max(50).default(20).describe('Max messages to retrieve'),\n  }),\n  execute: async ({ conversationId, messageLimit }, { userId }) => {\n    const log = logger.child({ tool: 'recallConversation', conversationId });\n\n    try {\n      const conversation = await prisma.conversation.findUnique({\n        where: { id: conversationId },\n        include: {\n          messages: {\n            orderBy: { messageIndex: 'asc' },\n            take: messageLimit,\n            select: {\n              role: true,\n              parts: true,\n              messageIndex: true,\n              createdAt: true,\n              author: true,\n            },\n          },\n        },\n      });\n\n      if (!conversation) {\n        return { error: 'Conversation not found' };\n      }\n\n      // Security check\n      if (conversation.ownerId && conversation.ownerId !== userId) {\n        return { error: 'Access denied' };\n      }\n\n      const messages = conversation.messages.map((m) => ({\n        role: m.role,\n        content: Array.isArray(m.parts)\n          ? m.parts.map((p) => p.text || p.content || '').join('')\n          : String(m.parts),\n        author: m.author,\n        index: m.messageIndex,\n      }));\n\n      return {\n        title: conversation.title,\n        provider: conversation.provider,\n        model: conversation.model,\n        messageCount: conversation.messageCount,\n        createdAt: conversation.createdAt,\n        messages,\n      };\n    } catch (error) {\n      log.error({ error: error.message }, 'Conversation recall failed');\n      return { error: error.message };\n    }\n  },\n});\n\n/**\n * Create a new memory/note in the user's second brain\n */\nexport const createMemory = tool({\n  description:\n    \"Save an important insight, decision, or piece of knowledge to the user's second brain. Use this when the conversation produces valuable knowledge that should be remembered.\",\n  parameters: z.object({\n    content: z.string().min(10).max(2000).describe('The knowledge content to save'),\n    category: z\n      .enum([\n        'insight', // Key realization or understanding\n        'decision', // A decision that was made\n        'preference', // User preference discovered\n        'fact', // Factual information\n        'action_item', // Something to do\n        'reference', // Reference material\n      ])\n      .describe('Category of the knowledge unit'),\n    tags: z.array(z.string()).max(5).default([]).describe('Optional tags for organization'),\n    importance: z\n      .enum(['low', 'medium', 'high', 'critical'])\n      .default('medium')\n      .describe('How important this knowledge is'),\n  }),\n  execute: async ({ content, category, tags, importance }, { userId, conversationId }) => {\n    const log = logger.child({ tool: 'createMemory', userId, category });\n\n    try {\n      const importanceScores = { low: 0.25, medium: 0.5, high: 0.75, critical: 1.0 };\n\n      // Create as an ACU if we have a conversation context\n      if (conversationId) {\n        const acu = await prisma.atomicContentUnit.create({\n          data: {\n            conversationId,\n            content,\n            type: 'extraction',\n            category,\n            embedding: new Array(768).fill(0), // Placeholder\n            metadata: { tags, importance, savedByAI: true, createdAt: new Date().toISOString() },\n          },\n        });\n\n        log.info({ acuId: acu.id, category }, 'Memory created as ACU');\n        return {\n          success: true,\n          id: acu.id,\n          message: `Saved to second brain as ${category}: \"${content.substring(0, 50)}...\"`,\n          type: 'acu',\n        };\n      }\n\n      // If no conversation, create as a topic note\n      const topicSlug = tags[0] || category;\n      await prisma.topicProfile.upsert({\n        where: { userId_slug: { userId, slug: topicSlug } },\n        update: {\n          lastEngagedAt: new Date(),\n          totalConversations: { increment: 1 },\n        },\n        create: {\n          userId,\n          slug: topicSlug,\n          label: topicSlug.charAt(0).toUpperCase() + topicSlug.slice(1),\n          domain: 'ai-memory',\n          importanceScore: importanceScores[importance],\n          embedding: new Array(768).fill(0),\n          firstEngagedAt: new Date(),\n          lastEngagedAt: new Date(),\n        },\n      });\n\n      log.info({ category, topicSlug }, 'Memory created as topic');\n      return {\n        success: true,\n        message: `Saved to second brain under topic \"${topicSlug}\": \"${content.substring(0, 50)}...\"`,\n        type: 'topic',\n      };\n    } catch (error) {\n      log.error({ error: error.message }, 'Memory creation failed');\n      return { success: false, error: error.message };\n    }\n  },\n});\n\n/**\n * Find related topics, entities, and conversations\n */\nexport const findRelated = tool({\n  description:\n    \"Find topics, entities, or conversations related to a given concept. Use this to help connect ideas across the user's knowledge base.\",\n  parameters: z.object({\n    concept: z.string().describe('The concept to find relations for'),\n    depth: z\n      .enum(['shallow', 'deep'])\n      .default('shallow')\n      .describe('How deep to search for connections'),\n  }),\n  execute: async ({ concept, depth }, { userId }) => {\n    const log = logger.child({ tool: 'findRelated', userId, concept });\n\n    try {\n      // Find related topics\n      const topics = await prisma.topicProfile.findMany({\n        where: {\n          userId,\n          OR: [\n            { label: { contains: concept, mode: 'insensitive' } },\n            { slug: { contains: concept.toLowerCase(), mode: 'insensitive' } },\n          ],\n        },\n        include: {\n          conversations: {\n            include: { conversation: { select: { id: true, title: true } } },\n            take: deep === 'deep' ? 5 : 2,\n          },\n        },\n        take: 5,\n      });\n\n      // Find related entities\n      const entities = await prisma.entityProfile.findMany({\n        where: {\n          userId,\n          OR: [\n            { name: { contains: concept, mode: 'insensitive' } },\n            { aliases: { has: concept.toLowerCase() } },\n          ],\n        },\n        select: {\n          id: true,\n          name: true,\n          type: true,\n          aliases: true,\n          totalMentions: true,\n        },\n        take: 5,\n      });\n\n      const connections = [];\n\n      for (const topic of topics) {\n        connections.push({\n          type: 'topic',\n          label: topic.label,\n          importance: topic.importanceScore,\n          relatedConversations: topic.conversations.map((tc) => ({\n            id: tc.conversation.id,\n            title: tc.conversation.title,\n          })),\n        });\n      }\n\n      for (const entity of entities) {\n        connections.push({\n          type: 'entity',\n          name: entity.name,\n          entityType: entity.type,\n          aliases: entity.aliases,\n          totalMentions: entity.totalMentions,\n        });\n      }\n\n      log.info({ connectionCount: connections.length }, 'Related items found');\n      return {\n        concept,\n        connectionCount: connections.length,\n        connections,\n      };\n    } catch (error) {\n      log.error({ error: error.message }, 'Find related failed');\n      return { concept, connectionCount: 0, connections: [], error: error.message };\n    }\n  },\n});\n\n/**\n * Summarize and extract key points from text\n */\nexport const extractKeyPoints = tool({\n  description:\n    'Extract and summarize the key points, decisions, and action items from a piece of text or conversation. Use this to help the user distill important information.',\n  parameters: z.object({\n    text: z.string().min(20).describe('The text to extract key points from'),\n    focus: z\n      .enum(['general', 'decisions', 'action_items', 'insights', 'technical'])\n      .default('general')\n      .describe('What aspect to focus the extraction on'),\n  }),\n  execute: async ({ text, focus }) => {\n    // This is a client-side extraction that helps the AI reason about content\n    // The AI itself will process these points, but having them structured helps\n    const wordCount = text.split(/\\s+/).length;\n    const sentences = text.split(/[.!?]+/).filter((s) => s.trim().length > 10);\n    const hasCode = /```[\\s\\S]*?```/.test(text) || /`[^`]+`/.test(text);\n    const hasQuestions = /\\?/.test(text);\n    const hasList = /^[\\s]*[-*â€¢]\\s/m.test(text);\n\n    return {\n      analysis: {\n        wordCount,\n        sentenceCount: sentences.length,\n        hasCode,\n        hasQuestions,\n        hasList,\n        focusArea: focus,\n      },\n      suggestion: `Analyze this ${wordCount}-word text focusing on ${focus}. It ${hasCode ? 'contains code blocks' : 'has no code'}${hasQuestions ? ', includes questions' : ''}${hasList ? ', has list items' : ''}.`,\n    };\n  },\n});\n\n/**\n * Get the user's active topics and interests\n */\nexport const getUserTopics = tool({\n  description:\n    \"Get the user's most active topics and interests from their knowledge base. Use this to understand what the user cares about and to personalize responses.\",\n  parameters: z.object({\n    limit: z.number().min(1).max(20).default(10).describe('Maximum topics to return'),\n    sortBy: z\n      .enum(['importance', 'recent', 'frequency'])\n      .default('recent')\n      .describe('How to sort topics'),\n  }),\n  execute: async ({ limit, sortBy }, { userId }) => {\n    try {\n      const orderBy = {\n        importance: { importanceScore: 'desc' },\n        recent: { lastEngagedAt: 'desc' },\n        frequency: { totalConversations: 'desc' },\n      }[sortBy];\n\n      const topics = await prisma.topicProfile.findMany({\n        where: { userId },\n        select: {\n          label: true,\n          slug: true,\n          domain: true,\n          importanceScore: true,\n          totalConversations: true,\n          lastEngagedAt: true,\n          firstEngagedAt: true,\n        },\n        orderBy,\n        take: limit,\n      });\n\n      return {\n        userId,\n        topicCount: topics.length,\n        topics: topics.map((t) => ({\n          label: t.label,\n          domain: t.domain,\n          importance: t.importanceScore,\n          conversations: t.totalConversations,\n          lastActive: t.lastEngagedAt,\n          tracking_since: t.firstEngagedAt,\n        })),\n      };\n    } catch (error) {\n      return { userId, topicCount: 0, topics: [], error: error.message };\n    }\n  },\n});\n\n/**\n * Build the complete tools object for AI SDK\n */\nexport function buildSecondBrainTools(userId, conversationId = null) {\n  // Create tool context that will be passed to execute functions\n  const toolContext = { userId, conversationId };\n\n  // Wrap tools to inject context\n  const wrapTool = (toolDef) => ({\n    ...toolDef,\n    execute: async (args) => toolDef.execute(args, toolContext),\n  });\n\n  return {\n    searchKnowledge: wrapTool(searchKnowledge),\n    recallConversation: wrapTool(recallConversation),\n    createMemory: wrapTool(createMemory),\n    findRelated: wrapTool(findRelated),\n    extractKeyPoints: wrapTool(extractKeyPoints),\n    getUserTopics: wrapTool(getUserTopics),\n  };\n}\n\n/**\n * Get tool descriptions for system prompt injection\n */\nexport function getToolDescriptions() {\n  return [\n    {\n      name: 'searchKnowledge',\n      description: 'Search across conversations, knowledge units, and topics',\n    },\n    { name: 'recallConversation', description: 'Recall full context from a past conversation' },\n    { name: 'createMemory', description: 'Save insights and decisions to the second brain' },\n    { name: 'findRelated', description: 'Find related topics and entities' },\n    { name: 'extractKeyPoints', description: 'Extract key points from text' },\n    { name: 'getUserTopics', description: \"View the user's active topics and interests\" },\n  ];\n}\n","usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\ai\\tools\\social-tools.js","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\ai\\unified-provider.js","messages":[{"ruleId":"no-unused-vars","severity":1,"message":"'ProviderType' is defined but never used.","line":20,"column":10,"nodeType":"Identifier","messageId":"unusedVar","endLine":20,"endColumn":22,"suggestions":[{"messageId":"removeVar","data":{"varName":"ProviderType"},"fix":{"range":[916,929],"text":""},"desc":"Remove unused variable 'ProviderType'."}]},{"ruleId":"no-unused-vars","severity":1,"message":"'providerApiKey' is defined but never used. Allowed unused args must match /^_/u.","line":76,"column":5,"nodeType":"Identifier","messageId":"unusedVar","endLine":76,"endColumn":19,"suggestions":[{"messageId":"removeVar","data":{"varName":"providerApiKey"},"fix":{"range":[2318,2338],"text":""},"desc":"Remove unused variable 'providerApiKey'."}]},{"ruleId":"no-unused-vars","severity":1,"message":"'providerApiKey' is defined but never used. Allowed unused args must match /^_/u.","line":161,"column":5,"nodeType":"Identifier","messageId":"unusedVar","endLine":161,"endColumn":19,"suggestions":[{"messageId":"removeVar","data":{"varName":"providerApiKey"},"fix":{"range":[4553,4573],"text":""},"desc":"Remove unused variable 'providerApiKey'."}]},{"ruleId":"no-unused-vars","severity":1,"message":"'encoder' is assigned a value but never used.","line":206,"column":13,"nodeType":"Identifier","messageId":"unusedVar","endLine":206,"endColumn":20,"suggestions":[{"messageId":"removeVar","data":{"varName":"encoder"},"fix":{"range":[5907,5941],"text":""},"desc":"Remove unused variable 'encoder'."}]}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":4,"fixableErrorCount":0,"fixableWarningCount":0,"source":"// apps/server/src/ai/unified-provider.js\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// UNIFIED AI PROVIDER - State-of-the-Art Vercel AI SDK Integration\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n//\n// Single entry point for ALL AI operations. Supports:\n// - Multi-provider model routing (OpenAI, Anthropic, Google, xAI, ZAI)\n// - Tool calling with automatic multi-step execution\n// - Structured output generation\n// - Streaming with proper Express integration\n// - Agent pipeline for autonomous tasks\n// - Telemetry and cost tracking\n\nimport { openai } from '@ai-sdk/openai';\nimport { anthropic } from '@ai-sdk/anthropic';\nimport { google } from '@ai-sdk/google';\nimport { xai } from '@ai-sdk/xai';\nimport { zai } from './providers/zai-provider.js';\nimport { generateText, streamText, generateObject, Output, stepCountIs } from 'ai';\nimport { ProviderType, ProviderConfig, getDefaultProvider } from '../types/ai.js';\nimport { logger } from '../lib/logger.js';\nimport { aiTelemetry } from './middleware/telemetry.js';\n\n/**\n * Unified AI Provider - Single entry point for all AI operations using Vercel AI SDK\n */\nclass UnifiedAIProvider {\n  constructor() {\n    this.providerInstances = {\n      openai,\n      anthropic,\n      google,\n      xai,\n      zai,\n    };\n    this.logger = logger.child({ module: 'UnifiedAIProvider' });\n  }\n\n  /**\n   * Get the correct model instance for a provider/model combination\n   */\n  getModel(providerKey, modelId) {\n    const config = ProviderConfig[providerKey];\n    if (!config) {\n      throw new Error(`Unknown provider: ${providerKey}`);\n    }\n\n    const model = modelId || config.defaultModel;\n    const instance = this.providerInstances[providerKey];\n\n    if (!instance) {\n      throw new Error(`Provider ${providerKey} not configured. Missing SDK package or API key.`);\n    }\n\n    // Each Vercel AI SDK provider returns a model reference\n    if (providerKey === 'gemini' || providerKey === 'google') {\n      return google(model);\n    }\n\n    return instance(model);\n  }\n\n  /**\n   * Generate text completion (non-streaming)\n   */\n  async generateCompletion({\n    provider = getDefaultProvider(),\n    model: modelId,\n    messages,\n    system,\n    tools,\n    maxSteps,\n    temperature,\n    maxTokens,\n    userId,\n    providerApiKey,\n  }) {\n    const startTime = Date.now();\n\n    try {\n      const aiModel = this.getModel(provider, modelId);\n\n      const options = {\n        model: aiModel,\n        messages,\n        ...(system && { system }),\n        ...(tools && { tools }),\n        ...(maxSteps && { maxSteps }),\n        ...(temperature !== undefined && { temperature }),\n        ...(maxTokens && { maxTokens }),\n      };\n\n      const result = await generateText(options);\n      const duration = Date.now() - startTime;\n\n      // Record telemetry\n      aiTelemetry.recordRequest({\n        provider,\n        model: modelId || ProviderConfig[provider]?.defaultModel,\n        userId,\n        promptTokens: result.usage?.promptTokens || 0,\n        completionTokens: result.usage?.completionTokens || 0,\n        durationMs: duration,\n        success: true,\n        mode: tools ? 'agent' : 'chat',\n        toolsUsed: result.steps?.flatMap((s) => s.toolCalls?.map((tc) => tc.toolName) || []) || [],\n        steps: result.steps?.length || 1,\n      });\n\n      this.logger.info(\n        {\n          provider,\n          model: modelId,\n          tokens: result.usage?.totalTokens,\n          duration,\n          steps: result.steps?.length || 1,\n        },\n        'Completion generated'\n      );\n\n      return {\n        text: result.text,\n        usage: result.usage,\n        finishReason: result.finishReason,\n        steps: result.steps,\n        toolCalls: result.steps?.flatMap((s) => s.toolCalls || []),\n        toolResults: result.steps?.flatMap((s) => s.toolResults || []),\n      };\n    } catch (error) {\n      const duration = Date.now() - startTime;\n      aiTelemetry.recordRequest({\n        provider,\n        model: modelId,\n        userId,\n        durationMs: duration,\n        success: false,\n      });\n\n      this.logger.error(\n        { provider, model: modelId, error: error.message, duration },\n        'Completion failed'\n      );\n      throw this._normalizeError(error, provider);\n    }\n  }\n\n  /**\n   * Stream text completion to Express response\n   */\n  async streamCompletion({\n    provider = getDefaultProvider(),\n    model: modelId,\n    messages,\n    system,\n    tools,\n    maxSteps,\n    temperature,\n    maxTokens,\n    userId,\n    res,\n    providerApiKey,\n  }) {\n    const startTime = Date.now();\n\n    try {\n      const aiModel = this.getModel(provider, modelId);\n\n      const options = {\n        model: aiModel,\n        messages,\n        ...(system && { system }),\n        ...(tools && { tools }),\n        ...(maxSteps && { maxSteps }),\n        ...(temperature !== undefined && { temperature }),\n        ...(maxTokens && { maxTokens }),\n        onFinish: (result) => {\n          const duration = Date.now() - startTime;\n          aiTelemetry.recordRequest({\n            provider,\n            model: modelId || ProviderConfig[provider]?.defaultModel,\n            userId,\n            promptTokens: result.usage?.promptTokens || 0,\n            completionTokens: result.usage?.completionTokens || 0,\n            durationMs: duration,\n            success: true,\n            mode: tools ? 'agent-stream' : 'stream',\n            toolsUsed:\n              result.steps?.flatMap((s) => s.toolCalls?.map((tc) => tc.toolName) || []) || [],\n            steps: result.steps?.length || 1,\n          });\n\n          this.logger.info(\n            {\n              provider,\n              model: modelId,\n              tokens: result.usage?.totalTokens,\n              duration,\n            },\n            'Stream completed'\n          );\n        },\n      };\n\n      const result = streamText(options);\n\n      const encoder = new TextEncoder();\n\n      function formatSSE(text) {\n        return `data: ${JSON.stringify({ content: text })}\\n\\n`;\n      }\n\n      res.writeHead(200, {\n        'Content-Type': 'text/event-stream',\n        'Cache-Control': 'no-cache',\n        Connection: 'keep-alive',\n      });\n\n      for await (const chunk of result.textStream) {\n        res.write(formatSSE(chunk));\n      }\n\n      res.write('data: [DONE]\\n\\n');\n      res.end();\n\n      return result;\n    } catch (error) {\n      this.logger.error({ provider, model: modelId, error: error.message }, 'Stream failed');\n      throw this._normalizeError(error, provider);\n    }\n  }\n\n  /**\n   * Generate structured output (JSON object matching a Zod schema)\n   */\n  async generateStructuredOutput({\n    provider = getDefaultProvider(),\n    model: modelId,\n    schema,\n    prompt,\n    messages,\n    system,\n    tools,\n    maxSteps,\n    temperature,\n    userId,\n  }) {\n    const startTime = Date.now();\n\n    try {\n      const aiModel = this.getModel(provider, modelId);\n\n      // If tools are provided, use generateText with Output.object\n      if (tools && Object.keys(tools).length > 0) {\n        const result = await generateText({\n          model: aiModel,\n          tools,\n          output: Output.object({ schema }),\n          stopWhen: stepCountIs(maxSteps || 5),\n          ...(prompt && { prompt }),\n          ...(messages && { messages }),\n          ...(system && { system }),\n          ...(temperature !== undefined && { temperature }),\n        });\n\n        const duration = Date.now() - startTime;\n        aiTelemetry.recordRequest({\n          provider,\n          model: modelId,\n          userId,\n          promptTokens: result.usage?.promptTokens || 0,\n          completionTokens: result.usage?.completionTokens || 0,\n          durationMs: duration,\n          success: true,\n          mode: 'structured+tools',\n        });\n\n        return { output: result.output, usage: result.usage };\n      }\n\n      // Without tools, use generateObject directly\n      const result = await generateObject({\n        model: aiModel,\n        schema,\n        ...(prompt && { prompt }),\n        ...(messages && { messages }),\n        ...(system && { system }),\n        ...(temperature !== undefined && { temperature }),\n      });\n\n      const duration = Date.now() - startTime;\n      aiTelemetry.recordRequest({\n        provider,\n        model: modelId,\n        userId,\n        promptTokens: result.usage?.promptTokens || 0,\n        completionTokens: result.usage?.completionTokens || 0,\n        durationMs: duration,\n        success: true,\n        mode: 'structured',\n      });\n\n      return { output: result.object, usage: result.usage };\n    } catch (error) {\n      this.logger.error(\n        { provider, model: modelId, error: error.message },\n        'Structured output failed'\n      );\n      throw this._normalizeError(error, provider);\n    }\n  }\n\n  /**\n   * Get a model instance for external use (e.g., by AgentPipeline)\n   */\n  resolveModel(provider, modelId) {\n    return this.getModel(provider || getDefaultProvider(), modelId);\n  }\n\n  /**\n   * Get available providers and their status\n   */\n  getProviderStatus() {\n    const status = {};\n    for (const [id, config] of Object.entries(ProviderConfig)) {\n      status[id] = {\n        displayName: config.displayName,\n        models: config.models,\n        defaultModel: config.defaultModel,\n        isFree: config.isFree || false,\n        isAvailable: this._isProviderAvailable(id),\n        capabilities: config.capabilities || [],\n        description: config.description || '',\n      };\n    }\n    return status;\n  }\n\n  /**\n   * Check if a provider has its required API key configured\n   */\n  _isProviderAvailable(providerId) {\n    const envKeys = {\n      openai: 'OPENAI_API_KEY',\n      anthropic: 'ANTHROPIC_API_KEY',\n      gemini: 'GOOGLE_GENERATIVE_AI_API_KEY',\n      google: 'GOOGLE_GENERATIVE_AI_API_KEY',\n      xai: 'XAI_API_KEY',\n      qwen: 'QWEN_API_KEY',\n      moonshot: 'MOONSHOT_API_KEY',\n      minimax: 'MINIMAX_API_KEY',\n      zai: 'ZAI_API_KEY',\n    };\n\n    const envKey = envKeys[providerId];\n    if (!envKey) {\n      return false;\n    }\n\n    // ZAI always available (free default)\n    if (providerId === 'zai') {\n      return true;\n    }\n\n    return !!process.env[envKey];\n  }\n\n  /**\n   * Normalize provider errors into consistent format\n   */\n  _normalizeError(error, provider) {\n    const message = error.message || 'Unknown AI error';\n\n    if (\n      message.includes('401') ||\n      message.includes('Unauthorized') ||\n      message.includes('Invalid API Key')\n    ) {\n      const err = new Error(`Authentication failed for ${provider}. Check your API key.`);\n      err.statusCode = 401;\n      err.provider = provider;\n      return err;\n    }\n\n    if (message.includes('429') || message.includes('Rate limit') || message.includes('quota')) {\n      const err = new Error(`Rate limit exceeded for ${provider}. Please try again later.`);\n      err.statusCode = 429;\n      err.provider = provider;\n      return err;\n    }\n\n    if (\n      message.includes('timeout') ||\n      message.includes('ECONNREFUSED') ||\n      message.includes('ENOTFOUND')\n    ) {\n      const err = new Error(`Cannot reach ${provider}. Network error.`);\n      err.statusCode = 503;\n      err.provider = provider;\n      return err;\n    }\n\n    const err = new Error(message);\n    err.statusCode = error.statusCode || 500;\n    err.provider = provider;\n    return err;\n  }\n}\n\n// Singleton\nexport const unifiedProvider = new UnifiedAIProvider();\nexport default unifiedProvider;\n","usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\capture-playwright.js","messages":[{"ruleId":"no-unused-vars","severity":1,"message":"'e' is defined but never used.","line":142,"column":12,"nodeType":"Identifier","messageId":"unusedVar","endLine":142,"endColumn":13}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * Playwright-based HTML Capture (Queue Managed)\n *\n * Routes capture requests through a concurrency-limited queue to prevent\n * server overload when handling multiple requests (e.g. 1000 links).\n * Spawns isolated Node.js workers for actual browser automation.\n */\n\nimport { spawn } from 'child_process';\nimport path from 'path';\nimport { fileURLToPath } from 'url';\nimport { logger } from './lib/logger.js';\n\nconst __filename = fileURLToPath(import.meta.url);\nconst __dirname = path.dirname(__filename);\n\n// CONFIGURATION\nconst MAX_CONCURRENT_CAPTURES = 2; // Keep low to prevent OOM\nconst WORKER_SCRIPT = path.join(__dirname, 'playwright-worker.js');\n\nclass CaptureQueue {\n  constructor(concurrency) {\n    this.concurrency = concurrency;\n    this.active = 0;\n    this.queue = [];\n  }\n\n  /**\n   * Add a capture task to the queue\n   * @param {Object} jobData - Data needed for the worker\n   * @returns {Promise<string>} - Resolves with result path\n   */\n  add(jobData) {\n    return new Promise((resolve, reject) => {\n      this.queue.push({\n        data: jobData,\n        resolve,\n        reject,\n        queuedAt: Date.now(),\n      });\n      this.processNext();\n    });\n  }\n\n  async processNext() {\n    if (this.active >= this.concurrency || this.queue.length === 0) {\n      return;\n    }\n\n    this.active++;\n    const job = this.queue.shift();\n    const { url, provider } = job.data;\n\n    const log = logger.child({\n      url,\n      provider,\n      queueSize: this.queue.length,\n      activeWorkers: this.active,\n    });\n\n    log.info('Starting capture job from queue');\n\n    try {\n      const resultPath = await this.executeWorker(job.data, log);\n      job.resolve(resultPath);\n    } catch (error) {\n      log.error({ error: error.message }, 'Capture job failed');\n      job.reject(error);\n    } finally {\n      this.active--;\n      this.processNext();\n    }\n  }\n\n  executeWorker(config, log) {\n    return new Promise((resolve, reject) => {\n      const child = spawn('node', [WORKER_SCRIPT, JSON.stringify(config)], {\n        stdio: ['ignore', 'pipe', 'inherit'], // Pipe stdout to capture result JSON\n        cwd: process.cwd(),\n        env: { ...process.env },\n      });\n\n      let stdoutData = '';\n\n      child.stdout.on('data', (data) => {\n        stdoutData += data.toString();\n      });\n\n      child.on('error', (err) => {\n        reject(new Error(`Failed to spawn worker: ${err.message}`));\n      });\n\n      child.on('close', (code) => {\n        if (code !== 0) {\n          return reject(new Error(`Worker exited with code ${code}`));\n        }\n\n        try {\n          // Parse the last line of stdout for JSON result\n          const lines = stdoutData.trim().split('\\n');\n          const lastLine = lines[lines.length - 1];\n          const result = JSON.parse(lastLine);\n\n          if (result.status === 'success') {\n            resolve(result.path);\n          } else {\n            reject(new Error(result.message || 'Unknown worker error'));\n          }\n        } catch (e) {\n          // Check if stdout contains useful error info before failing\n          log.warn({ stdout: stdoutData }, 'Worker stdout parse failed');\n          reject(new Error(`Failed to parse worker output: ${e.message}`));\n        }\n      });\n    });\n  }\n}\n\n// Global Singleton Queue\nconst captureQueue = new CaptureQueue(MAX_CONCURRENT_CAPTURES);\n\n/**\n * Capture a URL using the queue system\n */\nexport async function captureWithPlaywright(url, provider, options = {}) {\n  // Pass all options to the worker\n  const jobConfig = {\n    url,\n    provider,\n    ...options,\n  };\n\n  logger.info({ url, queueLength: captureQueue.queue.length }, 'Queueing capture request');\n  return captureQueue.add(jobConfig);\n}\n\nexport async function cleanupPlaywrightFile(filePath) {\n  // Existing cleanup logic\n  try {\n    const fs = await import('fs/promises');\n    await fs.unlink(filePath);\n  } catch (e) {\n    // ignore\n  }\n}\n","usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\capture.js","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\config\\index.js","messages":[{"ruleId":"no-unused-vars","severity":1,"message":"'e' is defined but never used.","line":85,"column":16,"nodeType":"Identifier","messageId":"unusedVar","endLine":85,"endColumn":17},{"ruleId":"no-unused-vars","severity":1,"message":"'e' is defined but never used.","line":100,"column":18,"nodeType":"Identifier","messageId":"unusedVar","endLine":100,"endColumn":19}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":2,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * Configuration Management\n */\n\nimport { z } from 'zod';\n\nconst configSchema = z.object({\n  nodeEnv: z.enum(['development', 'production', 'test']).default('development'),\n  port: z.number().min(1).max(65535).default(3000),\n  trustProxy: z.boolean().default(false),\n  logLevel: z.enum(['debug', 'info', 'warn', 'error']).default('info'),\n  logFormat: z.enum(['json', 'pretty']).default('json'),\n  corsOrigins: z.array(z.string()).default(['*']),\n  rateLimitMax: z.number().min(1).default(100),\n  databaseUrl: z.string().optional(),\n  shutdownTimeout: z.number().min(1000).default(30000),\n  enableSwagger: z.boolean().default(false),\n  browserWsEndpoint: z.string().optional(),\n  skipAuthForDevelopment: z.boolean().default(false),\n  // P2P Configuration\n  p2pListenAddresses: z.array(z.string()).default(['/ip4/0.0.0.0/tcp/4001']),\n  p2pBootstrapPeers: z.array(z.string()).default([]),\n});\n\nfunction loadConfig() {\n  const rawConfig = {\n    nodeEnv: process.env.NODE_ENV,\n    port: process.env.PORT ? parseInt(process.env.PORT, 10) : undefined,\n    trustProxy: process.env.TRUST_PROXY === 'true',\n    logLevel: process.env.LOG_LEVEL,\n    logFormat: process.env.LOG_FORMAT,\n    corsOrigins: process.env.CORS_ORIGINS?.split(',').map((s) => s.trim()),\n    rateLimitMax: process.env.RATE_LIMIT_MAX ? parseInt(process.env.RATE_LIMIT_MAX, 10) : undefined,\n    databaseUrl: process.env.DATABASE_URL,\n    shutdownTimeout: process.env.SHUTDOWN_TIMEOUT\n      ? parseInt(process.env.SHUTDOWN_TIMEOUT, 10)\n      : undefined,\n    enableSwagger: process.env.ENABLE_SWAGGER === 'true',\n    browserWsEndpoint: process.env.BROWSER_WS_ENDPOINT,\n    skipAuthForDevelopment:\n      process.env.SKIP_AUTH_FOR_DEVELOPMENT === 'true' || process.env.NODE_ENV === 'test',\n    // P2P Configuration\n    p2pListenAddresses: process.env.P2P_LISTEN_ADDRESSES\n      ? process.env.P2P_LISTEN_ADDRESSES.split(',').map((s) => s.trim())\n      : undefined,\n    p2pBootstrapPeers: process.env.P2P_BOOTSTRAP_PEERS\n      ? process.env.P2P_BOOTSTRAP_PEERS.split(',')\n          .map((s) => s.trim())\n          .filter((s) => s)\n      : undefined,\n  };\n  return configSchema.parse(rawConfig);\n}\n\nexport const config = loadConfig();\nexport const isDevelopment = config.nodeEnv === 'development';\nexport const isProduction = config.nodeEnv === 'production';\nexport const isTest = config.nodeEnv === 'test';\nconfig.isDevelopment = isDevelopment;\nconfig.isProduction = isProduction;\nconfig.isTest = isTest;\n\nexport function validateConfig() {\n  const errors = [];\n\n  // Production-specific validations\n  if (isProduction) {\n    // Database URL validation\n    if (!config.databaseUrl) {\n      errors.push('DATABASE_URL is required in production');\n    } else {\n      // Validate database URL format and security\n      try {\n        const dbUrl = new URL(config.databaseUrl);\n        if (dbUrl.protocol !== 'postgresql:' && dbUrl.protocol !== 'postgres:') {\n          errors.push('DATABASE_URL must use postgresql: or postgres: protocol in production');\n        }\n        // Check if SSL is enabled for production\n        if (\n          !config.databaseUrl.includes('sslmode=require') &&\n          !config.databaseUrl.includes('ssl=true')\n        ) {\n          console.warn('WARNING: SSL is not enabled for database connection in production');\n        }\n      } catch (e) {\n        errors.push('DATABASE_URL is not a valid URL format');\n      }\n    }\n\n    // CORS validation\n    if (!config.corsOrigins || config.corsOrigins.length === 0) {\n      errors.push('CORS_ORIGINS must be specified in production');\n    } else if (config.corsOrigins.includes('*')) {\n      errors.push('CORS_ORIGINS should be specific origins, not wildcard (*) in production');\n    } else {\n      // Validate each origin is a proper URL\n      for (const origin of config.corsOrigins) {\n        try {\n          new URL(origin);\n        } catch (e) {\n          errors.push(`Invalid CORS origin URL: ${origin}`);\n        }\n      }\n    }\n\n    // Security validations\n    if (config.enableSwagger) {\n      console.warn(\n        'WARNING: Swagger UI is enabled in production. This may expose API documentation publicly.'\n      );\n    }\n\n    // Session secret validation\n    if (!process.env.SESSION_SECRET) {\n      errors.push('SESSION_SECRET environment variable is required in production');\n    } else if (process.env.SESSION_SECRET.length < 32) {\n      errors.push('SESSION_SECRET must be at least 32 characters for production');\n    }\n\n    // Rate limiting should be more restrictive in production\n    if (config.rateLimitMax > 1000) {\n      console.warn(\n        'WARNING: Rate limit is set very high for production. Consider reducing RATE_LIMIT_MAX.'\n      );\n    }\n\n    // Log level validation\n    if (config.logLevel === 'debug') {\n      console.warn(\n        'WARNING: Debug logging is enabled in production. This may expose sensitive information.'\n      );\n    }\n  }\n\n  // Development-specific validations\n  if (isDevelopment) {\n    if (config.rateLimitMax < 100) {\n      console.warn('INFO: Rate limit is low for development. Consider increasing RATE_LIMIT_MAX.');\n    }\n  }\n\n  if (errors.length > 0) {\n    throw new Error(`Configuration validation failed: ${errors.join(', ')}`);\n  }\n  return true;\n}\n\nexport default config;\n","usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\container\\index.js","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\context\\isolated-context-engine.js","messages":[{"ruleId":"no-unused-vars","severity":1,"message":"'getUserDbPath' is defined but never used.","line":8,"column":25,"nodeType":"Identifier","messageId":"unusedVar","endLine":8,"endColumn":38,"suggestions":[{"messageId":"removeVar","data":{"varName":"getUserDbPath"},"fix":{"range":[200,215],"text":""},"desc":"Remove unused variable 'getUserDbPath'."}]},{"ruleId":"no-unused-vars","severity":1,"message":"'maxTokens' is assigned a value but never used.","line":320,"column":7,"nodeType":"Identifier","messageId":"unusedVar","endLine":320,"endColumn":16,"suggestions":[{"messageId":"removeVar","data":{"varName":"maxTokens"},"fix":{"range":[7592,7616],"text":""},"desc":"Remove unused variable 'maxTokens'."}]}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":2,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * Isolated Context Engine\n *\n * Provides 100% isolated context engine instances per user.\n * Each user gets their own context engine that only accesses their database.\n */\n\nimport { getUserClient, getUserDbPath } from '../lib/user-database-manager.js';\nimport { logger } from '../lib/logger.js';\nimport crypto from 'crypto';\n\nconst log = logger.child({ module: 'isolated-context-engine' });\n\n/**\n * Create an isolated context engine for a specific user\n */\nexport class IsolatedContextEngine {\n  constructor(userDid) {\n    this.userDid = userDid;\n    this.userDb = null;\n    this.initialized = false;\n  }\n\n  /**\n   * Initialize the context engine for the user\n   */\n  async initialize() {\n    if (this.initialized) {\n      return this;\n    }\n\n    try {\n      this.userDb = await getUserClient(this.userDid);\n      this.initialized = true;\n      log.info({ userDid: this.userDid }, 'IsolatedContextEngine initialized');\n    } catch (error) {\n      log.error(\n        { userDid: this.userDid, error: error.message },\n        'Failed to initialize IsolatedContextEngine'\n      );\n      throw error;\n    }\n\n    return this;\n  }\n\n  /**\n   * Ensure the engine is initialized\n   */\n  async ensureInitialized() {\n    if (!this.initialized) {\n      await this.initialize();\n    }\n  }\n\n  /**\n   * Get topic profiles for the user\n   */\n  async getTopicProfiles() {\n    await this.ensureInitialized();\n\n    return this.userDb.topicProfile.findMany({\n      where: { userId: this.userDid },\n      orderBy: { mentionCount: 'desc' },\n    });\n  }\n\n  /**\n   * Get entity profiles for the user\n   */\n  async getEntityProfiles() {\n    await this.ensureInitialized();\n\n    return this.userDb.entityProfile.findMany({\n      where: { userId: this.userDid },\n      orderBy: { mentionCount: 'desc' },\n    });\n  }\n\n  /**\n   * Get context bundles for the user\n   */\n  async getContextBundles() {\n    await this.ensureInitialized();\n\n    return this.userDb.contextBundle.findMany({\n      where: { userId: this.userDid },\n      orderBy: { lastUsedAt: 'desc' },\n    });\n  }\n\n  /**\n   * Get conversations for the user\n   */\n  async getConversations(options = {}) {\n    await this.ensureInitialized();\n    const { limit = 20, offset = 0 } = options;\n\n    return this.userDb.conversation.findMany({\n      where: { ownerId: this.userDid },\n      take: limit,\n      skip: offset,\n      orderBy: { createdAt: 'desc' },\n      include: { messages: true },\n    });\n  }\n\n  /**\n   * Get memories for the user\n   */\n  async getMemories(options = {}) {\n    await this.ensureInitialized();\n    const { limit = 50 } = options;\n\n    return this.userDb.memory.findMany({\n      where: { userId: this.userDid },\n      take: limit,\n      orderBy: { createdAt: 'desc' },\n    });\n  }\n\n  /**\n   * Get notebooks for the user\n   */\n  async getNotebooks() {\n    await this.ensureInitialized();\n\n    return this.userDb.notebook.findMany({\n      where: { userId: this.userDid },\n      orderBy: { updatedAt: 'desc' },\n    });\n  }\n\n  /**\n   * Get user context settings\n   */\n  async getContextSettings() {\n    await this.ensureInitialized();\n\n    return this.userDb.userContextSettings.findUnique({\n      where: { userId: this.userDid },\n    });\n  }\n\n  /**\n   * Update user context settings\n   */\n  async updateContextSettings(settings) {\n    await this.ensureInitialized();\n\n    return this.userDb.userContextSettings.upsert({\n      where: { userId: this.userDid },\n      create: {\n        userId: this.userDid,\n        ...settings,\n      },\n      update: settings,\n    });\n  }\n\n  /**\n   * Create a topic profile\n   */\n  async createTopicProfile(topicData) {\n    await this.ensureInitialized();\n\n    return this.userDb.topicProfile.create({\n      data: {\n        id: crypto.randomUUID(),\n        userId: this.userDid,\n        topic: topicData.topic,\n        mentionCount: 1,\n        lastMentionedAt: new Date(),\n        firstMentionedAt: new Date(),\n        confidence: topicData.confidence || 0.5,\n        relatedTopics: topicData.relatedTopics || [],\n        keyInsights: topicData.keyInsights || [],\n        associatedAcuIds: topicData.associatedAcuIds || [],\n      },\n    });\n  }\n\n  /**\n   * Create an entity profile\n   */\n  async createEntityProfile(entityData) {\n    await this.ensureInitialized();\n\n    return this.userDb.entityProfile.create({\n      data: {\n        id: crypto.randomUUID(),\n        userId: this.userDid,\n        name: entityData.name,\n        type: entityData.type,\n        mentionCount: 1,\n        lastMentionedAt: new Date(),\n        firstMentionedAt: new Date(),\n        confidence: entityData.confidence || 0.5,\n        description: entityData.description,\n        relationships: entityData.relationships || [],\n        associatedAcuIds: entityData.associatedAcuIds || [],\n      },\n    });\n  }\n\n  /**\n   * Create a context bundle\n   */\n  async createContextBundle(bundleData) {\n    await this.ensureInitialized();\n\n    return this.userDb.contextBundle.create({\n      data: {\n        id: crypto.randomUUID(),\n        userId: this.userDid,\n        name: bundleData.name,\n        description: bundleData.description,\n        topicIds: bundleData.topicIds || [],\n        entityIds: bundleData.entityIds || [],\n        acuIds: bundleData.acuIds || [],\n        bundleType: bundleData.bundleType || 'manual',\n        content: bundleData.content,\n        tokenCount: bundleData.tokenCount,\n        compiledAt: new Date(),\n        isDefault: bundleData.isDefault || false,\n      },\n    });\n  }\n\n  /**\n   * Update topic profile\n   */\n  async updateTopicProfile(topicId, data) {\n    await this.ensureInitialized();\n\n    return this.userDb.topicProfile.update({\n      where: { id: topicId },\n      data: {\n        ...data,\n        lastMentionedAt: new Date(),\n        updatedAt: new Date(),\n      },\n    });\n  }\n\n  /**\n   * Create a memory\n   */\n  async createMemory(memoryData) {\n    await this.ensureInitialized();\n\n    return this.userDb.memory.create({\n      data: {\n        id: crypto.randomUUID(),\n        userId: this.userDid,\n        content: memoryData.content,\n        memoryType: memoryData.memoryType || 'general',\n        importance: memoryData.importance || 50,\n        recency: memoryData.recency || 0,\n        sourceAcuIds: memoryData.sourceAcuIds || [],\n        sourceConversationIds: memoryData.sourceConversationIds || [],\n      },\n    });\n  }\n\n  /**\n   * Create a notebook\n   */\n  async createNotebook(notebookData) {\n    await this.ensureInitialized();\n\n    return this.userDb.notebook.create({\n      data: {\n        id: crypto.randomUUID(),\n        userId: this.userDid,\n        name: notebookData.name,\n        description: notebookData.description,\n        color: notebookData.color,\n        icon: notebookData.icon,\n      },\n    });\n  }\n\n  /**\n   * Add entry to notebook\n   */\n  async addNotebookEntry(notebookId, entryData) {\n    await this.ensureInitialized();\n\n    const entry = await this.userDb.notebookEntry.create({\n      data: {\n        id: crypto.randomUUID(),\n        notebookId,\n        userId: this.userDid,\n        title: entryData.title,\n        content: entryData.content,\n        sourceAcuId: entryData.sourceAcuId,\n        sourceConversationId: entryData.sourceConversationId,\n      },\n    });\n\n    await this.userDb.notebook.update({\n      where: { id: notebookId },\n      data: { entryCount: { increment: 1 } },\n    });\n\n    return entry;\n  }\n\n  /**\n   * Compile context for a conversation\n   */\n  async compileContext(conversationId, options = {}) {\n    await this.ensureInitialized();\n\n    const {\n      includeTopics = true,\n      includeEntities = true,\n      includeBundles = true,\n      maxTokens = 4000,\n    } = options;\n\n    const context = {\n      topics: [],\n      entities: [],\n      bundles: [],\n      memories: [],\n    };\n\n    if (includeTopics) {\n      context.topics = await this.getTopicProfiles();\n    }\n\n    if (includeEntities) {\n      context.entities = await this.getEntityProfiles();\n    }\n\n    if (includeBundles) {\n      context.bundles = await this.getContextBundles();\n    }\n\n    context.memories = await this.getMemories({ limit: 10 });\n\n    return context;\n  }\n\n  /**\n   * Get ACUs for context\n   */\n  async getACUs(options = {}) {\n    await this.ensureInitialized();\n    const { limit = 50, type, category } = options;\n\n    const where = {};\n    if (type) {\n      where.type = type;\n    }\n    if (category) {\n      where.category = category;\n    }\n\n    return this.userDb.atomicChatUnit.findMany({\n      where,\n      take: limit,\n      orderBy: { qualityOverall: 'desc' },\n    });\n  }\n\n  /**\n   * Get user statistics\n   */\n  async getStats() {\n    await this.ensureInitialized();\n\n    const [\n      conversationCount,\n      acuCount,\n      topicCount,\n      entityCount,\n      bundleCount,\n      memoryCount,\n      notebookCount,\n    ] = await Promise.all([\n      this.userDb.conversation.count(),\n      this.userDb.atomicChatUnit.count(),\n      this.userDb.topicProfile.count(),\n      this.userDb.entityProfile.count(),\n      this.userDb.contextBundle.count(),\n      this.userDb.memory.count(),\n      this.userDb.notebook.count(),\n    ]);\n\n    return {\n      conversations: conversationCount,\n      acus: acuCount,\n      topics: topicCount,\n      entities: entityCount,\n      bundles: bundleCount,\n      memories: memoryCount,\n      notebooks: notebookCount,\n    };\n  }\n\n  /**\n   * Disconnect the user database\n   */\n  async disconnect() {\n    if (this.userDb) {\n      await this.userDb.$disconnect();\n      this.userDb = null;\n      this.initialized = false;\n      log.info({ userDid: this.userDid }, 'IsolatedContextEngine disconnected');\n    }\n  }\n}\n\n/**\n * Create an isolated context engine for a user\n */\nexport async function createIsolatedContextEngine(userDid) {\n  const engine = new IsolatedContextEngine(userDid);\n  await engine.initialize();\n  return engine;\n}\n\nexport default {\n  IsolatedContextEngine,\n  createIsolatedContextEngine,\n};\n","usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\context\\unified-context-service.js","messages":[{"ruleId":"no-unused-vars","severity":1,"message":"'createUserContextSystem' is defined but never used.","line":7,"column":32,"nodeType":"Identifier","messageId":"unusedVar","endLine":7,"endColumn":55,"suggestions":[{"messageId":"removeVar","data":{"varName":"createUserContextSystem"},"fix":{"range":[144,169],"text":""},"desc":"Remove unused variable 'createUserContextSystem'."}]},{"ruleId":"no-unused-vars","severity":1,"message":"'log' is assigned a value but never used.","line":10,"column":7,"nodeType":"Identifier","messageId":"unusedVar","endLine":10,"endColumn":10,"suggestions":[{"messageId":"removeVar","data":{"varName":"log"},"fix":{"range":[249,313],"text":""},"desc":"Remove unused variable 'log'."}]},{"ruleId":"no-unused-vars","severity":1,"message":"'userDid' is assigned a value but never used.","line":201,"column":15,"nodeType":"Identifier","messageId":"unusedVar","endLine":201,"endColumn":22,"suggestions":[{"messageId":"removeVar","data":{"varName":"userDid"},"fix":{"range":[5214,5221],"text":""},"desc":"Remove unused variable 'userDid'."}]}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":3,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * Unified Context Service\n *\n * Provides context compilation using the isolated per-user context system.\n */\n\nimport { getUserContextSystem, createUserContextSystem } from './user-context-system.js';\nimport { logger } from '../lib/logger.js';\n\nconst log = logger.child({ module: 'unified-context-service' });\n\nconst engineCache = new Map();\n\nexport async function getContextEngine(userDid) {\n  if (engineCache.has(userDid)) {\n    return engineCache.get(userDid);\n  }\n\n  const engine = await getUserContextSystem(userDid);\n  engineCache.set(userDid, engine);\n\n  return engine;\n}\n\nexport async function compileContext(userDid, conversationId, options = {}) {\n  const engine = await getContextEngine(userDid);\n  return engine.compileContext(conversationId, options);\n}\n\nexport async function getUserTopics(userDid) {\n  const engine = await getContextEngine(userDid);\n  return engine.database.topicProfile.findMany({\n    where: { userId: userDid },\n    orderBy: { mentionCount: 'desc' },\n  });\n}\n\nexport async function getUserEntities(userDid) {\n  const engine = await getContextEngine(userDid);\n  return engine.database.entityProfile.findMany({\n    where: { userId: userDid },\n    orderBy: { mentionCount: 'desc' },\n  });\n}\n\nexport async function getUserBundles(userDid) {\n  const engine = await getContextEngine(userDid);\n  return engine.database.contextBundle.findMany({\n    where: { userId: userDid },\n    orderBy: { lastUsedAt: 'desc' },\n  });\n}\n\nexport async function createUserBundle(userDid, bundleData) {\n  const engine = await getContextEngine(userDid);\n  return engine.database.contextBundle.create({\n    data: {\n      id: crypto.randomUUID(),\n      userId: userDid,\n      ...bundleData,\n    },\n  });\n}\n\nexport async function getUserConversations(userDid, options = {}) {\n  const engine = await getContextEngine(userDid);\n  const { limit = 20, offset = 0 } = options;\n\n  return engine.database.conversation.findMany({\n    where: { ownerId: userDid },\n    take: limit,\n    skip: offset,\n    orderBy: { createdAt: 'desc' },\n    include: { messages: true },\n  });\n}\n\nexport async function getUserMemories(userDid, options = {}) {\n  const engine = await getContextEngine(userDid);\n  const { limit = 50 } = options;\n\n  return engine.database.memory.findMany({\n    where: { userId: userDid },\n    take: limit,\n    orderBy: { createdAt: 'desc' },\n  });\n}\n\nexport async function createUserMemory(userDid, memoryData) {\n  const engine = await getContextEngine(userDid);\n  return engine.database.memory.create({\n    data: {\n      id: crypto.randomUUID(),\n      userId: userDid,\n      ...memoryData,\n    },\n  });\n}\n\nexport async function getUserNotebooks(userDid) {\n  const engine = await getContextEngine(userDid);\n  return engine.database.notebook.findMany({\n    where: { userId: userDid },\n    orderBy: { updatedAt: 'desc' },\n  });\n}\n\nexport async function createUserNotebook(userDid, notebookData) {\n  const engine = await getContextEngine(userDid);\n  return engine.database.notebook.create({\n    data: {\n      id: crypto.randomUUID(),\n      userId: userDid,\n      ...notebookData,\n    },\n  });\n}\n\nexport async function addNotebookEntry(userDid, notebookId, entryData) {\n  const engine = await getContextEngine(userDid);\n\n  const entry = await engine.database.notebookEntry.create({\n    data: {\n      id: crypto.randomUUID(),\n      notebookId,\n      userId: userDid,\n      ...entryData,\n    },\n  });\n\n  await engine.database.notebook.update({\n    where: { id: notebookId },\n    data: { entryCount: { increment: 1 } },\n  });\n\n  return entry;\n}\n\nexport async function getUserSettings(userDid) {\n  const engine = await getContextEngine(userDid);\n  return engine.database.userContextSettings.findUnique({\n    where: { userId: userDid },\n  });\n}\n\nexport async function updateUserSettings(userDid, settings) {\n  const engine = await getContextEngine(userDid);\n  return engine.database.userContextSettings.upsert({\n    where: { userId: userDid },\n    create: {\n      userId: userDid,\n      ...settings,\n    },\n    update: settings,\n  });\n}\n\nexport async function getUserStats(userDid) {\n  const engine = await getContextEngine(userDid);\n  return engine.getStats();\n}\n\nexport async function getUserACUs(userDid, options = {}) {\n  const engine = await getContextEngine(userDid);\n  const { limit = 50, type, category } = options;\n\n  const where = {};\n  if (type) {\n    where.type = type;\n  }\n  if (category) {\n    where.category = category;\n  }\n\n  return engine.database.atomicChatUnit.findMany({\n    where,\n    take: limit,\n    orderBy: { qualityOverall: 'desc' },\n  });\n}\n\nexport async function semanticSearch(userDid, query, options = {}) {\n  const engine = await getContextEngine(userDid);\n  return engine.searchVectorStore(query, options.limit || 10);\n}\n\nexport async function addToVectorStore(userDid, acuId, content, metadata = {}) {\n  const engine = await getContextEngine(userDid);\n  return engine.addToVectorStore(acuId, content, metadata);\n}\n\nexport async function disconnectUserEngine(userDid) {\n  if (engineCache.has(userDid)) {\n    const engine = engineCache.get(userDid);\n    await engine.disconnect();\n    engineCache.delete(userDid);\n  }\n}\n\nexport async function disconnectAllEngines() {\n  for (const [userDid, engine] of engineCache) {\n    await engine.disconnect();\n  }\n  engineCache.clear();\n}\n\nimport crypto from 'crypto';\n\nexport default {\n  getContextEngine,\n  compileContext,\n  getUserTopics,\n  getUserEntities,\n  getUserBundles,\n  createUserBundle,\n  getUserConversations,\n  getUserMemories,\n  createUserMemory,\n  getUserNotebooks,\n  createUserNotebook,\n  addNotebookEntry,\n  getUserSettings,\n  updateUserSettings,\n  getUserStats,\n  getUserACUs,\n  semanticSearch,\n  addToVectorStore,\n  disconnectUserEngine,\n  disconnectAllEngines,\n};\n","usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\context\\user-context-system.js","messages":[{"ruleId":"no-unused-vars","severity":1,"message":"'i' is defined but never used. Allowed unused args must match /^_/u.","line":149,"column":26,"nodeType":"Identifier","messageId":"unusedVar","endLine":149,"endColumn":27,"suggestions":[{"messageId":"removeVar","data":{"varName":"i"},"fix":{"range":[4037,4040],"text":""},"desc":"Remove unused variable 'i'."}]}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":"import {\n  getUserClient,\n  createUserDatabase,\n  initializeUserDatabaseDir,\n} from '../lib/user-database-manager.js';\nimport { logger } from '../lib/logger.js';\n\nconst log = logger.child({ module: 'user-context-system' });\n\nconst userContextSystems = new Map();\n\nexport class UserContextSystem {\n  constructor(userDid) {\n    this.userDid = userDid;\n    this.database = null;\n    this.aiConfig = null;\n    this.embeddingModel = null;\n    this.initialized = false;\n  }\n\n  async initialize() {\n    if (this.initialized) {\n      return this;\n    }\n\n    log.info({ userDid: this.userDid }, 'Initializing UserContextSystem');\n\n    try {\n      this.database = await getUserClient(this.userDid);\n\n      await this.initializeAIConfig();\n      await this.initializeEmbeddingModel();\n\n      this.initialized = true;\n      log.info({ userDid: this.userDid }, 'UserContextSystem fully initialized');\n    } catch (error) {\n      log.error(\n        { userDid: this.userDid, error: error.message },\n        'Failed to initialize UserContextSystem'\n      );\n      throw error;\n    }\n\n    return this;\n  }\n\n  async initializeAIConfig() {\n    this.aiConfig = {\n      provider: process.env.DEFAULT_AI_PROVIDER || 'openai',\n      model: process.env.DEFAULT_AI_MODEL || 'gpt-4',\n      apiKey: null,\n      baseUrl: null,\n    };\n  }\n\n  async initializeEmbeddingModel() {\n    this.embeddingModel = {\n      provider: process.env.EMBEDDING_PROVIDER || 'openai',\n      model: process.env.EMBEDDING_MODEL || 'text-embedding-3-small',\n      dimension: parseInt(process.env.VECTOR_DIMENSION) || 384,\n    };\n  }\n\n  async addToVectorStore(acuId, content, embedding, metadata = {}) {\n    if (!this.database) {\n      log.warn({ userDid: this.userDid }, 'Database not initialized');\n      return null;\n    }\n\n    try {\n      await this.database.atomicChatUnit.upsert({\n        where: { id: acuId },\n        update: {\n          content: content.substring(0, 5000),\n          embedding,\n          ...metadata,\n        },\n        create: {\n          id: acuId,\n          content: content.substring(0, 5000),\n          embedding,\n          authorDid: this.userDid,\n          type: metadata.type || 'text',\n          state: 'ACTIVE',\n          ...metadata,\n        },\n      });\n\n      return true;\n    } catch (error) {\n      log.error({ userDid: this.userDid, error: error.message }, 'Failed to add to vector store');\n      return null;\n    }\n  }\n\n  async searchVectorStore(query, limit = 10) {\n    if (!this.database) {\n      return [];\n    }\n\n    try {\n      const { generateEmbedding: openAIEmbed } = await import('../services/embedding-service.js');\n      const embedding = await openAIEmbed(query, this.embeddingModel.model);\n\n      const results = await this.database.$queryRaw`\n        SELECT\n          id,\n          content,\n          type,\n          category,\n          1 - (embedding <=> ${embedding}::vector) as score\n        FROM atomic_chat_units\n        WHERE \"authorDid\" = ${this.userDid}\n          AND state = 'ACTIVE'\n          AND embedding IS NOT NULL\n          AND array_length(embedding, 1) > 0\n        ORDER BY embedding <=> ${embedding}::vector\n        LIMIT ${limit}\n      `;\n\n      return results.map((r) => ({\n        id: r.id,\n        score: r.score,\n        content: r.content,\n        type: r.type,\n        category: r.category,\n      }));\n    } catch (error) {\n      log.error({ userDid: this.userDid, error: error.message }, 'Vector search failed');\n      return [];\n    }\n  }\n\n  async generateEmbedding(text) {\n    try {\n      const { generateEmbedding: openAIEmbed } = await import('../services/embedding-service.js');\n      return await openAIEmbed(text, this.embeddingModel.model);\n    } catch (error) {\n      log.warn({ userDid: this.userDid, error: error.message }, 'Using fallback embedding');\n      return this.fallbackEmbedding(text);\n    }\n  }\n\n  fallbackEmbedding(text) {\n    const dim = this.embeddingModel.dimension;\n    const vec = new Array(dim).fill(0);\n    const words = text.toLowerCase().split(/\\s+/);\n\n    words.forEach((word, i) => {\n      const hash = this.simpleHash(word);\n      vec[hash % dim] += 1;\n    });\n\n    const mag = Math.sqrt(vec.reduce((a, b) => a + b * b, 0));\n    return mag > 0 ? vec.map((v) => v / mag) : vec;\n  }\n\n  simpleHash(str) {\n    let hash = 0;\n    for (let i = 0; i < str.length; i++) {\n      const char = str.charCodeAt(i);\n      hash = (hash << 5) - hash + char;\n      hash = hash & hash;\n    }\n    return Math.abs(hash);\n  }\n\n  async compileContext(conversationId, options = {}) {\n    const {\n      includeTopics = true,\n      includeEntities = true,\n      includeMemories = true,\n      useSemanticSearch = true,\n    } = options;\n\n    const context = {\n      topics: [],\n      entities: [],\n      memories: [],\n      recentACUs: [],\n      semanticMatches: [],\n      systemPrompt: '',\n    };\n\n    if (includeTopics) {\n      context.topics = await this.database.topicProfile.findMany({\n        orderBy: { mentionCount: 'desc' },\n        take: 20,\n      });\n    }\n\n    if (includeEntities) {\n      context.entities = await this.database.entityProfile.findMany({\n        orderBy: { mentionCount: 'desc' },\n        take: 20,\n      });\n    }\n\n    if (includeMemories) {\n      context.memories = await this.database.memory.findMany({\n        orderBy: { importance: 'desc' },\n        take: 10,\n      });\n    }\n\n    context.recentACUs = await this.database.atomicChatUnit.findMany({\n      orderBy: { sourceTimestamp: 'desc' },\n      take: 50,\n    });\n\n    if (useSemanticSearch && conversationId) {\n      const conv = await this.database.conversation.findUnique({\n        where: { id: conversationId },\n        include: { messages: { take: 5, orderBy: { createdAt: 'desc' } } },\n      });\n\n      if (conv?.messages) {\n        const lastUserMsg = conv.messages.find((m) => m.role === 'user');\n        if (lastUserMsg) {\n          const content = this.extractContent(lastUserMsg.parts);\n          context.semanticMatches = await this.searchVectorStore(content, 5);\n        }\n      }\n    }\n\n    context.systemPrompt = this.buildSystemPrompt(context);\n\n    return context;\n  }\n\n  buildSystemPrompt(context) {\n    const parts = ['You are an AI assistant with access to user context:'];\n\n    if (context.topics.length > 0) {\n      const topics = context.topics\n        .map((t) => t.topic)\n        .slice(0, 10)\n        .join(', ');\n      parts.push(`User interests: ${topics}`);\n    }\n\n    if (context.memories.length > 0) {\n      const memories = context.memories\n        .map((m) => m.content)\n        .slice(0, 5)\n        .join('; ');\n      parts.push(`Relevant memories: ${memories}`);\n    }\n\n    if (context.semanticMatches.length > 0) {\n      const matches = context.semanticMatches\n        .map((m) => m.content)\n        .slice(0, 3)\n        .join('; ');\n      parts.push(`Related past conversations: ${matches}`);\n    }\n\n    return parts.join('\\n');\n  }\n\n  extractContent(parts) {\n    if (!parts) {\n      return '';\n    }\n    if (typeof parts === 'string') {\n      return parts;\n    }\n    if (Array.isArray(parts)) {\n      return parts.map((p) => p.content || p.text || '').join('\\n');\n    }\n    return parts.content || parts.text || '';\n  }\n\n  async getStats() {\n    const stats = {\n      database: {},\n      aiConfig: {},\n    };\n\n    try {\n      const [convCount, acuCount, topicCount, entityCount, memoryCount] = await Promise.all([\n        this.database.conversation.count(),\n        this.database.atomicChatUnit.count(),\n        this.database.topicProfile.count(),\n        this.database.entityProfile.count(),\n        this.database.memory.count(),\n      ]);\n\n      stats.database = { convCount, acuCount, topicCount, entityCount, memoryCount };\n    } catch (e) {\n      stats.database = { error: e.message };\n    }\n\n    stats.aiConfig = {\n      provider: this.aiConfig?.provider,\n      model: this.aiConfig?.model,\n      hasApiKey: !!this.aiConfig?.apiKey,\n    };\n\n    return stats;\n  }\n\n  async disconnect() {\n    if (this.database) {\n      await this.database.$disconnect();\n    }\n    this.database = null;\n    this.aiConfig = null;\n    this.initialized = false;\n    log.info({ userDid: this.userDid }, 'UserContextSystem disconnected');\n  }\n}\n\nexport async function createUserContextSystem(userDid) {\n  initializeUserDatabaseDir();\n  await createUserDatabase(userDid);\n\n  const system = new UserContextSystem(userDid);\n  await system.initialize();\n\n  userContextSystems.set(userDid, system);\n\n  return system;\n}\n\nexport async function getUserContextSystem(userDid) {\n  if (userContextSystems.has(userDid)) {\n    return userContextSystems.get(userDid);\n  }\n\n  const system = new UserContextSystem(userDid);\n  await system.initialize();\n\n  userContextSystems.set(userDid, system);\n\n  return system;\n}\n\nexport async function destroyUserContextSystem(userDid) {\n  if (userContextSystems.has(userDid)) {\n    const system = userContextSystems.get(userDid);\n    await system.disconnect();\n    userContextSystems.delete(userDid);\n  }\n}\n\nexport default {\n  UserContextSystem,\n  createUserContextSystem,\n  getUserContextSystem,\n  destroyUserContextSystem,\n};\n","usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\docs\\swagger.js","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\extractors\\extractor-chatgpt.js","messages":[{"ruleId":"no-useless-escape","severity":2,"message":"Unnecessary escape character: \\[.","line":138,"column":50,"nodeType":"Literal","messageId":"unnecessaryEscape","endLine":138,"endColumn":51,"suggestions":[{"messageId":"removeEscape","fix":{"range":[3997,3998],"text":""},"desc":"Remove the `\\`. This maintains the current functionality."},{"messageId":"escapeBackslash","fix":{"range":[3997,3997],"text":"\\"},"desc":"Replace the `\\` with `\\\\` to include the actual backslash character."}]},{"ruleId":"no-unused-vars","severity":1,"message":"'e' is defined but never used.","line":141,"column":16,"nodeType":"Identifier","messageId":"unusedVar","endLine":141,"endColumn":17},{"ruleId":"no-unused-vars","severity":1,"message":"'e' is defined but never used.","line":149,"column":14,"nodeType":"Identifier","messageId":"unusedVar","endLine":149,"endColumn":15},{"ruleId":"no-useless-escape","severity":2,"message":"Unnecessary escape character: \\-.","line":404,"column":67,"nodeType":"Literal","messageId":"unnecessaryEscape","endLine":404,"endColumn":68,"suggestions":[{"messageId":"removeEscape","fix":{"range":[11542,11543],"text":""},"desc":"Remove the `\\`. This maintains the current functionality."},{"messageId":"escapeBackslash","fix":{"range":[11542,11542],"text":"\\"},"desc":"Replace the `\\` with `\\\\` to include the actual backslash character."}]},{"ruleId":"no-useless-escape","severity":2,"message":"Unnecessary escape character: \\-.","line":404,"column":69,"nodeType":"Literal","messageId":"unnecessaryEscape","endLine":404,"endColumn":70,"suggestions":[{"messageId":"removeEscape","fix":{"range":[11544,11545],"text":""},"desc":"Remove the `\\`. This maintains the current functionality."},{"messageId":"escapeBackslash","fix":{"range":[11544,11544],"text":"\\"},"desc":"Replace the `\\` with `\\\\` to include the actual backslash character."}]}],"suppressedMessages":[],"errorCount":3,"fatalErrorCount":0,"warningCount":2,"fixableErrorCount":0,"fixableWarningCount":0,"source":"import fs from 'fs/promises';\nimport * as cheerio from 'cheerio';\nimport { v4 as uuidv4 } from 'uuid';\nimport { logger } from '../lib/logger.js';\nimport { captureWithPlaywright, cleanupPlaywrightFile } from '../capture-playwright.js';\n\n/**\n * Extract conversation from ChatGPT share URL\n * @param {string} url - The share URL to extract from\n * @param {Object} options - Extraction options\n * @returns {Promise<Object>} The extracted conversation object\n */\nasync function extractChatgptConversation(url, options = {}) {\n  const {\n    timeout = 120000,\n    richFormatting = true,\n    metadataOnly = false,\n    headless = true,\n    waitForTimeout = 3000,\n  } = options;\n\n  let tempFilePath = null;\n\n  try {\n    logger.info(`Starting ChatGPT extraction for ${url} using Playwright...`);\n\n    // Capture the live page using Playwright (with stealth mode)\n    tempFilePath = await captureWithPlaywright(url, 'chatgpt', {\n      timeout,\n      headless,\n      waitForSelector: 'h1, [data-message-author-role]',\n      waitForTimeout: waitForTimeout,\n    });\n\n    logger.info(`Reading captured ChatGPT HTML from: ${tempFilePath}`);\n    const html = await fs.readFile(tempFilePath, 'utf8');\n    const $ = cheerio.load(html);\n\n    // Extract conversation data for ChatGPT\n    const conversation = extractChatgptData($, url, html, richFormatting);\n\n    if (conversation.messages.length === 0) {\n      const debugPath = `debug-chatgpt-${Date.now()}.html`;\n      await fs.writeFile(debugPath, html);\n      logger.warn(`No messages found for ChatGPT. Saved HTML to ${debugPath} for inspection.`);\n    }\n\n    // Add metadata and standardize\n    conversation.id = uuidv4();\n    conversation.sourceUrl = url;\n    conversation.provider = 'chatgpt';\n    conversation.exportedAt = new Date().toISOString();\n\n    // If metadata only, return early\n    if (metadataOnly) {\n      return {\n        id: conversation.id,\n        provider: conversation.provider,\n        sourceUrl: conversation.sourceUrl,\n        title: conversation.title,\n        createdAt: conversation.createdAt,\n        exportedAt: conversation.exportedAt,\n        metadata: conversation.metadata,\n        stats: conversation.stats,\n      };\n    }\n\n    // Calculate statistics\n    conversation.stats = calculateStats(conversation.messages);\n\n    return conversation;\n  } catch (error) {\n    throw new Error(`ChatGPT extraction failed: ${error.message}`);\n  } finally {\n    if (tempFilePath) {\n      await cleanupPlaywrightFile(tempFilePath);\n    }\n  }\n}\n\n/**\n * Extract ChatGPT conversation data\n */\nfunction extractChatgptData($, url, html, richFormatting = true) {\n  const title = $('title').text().replace(' - ChatGPT', '').trim() || 'ChatGPT Conversation';\n  const messages = [];\n\n  // Method 1: Extraction from React Router stream (Newer ChatGPT layout)\n  try {\n    // 1. Robustly extract enqueue arguments (JSON strings)\n    const chunks = [];\n    const searchStr = 'streamController.enqueue(\"';\n    let pos = 0;\n\n    while (true) {\n      pos = html.indexOf(searchStr, pos);\n      if (pos === -1) {\n        break;\n      }\n\n      pos += searchStr.length;\n      const start = pos;\n      let end = -1;\n      let escape = false;\n\n      // Find closing quote ignoring escaped quotes\n      for (let i = start; i < html.length; i++) {\n        const char = html[i];\n        if (escape) {\n          escape = false;\n          continue;\n        }\n        if (char === '\\\\') {\n          escape = true;\n          continue;\n        }\n        if (char === '\"') {\n          end = i;\n          break;\n        }\n      }\n\n      if (end !== -1) {\n        chunks.push(html.substring(start, end));\n        pos = end;\n      } else {\n        break;\n      }\n    }\n\n    // 2. Concatenate and Parse\n    let combinedJsonStr = '';\n    chunks.forEach((jsonPart) => {\n      try {\n        // Unescape the string literal content\n        const unescaped = JSON.parse(`\"${jsonPart}\"`);\n        // Filter out React Flight data chunks\n        if (!unescaped.trim().match(/^[A-Z0-9]+:[\\[]/)) {\n          combinedJsonStr += unescaped;\n        }\n      } catch (e) {\n        // Ignore unescape errors\n      }\n    });\n\n    let root = null;\n    try {\n      root = JSON.parse(combinedJsonStr);\n    } catch (e) {\n      // Tolerant parsing if possible\n    }\n\n    // 3. Resolve References and Extract Messages\n    if (root && Array.isArray(root)) {\n      const mappingIdx = root.indexOf('mapping');\n      if (mappingIdx !== -1 && mappingIdx + 1 < root.length) {\n        const mapping = root[mappingIdx + 1];\n\n        Object.values(mapping).forEach((nodeOrRef) => {\n          let node = nodeOrRef;\n          // Reference resolution\n          if (typeof nodeOrRef === 'number') {\n            node = root[nodeOrRef];\n          }\n\n          if (node && node.message) {\n            const msgData = node.message;\n            const role = msgData.author?.role;\n\n            if (role === 'user' || role === 'assistant' || role === 'system') {\n              let parts = [];\n\n              // Content parts resolution\n              if (msgData.content && msgData.content.parts) {\n                parts = msgData.content.parts.map((part) => {\n                  if (typeof part === 'number') {\n                    const resolved = root[part] || '';\n                    return { type: 'text', content: String(resolved) };\n                  }\n                  return { type: 'text', content: String(part) };\n                });\n              }\n\n              if (parts.length > 0) {\n                messages.push({\n                  id: msgData.id || uuidv4(),\n                  role: role,\n                  author: role === 'user' ? 'User' : 'ChatGPT',\n                  parts: parts,\n                  createdAt: msgData.create_time\n                    ? new Date(msgData.create_time * 1000).toISOString()\n                    : null,\n                  status: 'completed',\n                });\n              }\n            }\n          }\n        });\n      }\n    }\n  } catch (e) {\n    logger.error(`Error parsing ChatGPT stream: ${e.message}`);\n  }\n\n  // Method 2: Look for turns in older/standard layouts (article tags)\n  if (messages.length === 0) {\n    $('article').each((i, el) => {\n      const $art = $(el);\n      let role = null;\n      if ($art.find('h5').text().toLowerCase().includes('you said')) {\n        role = 'user';\n      } else if ($art.find('h6').text().toLowerCase().includes('chatgpt said')) {\n        role = 'assistant';\n      }\n\n      if (!role) {\n        if ($art.find('.bg-user-pixel, .rounded-sm > svg').length > 0) {\n          role = 'user';\n        } else if ($art.find('.markdown, .prose').length > 0) {\n          role = 'assistant';\n        }\n      }\n\n      if (role) {\n        const $content = $art.find('.whitespace-pre-wrap, .markdown, .prose').first();\n        const $target = $content.length > 0 ? $content : $art;\n\n        // Extract parts using rich content extractor\n        const parts = extractChatgptRichContent($target, $, richFormatting);\n\n        if (parts.length > 0) {\n          messages.push({\n            id: uuidv4(),\n            role,\n            author: role === 'user' ? 'User' : 'ChatGPT',\n            parts,\n            createdAt: null,\n            status: 'completed',\n          });\n        }\n      }\n    });\n  }\n\n  // Method 3: Fallback to data attributes\n  if (messages.length === 0) {\n    $('[data-message-author-role]').each((i, el) => {\n      const $el = $(el);\n      const role = $el.attr('data-message-author-role');\n      if (role === 'user' || role === 'assistant') {\n        const parts = extractChatgptRichContent($el, $, richFormatting);\n        if (parts.length > 0) {\n          messages.push({\n            id: uuidv4(),\n            role,\n            author: role === 'user' ? 'User' : 'ChatGPT',\n            parts,\n            createdAt: null,\n            status: 'completed',\n          });\n        }\n      }\n    });\n  }\n\n  // Calculate statistics\n  const stats = calculateStats(messages);\n\n  return {\n    id: uuidv4(),\n    provider: 'chatgpt',\n    sourceUrl: url,\n    title,\n    model: 'ChatGPT',\n    createdAt: new Date().toISOString(),\n    updatedAt: new Date().toISOString(),\n    capturedAt: new Date().toISOString(),\n    messages,\n    metadata: {\n      provider: 'chatgpt',\n      model: 'ChatGPT',\n    },\n    ...stats,\n  };\n}\n\n/**\n * Extract rich content from ChatGPT message element\n */\nfunction extractChatgptRichContent($el, $, richFormatting = true) {\n  if (!richFormatting) {\n    return [{ type: 'text', content: $el.text().trim() }];\n  }\n\n  const $clone = $el.clone();\n  $clone.find('h5, h6').remove(); // Remove headers like \"You said\"\n\n  const contentBlocks = [];\n\n  // 1. Identify Mermaid diagrams in code blocks\n  $clone.find('pre, code').each((index, elem) => {\n    const $elem = $(elem);\n    const text = $elem.text().trim();\n    if (\n      text.match(\n        /^(graph|flowchart|sequenceDiagram|classDiagram|stateDiagram|erDiagram|journey|gantt|pie|quadrantChart|requirementDiagram|gitGraph|C4Context|C4Container|C4Component|C4Dynamic|C4Deployment|mindmap|timeline|zenuml)/i\n      )\n    ) {\n      contentBlocks.push({\n        type: 'mermaid',\n        content: text,\n        metadata: { diagramType: text.split('\\n')[0].trim() },\n      });\n      $elem.remove();\n    }\n  });\n\n  // 2. Identify code blocks\n  $clone.find('pre').each((index, elem) => {\n    const $pre = $(elem);\n    const $code = $pre.find('code');\n    const text = $code.text().trim();\n    if (text) {\n      const language = $code.attr('class')?.match(/language-(\\w+)/)?.[1] || 'text';\n      contentBlocks.push({\n        type: 'code',\n        content: text,\n        metadata: { language },\n      });\n      $pre.remove();\n    }\n  });\n\n  // 3. Identify images\n  $clone.find('img').each((index, elem) => {\n    const $elem = $(elem);\n    const src = $elem.attr('src');\n    if (\n      src &&\n      !src.includes('profile') &&\n      !src.includes('avatar') &&\n      !src.includes('data:image/svg')\n    ) {\n      contentBlocks.push({\n        type: 'image',\n        content: src,\n        metadata: { alt: $elem.attr('alt') || '' },\n      });\n    }\n    $elem.remove();\n  });\n\n  // 4. Identify LaTeX\n  $clone.find('.katex-block, .katex-display').each((_, elem) => {\n    const $elem = $(elem);\n    const tex = $elem.find('annotation[encoding=\"application/x-tex\"]').text() || $elem.text();\n    contentBlocks.push({\n      type: 'latex',\n      content: tex,\n      metadata: { display: 'block' },\n    });\n    $elem.remove();\n  });\n\n  $clone.find('.katex').each((_, elem) => {\n    const $elem = $(elem);\n    const tex = $elem.find('annotation[encoding=\"application/x-tex\"]').text() || $elem.text();\n    contentBlocks.push({\n      type: 'latex',\n      content: tex,\n      metadata: { display: 'inline' },\n    });\n    $elem.remove();\n  });\n\n  // 5. Identify Tables\n  $clone.find('table').each((index, elem) => {\n    const $table = $(elem);\n    const headers = [];\n    $table.find('thead th').each((_, th) => headers.push($(th).text().trim()));\n\n    const rows = [];\n    $table.find('tbody tr').each((_, tr) => {\n      const row = [];\n      $(tr)\n        .find('td')\n        .each((_, td) => row.push($(td).text().trim()));\n      rows.push(row);\n    });\n\n    if (rows.length > 0) {\n      contentBlocks.push({\n        type: 'table',\n        content: { headers, rows },\n        metadata: { format: 'html' },\n      });\n      $table.remove();\n    }\n  });\n\n  // 6. Handle remaining text and potential hidden diagrams\n  const remainingText = $clone.text().trim();\n\n  const mermaidRegex = /(?:^|\\n)\\s*(graph\\s+[LRTDBC]{2}[\\s\\S]*?(?=\\-\\-|\\n|###|Goal:|1\\s+|2\\s+))/gi;\n  let match;\n  let lastIndex = 0;\n  const newTextBlocks = [];\n\n  while ((match = mermaidRegex.exec(remainingText)) !== null) {\n    const textBefore = remainingText.substring(lastIndex, match.index).trim();\n    if (textBefore) {\n      newTextBlocks.push({ type: 'text', content: textBefore });\n    }\n    contentBlocks.push({ type: 'mermaid', content: match[1].trim() });\n    lastIndex = match.index + match[0].length;\n  }\n\n  const finalRemainingText = remainingText.substring(lastIndex).trim();\n  if (finalRemainingText) {\n    newTextBlocks.push({ type: 'text', content: finalRemainingText });\n  }\n\n  const finalBlocks = [...newTextBlocks, ...contentBlocks];\n\n  return finalBlocks;\n}\n\n/**\n * Calculate statistics\n */\nfunction calculateStats(messages) {\n  let totalWords = 0;\n  let totalCharacters = 0;\n  let totalCodeBlocks = 0;\n  let totalMermaidDiagrams = 0;\n  let totalImages = 0;\n  let totalTables = 0;\n  let totalLatexBlocks = 0;\n  let totalToolCalls = 0;\n  let userMessageCount = 0;\n  let aiMessageCount = 0;\n\n  for (const message of messages) {\n    if (message.role === 'user') {\n      userMessageCount++;\n    }\n    if (message.role === 'assistant') {\n      aiMessageCount++;\n    }\n\n    if (message.parts) {\n      message.parts.forEach((part) => {\n        if (part.type === 'text') {\n          totalWords += part.content.split(/\\s+/).filter((w) => w).length;\n          totalCharacters += part.content.length;\n        } else if (part.type === 'code') {\n          totalCodeBlocks++;\n          totalCharacters += part.content.length;\n        } else if (part.type === 'mermaid') {\n          totalMermaidDiagrams++;\n          totalCharacters += part.content.length;\n        } else if (part.type === 'image') {\n          totalImages++;\n        } else if (part.type === 'table') {\n          totalTables++;\n        } else if (part.type === 'latex') {\n          totalLatexBlocks++;\n        } else if (part.type === 'tool_call') {\n          totalToolCalls++;\n        }\n      });\n    }\n  }\n\n  return {\n    messageCount: messages.length,\n    userMessageCount,\n    aiMessageCount,\n    totalWords,\n    totalCharacters,\n    totalCodeBlocks,\n    totalMermaidDiagrams,\n    totalImages,\n    totalTables,\n    totalLatexBlocks,\n    totalToolCalls,\n    firstMessageAt: messages[0]?.createdAt || new Date().toISOString(),\n    lastMessageAt: messages[messages.length - 1]?.createdAt || new Date().toISOString(),\n  };\n}\n\nexport { extractChatgptConversation, extractChatgptData };\n","usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\extractors\\extractor-claude.js","messages":[{"ruleId":"no-unused-vars","severity":1,"message":"'err' is defined but never used.","line":46,"column":18,"nodeType":"Identifier","messageId":"unusedVar","endLine":46,"endColumn":21}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":"import fs from 'fs/promises';\nimport * as cheerio from 'cheerio';\nimport { v4 as uuidv4 } from 'uuid';\nimport { logger } from '../lib/logger.js';\nimport { captureWithPlaywright, cleanupPlaywrightFile } from '../capture-playwright.js';\n\n/**\n * Extract conversation from Claude share URL\n * @param {string} url - The share URL to extract from\n * @param {Object} options - Extraction options\n * @returns {Promise<Object>} The extracted conversation object\n */\nasync function extractClaudeConversation(url, options = {}) {\n  const { timeout = 60000, headless = true } = options;\n\n  let tempFilePath = null;\n\n  try {\n    logger.info(`Starting Claude extraction for ${url}...`);\n\n    // Capture the live page using Playwright\n    // Claude share pages render conversation in a list\n    tempFilePath = await captureWithPlaywright(url, 'claude', {\n      timeout,\n      headless,\n      // Try to wait for message containers\n      waitForSelector:\n        '[data-testid=\"user-message\"], .font-claude-response-body, .prose-claude, .standard-markdown',\n      waitForTimeout: 5000,\n      pageHandler: async (page, log) => {\n        // Claude sometimes has a \"I understand\" button or cookie banner\n        try {\n          const bannerButtons = [\n            'button:has-text(\"I understand\")',\n            'button:has-text(\"Accept\")',\n            'button:has-text(\"Agree\")',\n          ];\n\n          for (const selector of bannerButtons) {\n            const button = page.locator(selector).first();\n            if (await button.isVisible({ timeout: 2000 })) {\n              await button.click();\n              log.info({ selector }, 'Dismissed Claude banner');\n            }\n          }\n        } catch (err) {\n          // Ignore banner errors\n        }\n      },\n    });\n\n    logger.info(`Reading captured Claude HTML from: ${tempFilePath}`);\n    const html = await fs.readFile(tempFilePath, 'utf8');\n    const $ = cheerio.load(html);\n\n    // Extract conversation data\n    const conversation = extractClaudeData($, url);\n\n    if (conversation.messages.length === 0) {\n      const debugPath = `debug-claude-${Date.now()}.html`;\n      await fs.writeFile(debugPath, html);\n      logger.warn(`No messages found for Claude. Saved HTML to ${debugPath} for inspection.`);\n    }\n\n    return conversation;\n  } catch (error) {\n    throw new Error(`Claude extraction failed: ${error.message}`);\n  } finally {\n    if (tempFilePath) {\n      await cleanupPlaywrightFile(tempFilePath);\n    }\n  }\n}\n\n/**\n * Extract Claude conversation data\n */\nfunction extractClaudeData($, url) {\n  const title =\n    $('title').text().replace(' - Claude', '').trim() ||\n    $('h1').first().text().trim() ||\n    'Claude Conversation';\n\n  const messages = [];\n\n  // Claude's share pages usually have a consistent structure:\n  // User messages are in [data-testid=\"user-message\"]\n  // Assistant messages are in .prose-claude or .standard-markdown\n\n  // We want to find each distinct message.\n  // Often they are inside a container that represents a \"turn\"\n\n  // Find all user messages\n  const userMessages = $('[data-testid=\"user-message\"]').toArray();\n  // Find all assistant messages\n  const assistantMessages = $('.prose-claude, .standard-markdown').toArray();\n\n  // Filter assistant messages to remove nested ones (if any)\n  const topAssistantMessages = assistantMessages.filter((el) => {\n    return $(el).parents('.prose-claude, .standard-markdown').length === 0;\n  });\n\n  const allMessages = [...userMessages, ...topAssistantMessages];\n\n  // Sort by position in DOM\n  const indexedMessages = allMessages\n    .map((el) => ({\n      el,\n      index: indexInDocument($, el),\n    }))\n    .sort((a, b) => a.index - b.index);\n\n  indexedMessages.forEach((item, index) => {\n    const $el = $(item.el);\n    let role = 'assistant';\n    let author = 'Claude';\n\n    if (\n      $el.attr('data-testid') === 'user-message' ||\n      $el.find('[data-testid=\"user-message\"]').length > 0\n    ) {\n      role = 'user';\n      author = 'User';\n    }\n\n    const parts = extractContentParts($el, $);\n\n    if (parts.length > 0) {\n      messages.push({\n        id: uuidv4(),\n        role,\n        author,\n        messageIndex: index,\n        parts,\n        createdAt: new Date().toISOString(),\n        status: 'completed',\n        metadata: {},\n      });\n    }\n  });\n\n  // Calculate stats\n  const stats = calculateStats(messages);\n\n  return {\n    id: uuidv4(),\n    provider: 'claude',\n    sourceUrl: url,\n    title,\n    model: 'claude',\n    createdAt: new Date().toISOString(),\n    updatedAt: new Date().toISOString(),\n    capturedAt: new Date().toISOString(),\n    messages,\n    metadata: {\n      url,\n    },\n    ...stats,\n  };\n}\n\n/**\n * Find index of element in document to maintain order\n */\nfunction indexInDocument($, el) {\n  return Array.from($('*')).indexOf(el);\n}\n\n/**\n * Extract structured content parts from a Claude message element\n */\nfunction extractContentParts($el, $) {\n  const parts = [];\n  const $clone = $el.clone();\n\n  // 1. Extract Code Blocks\n  // Claude wraps code in a container with a language label\n  // We target the container to get the language, but avoid matching the pre inside it twice.\n  $clone.find('.bg-bg-000\\\\/50').each((_, elem) => {\n    const $container = $(elem);\n    const $pre = $container.find('pre');\n\n    if ($pre.length > 0) {\n      const $code = $pre.find('code');\n      const language =\n        $container.find('.text-text-500').first().text().trim() ||\n        $code.attr('class')?.match(/language-(\\w+)/)?.[1] ||\n        'text';\n\n      const codeContent = $code.text().trim() || $pre.text().trim();\n\n      if (codeContent) {\n        // Check for Mermaid\n        const isMermaid =\n          language.toLowerCase() === 'mermaid' ||\n          codeContent.match(\n            /^(graph|flowchart|sequenceDiagram|classDiagram|stateDiagram|erDiagram|journey|gantt|pie|quadrantChart|requirementDiagram|gitGraph|C4Context|mindmap|timeline|zenuml)/i\n          );\n\n        if (isMermaid) {\n          parts.push({\n            type: 'mermaid',\n            content: codeContent,\n            metadata: { diagramType: isMermaid[0]?.toLowerCase() || 'flowchart' },\n          });\n        } else {\n          parts.push({\n            type: 'code',\n            content: codeContent,\n            metadata: { language: language.toLowerCase() },\n          });\n        }\n        $container.remove();\n      }\n    }\n  });\n\n  // Catch any remaining pre blocks that weren't in the standard container\n  $clone.find('pre').each((_, elem) => {\n    const $pre = $(elem);\n    const $code = $pre.find('code');\n    const language = $code.attr('class')?.match(/language-(\\w+)/)?.[1] || 'text';\n    const codeContent = $code.text().trim() || $pre.text().trim();\n\n    if (codeContent) {\n      parts.push({\n        type: 'code',\n        content: codeContent,\n        metadata: { language: language.toLowerCase() },\n      });\n      $pre.remove();\n    }\n  });\n\n  // 2. Extract Math (KaTeX)\n  // Target the container to avoid double matching katex-mathml and katex-html\n  $clone.find('.katex-display, .katex:not(.katex-display .katex)').each((_, elem) => {\n    const $math = $(elem);\n    let tex = $math.find('annotation[encoding=\"application/x-tex\"]').first().text().trim();\n\n    if (!tex) {\n      tex = $math.text().trim();\n    }\n\n    if (tex) {\n      parts.push({\n        type: 'latex',\n        content: tex,\n        metadata: {\n          display: $math.hasClass('katex-display') ? 'block' : 'inline',\n        },\n      });\n      $math.remove();\n    }\n  });\n\n  // 3. Extract Tables\n  $clone.find('table').each((_, elem) => {\n    const $table = $(elem);\n    const headers = [];\n    const rows = [];\n\n    $table.find('th').each((_, th) => headers.push($(th).text().trim()));\n    $table.find('tr').each((_, tr) => {\n      const row = [];\n      const $cells = $(tr).find('td');\n      if ($cells.length > 0) {\n        $cells.each((_, td) => row.push($(td).text().trim()));\n        rows.push(row);\n      }\n    });\n\n    if (rows.length > 0 || headers.length > 0) {\n      parts.push({\n        type: 'table',\n        content: { headers, rows },\n        metadata: { format: 'html' },\n      });\n      $table.remove();\n    }\n  });\n\n  // 4. Extract Images\n  $clone.find('img').each((_, elem) => {\n    const $img = $(elem);\n    const src = $img.attr('src');\n    if (src && !src.includes('avatar') && !src.includes('icon')) {\n      parts.push({\n        type: 'image',\n        content: src,\n        metadata: { alt: $img.attr('alt') || 'Claude Image' },\n      });\n      $img.remove();\n    }\n  });\n\n  // 5. Remaining Text\n  const textContent = $clone\n    .text()\n    .trim()\n    .replace(/\\n\\s+\\n/g, '\\n\\n');\n  if (textContent) {\n    parts.push({\n      type: 'text',\n      content: textContent,\n      metadata: { format: 'markdown' },\n    });\n  }\n\n  return parts;\n}\n\n/**\n * Calculate statistics\n */\nfunction calculateStats(messages) {\n  let totalWords = 0;\n  let totalCharacters = 0;\n  let totalCodeBlocks = 0;\n  let totalMermaidDiagrams = 0;\n  let totalImages = 0;\n  let totalTables = 0;\n  let totalLatexBlocks = 0;\n  let userMessageCount = 0;\n  let aiMessageCount = 0;\n\n  for (const message of messages) {\n    if (message.role === 'user') {\n      userMessageCount++;\n    }\n    if (message.role === 'assistant') {\n      aiMessageCount++;\n    }\n\n    for (const part of message.parts) {\n      if (part.type === 'text') {\n        const text = part.content;\n        totalWords += text.split(/\\s+/).filter((w) => w).length;\n        totalCharacters += text.length;\n      } else if (part.type === 'code') {\n        totalCodeBlocks++;\n        totalCharacters += part.content.length;\n      } else if (part.type === 'image') {\n        totalImages++;\n      } else if (part.type === 'table') {\n        totalTables++;\n      } else if (part.type === 'latex') {\n        totalLatexBlocks++;\n      } else if (part.type === 'mermaid') {\n        totalMermaidDiagrams++;\n      }\n    }\n  }\n\n  return {\n    messageCount: messages.length,\n    userMessageCount,\n    aiMessageCount,\n    totalWords,\n    totalCharacters,\n    totalCodeBlocks,\n    totalMermaidDiagrams,\n    totalImages,\n    totalTables,\n    totalLatexBlocks,\n    totalToolCalls: 0, // Claude doesn't usually show tool calls in share links\n  };\n}\n\nexport { extractClaudeConversation };\n","usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\extractors\\extractor-deepseek.js","messages":[{"ruleId":"no-unused-vars","severity":1,"message":"'index' is defined but never used. Allowed unused args must match /^_/u.","line":107,"column":32,"nodeType":"Identifier","messageId":"unusedVar","endLine":107,"endColumn":37,"suggestions":[{"messageId":"removeVar","data":{"varName":"index"},"fix":{"range":[3131,3138],"text":""},"desc":"Remove unused variable 'index'."}]}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":"import fs from 'fs/promises';\nimport * as cheerio from 'cheerio';\nimport { v4 as uuidv4 } from 'uuid';\nimport { logger } from '../lib/logger.js';\nimport { captureWithSingleFile, cleanupTempFile } from '../capture.js';\n\n/**\n * Extract conversation from DeepSeek share URL\n * @param {string} url - The share URL to extract from\n * @param {Object} options - Extraction options\n * @returns {Promise<Object>} The extracted conversation object\n */\nasync function extractDeepseekConversation(url, options = {}) {\n  const {\n    timeout = 120000,\n    richFormatting = true,\n    metadataOnly = false,\n    headless = true,\n  } = options;\n\n  let tempFilePath = null;\n\n  try {\n    logger.info(`Starting DeepSeek extraction for ${url}...`);\n\n    // Capture the live page using SingleFile CLI\n    tempFilePath = await captureWithSingleFile(url, 'deepseek', { timeout, headless });\n\n    logger.info(`Reading captured DeepSeek HTML from: ${tempFilePath}`);\n    const html = await fs.readFile(tempFilePath, 'utf8');\n    const $ = cheerio.load(html);\n\n    // Extract conversation data for DeepSeek\n    const conversation = extractDeepseekData($, url, richFormatting);\n\n    // Add metadata and standardize\n    conversation.id = uuidv4();\n    conversation.sourceUrl = url;\n    conversation.provider = 'deepseek';\n    conversation.exportedAt = new Date().toISOString();\n\n    // If metadata only, return early\n    if (metadataOnly) {\n      return {\n        id: conversation.id,\n        provider: conversation.provider,\n        sourceUrl: conversation.sourceUrl,\n        title: conversation.title,\n        createdAt: conversation.createdAt,\n        exportedAt: conversation.exportedAt,\n        metadata: conversation.metadata,\n        stats: conversation.stats,\n      };\n    }\n\n    // Calculate statistics\n    conversation.stats = calculateStats(conversation);\n\n    return conversation;\n  } catch (error) {\n    throw new Error(`DeepSeek extraction failed: ${error.message}`);\n  } finally {\n    // Always clean up the temporary file\n    if (tempFilePath) {\n      await cleanupTempFile(tempFilePath);\n    }\n  }\n}\n\n/**\n * Extract DeepSeek conversation data\n */\nfunction extractDeepseekData($, url, richFormatting = true) {\n  const title = $('title').text().replace(' - DeepSeek', '').trim() || 'DeepSeek Conversation';\n\n  const messages = [];\n\n  // Try multiple selectors for message containers\n  const selectors = [\n    '.ds-message',\n    '[class*=\"message\" i]',\n    '.chat-message',\n    '.conversation-message',\n  ];\n\n  let messageElements = [];\n  for (const selector of selectors) {\n    messageElements = $(selector).toArray();\n    if (messageElements.length > 0) {\n      break;\n    }\n  }\n\n  if (messageElements.length === 0) {\n    logger.warn('No message elements found with standard selectors, trying generic approach');\n    // Fallback: look for alternating div patterns\n    const allDivs = $('div').toArray();\n    messageElements = allDivs\n      .filter((el) => {\n        const $el = $(el);\n        const text = $el.text().trim();\n        return text.length > 10 && text.length < 10000;\n      })\n      .slice(0, 50);\n  }\n\n  messageElements.forEach((el, index) => {\n    const $el = $(el);\n    const className = $el.attr('class') || '';\n    const text = $el.text().trim();\n\n    // Multiple heuristics for role detection\n    let role = 'assistant';\n\n    // Heuristic 1: Check for user-specific indicators\n    const isUser =\n      className.match(/[a-f0-9]{7,}/) || // Dynamic hash classes (like d29f3d7d)\n      $el.find('img[src*=\"user\"], .avatar-user, [data-role=\"user\"]').length > 0 ||\n      text.startsWith('You:') ||\n      text.startsWith('User:');\n\n    // Heuristic 2: Position-based (alternating)\n    if (!isUser && messages.length > 0) {\n      const prevRole = messages[messages.length - 1].role;\n      if (prevRole === 'assistant') {\n        role = 'user';\n      }\n    }\n\n    if (isUser) {\n      role = 'user';\n    }\n\n    // Skip if this looks like a duplicate or system message\n    if (text.length < 2 || text.length > 50000) {\n      return;\n    }\n\n    const content = richFormatting ? extractDeepseekRichContent($el, $, richFormatting) : text;\n\n    if (content && content.length > 0) {\n      messages.push({\n        id: uuidv4(),\n        role,\n        content,\n        timestamp: null,\n      });\n    }\n  });\n\n  // Remove duplicate messages\n  const uniqueMessages = messages.filter(\n    (msg, index, self) => index === self.findIndex((m) => m.content === msg.content)\n  );\n\n  return {\n    title,\n    createdAt: new Date().toISOString(),\n    messages: uniqueMessages,\n    metadata: {\n      provider: 'deepseek',\n      model: 'DeepSeek-V3',\n    },\n  };\n}\n\n/**\n * Extract rich content from DeepSeek message element\n */\nfunction extractDeepseekRichContent($el, $, richFormatting = true) {\n  if (!richFormatting) {\n    return $el.text().trim();\n  }\n\n  const $clone = $el.clone();\n  const contentBlocks = [];\n\n  // 1. Identify \"Thought\" or \"Thinking\" blocks\n  // DeepSeek often has a \"Thought for X seconds\" section\n  const thoughtMatch = $clone.text().match(/Thought for \\d+ seconds/i);\n  if (thoughtMatch) {\n    // Find the thought block - often a specific div or just text at the start\n    // For now, we'll just extract the text and mark it\n    contentBlocks.push({\n      type: 'text',\n      content: thoughtMatch[0],\n      isThought: true,\n    });\n    // Try to remove it from the clone to avoid duplication\n    // This is a bit tricky as it might not be in a separate tag\n  }\n\n  // 2. Identify Code Blocks\n  $clone.find('.md-code-block, pre').each((index, elem) => {\n    const $pre = $(elem);\n    const $code = $pre.find('code');\n    const text = $code.length > 0 ? $code.text().trim() : $pre.text().trim();\n    if (text) {\n      const language =\n        $pre.attr('class')?.match(/language-(\\w+)/)?.[1] ||\n        $code.attr('class')?.match(/language-(\\w+)/)?.[1] ||\n        'text';\n      contentBlocks.push({\n        type: 'code',\n        content: text,\n        language: language,\n      });\n      $pre.remove();\n    }\n  });\n\n  // 3. Identify images\n  $clone.find('img').each((index, elem) => {\n    const $elem = $(elem);\n    const src = $elem.attr('src');\n    if (src && !src.includes('avatar') && !src.includes('logo')) {\n      contentBlocks.push({\n        type: 'image',\n        content: src,\n        alt: $elem.attr('alt') || '',\n      });\n    }\n    $elem.remove();\n  });\n\n  // 4. Handle remaining text\n  const remainingText = $clone\n    .text()\n    .replace(/Thought for \\d+ seconds/i, '')\n    .trim();\n  if (remainingText) {\n    // Check for mermaid in text\n    const mermaidRegex = /(?:^|\\n)\\s*(graph\\s+[LRTDBC]{2}[\\s\\S]*?(?=---|###|$))/gi;\n    let match;\n    let lastIndex = 0;\n    const newTextBlocks = [];\n\n    while ((match = mermaidRegex.exec(remainingText)) !== null) {\n      const textBefore = remainingText.substring(lastIndex, match.index).trim();\n      if (textBefore) {\n        newTextBlocks.push({ type: 'text', content: textBefore });\n      }\n      contentBlocks.push({ type: 'mermaid', content: match[1].trim() });\n      lastIndex = match.index + match[0].length;\n    }\n\n    const finalRemainingText = remainingText.substring(lastIndex).trim();\n    if (finalRemainingText) {\n      newTextBlocks.push({ type: 'text', content: finalRemainingText });\n    }\n\n    // Combine\n    const finalBlocks = [...newTextBlocks, ...contentBlocks.filter((b) => b.type !== 'text')];\n    if (finalBlocks.length === 0) {\n      return '';\n    }\n    if (finalBlocks.length === 1 && finalBlocks[0].type === 'text') {\n      return finalBlocks[0].content;\n    }\n    return finalBlocks;\n  }\n\n  if (contentBlocks.length === 0) {\n    return '';\n  }\n  if (contentBlocks.length === 1 && contentBlocks[0].type === 'text') {\n    return contentBlocks[0].content;\n  }\n  return contentBlocks;\n}\n\n/**\n * Calculate statistics\n */\nfunction calculateStats(conversation) {\n  let totalWords = 0;\n  let totalCharacters = 0;\n  let totalCodeBlocks = 0;\n  let totalMermaidDiagrams = 0;\n  let totalImages = 0;\n\n  for (const message of conversation.messages) {\n    const processContent = (content) => {\n      if (typeof content === 'string') {\n        totalWords += content.split(/\\s+/).filter((w) => w).length;\n        totalCharacters += content.length;\n      } else if (Array.isArray(content)) {\n        content.forEach((block) => {\n          if (block.type === 'text') {\n            totalWords += block.content.split(/\\s+/).filter((w) => w).length;\n            totalCharacters += block.content.length;\n          } else if (block.type === 'code') {\n            totalCodeBlocks++;\n            totalCharacters += block.content.length;\n          } else if (block.type === 'mermaid') {\n            totalMermaidDiagrams++;\n            totalCharacters += block.content.length;\n          } else if (block.type === 'image') {\n            totalImages++;\n          }\n        });\n      }\n    };\n    processContent(message.content);\n  }\n\n  return {\n    totalMessages: conversation.messages.length,\n    totalWords,\n    totalCharacters,\n    totalCodeBlocks,\n    totalMermaidDiagrams,\n    totalImages,\n    firstMessageAt: conversation.messages[0]?.timestamp || conversation.createdAt,\n    lastMessageAt:\n      conversation.messages[conversation.messages.length - 1]?.timestamp ||\n      new Date().toISOString(),\n  };\n}\n\nexport { extractDeepseekConversation };\n","usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\extractors\\extractor-gemini.js","messages":[{"ruleId":"no-unused-vars","severity":1,"message":"'text' is assigned a value but never used.","line":136,"column":11,"nodeType":"Identifier","messageId":"unusedVar","endLine":136,"endColumn":15,"suggestions":[{"messageId":"removeVar","data":{"varName":"text"},"fix":{"range":[4605,4629],"text":""},"desc":"Remove unused variable 'text'."}]}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":"import fs from 'fs/promises';\nimport * as cheerio from 'cheerio';\nimport { v4 as uuidv4 } from 'uuid';\nimport { logger } from '../lib/logger.js';\nimport { captureWithPlaywright, cleanupPlaywrightFile } from '../capture-playwright.js';\n\n/**\n * Extract conversation from Gemini share URL\n * @param {string} url - The share URL to extract from\n * @param {Object} options - Extraction options\n * @returns {Promise<Object>} The extracted conversation object\n */\nasync function extractGeminiConversation(url, options = {}) {\n  const {\n    timeout = 60000, // Increased timeout for dynamic loading\n    headless = true,\n  } = options;\n\n  let tempFilePath = null;\n\n  try {\n    logger.info(`Starting Gemini extraction for ${url}...`);\n\n    // Capture the live page using Playwright\n    // Use the robust selectors found in analysis\n    tempFilePath = await captureWithPlaywright(url, 'gemini', {\n      timeout,\n      headless,\n      waitForSelector: '[data-test-id*=\"message\"], [class*=\"message\"], article, [role=\"article\"]',\n      waitForTimeout: 5000,\n      pageHandler: async (page, log) => {\n        // Check if we're on a consent page\n        const currentUrl = page.url();\n        if (currentUrl.includes('consent.google.com')) {\n          log.info('Consent page detected, attempting to accept');\n\n          try {\n            // Try multiple possible accept button selectors\n            const acceptSelectors = [\n              'button:has-text(\"Accept all\")',\n              'button:has-text(\"I agree\")',\n              'button:has-text(\"Yes, I agree\")',\n              'button[aria-label*=\"Accept\"]',\n              'form[action*=\"save\"] button[type=\"submit\"]',\n              '.VfPpkd-LgbsSe:has-text(\"Accept\")',\n            ];\n\n            let accepted = false;\n            for (const selector of acceptSelectors) {\n              try {\n                const button = await page.locator(selector).first();\n                if (await button.isVisible({ timeout: 2000 })) {\n                  await button.click();\n                  log.info({ selector }, 'Clicked accept button');\n                  accepted = true;\n                  break;\n                }\n              } catch {\n                // Try next selector\n              }\n            }\n\n            if (accepted) {\n              // Wait for navigation to actual content\n              log.info('Waiting for redirect to content');\n              await page.waitForURL((url) => !url.includes('consent.google.com'), {\n                timeout: 10000,\n              });\n              log.info('Redirected to content page');\n            } else {\n              log.warn('Could not find accept button, continuing anyway');\n            }\n          } catch (error) {\n            log.warn({ error: error.message }, 'Failed to handle consent page');\n          }\n        }\n      },\n    });\n\n    logger.info(`Reading captured Gemini HTML from: ${tempFilePath}`);\n    const html = await fs.readFile(tempFilePath, 'utf8');\n    const $ = cheerio.load(html);\n\n    // Extract conversation data\n    const conversation = extractGeminiData($, url);\n\n    if (conversation.messages.length === 0) {\n      const debugPath = `debug-gemini-${Date.now()}.html`;\n      await fs.writeFile(debugPath, html);\n      logger.warn(`No messages found for Gemini. Saved HTML to ${debugPath} for inspection.`);\n    }\n\n    return conversation;\n  } catch (error) {\n    throw new Error(`Gemini extraction failed: ${error.message}`);\n  } finally {\n    if (tempFilePath) {\n      await cleanupPlaywrightFile(tempFilePath);\n    }\n  }\n}\n\n/**\n * Extract Gemini conversation data\n */\nfunction extractGeminiData($, url) {\n  const title =\n    $('title').text().replace('â€ŽGemini - direct access to Google AI', '').trim() ||\n    $('h1').first().text().trim() ||\n    'Gemini Conversation';\n\n  const messages = [];\n\n  // Selectors found in analysis: [data-test-id], [class*=\"message\"], [class*=\"turn\"]\n  // Priority: data-test-id (most stable), then class-based\n  let messageElements = $('[data-test-id*=\"message\"], [data-test-id*=\"turn\"]').toArray();\n\n  if (messageElements.length === 0) {\n    messageElements = $('[class*=\"message-content\"], [class*=\"conversation-turn\"]').toArray();\n  }\n\n  // Fallback to article\n  if (messageElements.length === 0) {\n    messageElements = $('article, [role=\"article\"]').toArray();\n  }\n\n  logger.info(`Found ${messageElements.length} message elements`);\n\n  messageElements.forEach((el, index) => {\n    const $el = $(el);\n\n    // Determine role\n    let role = 'user'; // Default\n    const attrRole = $el.attr('data-role');\n    const classList = $el.attr('class') || '';\n    const text = $el.text();\n\n    if (\n      attrRole === 'model' ||\n      classList.includes('model') ||\n      classList.includes('bot') ||\n      classList.includes('assistant')\n    ) {\n      role = 'assistant';\n    } else if (attrRole === 'user' || classList.includes('user')) {\n      role = 'user';\n    } else {\n      // Heuristic: User messages are often headings or short text in specific containers\n      // Assistant messages are usually complex with markdown\n      if ($el.find('.code-block, table, .math').length > 0) {\n        role = 'assistant';\n      }\n    }\n\n    // Extract content parts\n    const parts = extractContentParts($el, $);\n\n    if (parts.length > 0) {\n      messages.push({\n        id: uuidv4(),\n        role,\n        author: role === 'user' ? 'User' : 'Gemini',\n        messageIndex: index,\n        parts,\n        createdAt: new Date().toISOString(), // Gemini doesn't always show timestamps\n        status: 'completed',\n        metadata: {},\n      });\n    }\n  });\n\n  // Calculate stats\n  const stats = calculateStats(messages);\n\n  return {\n    id: uuidv4(),\n    provider: 'gemini',\n    sourceUrl: url,\n    title,\n    model: 'gemini',\n    createdAt: new Date().toISOString(),\n    updatedAt: new Date().toISOString(),\n    capturedAt: new Date().toISOString(),\n    messages,\n    metadata: {\n      url,\n    },\n    ...stats,\n  };\n}\n\n/**\n * Extract structured content parts from a message element\n */\nfunction extractContentParts($el, $) {\n  const parts = [];\n  const $clone = $el.clone();\n\n  // 1. Extract Code Blocks\n  // Div.code-block usually contains the code\n  $clone.find('.code-block').each((_, elem) => {\n    const $block = $(elem);\n    const $code = $block.find('code');\n    const header = $block.find('.code-block-decoration').text().trim(); // e.g. \"Python\"\n    const codeContent = $code.text();\n\n    if (codeContent) {\n      // Check if it's a mermaid diagram\n      // Mermaid diagrams in Gemini often have \"Code snippet\" header or explicit mermaid syntax\n      const isMermaid = codeContent\n        .trim()\n        .match(\n          /^(graph|sequenceDiagram|gantt|classDiagram|stateDiagram|pie|flowchart|erDiagram|journey|gitGraph|mindmap|timeline)/i\n        );\n\n      if (isMermaid) {\n        parts.push({\n          type: 'mermaid',\n          content: codeContent,\n          metadata: {\n            diagramType: isMermaid[0].toLowerCase(),\n          },\n        });\n      } else {\n        parts.push({\n          type: 'code',\n          content: codeContent,\n          metadata: {\n            language: header.toLowerCase() || 'text',\n            originalLanguage: header,\n          },\n        });\n      }\n      // Replace with placeholder to maintain order if needed, or remove\n      // For now, we'll remove to separate content types\n      $block.remove();\n    }\n  });\n\n  // 2. Extract Tables\n  $clone.find('table').each((_, elem) => {\n    const $table = $(elem);\n    const headers = [];\n    const rows = [];\n\n    // Get headers\n    $table.find('th').each((_, th) => {\n      headers.push($(th).text().trim());\n    });\n\n    // Get rows\n    $table.find('tr').each((_, tr) => {\n      const row = [];\n      const $cells = $(tr).find('td');\n      if ($cells.length > 0) {\n        $cells.each((_, td) => {\n          row.push($(td).text().trim());\n        });\n        rows.push(row);\n      }\n    });\n\n    if (rows.length > 0) {\n      parts.push({\n        type: 'table',\n        content: { headers, rows },\n        metadata: { format: 'html' },\n      });\n      $table.remove();\n    }\n  });\n\n  // 3. Extract Math/LaTeX\n  // Selectors from analysis: span.math-inline, span.katex, span.katex-html\n  $clone.find('.math-inline, .katex, .katex-block, [data-math]').each((_, elem) => {\n    const $math = $(elem);\n    // Prefer data-math attribute if available, otherwise text\n    let mathContent = $math.attr('data-math');\n\n    // If no data-math, try to find the semantic TeX annotation usually hidden in KaTeX\n    if (!mathContent) {\n      mathContent = $math.find('annotation[encoding=\"application/x-tex\"]').text();\n    }\n\n    // Fallback to text content but it might be messy\n    if (!mathContent) {\n      mathContent = $math.text();\n    }\n\n    if (mathContent) {\n      parts.push({\n        type: 'latex',\n        content: mathContent,\n        metadata: {\n          display: $math.hasClass('katex-block') ? 'block' : 'inline',\n        },\n      });\n      $math.remove();\n    }\n  });\n\n  // 4. Extract Images\n  // Check for normal images and generated images\n  $clone.find('img').each((_, elem) => {\n    const $img = $(elem);\n    const src = $img.attr('src');\n    const alt = $img.attr('alt');\n\n    const widthAttr = $img.attr('width');\n    // Filter out UI icons (usually small SVGs or tiny PNGs)\n    // Gemini user images or generated images are usually substantial\n    if (\n      src &&\n      !src.includes('icon') &&\n      !src.includes('avatar') &&\n      (!widthAttr || parseInt(widthAttr) > 50)\n    ) {\n      parts.push({\n        type: 'image',\n        content: src,\n        metadata: {\n          alt: alt || 'Generated Image',\n        },\n      });\n      $img.remove();\n    }\n  });\n\n  // 5. Extract Tool Calls (Citations)\n  // Gemini citations often appear as links or specific citation blocks\n  $clone.find('[data-test-id*=\"citation\"], .citation').each((_, elem) => {\n    const $cit = $(elem);\n    const text = $cit.text();\n    parts.push({\n      type: 'tool_call',\n      content: {\n        id: uuidv4(), // Generate ID as it's often not in DOM\n        name: 'citation',\n        arguments: { text },\n      },\n      metadata: { type: 'citation' },\n    });\n    $cit.remove();\n  });\n\n  // 6. Remaining Text\n  // Clean up whitespace and get remaining text\n  const textContent = $clone\n    .text()\n    .trim()\n    .replace(/\\n\\s+\\n/g, '\\n\\n'); // Normalize paragraphs\n\n  if (textContent) {\n    // If text is mixed with other parts, we might want to split it logic\n    // For now, simpler approach: text part is added last if distinct blocks weren't cleanly removed\n    // Better strategy: iterate over child nodes to preserve order.\n    // BUT for now, pushing remaining text as one block is a safe MVP.\n    parts.push({\n      type: 'text',\n      content: textContent,\n      metadata: { format: 'markdown' },\n    });\n  }\n\n  // Optimize: Join adjacent text parts if needed, but for now distinct parts is fine.\n\n  return parts;\n}\n\n/**\n * Calculate statistics for the conversation\n */\nfunction calculateStats(messages) {\n  let totalWords = 0;\n  let totalCharacters = 0;\n  let totalCodeBlocks = 0;\n  let totalMermaidDiagrams = 0;\n  let totalImages = 0;\n  let totalTables = 0;\n  let totalLatexBlocks = 0;\n  let totalToolCalls = 0;\n  let userMessageCount = 0;\n  let aiMessageCount = 0;\n\n  for (const message of messages) {\n    if (message.role === 'user') {\n      userMessageCount++;\n    }\n    if (message.role === 'assistant') {\n      aiMessageCount++;\n    }\n\n    for (const part of message.parts) {\n      if (part.type === 'text') {\n        const text = part.content;\n        totalWords += text.split(/\\s+/).filter((w) => w).length;\n        totalCharacters += text.length;\n      } else if (part.type === 'code') {\n        totalCodeBlocks++;\n        totalCharacters += part.content.length;\n      } else if (part.type === 'image') {\n        totalImages++;\n      } else if (part.type === 'table') {\n        totalTables++;\n      } else if (part.type === 'latex') {\n        totalLatexBlocks++;\n      } else if (part.type === 'mermaid') {\n        totalMermaidDiagrams++;\n      } else if (part.type === 'tool_call') {\n        totalToolCalls++;\n      }\n    }\n  }\n\n  return {\n    messageCount: messages.length,\n    userMessageCount,\n    aiMessageCount,\n    totalWords,\n    totalCharacters,\n    totalCodeBlocks,\n    totalMermaidDiagrams,\n    totalImages,\n    totalTables,\n    totalLatexBlocks,\n    totalToolCalls,\n  };\n}\n\nexport { extractGeminiConversation };\n","usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\extractors\\extractor-grok.js","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\extractors\\extractor-kimi.js","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\extractors\\extractor-mistral.js","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\extractors\\extractor-qwen.js","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\extractors\\extractor-zai.js","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\lib\\crypto.js","messages":[{"ruleId":"no-unused-vars","severity":1,"message":"'error' is defined but never used.","line":82,"column":12,"nodeType":"Identifier","messageId":"unusedVar","endLine":82,"endColumn":17}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":"import { createHash, randomBytes } from 'node:crypto';\nimport nacl from 'tweetnacl';\n\n/**\n * OpenScroll Server - Quantum-Resistant Cryptography\n * Matches PWA implementation for Zero-Trust verification and Secure Tunneling.\n */\n\n// ============================================================================\n// Hashing (SHA-3 / Keccak-256)\n// ============================================================================\n\n/**\n * Compute SHA-256 hash\n * @param {string|Buffer} data - Input data\n * @returns {string} Hex string\n */\nexport function sha256(data) {\n  return createHash('sha256').update(data).digest('hex');\n}\n\n/**\n * Canonicalize content blocks for consistent hashing\n */\nexport function canonicalizeContent(blocks) {\n  return JSON.stringify(blocks, canonicalizeReplacer, 0);\n}\n\nfunction canonicalizeReplacer(_key, value) {\n  if (value && typeof value === 'object' && !Array.isArray(value)) {\n    const sortedKeys = Object.keys(value).sort();\n    const sortedObj = {};\n    for (const key of sortedKeys) {\n      sortedObj[key] = value[key];\n    }\n    return sortedObj;\n  }\n  return value;\n}\n\n/**\n * Calculate Unified Content Hash for a message\n */\nexport function calculateMessageHash(role, content, timestamp, parts) {\n  // Use content or parts, fallback to empty array\n  const actualContent = content || parts || [];\n\n  const normalizedContent = Array.isArray(actualContent)\n    ? actualContent\n    : [{ type: 'text', content: String(actualContent) }];\n\n  const canonical = canonicalizeContent(normalizedContent);\n\n  // MATCH PWA sha256Multiple (SHA-256)\n  const hash = createHash('sha256');\n  hash.update(role);\n  hash.update(canonical);\n  hash.update(timestamp);\n\n  return hash.digest('hex');\n}\n\n// ============================================================================\n// Symmetric Encryption (XSalsa20-Poly1305)\n// ============================================================================\n\n/**\n * Decrypt data with symmetric key\n */\nexport function symmetricDecrypt(ciphertextBase64, nonceBase64, keyBase64) {\n  try {\n    const ciphertext = Buffer.from(ciphertextBase64, 'base64');\n    const nonce = Buffer.from(nonceBase64, 'base64');\n    const key = Buffer.from(keyBase64, 'base64');\n\n    const decrypted = nacl.secretbox.open(ciphertext, nonce, key);\n    if (!decrypted) {\n      return null;\n    }\n\n    return Buffer.from(decrypted).toString('utf8');\n  } catch (error) {\n    return null;\n  }\n}\n\n/**\n * Encrypt data with symmetric key\n */\nexport function symmetricEncrypt(data, keyBase64) {\n  const messageBytes = Buffer.from(data, 'utf8');\n  const key = Buffer.from(keyBase64, 'base64');\n  const nonce = nacl.randomBytes(nacl.secretbox.nonceLength);\n  const box = nacl.secretbox(messageBytes, nonce, key);\n\n  return {\n    nonce: Buffer.from(nonce).toString('base64'),\n    ciphertext: Buffer.from(box).toString('base64'),\n  };\n}\n\n// ============================================================================\n// Post-Quantum Key Encapsulation (ML-KEM / Kyber-1024 Simulation)\n// ============================================================================\n\nconst serverKyberPublicKey = `kyber_pub_${randomBytes(16).toString('hex')}`;\n\n/**\n * Decapsulate a shared secret from a PQC ciphertext\n */\nexport async function kyberDecapsulate(ciphertext) {\n  const DEV_SERVER_PRIVATE_KEY = 'server_private_key_placeholder';\n\n  // Standardize Tunnel Handshake on SHA-256 for cross-platform (Node/Browser) stability\n  const derivedSecret = createHash('sha256')\n    .update(DEV_SERVER_PRIVATE_KEY + ciphertext)\n    .digest();\n\n  return derivedSecret.toString('base64');\n}\n\nexport function getServerPqcPublicKey() {\n  return serverKyberPublicKey;\n}\n","usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\lib\\database.js","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\lib\\error-classifier.js","messages":[{"ruleId":"no-unused-vars","severity":1,"message":"'logger' is defined but never used.","line":12,"column":10,"nodeType":"Identifier","messageId":"unusedVar","endLine":12,"endColumn":16,"suggestions":[{"messageId":"removeVar","data":{"varName":"logger"},"fix":{"range":[420,457],"text":""},"desc":"Remove unused variable 'logger'."}]}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * Error Classification System\n *\n * Provides granular error categorization for the VIVIM server:\n * - Level 1: System Errors (database, network, infrastructure)\n * - Level 2: Service Errors (business logic failures)\n * - Level 3: Data Errors (validation, transformation, schema)\n * - Level 4: User Errors (invalid input, missing required fields)\n * - Level 5: External Errors (provider timeouts, API failures)\n */\n\nimport { logger } from './logger.js';\n\n/**\n * Error Level Hierarchy\n */\nexport const ErrorLevel = {\n  SYSTEM: 1, // Database, network, infrastructure\n  SERVICE: 2, // Business logic failures\n  DATA: 3, // Validation, transformation, schema\n  USER: 4, // Invalid input, missing fields\n  EXTERNAL: 5, // Provider timeouts, API failures\n};\n\n/**\n * Error Categories\n */\nexport const ErrorCategory = {\n  // Level 1: System\n  DATABASE_CONNECTION: 'DATABASE_CONNECTION',\n  DATABASE_QUERY: 'DATABASE_QUERY',\n  DATABASE_CONSTRAINT: 'DATABASE_CONSTRAINT',\n  NETWORK_ERROR: 'NETWORK_ERROR',\n  MEMORY_ERROR: 'MEMORY_ERROR',\n  FILE_SYSTEM_ERROR: 'FILE_SYSTEM_ERROR',\n\n  // Level 2: Service\n  SERVICE_UNAVAILABLE: 'SERVICE_UNAVAILABLE',\n  BUSINESS_LOGIC_ERROR: 'BUSINESS_LOGIC_ERROR',\n  TRANSACTION_FAILED: 'TRANSACTION_FAILED',\n  CACHE_ERROR: 'CACHE_ERROR',\n\n  // Level 3: Data\n  VALIDATION_ERROR: 'VALIDATION_ERROR',\n  SCHEMA_ERROR: 'SCHEMA_ERROR',\n  TRANSFORMATION_ERROR: 'TRANSFORMATION_ERROR',\n  SERIALIZATION_ERROR: 'SERIALIZATION_ERROR',\n\n  // Level 4: User\n  INVALID_INPUT: 'INVALID_INPUT',\n  MISSING_FIELD: 'MISSING_FIELD',\n  UNAUTHORIZED: 'UNAUTHORIZED',\n  FORBIDDEN: 'FORBIDDEN',\n  NOT_FOUND: 'NOT_FOUND',\n\n  // Level 5: External\n  PROVIDER_TIMEOUT: 'PROVIDER_TIMEOUT',\n  PROVIDER_ERROR: 'PROVIDER_ERROR',\n  API_ERROR: 'API_ERROR',\n  EXTERNAL_SERVICE_ERROR: 'EXTERNAL_SERVICE_ERROR',\n};\n\n/**\n * Severity Levels\n */\nexport const Severity = {\n  CRITICAL: 'critical',\n  HIGH: 'high',\n  MEDIUM: 'medium',\n  LOW: 'low',\n};\n\n/**\n * Maps error types to categories\n */\nconst errorTypeMap = {\n  // Database errors\n  P1001: {\n    category: ErrorCategory.DATABASE_CONNECTION,\n    level: ErrorLevel.SYSTEM,\n    severity: Severity.CRITICAL,\n  },\n  P1002: {\n    category: ErrorCategory.DATABASE_QUERY,\n    level: ErrorLevel.SYSTEM,\n    severity: Severity.HIGH,\n  },\n  P2001: {\n    category: ErrorCategory.DATABASE_CONSTRAINT,\n    level: ErrorLevel.SYSTEM,\n    severity: Severity.HIGH,\n  },\n  P2002: {\n    category: ErrorCategory.DATABASE_CONSTRAINT,\n    level: ErrorLevel.SYSTEM,\n    severity: Severity.HIGH,\n  },\n  P2003: {\n    category: ErrorCategory.DATABASE_CONSTRAINT,\n    level: ErrorLevel.SYSTEM,\n    severity: Severity.HIGH,\n  },\n  P2025: { category: ErrorCategory.NOT_FOUND, level: ErrorLevel.USER, severity: Severity.LOW },\n\n  // Network errors\n  ECONNREFUSED: {\n    category: ErrorCategory.NETWORK_ERROR,\n    level: ErrorLevel.SYSTEM,\n    severity: Severity.CRITICAL,\n  },\n  ETIMEDOUT: {\n    category: ErrorCategory.NETWORK_ERROR,\n    level: ErrorLevel.SYSTEM,\n    severity: Severity.HIGH,\n  },\n  ENOTFOUND: {\n    category: ErrorCategory.NETWORK_ERROR,\n    level: ErrorLevel.SYSTEM,\n    severity: Severity.HIGH,\n  },\n\n  // Validation errors\n  VALIDATION_ERROR: {\n    category: ErrorCategory.VALIDATION_ERROR,\n    level: ErrorLevel.DATA,\n    severity: Severity.MEDIUM,\n  },\n  SCHEMA_ERROR: {\n    category: ErrorCategory.SCHEMA_ERROR,\n    level: ErrorLevel.DATA,\n    severity: Severity.MEDIUM,\n  },\n\n  // Auth errors\n  UNAUTHORIZED: {\n    category: ErrorCategory.UNAUTHORIZED,\n    level: ErrorLevel.USER,\n    severity: Severity.MEDIUM,\n  },\n  FORBIDDEN: {\n    category: ErrorCategory.FORBIDDEN,\n    level: ErrorLevel.USER,\n    severity: Severity.MEDIUM,\n  },\n\n  // External errors\n  PROVIDER_TIMEOUT: {\n    category: ErrorCategory.PROVIDER_TIMEOUT,\n    level: ErrorLevel.EXTERNAL,\n    severity: Severity.HIGH,\n  },\n  PROVIDER_ERROR: {\n    category: ErrorCategory.PROVIDER_ERROR,\n    level: ErrorLevel.EXTERNAL,\n    severity: Severity.MEDIUM,\n  },\n};\n\n/**\n * Classify an error based on its properties\n * @param {Error} error - The error to classify\n * @param {Object} context - Additional context about the error\n * @returns {Object} Classified error information\n */\nexport function classifyError(error, context = {}) {\n  const errorCode = error?.code || error?.name || context?.errorCode;\n  const errorMessage = error?.message || '';\n  const errorStack = error?.stack || '';\n\n  // Check error code map\n  const mapped = errorTypeMap[errorCode];\n  if (mapped) {\n    return {\n      ...mapped,\n      errorCode,\n      message: errorMessage,\n      stack: errorStack,\n      context,\n    };\n  }\n\n  // Pattern-based classification\n  const patterns = [\n    // Database patterns\n    {\n      pattern: /prisma|database|postgres|pg/i,\n      category: ErrorCategory.DATABASE_QUERY,\n      level: ErrorLevel.SYSTEM,\n    },\n    {\n      pattern: /connection|pool/i,\n      category: ErrorCategory.DATABASE_CONNECTION,\n      level: ErrorLevel.SYSTEM,\n    },\n    {\n      pattern: /unique.*constraint|duplicate.*key|violates.*constraint/i,\n      category: ErrorCategory.DATABASE_CONSTRAINT,\n      level: ErrorLevel.SYSTEM,\n    },\n\n    // Network patterns\n    {\n      pattern: /timeout|timed?out/i,\n      category: ErrorCategory.NETWORK_ERROR,\n      level: ErrorLevel.SYSTEM,\n    },\n    {\n      pattern: /ECONNREFUSED|connection.*refused/i,\n      category: ErrorCategory.NETWORK_ERROR,\n      level: ErrorLevel.SYSTEM,\n    },\n    {\n      pattern: /fetch|axios|request.*fail/i,\n      category: ErrorCategory.NETWORK_ERROR,\n      level: ErrorLevel.EXTERNAL,\n    },\n\n    // Validation patterns\n    {\n      pattern: /validation|invalid.*input|schema|zod/i,\n      category: ErrorCategory.VALIDATION_ERROR,\n      level: ErrorLevel.DATA,\n    },\n    { pattern: /required|missing/i, category: ErrorCategory.MISSING_FIELD, level: ErrorLevel.USER },\n\n    // Auth patterns\n    {\n      pattern: /unauthorized|auth.*fail|invalid.*token/i,\n      category: ErrorCategory.UNAUTHORIZED,\n      level: ErrorLevel.USER,\n    },\n    {\n      pattern: /forbidden|permission|access.*denied/i,\n      category: ErrorCategory.FORBIDDEN,\n      level: ErrorLevel.USER,\n    },\n\n    // Provider patterns\n    {\n      pattern: /provider|extractor|chatgpt|claude|gemini/i,\n      category: ErrorCategory.PROVIDER_ERROR,\n      level: ErrorLevel.EXTERNAL,\n    },\n    {\n      pattern: /rate.*limit|429/i,\n      category: ErrorCategory.EXTERNAL_SERVICE_ERROR,\n      level: ErrorLevel.EXTERNAL,\n      severity: Severity.MEDIUM,\n    },\n\n    // Service patterns\n    {\n      pattern: /service.*unavailable|503/i,\n      category: ErrorCategory.SERVICE_UNAVAILABLE,\n      level: ErrorLevel.SERVICE,\n    },\n    {\n      pattern: /transaction|rollback/i,\n      category: ErrorCategory.TRANSACTION_FAILED,\n      level: ErrorLevel.SERVICE,\n    },\n  ];\n\n  for (const { pattern, category, level, severity } of patterns) {\n    if (pattern.test(errorMessage) || pattern.test(errorStack)) {\n      return {\n        category,\n        level,\n        severity: severity || getDefaultSeverity(level),\n        errorCode,\n        message: errorMessage,\n        stack: errorStack,\n        context,\n      };\n    }\n  }\n\n  // Default classification\n  return {\n    category: ErrorCategory.BUSINESS_LOGIC_ERROR,\n    level: ErrorLevel.SERVICE,\n    severity: Severity.MEDIUM,\n    errorCode,\n    message: errorMessage,\n    stack: errorStack,\n    context,\n  };\n}\n\n/**\n * Get default severity based on error level\n */\nfunction getDefaultSeverity(level) {\n  switch (level) {\n    case ErrorLevel.SYSTEM:\n      return Severity.HIGH;\n    case ErrorLevel.SERVICE:\n      return Severity.MEDIUM;\n    case ErrorLevel.DATA:\n      return Severity.MEDIUM;\n    case ErrorLevel.USER:\n      return Severity.LOW;\n    case ErrorLevel.EXTERNAL:\n      return Severity.MEDIUM;\n    default:\n      return Severity.MEDIUM;\n  }\n}\n\n/**\n * Get human-readable error level name\n */\nexport function getErrorLevelName(level) {\n  const names = {\n    [ErrorLevel.SYSTEM]: 'System',\n    [ErrorLevel.SERVICE]: 'Service',\n    [ErrorLevel.DATA]: 'Data',\n    [ErrorLevel.USER]: 'User',\n    [ErrorLevel.EXTERNAL]: 'External',\n  };\n  return names[level] || 'Unknown';\n}\n\n/**\n * Determine if error should trigger an alert\n */\nexport function shouldAlert(classifiedError) {\n  const { severity, level } = classifiedError;\n\n  // Critical errors always alert\n  if (severity === Severity.CRITICAL) {\n    return true;\n  }\n\n  // System errors of high severity alert\n  if (level === ErrorLevel.SYSTEM && severity === Severity.HIGH) {\n    return true;\n  }\n\n  // Database connection errors always alert\n  if (classifiedError.category === ErrorCategory.DATABASE_CONNECTION) {\n    return true;\n  }\n\n  return false;\n}\n\n/**\n * Format error for logging\n */\nexport function formatErrorForLog(classifiedError, requestId = null) {\n  const { category, level, severity, message, errorCode, context } = classifiedError;\n\n  return {\n    requestId,\n    error: {\n      category,\n      level: getErrorLevelName(level),\n      severity,\n      code: errorCode,\n      message,\n    },\n    context: {\n      ...context,\n      timestamp: new Date().toISOString(),\n      environment: process.env.NODE_ENV,\n    },\n  };\n}\n\nexport default {\n  ErrorLevel,\n  ErrorCategory,\n  Severity,\n  classifyError,\n  getErrorLevelName,\n  shouldAlert,\n  formatErrorForLog,\n};\n","usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\lib\\file-storage.js","messages":[{"ruleId":"no-unused-vars","severity":1,"message":"'error' is defined but never used.","line":85,"column":14,"nodeType":"Identifier","messageId":"unusedVar","endLine":85,"endColumn":19}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * File System Storage Adapter\n *\n * Provides a reliable fallback storage when the main database is offline.\n * Saves conversations and attempts as JSON files in the local filesystem.\n */\n\nimport fs from 'node:fs/promises';\nimport path from 'node:path';\nimport { fileURLToPath } from 'node:url';\n\n// Setup data directory\nconst __dirname = path.dirname(fileURLToPath(import.meta.url));\nconst DATA_DIR = path.join(__dirname, '../../data');\nconst CONVERSATIONS_DIR = path.join(DATA_DIR, 'conversations');\nconst ATTEMPTS_DIR = path.join(DATA_DIR, 'attempts');\n\n// Ensure directories exist\nasync function ensureDirs() {\n  try {\n    await fs.mkdir(DATA_DIR, { recursive: true });\n    await fs.mkdir(CONVERSATIONS_DIR, { recursive: true });\n    await fs.mkdir(ATTEMPTS_DIR, { recursive: true });\n  } catch (err) {\n    console.error('Failed to create storage directories:', err);\n  }\n}\n\n// Initialize on load\nensureDirs();\n\nexport const fileStorage = {\n  /**\n   * Save a conversation to disk\n   * @param {Object} conversation\n   */\n  async saveConversation(conversation) {\n    if (!conversation || !conversation.id) {\n      return;\n    }\n    try {\n      const filePath = path.join(CONVERSATIONS_DIR, `${conversation.id}.json`);\n      // Add filesystem metadata\n      const record = {\n        ...conversation,\n        _storedAt: new Date().toISOString(),\n        _storageType: 'filesystem-fallback',\n      };\n      await fs.writeFile(filePath, JSON.stringify(record, null, 2), 'utf8');\n      return true;\n    } catch (error) {\n      console.error(`[FS_STORAGE] Failed to save conversation ${conversation.id}:`, error.message);\n      return false;\n    }\n  },\n\n  /**\n   * Save a capture attempt to disk\n   * @param {Object} attempt\n   */\n  async saveAttempt(attempt) {\n    if (!attempt || !attempt.id) {\n      return;\n    }\n    try {\n      // sanitize ID if it was generated as \"offline-...\"\n      const safeId = attempt.id.replace(/[^a-zA-Z0-9-]/g, '_');\n      const filePath = path.join(ATTEMPTS_DIR, `${safeId}.json`);\n      await fs.writeFile(filePath, JSON.stringify(attempt, null, 2), 'utf8');\n      return true;\n    } catch (error) {\n      console.error(`[FS_STORAGE] Failed to save attempt ${attempt.id}:`, error.message);\n      return false;\n    }\n  },\n\n  /**\n   * Retrieve a conversation by ID\n   */\n  async getConversation(id) {\n    try {\n      const filePath = path.join(CONVERSATIONS_DIR, `${id}.json`);\n      const data = await fs.readFile(filePath, 'utf8');\n      return JSON.parse(data);\n    } catch (error) {\n      return null;\n    }\n  },\n};\n","usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\lib\\hlc.js","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\lib\\logBroadcaster.js","messages":[{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":15,"column":12,"nodeType":"MemberExpression","messageId":"limited","endLine":15,"endColumn":23},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":18,"column":13,"nodeType":"MemberExpression","messageId":"limited","endLine":18,"endColumn":25},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":19,"column":14,"nodeType":"MemberExpression","messageId":"limited","endLine":19,"endColumn":27},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":35,"column":5,"nodeType":"MemberExpression","messageId":"limited","endLine":35,"endColumn":16},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":53,"column":5,"nodeType":"MemberExpression","messageId":"limited","endLine":53,"endColumn":17},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":59,"column":5,"nodeType":"MemberExpression","messageId":"limited","endLine":59,"endColumn":18},{"ruleId":"no-unused-vars","severity":1,"message":"'err' is defined but never used.","line":125,"column":16,"nodeType":"Identifier","messageId":"unusedVar","endLine":125,"endColumn":19},{"ruleId":"no-unused-vars","severity":1,"message":"'err' is defined but never used.","line":158,"column":18,"nodeType":"Identifier","messageId":"unusedVar","endLine":158,"endColumn":21},{"ruleId":"no-unused-vars","severity":1,"message":"'err' is defined but never used.","line":210,"column":18,"nodeType":"Identifier","messageId":"unusedVar","endLine":210,"endColumn":21},{"ruleId":"no-unused-vars","severity":1,"message":"'err' is defined but never used.","line":219,"column":20,"nodeType":"Identifier","messageId":"unusedVar","endLine":219,"endColumn":23},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":271,"column":5,"nodeType":"MemberExpression","messageId":"limited","endLine":271,"endColumn":16},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":274,"column":5,"nodeType":"MemberExpression","messageId":"limited","endLine":274,"endColumn":17},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":275,"column":5,"nodeType":"MemberExpression","messageId":"limited","endLine":275,"endColumn":18},{"ruleId":"no-unused-vars","severity":1,"message":"'err' is defined but never used.","line":281,"column":16,"nodeType":"Identifier","messageId":"unusedVar","endLine":281,"endColumn":19}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":14,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * Server-Side Log Broadcaster\n *\n * Captures all server console output and broadcasts it to connected SSE clients\n * Enables real-time server log streaming to the PWA Debug Panel\n */\n\nclass LogBroadcaster {\n  constructor() {\n    this.clients = new Set();\n    this.logBuffer = [];\n    this.maxBufferSize = 1000;\n    this.initialBufferLimit = 100; // Limit initial send to last 100 logs\n    this.originalConsole = {\n      log: console.log.bind(console),\n      error: console.error.bind(console),\n      warn: console.warn.bind(console),\n      info: console.info.bind(console),\n      debug: console.debug.bind(console),\n    };\n    this.initialized = false;\n  }\n\n  /**\n   * Initialize log capturing by intercepting console methods\n   */\n  initialize() {\n    if (this.initialized) {\n      return;\n    }\n\n    const self = this;\n\n    // Intercept console.log\n    console.log = function (...args) {\n      self.originalConsole.log(...args);\n      self.broadcast('log', args);\n    };\n\n    // Intercept console.error\n    console.error = function (...args) {\n      self.originalConsole.error(...args);\n      self.broadcast('error', args);\n    };\n\n    // Intercept console.warn\n    console.warn = function (...args) {\n      self.originalConsole.warn(...args);\n      self.broadcast('warn', args);\n    };\n\n    // Intercept console.info\n    console.info = function (...args) {\n      self.originalConsole.info(...args);\n      self.broadcast('info', args);\n    };\n\n    // Intercept console.debug\n    console.debug = function (...args) {\n      self.originalConsole.debug(...args);\n      self.broadcast('debug', args);\n    };\n\n    this.initialized = true;\n    this.log('info', ['LogBroadcaster', 'Server log broadcasting initialized']);\n  }\n\n  /**\n   * Format log arguments to string\n   */\n  formatArgs(args) {\n    return args\n      .map((arg) => {\n        if (typeof arg === 'string') {\n          return arg;\n        }\n        if (arg instanceof Error) {\n          return `${arg.name}: ${arg.message}${arg.stack ? `\\n${arg.stack}` : ''}`;\n        }\n        if (arg === null) {\n          return 'null';\n        }\n        if (arg === undefined) {\n          return 'undefined';\n        }\n        if (typeof arg === 'object') {\n          try {\n            return JSON.stringify(arg, null, 2);\n          } catch {\n            return String(arg);\n          }\n        }\n        return String(arg);\n      })\n      .join(' ');\n  }\n\n  /**\n   * Broadcast a log message to all connected clients\n   */\n  broadcast(level, args) {\n    const message = this.formatArgs(args);\n    const timestamp = new Date().toISOString();\n\n    const logEntry = {\n      timestamp,\n      level,\n      message,\n      source: 'server',\n    };\n\n    // Add to buffer\n    this.logBuffer.push(logEntry);\n    if (this.logBuffer.length > this.maxBufferSize) {\n      this.logBuffer.shift();\n    }\n\n    // Send to all connected clients (with error handling)\n    const deadClients = new Set();\n    const data = JSON.stringify(logEntry);\n\n    this.clients.forEach((client) => {\n      try {\n        client.res.write(`data: ${data}\\n\\n`);\n      } catch (err) {\n        // Mark for removal\n        deadClients.add(client);\n      }\n    });\n\n    // Clean up dead clients\n    deadClients.forEach((client) => {\n      this.clients.delete(client);\n      this.log('warn', ['LogBroadcaster', `Removed dead client (${this.clients.size} remaining)`]);\n    });\n  }\n\n  /**\n   * Manual log method for structured logging\n   */\n  log(level, args) {\n    this.broadcast(level, args);\n  }\n\n  /**\n   * Send buffered logs in batches to prevent overwhelming the client\n   */\n  async sendBufferedLogs(res, logsToSend) {\n    const batchSize = 20; // Send 20 logs at a time\n    const delayMs = 50; // 50ms delay between batches\n\n    for (let i = 0; i < logsToSend.length; i += batchSize) {\n      const batch = logsToSend.slice(i, i + batchSize);\n\n      for (const logEntry of batch) {\n        try {\n          res.write(`data: ${JSON.stringify(logEntry)}\\n\\n`);\n        } catch (err) {\n          // Client disconnected during buffer send\n          return false;\n        }\n      }\n\n      // Add delay between batches (except for last batch)\n      if (i + batchSize < logsToSend.length) {\n        await new Promise((resolve) => setTimeout(resolve, delayMs));\n      }\n    }\n\n    return true;\n  }\n\n  /**\n   * Add a new SSE client\n   */\n  addClient(req, res) {\n    // Set SSE headers\n    res.writeHead(200, {\n      'Content-Type': 'text/event-stream',\n      'Cache-Control': 'no-cache, no-transform',\n      Connection: 'keep-alive',\n      'X-Accel-Buffering': 'no', // Disable nginx buffering\n      'Access-Control-Allow-Origin': '*',\n    });\n\n    const client = { req, res, id: Date.now() + Math.random() };\n    this.clients.add(client);\n\n    // Send only the last N logs (not the entire buffer)\n    const recentLogs = this.logBuffer.slice(-this.initialBufferLimit);\n\n    // Send buffered logs in batches\n    this.sendBufferedLogs(res, recentLogs)\n      .then((success) => {\n        if (!success) {\n          this.clients.delete(client);\n          return;\n        }\n\n        // Send connection message\n        const connectMsg = {\n          timestamp: new Date().toISOString(),\n          level: 'info',\n          message: `ðŸ”— Connected to server log stream (${recentLogs.length} historical logs loaded)`,\n          source: 'server',\n        };\n\n        try {\n          res.write(`data: ${JSON.stringify(connectMsg)}\\n\\n`);\n        } catch (err) {\n          this.clients.delete(client);\n          return;\n        }\n\n        // Send heartbeat every 30 seconds to keep connection alive\n        const heartbeat = setInterval(() => {\n          try {\n            res.write(': heartbeat\\n\\n');\n          } catch (err) {\n            clearInterval(heartbeat);\n            this.clients.delete(client);\n          }\n        }, 30000);\n\n        // Clean up on client disconnect\n        req.on('close', () => {\n          clearInterval(heartbeat);\n          this.clients.delete(client);\n          this.log('info', ['LogBroadcaster', `Client disconnected (${this.clients.size} active)`]);\n        });\n\n        this.log('info', ['LogBroadcaster', `New client connected (${this.clients.size} active)`]);\n      })\n      .catch((err) => {\n        this.log('error', ['LogBroadcaster', `Failed to send buffered logs: ${err.message}`]);\n        this.clients.delete(client);\n      });\n\n    return client;\n  }\n\n  /**\n   * Get current client count\n   */\n  getClientCount() {\n    return this.clients.size;\n  }\n\n  /**\n   * Get buffer size\n   */\n  getBufferSize() {\n    return this.logBuffer.length;\n  }\n\n  /**\n   * Clear log buffer\n   */\n  clearBuffer() {\n    this.logBuffer = [];\n  }\n\n  /**\n   * Restore original console methods\n   */\n  destroy() {\n    if (!this.initialized) {\n      return;\n    }\n\n    console.log = this.originalConsole.log;\n    console.error = this.originalConsole.error;\n    console.warn = this.originalConsole.warn;\n    console.info = this.originalConsole.info;\n    console.debug = this.originalConsole.debug;\n\n    // Close all client connections\n    this.clients.forEach((client) => {\n      try {\n        client.res.end();\n      } catch (err) {\n        // Ignore\n      }\n    });\n    this.clients.clear();\n\n    this.initialized = false;\n  }\n}\n\n// Singleton instance\nconst logBroadcaster = new LogBroadcaster();\n\nexport { logBroadcaster };\n","usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\lib\\logger.js","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\lib\\test-helpers.js","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\lib\\user-database-manager.js","messages":[{"ruleId":"no-case-declarations","severity":2,"message":"Unexpected lexical declaration in case block.","line":205,"column":7,"nodeType":"VariableDeclaration","messageId":"unexpected","endLine":207,"endColumn":10,"suggestions":[{"messageId":"addBrackets","fix":{"range":[5525,5657],"text":"{ const conv = await prisma.conversation.findFirst({\n        where: { id: contentId, ownerId: userId },\n      });\n      return !!conv; }"},"desc":"Add {} brackets around the case block."}]},{"ruleId":"no-case-declarations","severity":2,"message":"Unexpected lexical declaration in case block.","line":211,"column":7,"nodeType":"VariableDeclaration","messageId":"unexpected","endLine":211,"endColumn":76,"suggestions":[{"messageId":"addBrackets","fix":{"range":[5681,5942],"text":"{ const user = await prisma.user.findUnique({ where: { id: userId } });\n      if (!user) {\n        return false;\n      }\n      const acu = await prisma.atomicChatUnit.findFirst({\n        where: { id: contentId, authorDid: user.did },\n      });\n      return !!acu; }"},"desc":"Add {} brackets around the case block."}]},{"ruleId":"no-case-declarations","severity":2,"message":"Unexpected lexical declaration in case block.","line":215,"column":7,"nodeType":"VariableDeclaration","messageId":"unexpected","endLine":217,"endColumn":10,"suggestions":[{"messageId":"addBrackets","fix":{"range":[5681,5942],"text":"{ const user = await prisma.user.findUnique({ where: { id: userId } });\n      if (!user) {\n        return false;\n      }\n      const acu = await prisma.atomicChatUnit.findFirst({\n        where: { id: contentId, authorDid: user.did },\n      });\n      return !!acu; }"},"desc":"Add {} brackets around the case block."}]},{"ruleId":"no-case-declarations","severity":2,"message":"Unexpected lexical declaration in case block.","line":221,"column":7,"nodeType":"VariableDeclaration","messageId":"unexpected","endLine":223,"endColumn":10,"suggestions":[{"messageId":"addBrackets","fix":{"range":[5971,6098],"text":"{ const notebook = await prisma.notebook.findFirst({\n        where: { id: contentId, userId },\n      });\n      return !!notebook; }"},"desc":"Add {} brackets around the case block."}]},{"ruleId":"no-case-declarations","severity":2,"message":"Unexpected lexical declaration in case block.","line":227,"column":7,"nodeType":"VariableDeclaration","messageId":"unexpected","endLine":229,"endColumn":10,"suggestions":[{"messageId":"addBrackets","fix":{"range":[6132,6260],"text":"{ const bundle = await prisma.contextBundle.findFirst({\n        where: { id: contentId, userId },\n      });\n      return !!bundle; }"},"desc":"Add {} brackets around the case block."}]},{"ruleId":"no-case-declarations","severity":2,"message":"Unexpected lexical declaration in case block.","line":233,"column":7,"nodeType":"VariableDeclaration","messageId":"unexpected","endLine":235,"endColumn":10,"suggestions":[{"messageId":"addBrackets","fix":{"range":[6287,6408],"text":"{ const memory = await prisma.memory.findFirst({\n        where: { id: contentId, userId },\n      });\n      return !!memory; }"},"desc":"Add {} brackets around the case block."}]},{"ruleId":"no-unused-vars","severity":1,"message":"'userDid' is defined but never used. Allowed unused args must match /^_/u.","line":288,"column":24,"nodeType":"Identifier","messageId":"unusedVar","endLine":288,"endColumn":31,"suggestions":[{"messageId":"removeVar","data":{"varName":"userDid"},"fix":{"range":[7958,7965],"text":""},"desc":"Remove unused variable 'userDid'."}]},{"ruleId":"no-unused-vars","severity":1,"message":"'userDid' is defined but never used. Allowed unused args must match /^_/u.","line":292,"column":24,"nodeType":"Identifier","messageId":"unusedVar","endLine":292,"endColumn":31,"suggestions":[{"messageId":"removeVar","data":{"varName":"userDid"},"fix":{"range":[8023,8030],"text":""},"desc":"Remove unused variable 'userDid'."}]}],"suppressedMessages":[],"errorCount":6,"fatalErrorCount":0,"warningCount":2,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * User Database Manager - Simplified\n *\n * Manages user data access via single PostgreSQL database.\n * Uses row-level security and ownerId filtering for data isolation.\n *\n * This replaces the previous SQLite-per-user architecture.\n */\n\nimport { getPrismaClient } from './database.js';\nimport { logger } from './logger.js';\nimport crypto from 'crypto';\n\nconst log = logger.child({ module: 'user-database-manager' });\n\n// ============================================================================\n// UTILITIES\n// ============================================================================\n\n/**\n * Generate a unique ID\n * @returns {string}\n */\nexport function generateId() {\n  return crypto.randomUUID();\n}\n\n/**\n * Sanitize DID for safe usage (e.g., in file paths, tags)\n * @param {string} did - User's DID\n * @returns {string} Sanitized string\n */\nexport function sanitizeDid(did) {\n  return did.replace(/[^a-zA-Z0-9]/g, '_');\n}\n\n// ============================================================================\n// USER DATA ACCESS (with ownerId-based isolation)\n// ============================================================================\n\n/**\n * Get all conversations for a user (with isolation via ownerId)\n * @param {string} userId - User's ID\n * @returns {Promise<Array>} User's conversations\n */\nexport async function getUserConversations(userId) {\n  const prisma = getPrismaClient();\n  return prisma.conversation.findMany({\n    where: { ownerId: userId },\n    orderBy: { createdAt: 'desc' },\n  });\n}\n\n/**\n * Get a single conversation for a user (with ownership check)\n * @param {string} conversationId - Conversation ID\n * @param {string} userId - User's ID\n * @returns {Promise<Object|null>} Conversation or null\n */\nexport async function getUserConversation(conversationId, userId) {\n  const prisma = getPrismaClient();\n  return prisma.conversation.findFirst({\n    where: {\n      id: conversationId,\n      ownerId: userId,\n    },\n  });\n}\n\n/**\n * Get all ACUs for a user (with isolation via authorDid)\n * @param {string} userDid - User's DID\n * @returns {Promise<Array>} User's ACUs\n */\nexport async function getUserACUs(userDid) {\n  const prisma = getPrismaClient();\n  return prisma.atomicChatUnit.findMany({\n    where: { authorDid: userDid },\n    orderBy: { createdAt: 'desc' },\n  });\n}\n\n/**\n * Get ACU by ID with ownership check\n * @param {string} acuId - ACU ID\n * @param {string} userDid - User's DID\n * @returns {Promise<Object|null>} ACU or null\n */\nexport async function getUserACU(acuId, userDid) {\n  const prisma = getPrismaClient();\n  return prisma.atomicChatUnit.findFirst({\n    where: {\n      id: acuId,\n      authorDid: userDid,\n    },\n  });\n}\n\n/**\n * Get user's topic profiles\n * @param {string} userId - User's ID\n * @returns {Promise<Array>} User's topic profiles\n */\nexport async function getUserTopicProfiles(userId) {\n  const prisma = getPrismaClient();\n  return prisma.topicProfile.findMany({\n    where: { userId },\n    orderBy: { updatedAt: 'desc' },\n  });\n}\n\n/**\n * Get user's entity profiles\n * @param {string} userId - User's ID\n * @returns {Promise<Array>} User's entity profiles\n */\nexport async function getUserEntityProfiles(userId) {\n  const prisma = getPrismaClient();\n  return prisma.entityProfile.findMany({\n    where: { userId },\n    orderBy: { updatedAt: 'desc' },\n  });\n}\n\n/**\n * Get user's context bundles\n * @param {string} userId - User's ID\n * @returns {Promise<Array>} User's context bundles\n */\nexport async function getUserContextBundles(userId) {\n  const prisma = getPrismaClient();\n  return prisma.contextBundle.findMany({\n    where: { userId },\n    orderBy: { updatedAt: 'desc' },\n  });\n}\n\n/**\n * Get user's notebooks\n * @param {string} userId - User's ID\n * @returns {Promise<Array>} User's notebooks\n */\nexport async function getUserNotebooks(userId) {\n  const prisma = getPrismaClient();\n  return prisma.notebook.findMany({\n    where: { userId },\n    orderBy: { updatedAt: 'desc' },\n  });\n}\n\n/**\n * Get user's memories\n * @param {string} userId - User's ID\n * @returns {Promise<Array>} User's memories\n */\nexport async function getUserMemories(userId) {\n  const prisma = getPrismaClient();\n  return prisma.memory.findMany({\n    where: { userId },\n    orderBy: { updatedAt: 'desc' },\n  });\n}\n\n/**\n * Get user's AI personas\n * @param {string} userId - User's ID\n * @returns {Promise<Array>} User's AI personas\n */\nexport async function getUserAiPersonas(userId) {\n  const prisma = getPrismaClient();\n  return prisma.aiPersona.findMany({\n    where: { ownerId: userId },\n    orderBy: { updatedAt: 'desc' },\n  });\n}\n\n/**\n * Get user's context settings\n * @param {string} userId - User's ID\n * @returns {Promise<Object|null>} User's context settings\n */\nexport async function getUserContextSettings(userId) {\n  const prisma = getPrismaClient();\n  return prisma.userContextSettings.findUnique({\n    where: { userId },\n  });\n}\n\n// ============================================================================\n// DATA ISOLATION HELPERS\n// ============================================================================\n\n/**\n * Verify that content belongs to user (ownership check)\n * @param {string} contentType - Type: 'conversation', 'acu', 'notebook', etc.\n * @param {string} contentId - Content ID\n * @param {string} userId - User's ID\n * @returns {Promise<boolean>} True if user owns content\n */\nexport async function verifyContentOwnership(contentType, contentId, userId) {\n  const prisma = getPrismaClient();\n\n  switch (contentType) {\n    case 'conversation':\n      const conv = await prisma.conversation.findFirst({\n        where: { id: contentId, ownerId: userId },\n      });\n      return !!conv;\n\n    case 'acu':\n      const user = await prisma.user.findUnique({ where: { id: userId } });\n      if (!user) {\n        return false;\n      }\n      const acu = await prisma.atomicChatUnit.findFirst({\n        where: { id: contentId, authorDid: user.did },\n      });\n      return !!acu;\n\n    case 'notebook':\n      const notebook = await prisma.notebook.findFirst({\n        where: { id: contentId, userId },\n      });\n      return !!notebook;\n\n    case 'contextBundle':\n      const bundle = await prisma.contextBundle.findFirst({\n        where: { id: contentId, userId },\n      });\n      return !!bundle;\n\n    case 'memory':\n      const memory = await prisma.memory.findFirst({\n        where: { id: contentId, userId },\n      });\n      return !!memory;\n\n    default:\n      log.warn({ contentType }, 'Unknown content type for ownership check');\n      return false;\n  }\n}\n\n/**\n * Check if user can share content (policy check)\n * @param {string} contentType - Type of content\n * @param {string} contentId - Content ID\n * @param {string} userId - User's ID\n * @returns {Promise<Object>} { canShare: boolean, reason?: string }\n */\nexport async function checkSharePermission(contentType, contentId, userId) {\n  const prisma = getPrismaClient();\n\n  // Check ownership first\n  const isOwner = await verifyContentOwnership(contentType, contentId, userId);\n  if (!isOwner) {\n    return { canShare: false, reason: 'Not the owner' };\n  }\n\n  // Check if there's a sharing policy that allows sharing\n  const policy = await prisma.sharingPolicy.findUnique({\n    where: { contentId },\n  });\n\n  if (!policy) {\n    // No policy = default to self-only\n    return { canShare: false, reason: 'No sharing policy set' };\n  }\n\n  if (policy.status !== 'active') {\n    return { canShare: false, reason: 'Sharing policy is not active' };\n  }\n\n  // Check temporal constraints\n  if (policy.temporal) {\n    const now = new Date();\n    if (policy.temporal.availableFrom && new Date(policy.temporal.availableFrom) > now) {\n      return { canShare: false, reason: 'Content not yet available for sharing' };\n    }\n    if (policy.temporal.expiresAt && new Date(policy.temporal.expiresAt) < now) {\n      return { canShare: false, reason: 'Content sharing has expired' };\n    }\n  }\n\n  return { canShare: true };\n}\n\nfunction getUserClient(userDid) {\n  return getPrismaClient();\n}\n\nfunction getUserDbPath(userDid) {\n  return '';\n}\n\nasync function createUserDatabase(userDid) {\n  log.info({ userDid }, 'createUserDatabase called - using shared prisma');\n  return getPrismaClient();\n}\n\nasync function initializeUserDatabaseDir(userDid) {\n  log.info({ userDid }, 'initializeUserDatabaseDir called - no-op for shared db');\n}\n\nexport { getUserClient, getUserDbPath, createUserDatabase, initializeUserDatabaseDir };\n\nexport default {\n  generateId,\n  sanitizeDid,\n  getUserConversations,\n  getUserConversation,\n  getUserACUs,\n  getUserACU,\n  getUserTopicProfiles,\n  getUserEntityProfiles,\n  getUserContextBundles,\n  getUserNotebooks,\n  getUserMemories,\n  getUserAiPersonas,\n  getUserContextSettings,\n  verifyContentOwnership,\n  checkSharePermission,\n  getUserClient,\n  getUserDbPath,\n  createUserDatabase,\n  initializeUserDatabaseDir,\n};\n","usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\middleware\\account-status.js","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\middleware\\admin-auth.js","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\middleware\\auth.js","messages":[{"ruleId":"no-unused-vars","severity":1,"message":"'config' is defined but never used.","line":8,"column":10,"nodeType":"Identifier","messageId":"unusedVar","endLine":8,"endColumn":16,"suggestions":[{"messageId":"removeVar","data":{"varName":"config"},"fix":{"range":[151,195],"text":""},"desc":"Remove unused variable 'config'."}]},{"ruleId":"no-unused-vars","severity":1,"message":"'UnauthorizedError' is defined but never used.","line":9,"column":10,"nodeType":"Identifier","messageId":"unusedVar","endLine":9,"endColumn":27,"suggestions":[{"messageId":"removeVar","data":{"varName":"UnauthorizedError"},"fix":{"range":[196,250],"text":""},"desc":"Remove unused variable 'UnauthorizedError'."}]},{"ruleId":"no-unused-vars","severity":1,"message":"'requiredPermissions' is assigned a value but never used. Allowed unused args must match /^_/u.","line":146,"column":36,"nodeType":"Identifier","messageId":"unusedVar","endLine":146,"endColumn":55,"suggestions":[{"messageId":"removeVar","data":{"varName":"requiredPermissions"},"fix":{"range":[3931,3957],"text":""},"desc":"Remove unused variable 'requiredPermissions'."}]},{"ruleId":"no-unused-vars","severity":1,"message":"'error' is defined but never used.","line":275,"column":12,"nodeType":"Identifier","messageId":"unusedVar","endLine":275,"endColumn":17}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":4,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * Authentication Middleware\n *\n * Implements API key-based authentication for sensitive endpoints\n */\n\nimport { logger } from '../lib/logger.js';\nimport { config } from '../config/index.js';\nimport { UnauthorizedError } from './errorHandler.js';\n\n// ============================================================================\n// AUTHENTICATION CONFIGURATION\n// ============================================================================\n\n// In production, API keys should be stored securely (e.g., environment variables, vault)\nconst API_KEYS = process.env.API_KEYS?.split(',') || [];\nconst MASTER_KEY = process.env.MASTER_API_KEY || null;\n\n// ============================================================================\n// AUTHENTICATION HELPERS\n// ============================================================================\n\n/**\n * Verify API key against stored keys\n * @param {string} apiKey - API key to verify\n * @returns {boolean} True if valid\n */\nfunction isValidApiKey(apiKey) {\n  if (!apiKey) {\n    return false;\n  }\n\n  // Check master key first\n  if (MASTER_KEY && apiKey === MASTER_KEY) {\n    return true;\n  }\n\n  // Check individual API keys\n  return API_KEYS.includes(apiKey);\n}\n\n/**\n * Extract API key from request\n * @param {Object} req - Express request object\n * @returns {string|null} API key or null if not found\n */\nfunction extractApiKey(req) {\n  // Check header first\n  const authHeader = req.headers.authorization;\n  if (authHeader && authHeader.startsWith('Bearer ')) {\n    return authHeader.substring(7); // Remove 'Bearer ' prefix\n  }\n\n  // Check custom header as fallback\n  if (req.headers['x-api-key']) {\n    return req.headers['x-api-key'];\n  }\n\n  // Check query parameter as fallback (less secure, but needed for SSE)\n  if (req.query.api_key) {\n    return req.query.api_key;\n  }\n\n  return null;\n}\n\n// ============================================================================\n// AUTHENTICATION MIDDLEWARE\n// ============================================================================\n\n/**\n * Require API key authentication\n * @param {Array<string>} [permissions] - Required permissions (currently unused)\n */\nexport function requireApiKey(permissions = []) {\n  return (req, res, next) => {\n    // Check if already authenticated (e.g. via dev bypass or other middleware)\n    if (req.auth && req.auth.isAuthenticated) {\n      return next();\n    }\n\n    const apiKey = extractApiKey(req);\n\n    if (!isValidApiKey(apiKey)) {\n      const log = req.log || logger;\n      log.warn(\n        {\n          path: req.path,\n          method: req.method,\n          hasKey: !!apiKey,\n          ip: req.ip,\n        },\n        'Unauthorized API access attempt'\n      );\n\n      return res.status(401).json({\n        success: false,\n        error: 'Unauthorized: Invalid or missing API key',\n        code: 'UNAUTHORIZED',\n      });\n    }\n\n    req.auth = {\n      isAuthenticated: true,\n      apiKey: `${apiKey.substring(0, 8)}...`,\n      permissions: permissions,\n    };\n\n    return next();\n  };\n}\n\n/**\n * Optional authentication - allows both authenticated and unauthenticated requests\n */\nexport function optionalAuth(req, res, next) {\n  const apiKey = extractApiKey(req);\n\n  if (apiKey && isValidApiKey(apiKey)) {\n    req.auth = {\n      isAuthenticated: true,\n      apiKey: `${apiKey.substring(0, 8)}...`, // Mask for logging\n      permissions: [],\n    };\n  } else {\n    req.auth = {\n      isAuthenticated: false,\n      apiKey: null,\n      permissions: [],\n    };\n  }\n\n  next();\n}\n\n// ============================================================================\n// AUTHORIZATION HELPERS\n// ============================================================================\n\n/**\n * Check if user has required permissions\n * @param {Object} req - Express request object\n * @param {Array<string>} requiredPermissions - Permissions required\n * @returns {boolean} True if authorized\n */\nexport function hasPermission(req, requiredPermissions = []) {\n  if (!req.auth?.isAuthenticated) {\n    return false;\n  }\n\n  // For now, we don't implement fine-grained permissions\n  // This can be expanded in the future\n  return true;\n}\n\n// ============================================================================\n// DID-BASED AUTHENTICATION (Phase 1)\n// ============================================================================\n\nimport { verify } from 'tweetnacl';\nimport { decodeBase64 } from 'tweetnacl-util';\nimport { identityService } from '../services/identity-service.js';\nimport { getUserDbPath, getUserClient } from '../lib/user-database-manager.js';\n\n/**\n * Authenticate using DID\n */\nexport async function authenticateDID(req, res, next) {\n  try {\n    const authHeader = req.headers['authorization'] || '';\n    const did = req.headers['x-did'] || authHeader.replace('Bearer did:', 'did:');\n    const signature = req.headers['x-signature'];\n    const timestamp = req.headers['x-timestamp'];\n    const deviceId = req.headers['x-device-id'];\n\n    if (!did) {\n      return res.status(401).json({\n        success: false,\n        error: 'DID required',\n        code: 'MISSING_DID',\n      });\n    }\n\n    if (!identityService.validateDID(did)) {\n      return res.status(401).json({\n        success: false,\n        error: 'Invalid DID format',\n        code: 'INVALID_DID',\n      });\n    }\n\n    if (req.method !== 'GET' && signature) {\n      const isValid = await verifyRequestSignature(req, did, signature, timestamp);\n      if (!isValid) {\n        return res.status(401).json({\n          success: false,\n          error: 'Invalid signature',\n          code: 'INVALID_SIGNATURE',\n        });\n      }\n    }\n\n    const didDoc = await identityService.resolveDID(did);\n    if (!didDoc) {\n      return res.status(401).json({\n        success: false,\n        error: 'Could not resolve DID',\n        code: 'DID_RESOLUTION_FAILED',\n      });\n    }\n\n    const publicKey = identityService.didToPublicKey(did);\n    const user = await identityService.getOrCreateUser(\n      did,\n      Buffer.from(publicKey).toString('base64')\n    );\n\n    const databasePath = getUserDbPath(did);\n\n    let userClient = null;\n    try {\n      userClient = await getUserClient(did);\n    } catch (clientError) {\n      logger.warn(\n        { did, error: clientError.message },\n        'User client not available yet (user DB may not exist)'\n      );\n    }\n\n    req.user = {\n      did,\n      userId: user.id,\n      deviceId,\n      publicKey: Buffer.from(publicKey).toString('base64'),\n      databasePath,\n      userClient,\n    };\n\n    next();\n  } catch (error) {\n    logger.error({ error: error.message, stack: error.stack }, 'Authentication failed');\n    if (!res || !res.status) {\n      return next(error);\n    }\n    res.status(500).json({\n      success: false,\n      error: 'Authentication failed',\n    });\n  }\n}\n\nasync function verifyRequestSignature(req, did, signature, timestamp) {\n  try {\n    if (timestamp) {\n      const requestTime = parseInt(timestamp);\n      const now = Date.now();\n      const fiveMinutes = 5 * 60 * 1000;\n\n      if (Math.abs(now - requestTime) > fiveMinutes) {\n        return false;\n      }\n    }\n\n    const message = [req.method, req.path, timestamp || Date.now().toString()];\n    if (['POST', 'PUT', 'PATCH'].includes(req.method) && req.body) {\n      message.push(JSON.stringify(req.body));\n    }\n\n    const publicKey = identityService.didToPublicKey(did);\n    if (!publicKey) {\n      return false;\n    }\n\n    return verify(new TextEncoder().encode(message.join(':')), decodeBase64(signature), publicKey);\n  } catch (error) {\n    return false;\n  }\n}\n\n/**\n * Require minimum verification level\n */\nexport function requireVerification(minLevel) {\n  return async (req, res, next) => {\n    if (!req.user) {\n      return res.status(401).json({\n        success: false,\n        error: 'Authentication required',\n      });\n    }\n\n    const { getPrismaClient } = await import('../lib/database.js');\n    const prisma = getPrismaClient();\n\n    const user = await prisma.user.findUnique({\n      where: { id: req.user.userId },\n      select: { verificationLevel: true },\n    });\n\n    if (!user || user.verificationLevel < minLevel) {\n      return res.status(403).json({\n        success: false,\n        error: `Verification level ${minLevel} required`,\n        code: 'INSUFFICIENT_VERIFICATION',\n        currentLevel: user?.verificationLevel || 0,\n      });\n    }\n\n    next();\n  };\n}\n\n/**\n * Require moderator role\n */\nexport function requireModerator() {\n  return async (req, res, next) => {\n    if (!req.user) {\n      return res.status(401).json({\n        success: false,\n        error: 'Authentication required',\n      });\n    }\n\n    const { getPrismaClient } = await import('../lib/database.js');\n    const prisma = getPrismaClient();\n\n    const user = await prisma.user.findUnique({\n      where: { id: req.user.userId },\n      select: { status: true, settings: true },\n    });\n\n    if (!user) {\n      return res.status(404).json({\n        success: false,\n        error: 'User not found',\n      });\n    }\n\n    const settings = user.settings || {};\n    const isModerator =\n      settings.moderator === true || settings.role === 'moderator' || settings.role === 'admin';\n\n    if (!isModerator) {\n      return res.status(403).json({\n        success: false,\n        error: 'Moderator access required',\n      });\n    }\n\n    next();\n  };\n}\n","usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\middleware\\dev-auth.js","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\middleware\\error-handlers.js","messages":[{"ruleId":"no-unused-vars","severity":1,"message":"'next' is defined but never used. Allowed unused args must match /^_/u.","line":92,"column":48,"nodeType":"Identifier","messageId":"unusedVar","endLine":92,"endColumn":52,"suggestions":[{"messageId":"removeVar","data":{"varName":"next"},"fix":{"range":[2148,2154],"text":""},"desc":"Remove unused variable 'next'."}]},{"ruleId":"no-unused-vars","severity":1,"message":"'next' is defined but never used. Allowed unused args must match /^_/u.","line":289,"column":49,"nodeType":"Identifier","messageId":"unusedVar","endLine":289,"endColumn":53,"suggestions":[{"messageId":"removeVar","data":{"varName":"next"},"fix":{"range":[6535,6541],"text":""},"desc":"Remove unused variable 'next'."}]}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":2,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * Enhanced Error Handling Middleware\n * Provides comprehensive error tracking for all API endpoints\n */\n\nimport { logger } from '../lib/logger.js';\nimport { serverErrorReporter } from '../utils/server-error-reporting.js';\nimport { config } from '../config/index.js';\n\n/**\n * Async handler wrapper that automatically catches and reports errors\n * Usage: router.get('/path', asyncHandler(async (req, res) => { ... }))\n */\nexport const asyncHandler = (fn) => (req, res, next) => {\n  Promise.resolve(fn(req, res, next)).catch(next);\n};\n\n/**\n * Request timing middleware for performance tracking\n */\nexport const requestTimer = (req, res, next) => {\n  const startTime = Date.now();\n\n  res.on('finish', () => {\n    const duration = Date.now() - startTime;\n    res.locals.responseTime = duration;\n\n    // Log slow requests\n    if (duration > 1000) {\n      logger.warn(\n        {\n          method: req.method,\n          path: req.path,\n          duration,\n          statusCode: res.statusCode,\n        },\n        'Slow request detected'\n      );\n\n      // Report performance issue for very slow requests\n      if (duration > 5000) {\n        serverErrorReporter.reportPerformanceIssue(\n          'response_time',\n          duration,\n          5000,\n          { endpoint: req.path, method: req.method },\n          'medium',\n          req.id\n        );\n      }\n    }\n  });\n\n  next();\n};\n\n/**\n * Validation error handler\n */\nexport const handleValidationError = (err, req, res, next) => {\n  if (err.name === 'ZodError' || err.name === 'ValidationError') {\n    const fields =\n      err.errors?.map((e) => ({\n        field: e.path?.join('.') || 'unknown',\n        error: e.message,\n        value: e.input,\n      })) || [];\n\n    serverErrorReporter.reportValidationError(\n      req.path,\n      fields,\n      err,\n      { requestBody: req.body },\n      'low',\n      req.id\n    );\n\n    return res.status(400).json({\n      success: false,\n      error: 'Validation failed',\n      code: 'VALIDATION_ERROR',\n      details: fields,\n    });\n  }\n\n  next(err);\n};\n\n/**\n * API error handler with comprehensive reporting\n */\nexport const apiErrorHandler = (err, req, res, next) => {\n  const requestId = req.id || 'unknown';\n  const responseTime = res.locals?.responseTime || 0;\n\n  // Determine error type and status code\n  const statusCode = err.statusCode || err.status || 500;\n  const errorType = getErrorType(err);\n\n  // Prepare error context\n  const errorContext = {\n    requestId,\n    endpoint: req.path,\n    method: req.method,\n    statusCode,\n    responseTime,\n    ip: req.ip,\n    userAgent: req.get('User-Agent'),\n    userId: req.user?.id || req.session?.userId,\n    query: req.query,\n    requestBody: sanitizeRequestBody(req.body),\n    timestamp: new Date().toISOString(),\n  };\n\n  // Report error based on type and severity\n  if (statusCode >= 500) {\n    serverErrorReporter.reportAPIError(\n      req.path,\n      req.method,\n      statusCode,\n      err,\n      errorContext,\n      'critical',\n      requestId\n    );\n  } else if (statusCode >= 400) {\n    serverErrorReporter.reportAPIError(\n      req.path,\n      req.method,\n      statusCode,\n      err,\n      errorContext,\n      statusCode >= 403 ? 'high' : 'medium',\n      requestId\n    );\n  }\n\n  // Log error\n  logger.error(\n    {\n      error: err.message,\n      code: errorType,\n      statusCode,\n      stack: config.isDevelopment ? err.stack : undefined,\n      ...errorContext,\n    },\n    'API error handled'\n  );\n\n  // Send response\n  res.status(statusCode).json({\n    success: false,\n    error: getErrorMessage(err, statusCode),\n    code: errorType,\n    requestId,\n    ...(config.isDevelopment && { stack: err.stack, details: err.details }),\n  });\n};\n\n/**\n * Get error type from error object\n */\nfunction getErrorType(err) {\n  if (err.name === 'ZodError') {\n    return 'VALIDATION_ERROR';\n  }\n  if (err.name === 'JsonWebTokenError') {\n    return 'AUTH_ERROR';\n  }\n  if (err.name === 'UnauthorizedError') {\n    return 'UNAUTHORIZED';\n  }\n  if (err.code === 'ECONNREFUSED') {\n    return 'CONNECTION_ERROR';\n  }\n  if (err.code === 'ETIMEDOUT') {\n    return 'TIMEOUT_ERROR';\n  }\n  if (err.code === 'ENOENT') {\n    return 'NOT_FOUND_ERROR';\n  }\n  if (err.name === 'PrismaClientKnownRequestError') {\n    switch (err.code) {\n      case 'P2002':\n        return 'UNIQUE_CONSTRAINT_ERROR';\n      case 'P2025':\n        return 'RECORD_NOT_FOUND_ERROR';\n      default:\n        return 'DATABASE_ERROR';\n    }\n  }\n  return err.code || 'INTERNAL_ERROR';\n}\n\n/**\n * Get user-friendly error message\n */\nfunction getErrorMessage(err, statusCode) {\n  if (err.message) {\n    // Don't expose internal error details in production\n    if (config.isProduction && statusCode >= 500) {\n      return 'An unexpected error occurred';\n    }\n    return err.message;\n  }\n\n  switch (statusCode) {\n    case 400:\n      return 'Bad request';\n    case 401:\n      return 'Unauthorized';\n    case 403:\n      return 'Forbidden';\n    case 404:\n      return 'Resource not found';\n    case 409:\n      return 'Conflict';\n    case 422:\n      return 'Validation failed';\n    case 429:\n      return 'Too many requests';\n    case 500:\n      return 'Internal server error';\n    case 502:\n      return 'Bad gateway';\n    case 503:\n      return 'Service unavailable';\n    default:\n      return 'An error occurred';\n  }\n}\n\n/**\n * Sanitize request body for logging (remove sensitive data)\n */\nfunction sanitizeRequestBody(body) {\n  if (!body) {\n    return undefined;\n  }\n\n  const sensitive = ['password', 'secret', 'token', 'apiKey', 'api_key', 'creditCard', 'ssn'];\n  const sanitized = { ...body };\n\n  for (const key of Object.keys(sanitized)) {\n    if (sensitive.some((s) => key.toLowerCase().includes(s))) {\n      sanitized[key] = '[REDACTED]';\n    }\n  }\n\n  return sanitized;\n}\n\n/**\n * Not found handler\n */\nexport const notFoundHandler = (req, res) => {\n  const requestId = req.id || 'unknown';\n\n  serverErrorReporter.reportAPIError(\n    req.path,\n    req.method,\n    404,\n    new Error(`Route not found: ${req.method} ${req.path}`),\n    {\n      requestId,\n      endpoint: req.path,\n      method: req.method,\n      statusCode: 404,\n      ip: req.ip,\n      userAgent: req.get('User-Agent'),\n    },\n    'low',\n    requestId\n  );\n\n  res.status(404).json({\n    success: false,\n    error: 'Not found',\n    code: 'NOT_FOUND',\n    message: `Cannot ${req.method} ${req.path}`,\n    requestId,\n    ...(config.enableSwagger && { documentationUrl: '/api-docs' }),\n  });\n};\n\n/**\n * Rate limit error handler\n */\nexport const rateLimitErrorHandler = (req, res, next) => {\n  const requestId = req.id || 'unknown';\n\n  serverErrorReporter.reportSecurityIssue(\n    'rate_limit_exceeded',\n    {\n      ip: req.ip,\n      endpoint: req.path,\n      method: req.method,\n      userAgent: req.get('User-Agent'),\n    },\n    undefined,\n    requestId\n  );\n\n  res.status(429).json({\n    success: false,\n    error: 'Too many requests',\n    code: 'RATE_LIMIT_EXCEEDED',\n    message: 'Rate limit exceeded. Please try again later.',\n    retryAfter: '60',\n    requestId,\n  });\n};\n\n/**\n * Authentication error handler\n */\nexport const authErrorHandler = (err, req, res, next) => {\n  if (err.name === 'UnauthorizedError' || err.message?.includes('Unauthorized')) {\n    const requestId = req.id || 'unknown';\n\n    serverErrorReporter.reportAuthError(\n      'Authentication failed',\n      err,\n      {\n        action: 'token_validation',\n        reason: err.message,\n        ip: req.ip,\n        userAgent: req.get('User-Agent'),\n      },\n      'medium',\n      requestId\n    );\n\n    return res.status(401).json({\n      success: false,\n      error: 'Unauthorized',\n      code: 'UNAUTHORIZED',\n      message: 'Invalid or missing authentication token',\n      requestId,\n    });\n  }\n\n  next(err);\n};\n","usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\middleware\\errorHandler.js","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\middleware\\google-auth.js","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\middleware\\requestId.js","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\middleware\\requestLogger.js","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\middleware\\unified-auth.js","messages":[{"ruleId":"no-unused-vars","severity":1,"message":"'passport' is defined but never used.","line":6,"column":8,"nodeType":"Identifier","messageId":"unusedVar","endLine":6,"endColumn":16,"suggestions":[{"messageId":"removeVar","data":{"varName":"passport"},"fix":{"range":[112,126],"text":""},"desc":"Remove unused variable 'passport'."}]},{"ruleId":"prefer-destructuring","severity":1,"message":"Use object destructuring.","line":16,"column":5,"nodeType":"AssignmentExpression","messageId":"preferDestructuring","endLine":16,"endColumn":29},{"ruleId":"prefer-destructuring","severity":1,"message":"Use object destructuring.","line":71,"column":5,"nodeType":"AssignmentExpression","messageId":"preferDestructuring","endLine":71,"endColumn":29}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":3,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * Unified Authentication Middleware\n * Supports both Google OAuth (session) and DID-based auth\n */\n\nimport passport from './google-auth.js';\nimport { identityService } from '../services/identity-service.js';\nimport { canUserAccess } from '../services/account-lifecycle-service.js';\nimport { apiKeyService } from '../services/api-key-service.js';\n\nexport async function requireAuth(req, res, next) {\n  let userId = null;\n  let did = null;\n\n  if (req.isAuthenticated() && req.user?.userId) {\n    userId = req.user.userId;\n  } else {\n    // Check API Key first\n    const apiKeyHeader = req.headers['x-api-key'];\n    const authHeader = req.headers['authorization'] || '';\n    let apiKey = apiKeyHeader;\n\n    if (!apiKey && authHeader.startsWith('Bearer vk_live_')) {\n      apiKey = authHeader.replace('Bearer ', '');\n    }\n\n    if (apiKey) {\n      const user = await apiKeyService.verifyApiKey(apiKey);\n      if (user) {\n        userId = user.id;\n        // Mock req.user for consistency\n        req.user = { userId: user.id, email: user.email, did: user.did };\n      }\n    } else {\n      did = req.headers['x-did'] || authHeader.replace('Bearer did:', 'did:');\n      if (did && did.startsWith('did:') && identityService.validateDID(did)) {\n        const publicKey = identityService.didToPublicKey(did);\n        if (publicKey) {\n          const user = await identityService.getOrCreateUser(\n            did,\n            Buffer.from(publicKey).toString('base64')\n          );\n          if (user) {\n            userId = user.id;\n          }\n        }\n      }\n    }\n  }\n\n  if (!userId) {\n    return res.status(401).json({ success: false, error: 'Authentication required' });\n  }\n\n  const { allowed, reason } = await canUserAccess(userId);\n  if (!allowed) {\n    return res.status(403).json({ success: false, error: 'Account access denied', reason });\n  }\n\n  req.userId = userId;\n  if (did) {\n    req.user = { ...req.user, did, userId };\n  }\n  next();\n}\n\nexport async function optionalAuth(req, res, next) {\n  let userId = null;\n\n  if (req.isAuthenticated() && req.user?.userId) {\n    userId = req.user.userId;\n  } else {\n    const apiKeyHeader = req.headers['x-api-key'];\n    const authHeader = req.headers['authorization'] || '';\n    let apiKey = apiKeyHeader;\n\n    if (!apiKey && authHeader.startsWith('Bearer vk_live_')) {\n      apiKey = authHeader.replace('Bearer ', '');\n    }\n\n    if (apiKey) {\n      const user = await apiKeyService.verifyApiKey(apiKey);\n      if (user) {\n        userId = user.id;\n        req.user = { userId: user.id, email: user.email, did: user.did };\n      }\n    } else {\n      const did = req.headers['x-did'];\n      if (did && identityService.validateDID(did)) {\n        const publicKey = identityService.didToPublicKey(did);\n        if (publicKey) {\n          const user = await identityService.getOrCreateUser(\n            did,\n            Buffer.from(publicKey).toString('base64')\n          );\n          if (user) {\n            userId = user.id;\n          }\n        }\n      }\n    }\n  }\n\n  if (userId) {\n    const { allowed } = await canUserAccess(userId);\n    if (allowed) {\n      req.userId = userId;\n    }\n  }\n  next();\n}\n","usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\playwright-worker.js","messages":[{"ruleId":"no-unused-vars","severity":1,"message":"'e' is defined but never used.","line":45,"column":18,"nodeType":"Identifier","messageId":"unusedVar","endLine":45,"endColumn":19},{"ruleId":"no-unused-vars","severity":1,"message":"'e' is defined but never used.","line":74,"column":12,"nodeType":"Identifier","messageId":"unusedVar","endLine":74,"endColumn":13},{"ruleId":"no-unused-vars","severity":1,"message":"'e' is defined but never used.","line":138,"column":16,"nodeType":"Identifier","messageId":"unusedVar","endLine":138,"endColumn":17},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":152,"column":5,"nodeType":"MemberExpression","messageId":"limited","endLine":152,"endColumn":16,"suggestions":[{"fix":{"range":[4497,4568],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":155,"column":5,"nodeType":"MemberExpression","messageId":"limited","endLine":155,"endColumn":16,"suggestions":[{"fix":{"range":[4648,4721],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":5,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * Standalone Playwright Worker (Node.js)\n *\n * This script runs in a separate Node.js process to ensure isolation\n * and proper runtime support for Playwright/Puppeteer dependencies.\n *\n * Usage: node src/playwright-worker.js <JSON_CONFIG_STRING>\n */\n\nimport { chromium } from 'playwright-extra';\nimport StealthPlugin from 'puppeteer-extra-plugin-stealth';\nimport fs from 'fs/promises';\nimport path from 'path';\nimport os from 'os';\nimport { v4 as uuidv4 } from 'uuid';\n\n// Apply stealth plugin\nchromium.use(StealthPlugin());\n\nasync function handleGeminiConsent(page) {\n  try {\n    const currentUrl = page.url();\n    if (currentUrl.includes('consent.google.com')) {\n      console.error('[Worker] Consent page detected, attempting to accept');\n\n      const acceptSelectors = [\n        'button:has-text(\"Accept all\")',\n        'button:has-text(\"I agree\")',\n        'button:has-text(\"Yes, I agree\")',\n        'button[aria-label*=\"Accept\"]',\n        'form[action*=\"save\"] button[type=\"submit\"]',\n        '.VfPpkd-LgbsSe:has-text(\"Accept\")',\n      ];\n\n      let accepted = false;\n      for (const selector of acceptSelectors) {\n        try {\n          const button = await page.locator(selector).first();\n          if (await button.isVisible({ timeout: 2000 })) {\n            await button.click();\n            console.error(`[Worker] Clicked accept button: ${selector}`);\n            accepted = true;\n            break;\n          }\n        } catch (e) {\n          // Try next\n        }\n      }\n\n      if (accepted) {\n        console.error('[Worker] Waiting for redirect...');\n        await page.waitForURL((url) => !url.includes('consent.google.com'), { timeout: 15000 });\n        console.error('[Worker] Redirected successfully');\n      } else {\n        console.error('[Worker] Could not find accept button');\n      }\n    }\n  } catch (error) {\n    console.error(`[Worker] Consent handler error: ${error.message}`);\n  }\n}\n\nasync function runCapture() {\n  // 1. Parse Arguments\n  const args = process.argv.slice(2);\n  if (args.length === 0) {\n    console.error('Error: No configuration provided');\n    process.exit(1);\n  }\n\n  let config;\n  try {\n    config = JSON.parse(args[0]);\n  } catch (e) {\n    console.error('Error: Invalid JSON config');\n    process.exit(1);\n  }\n\n  const {\n    url,\n    provider,\n    timeout = 60000,\n    headless = true,\n    tempDir = null,\n    waitForSelector,\n    waitForTimeout,\n  } = config;\n\n  let browser = null;\n  let tempFilePath = null;\n\n  try {\n    // 2. Setup Files\n    const tempDirectory = path.resolve(tempDir || os.tmpdir());\n    const tempFileName = `openscroll-pw-${provider}-${uuidv4()}.html`;\n    tempFilePath = path.join(tempDirectory, tempFileName);\n\n    // 3. Launch Browser\n    browser = await chromium.launch({\n      headless,\n      args: ['--no-sandbox', '--disable-setuid-sandbox'],\n    });\n\n    const context = await browser.newContext({\n      userAgent:\n        'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36',\n      viewport: { width: 1920, height: 1080 },\n      locale: 'en-US',\n    });\n\n    const page = await context.newPage();\n\n    // 4. Navigate (with fallback)\n    console.error(`[Worker] Navigating to ${url}`);\n    try {\n      // First try domcontentloaded as it's faster and more reliable for heavy JS sites\n      await page.goto(url, { waitUntil: 'domcontentloaded', timeout });\n    } catch (gotoError) {\n      console.error(\n        `[Worker] Initial navigation failed: ${gotoError.message}. Retrying with load...`\n      );\n      await page.goto(url, { waitUntil: 'load', timeout });\n    }\n\n    // 5. Handle Provider Specifics (e.g. Consent)\n    if (provider === 'gemini') {\n      await handleGeminiConsent(page);\n    }\n\n    // 6. Wait for Content\n    if (waitForSelector) {\n      console.error(`[Worker] Waiting for selector: ${waitForSelector}`);\n      try {\n        // Wait for the selector to actually have content if possible\n        await page.waitForSelector(waitForSelector, { timeout: 15000, state: 'attached' });\n        // Brief pause to let any dynamic content settle\n        await page.waitForTimeout(1000);\n      } catch (e) {\n        console.error('[Worker] Selector wait timed out, continuing...');\n      }\n    }\n\n    if (waitForTimeout) {\n      await page.waitForTimeout(waitForTimeout);\n    }\n\n    // 7. Extract\n    const html = await page.content();\n    await fs.writeFile(tempFilePath, html, 'utf8');\n\n    // 8. Output Result (JSON to stdout)\n    console.log(JSON.stringify({ status: 'success', path: tempFilePath }));\n  } catch (error) {\n    console.error(`[Worker] Error: ${error.message}`);\n    console.log(JSON.stringify({ status: 'error', message: error.message }));\n    process.exit(1);\n  } finally {\n    if (browser) {\n      await browser.close();\n    }\n  }\n}\n\nrunCapture();\n","usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\repositories\\CaptureAttemptRepository.js","messages":[{"ruleId":"no-unused-vars","severity":1,"message":"'recordOperation' is defined but never used.","line":4,"column":10,"nodeType":"Identifier","messageId":"unusedVar","endLine":4,"endColumn":25,"suggestions":[{"messageId":"removeVar","data":{"varName":"recordOperation"},"fix":{"range":[151,213],"text":""},"desc":"Remove unused variable 'recordOperation'."}]}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":"import { getPrismaClient } from '../lib/database.js';\nimport { logger } from '../lib/logger.js';\nimport { fileStorage } from '../lib/file-storage.js';\nimport { recordOperation } from '../services/sync-service.js';\n\n// ============================================================================\n// CREATE\n// ============================================================================\n\n/**\n * Create a capture attempt record\n * @param {Object} data - Attempt data\n * @param {Object} userClient - Optional user-specific Prisma client\n * @returns {Promise<Object>} Created attempt\n */\nexport async function createCaptureAttempt(data, userClient = null) {\n  const db = userClient || getPrismaClient();\n\n  try {\n    const attempt = await db.captureAttempt.create({\n      data: {\n        sourceUrl: data.sourceUrl,\n        provider: data.provider,\n        status: data.status,\n        errorCode: data.errorCode,\n        errorMessage: data.errorMessage,\n        startedAt: new Date(data.startedAt),\n        completedAt: data.completedAt ? new Date(data.completedAt) : null,\n        duration: data.duration,\n        ipAddress: data.ipAddress,\n        conversationId: data.conversationId,\n      },\n    });\n\n    logger.debug({ attemptId: attempt.id, status: attempt.status }, 'Capture attempt recorded');\n\n    return attempt;\n  } catch (error) {\n    if (error.message.includes(\"Can't reach database server\")) {\n      logger.warn('ðŸ’¾ [DATABASE OFFLINE] Saving attempt to local filesystem...');\n      const attempt = { id: `offline-${Date.now()}`, ...data };\n      await fileStorage.saveAttempt(attempt);\n      return attempt;\n    }\n    logger.error({ error: error.message }, 'Failed to create capture attempt');\n    throw error;\n  }\n}\n\n/**\n * Update capture attempt with completion status\n * @param {string} id - Attempt ID\n * @param {Object} data - Update data\n * @param {Object} userClient - Optional user-specific Prisma client\n * @returns {Promise<Object>} Updated attempt\n */\nexport async function completeCaptureAttempt(id, data, userClient = null) {\n  const db = userClient || getPrismaClient();\n\n  try {\n    if (String(id).startsWith('offline-')) {\n      logger.debug(\n        { attemptId: id, status: data.status },\n        'Capture attempt completed (offline mode)'\n      );\n      return { id, ...data };\n    }\n\n    const attempt = await db.captureAttempt.update({\n      where: { id },\n      data: {\n        status: data.status,\n        completedAt: new Date(),\n        duration: data.duration,\n        errorCode: data.errorCode,\n        errorMessage: data.errorMessage,\n        conversationId: data.conversationId,\n      },\n    });\n\n    logger.debug({ attemptId: id, status: data.status }, 'Capture attempt completed');\n\n    return attempt;\n  } catch (error) {\n    if (error.message.includes(\"Can't reach database server\")) {\n      logger.warn('ðŸ’¾ [DATABASE OFFLINE] Could not update capture attempt (DB down).');\n      return { id, ...data };\n    }\n    logger.error({ error: error.message, id }, 'Failed to complete capture attempt');\n    throw error;\n  }\n}\n\n// ============================================================================\n// QUERY\n// ============================================================================\n\n/**\n * Get recent capture attempts\n * @param {Object} options - Query options\n * @returns {Promise<Array>} Capture attempts\n */\nexport async function getRecentAttempts(options = {}) {\n  const { limit = 50, status, ipAddress } = options;\n\n  try {\n    const where = {};\n    if (status) {\n      where.status = status;\n    }\n    if (ipAddress) {\n      where.ipAddress = ipAddress;\n    }\n\n    const attempts = await getPrismaClient().captureAttempt.findMany({\n      where,\n      take: limit,\n      orderBy: { createdAt: 'desc' },\n    });\n\n    return attempts;\n  } catch (error) {\n    logger.error({ error: error.message }, 'Failed to get recent attempts');\n    throw error;\n  }\n}\n\n/**\n * Get capture statistics\n * @param {Object} options - Filter options\n * @returns {Promise<Object>} Statistics\n */\nexport async function getCaptureStats(options = {}) {\n  const { startDate, endDate, ipAddress } = options;\n\n  try {\n    const where = {};\n    if (startDate || endDate) {\n      where.createdAt = {};\n      if (startDate) {\n        where.createdAt.gte = new Date(startDate);\n      }\n      if (endDate) {\n        where.createdAt.lte = new Date(endDate);\n      }\n    }\n    if (ipAddress) {\n      where.ipAddress = ipAddress;\n    }\n\n    const [total, successful, failed, avgDuration] = await Promise.all([\n      getPrismaClient().captureAttempt.count({ where }),\n      getPrismaClient().captureAttempt.count({ where: { ...where, status: 'success' } }),\n      getPrismaClient().captureAttempt.count({ where: { ...where, status: 'failed' } }),\n      getPrismaClient().captureAttempt.aggregate({\n        where: { ...where, duration: { not: null } },\n        _avg: { duration: true },\n      }),\n    ]);\n\n    return {\n      total,\n      successful,\n      failed,\n      successRate: total > 0 ? (successful / total) * 100 : 0,\n      avgDuration: avgDuration._avg.duration || 0,\n    };\n  } catch (error) {\n    logger.error({ error: error.message }, 'Failed to get capture stats');\n    throw error;\n  }\n}\n\n/**\n * Check if URL was recently captured (cache check)\n * @param {string} sourceUrl - Source URL\n * @param {number} minutes - Minutes to look back\n * @param {Object} userClient - Optional user-specific Prisma client\n * @returns {Promise<Object|null>} Recent successful attempt or null\n */\nexport async function findRecentSuccessfulAttempt(sourceUrl, minutes = 60, userClient = null) {\n  const db = userClient || getPrismaClient();\n\n  try {\n    const since = new Date(Date.now() - minutes * 60 * 1000);\n\n    const attempt = await db.captureAttempt.findFirst({\n      where: {\n        sourceUrl,\n        status: 'success',\n        completedAt: { gte: since },\n      },\n      orderBy: { completedAt: 'desc' },\n    });\n\n    return attempt;\n  } catch (error) {\n    logger.error({ error: error.message, sourceUrl }, 'Failed to find recent attempt');\n    return null;\n  }\n}\n\nexport default {\n  createCaptureAttempt,\n  completeCaptureAttempt,\n  getRecentAttempts,\n  getCaptureStats,\n  findRecentSuccessfulAttempt,\n};\n","usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\repositories\\ConversationRepository.js","messages":[{"ruleId":"prefer-const","severity":1,"message":"'conversation' is never reassigned. Use 'const' instead.","line":85,"column":5,"nodeType":"Identifier","messageId":"useConst","endLine":85,"endColumn":17},{"ruleId":"no-unused-vars","severity":1,"message":"'includeShared' is assigned a value but never used.","line":220,"column":5,"nodeType":"Identifier","messageId":"unusedVar","endLine":220,"endColumn":18,"suggestions":[{"messageId":"removeVar","data":{"varName":"includeShared"},"fix":{"range":[7208,7261],"text":""},"desc":"Remove unused variable 'includeShared'."}]}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":2,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * Conversation Repository\n *\n * Data access layer for conversation operations\n */\n\nimport { getPrismaClient } from '../lib/database.js';\nimport { logger } from '../lib/logger.js';\nimport { fileStorage } from '../lib/file-storage.js';\nimport { recordOperation } from '../services/sync-service.js';\nimport { cacheService } from '../services/cache-service.js';\nimport { v4 as uuidv4 } from 'uuid';\n\n// ============================================================================\n// TRANSACTION HELPER\n// ============================================================================\n\n/**\n * Run a callback inside a Prisma interactive transaction\n * @template T\n * @param {(tx: import('@prisma/client').PrismaClient) => Promise<T>} fn\n * @returns {Promise<T>}\n */\nasync function withTransaction(fn) {\n  const prisma = getPrismaClient();\n  return prisma.$transaction(fn);\n}\n\n// ============================================================================\n// CRUD OPERATIONS\n// ============================================================================\n\n/**\n * Create or update a conversation\n * @param {Object} data - Conversation data\n * @param {Object} userClient - Optional user-specific Prisma client\n * @returns {Promise<Object>} Created or updated conversation\n */\nexport async function createConversation(data, userClient = null) {\n  const db = userClient || getPrismaClient();\n\n  try {\n    logger.debug({ sourceUrl: data.sourceUrl }, 'createConversation: Checking for existing record');\n    const existing = await db.conversation.findUnique({\n      where: { sourceUrl: data.sourceUrl },\n    });\n\n    if (existing) {\n      logger.info(\n        { id: existing.id, sourceUrl: data.sourceUrl },\n        'createConversation: Found existing record'\n      );\n    } else {\n      logger.debug({ sourceUrl: data.sourceUrl }, 'createConversation: No existing record found');\n    }\n\n    const conversationData = {\n      provider: data.provider,\n      title: data.title,\n      model: data.model,\n      createdAt: new Date(data.createdAt),\n      updatedAt: new Date(data.updatedAt || new Date()),\n      capturedAt: new Date(data.capturedAt || new Date()),\n      contentHash: data.contentHash || null,\n\n      messageCount: data.messageCount || data.stats?.totalMessages || data.messages?.length || 0,\n      userMessageCount: data.userMessageCount || data.stats?.userMessageCount || 0,\n      aiMessageCount: data.aiMessageCount || data.stats?.aiMessageCount || 0,\n      totalWords: data.totalWords || data.stats?.totalWords || 0,\n      totalCharacters: data.totalCharacters || data.stats?.totalCharacters || 0,\n      totalTokens: data.totalTokens || data.stats?.totalTokens || null,\n      totalCodeBlocks: data.totalCodeBlocks || data.stats?.totalCodeBlocks || 0,\n      totalMermaidDiagrams: data.totalMermaidDiagrams || data.stats?.totalMermaidDiagrams || 0,\n      totalImages: data.totalImages || data.stats?.totalImages || 0,\n      totalTables: data.totalTables || data.stats?.totalTables || 0,\n      totalLatexBlocks: data.totalLatexBlocks || data.stats?.totalLatexBlocks || 0,\n      totalToolCalls: data.totalToolCalls || data.stats?.totalToolCalls || 0,\n\n      metadata: data.metadata || {},\n    };\n\n    let conversation;\n\n    // Use upsert to handle create/update of the conversation record itself\n    conversation = await db.conversation.upsert({\n      where: { sourceUrl: data.sourceUrl },\n      update: {\n        ...conversationData,\n        version: { increment: 1 }, // Ensure version increments on update\n      },\n      create: {\n        id: data.id || uuidv4(),\n        sourceUrl: data.sourceUrl,\n        ...conversationData,\n        version: 1,\n      },\n      include: {\n        messages: {\n          select: { id: true, messageIndex: true },\n        },\n      },\n    });\n\n    const existingMessageIds = new Set(conversation.messages.map((m) => m.id));\n    const newMessages = (data.messages || []).filter((msg) => !existingMessageIds.has(msg.id));\n\n    if (newMessages.length > 0) {\n      logger.info(\n        {\n          conversationId: conversation.id,\n          count: newMessages.length,\n        },\n        'Creating new messages for conversation'\n      );\n\n      await db.message.createMany({\n        data: newMessages.map((msg, index) => ({\n          id: msg.id || uuidv4(),\n          conversationId: conversation.id,\n          role: msg.role,\n          author: msg.author,\n          messageIndex: msg.messageIndex ?? conversation.messages.length + index,\n          parts: msg.parts || [],\n          createdAt: new Date(msg.createdAt || msg.timestamp || new Date()),\n          status: msg.status || 'completed',\n          contentHash: msg.contentHash || null,\n          tokenCount: msg.tokenCount,\n          metadata: msg.metadata || {},\n        })),\n      });\n    }\n\n    // Invalidate cache\n    await cacheService.del(`conversation:${conversation.id}`);\n\n    return conversation;\n  } catch (error) {\n    if (error.message.includes(\"Can't reach database server\")) {\n      logger.warn('ðŸ’¾ [DATABASE OFFLINE] Saving conversation to local filesystem instead...');\n      await fileStorage.saveConversation(data);\n      logger.info('âœ… [FS_STORAGE] Conversation saved to local file');\n      return data;\n    }\n    logger.error({ error: error.message }, 'Failed to save conversation to DB');\n    throw error;\n  }\n}\n\n/**\n * Find conversation by ID\n * @param {string} id - Conversation ID\n * @returns {Promise<Object|null>} Conversation or null\n */\nexport async function findConversationById(id) {\n  try {\n    const cacheKey = `conversation:${id}`;\n    const cached = await cacheService.get(cacheKey);\n    if (cached) {\n      logger.debug({ id }, 'findConversationById: Cache hit');\n      // Revive date objects if necessary, though express res.json handles strings fine\n      return cached;\n    }\n\n    const conversation = await getPrismaClient().conversation.findUnique({\n      where: { id },\n      include: {\n        _count: {\n          select: { messages: true },\n        },\n      },\n    });\n\n    if (conversation) {\n      await cacheService.set(cacheKey, conversation, 300); // 5 min cache\n    }\n\n    return conversation;\n  } catch (error) {\n    logger.error({ error: error.message, id }, 'Failed to find conversation');\n    throw error;\n  }\n}\n\n/**\n * Find conversation by source URL\n * @param {string} sourceUrl - Source URL\n * @param {Object} userClient - Optional user-specific Prisma client\n * @returns {Promise<Object|null>} Conversation or null\n */\nexport async function findBySourceUrl(sourceUrl, userClient = null) {\n  const db = userClient || getPrismaClient();\n\n  try {\n    const conversation = await db.conversation.findUnique({\n      where: { sourceUrl },\n    });\n\n    return conversation;\n  } catch (error) {\n    logger.error({ error: error.message, sourceUrl }, 'Failed to find conversation');\n    throw error;\n  }\n}\n\n/**\n * List conversations with filters and pagination\n * @param {Object} options - Query options\n * @returns {Promise<Object>} Conversations with pagination\n */\nexport async function listConversations(options = {}) {\n  const {\n    provider,\n    limit = 20,\n    offset = 0,\n    orderBy = 'createdAt',\n    orderDirection = 'desc',\n    startDate,\n    endDate,\n    userId, // ADD: Filter by user ID\n    includeShared = false, // ADD: Include conversations shared with user\n    includeMessages = false, // ADD: Include messages in the response\n  } = options;\n\n  try {\n    const where = {};\n\n    // SECURITY: Filter by userId to only return user's own conversations\n    if (userId) {\n      where.ownerId = userId;\n    }\n\n    // Filter by provider\n    if (provider) {\n      where.provider = provider;\n    }\n\n    // Filter by date range\n    if (startDate || endDate) {\n      where.createdAt = {};\n      if (startDate) {\n        where.createdAt.gte = new Date(startDate);\n      }\n      if (endDate) {\n        where.createdAt.lte = new Date(endDate);\n      }\n    }\n\n    // Filter out archived/deleted conversations by default\n    if (!options.includeArchived) {\n      where.state = 'ACTIVE';\n    }\n\n    const [conversations, total] = await Promise.all([\n      getPrismaClient().conversation.findMany({\n        where,\n        take: limit,\n        skip: offset,\n        orderBy: { [orderBy]: orderDirection },\n        ...(includeMessages && {\n          include: {\n            messages: {\n              orderBy: { messageIndex: 'asc' },\n            },\n          },\n        }),\n      }),\n      getPrismaClient().conversation.count({ where }),\n    ]);\n\n    return {\n      conversations,\n      pagination: {\n        total,\n        limit,\n        offset,\n        hasMore: offset + conversations.length < total,\n      },\n    };\n  } catch (error) {\n    logger.error({ error: error.message }, 'Failed to list conversations');\n    throw error;\n  }\n}\n\n/**\n * Update conversation\n * @param {string} id - Conversation ID\n * @param {Object} data - Update data\n * @returns {Promise<Object>} Updated conversation\n */\nexport async function updateConversation(id, data) {\n  try {\n    const conversation = await getPrismaClient().conversation.update({\n      where: { id },\n      data: {\n        ...data,\n        updatedAt: new Date(),\n      },\n    });\n\n    await cacheService.del(`conversation:${id}`);\n    logger.info({ conversationId: id }, 'Conversation updated');\n\n    return conversation;\n  } catch (error) {\n    logger.error({ error: error.message, id }, 'Failed to update conversation');\n    throw error;\n  }\n}\n\n/**\n * Delete conversation\n * @param {string} id - Conversation ID\n * @returns {Promise<Object>} Deleted conversation\n */\nexport async function deleteConversation(id) {\n  try {\n    const conversation = await getPrismaClient().conversation.delete({\n      where: { id },\n    });\n\n    await cacheService.del(`conversation:${id}`);\n    logger.info({ conversationId: id }, 'Conversation deleted');\n\n    return conversation;\n  } catch (error) {\n    logger.error({ error: error.message, id }, 'Failed to delete conversation');\n    throw error;\n  }\n}\n\n/**\n * Add a message to an existing conversation\n * @param {string} conversationId - Conversation ID\n * @param {Object} messageData - Message data\n * @returns {Promise<Object>} Created message\n */\nexport async function addMessageToConversation(conversationId, messageData) {\n  return withTransaction(async (tx) => {\n    const conversation = await tx.conversation.findUnique({\n      where: { id: conversationId },\n      include: { _count: { select: { messages: true } } },\n    });\n\n    if (!conversation) {\n      throw new Error(`Conversation ${conversationId} not found`);\n    }\n\n    const messageIndex = messageData.messageIndex ?? conversation._count.messages;\n\n    const message = await tx.message.create({\n      data: {\n        id: messageData.id || uuidv4(),\n        conversationId,\n        role: messageData.role,\n        author: messageData.author,\n        messageIndex,\n        parts: messageData.parts || [],\n        createdAt: new Date(messageData.createdAt || new Date()),\n        status: messageData.status || 'completed',\n        finishReason: messageData.finishReason,\n        tokenCount: messageData.tokenCount,\n        metadata: messageData.metadata || {},\n      },\n    });\n\n    // Update conversation stats\n    const isUser = messageData.role === 'user';\n    const isAi = messageData.role === 'assistant';\n\n    await tx.conversation.update({\n      where: { id: conversationId },\n      data: {\n        updatedAt: new Date(),\n        messageCount: { increment: 1 },\n        userMessageCount: isUser ? { increment: 1 } : undefined,\n        aiMessageCount: isAi ? { increment: 1 } : undefined,\n        totalTokens: messageData.tokenCount ? { increment: messageData.tokenCount } : undefined,\n      },\n    });\n\n    // Record sync operation for the new message\n    await recordOperation(\n      {\n        entityType: 'message',\n        entityId: message.id,\n        operation: 'INSERT',\n        payload: message,\n        tableName: 'messages',\n        recordId: message.id,\n      },\n      tx\n    );\n\n    await cacheService.del(`conversation:${conversationId}`);\n    await cacheService.delPattern(`messages:${conversationId}:*`);\n\n    return message;\n  });\n}\n\n// ============================================================================\n// BATCH OPERATIONS\n// ============================================================================\n\n/**\n * Create multiple conversations in a transaction\n * @param {Array} conversations - Array of conversation data\n * @returns {Promise<Array>} Created conversations\n */\nexport async function createConversationsBatch(conversations) {\n  return withTransaction(async (tx) => {\n    const created = [];\n\n    for (const data of conversations) {\n      const conversation = await tx.conversation.create({\n        data: {\n          id: data.id,\n          provider: data.provider,\n          sourceUrl: data.sourceUrl,\n          title: data.title,\n          createdAt: new Date(data.createdAt),\n          updatedAt: new Date(data.updatedAt || new Date()),\n          capturedAt: new Date(data.capturedAt || new Date()),\n          messageCount: data.messageCount || data.stats?.totalMessages || 0,\n          userMessageCount: data.userMessageCount || data.stats?.userMessageCount || 0,\n          aiMessageCount: data.aiMessageCount || data.stats?.aiMessageCount || 0,\n          totalWords: data.totalWords || data.stats?.totalWords || 0,\n          totalCharacters: data.totalCharacters || data.stats?.totalCharacters || 0,\n          totalCodeBlocks: data.totalCodeBlocks || data.stats?.totalCodeBlocks || 0,\n          totalMermaidDiagrams: data.totalMermaidDiagrams || data.stats?.totalMermaidDiagrams || 0,\n          totalImages: data.totalImages || data.stats?.totalImages || 0,\n          totalTables: data.totalTables || data.stats?.totalTables || 0,\n          metadata: data.metadata || {},\n          messages: {\n            create: (data.messages || []).map((msg, index) => ({\n              id: msg.id,\n              role: msg.role,\n              author: msg.author,\n              messageIndex: msg.messageIndex ?? index,\n              parts: msg.parts || [],\n              createdAt: new Date(msg.createdAt || new Date()),\n              status: msg.status || 'completed',\n              metadata: msg.metadata || {},\n            })),\n          },\n        },\n      });\n\n      created.push(conversation);\n    }\n\n    logger.info({ count: created.length }, 'Batch conversations created');\n\n    return created;\n  });\n}\n\n// ============================================================================\n// AGGREGATION QUERIES\n// ============================================================================\n\n/**\n * Get conversation statistics by provider\n * @returns {Promise<Array>} Provider statistics\n */\nexport async function getStatsByProvider() {\n  try {\n    const stats = await getPrismaClient().conversation.groupBy({\n      by: ['provider'],\n      _count: { id: true },\n      _avg: {\n        messageCount: true,\n        totalWords: true,\n      },\n      orderBy: { _count: { id: 'desc' } },\n    });\n\n    return stats.map((stat) => ({\n      provider: stat.provider,\n      count: stat._count.id,\n      avgMessageCount: stat._avg.messageCount || 0,\n      avgWords: stat._avg.totalWords || 0,\n    }));\n  } catch (error) {\n    logger.error({ error: error.message }, 'Failed to get provider stats');\n    throw error;\n  }\n}\n\n/**\n * Get recent conversations\n * @param {number} limit - Number of conversations to return\n * @returns {Promise<Array>} Recent conversations\n */\nexport async function getRecentConversations(limit = 10) {\n  try {\n    const conversations = await getPrismaClient().conversation.findMany({\n      take: limit,\n      orderBy: { createdAt: 'desc' },\n    });\n\n    return conversations;\n  } catch (error) {\n    logger.error({ error: error.message }, 'Failed to get recent conversations');\n    throw error;\n  }\n}\n\n// ============================================================================\n// SEARCH\n// ============================================================================\n\n/**\n * Search conversations by title\n * @param {string} query - Search query\n * @param {Object} options - Query options\n * @returns {Promise<Array>} Matching conversations\n */\nexport async function searchByTitle(query, options = {}) {\n  const { limit = 20, provider } = options;\n\n  try {\n    const conversations = await getPrismaClient().conversation.findMany({\n      where: {\n        title: {\n          contains: query,\n          mode: 'insensitive',\n        },\n        ...(provider && { provider }),\n      },\n      take: limit,\n      orderBy: { createdAt: 'desc' },\n    });\n\n    return conversations;\n  } catch (error) {\n    logger.error({ error: error.message, query }, 'Search failed');\n    throw error;\n  }\n}\n\nexport default {\n  createConversation,\n  findConversationById,\n  findBySourceUrl,\n  listConversations,\n  updateConversation,\n  deleteConversation,\n  createConversationsBatch,\n  getStatsByProvider,\n  getRecentConversations,\n  searchByTitle,\n};\n","usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\repositories\\index.js","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\routes\\account.js","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\routes\\acus.js","messages":[{"ruleId":"no-unused-vars","severity":1,"message":"'depth' is assigned a value but never used.","line":189,"column":13,"nodeType":"Identifier","messageId":"unusedVar","endLine":189,"endColumn":18,"suggestions":[{"messageId":"removeVar","data":{"varName":"depth"},"fix":{"range":[4287,4319],"text":""},"desc":"Remove unused variable 'depth'."}]},{"ruleId":"no-unused-vars","severity":1,"message":"'Prisma' is assigned a value but never used.","line":471,"column":13,"nodeType":"Identifier","messageId":"unusedVar","endLine":471,"endColumn":19,"suggestions":[{"messageId":"removeVar","data":{"varName":"Prisma"},"fix":{"range":[10743,10793],"text":""},"desc":"Remove unused variable 'Prisma'."}]},{"ruleId":"no-unused-vars","severity":1,"message":"'hash' is assigned a value but never used.","line":814,"column":13,"nodeType":"Identifier","messageId":"unusedVar","endLine":814,"endColumn":17},{"ruleId":"no-unused-vars","severity":1,"message":"'type' is defined but never used. Allowed unused args must match /^_/u.","line":984,"column":41,"nodeType":"Identifier","messageId":"unusedVar","endLine":984,"endColumn":45,"suggestions":[{"messageId":"removeVar","data":{"varName":"type"},"fix":{"range":[23855,23861],"text":""},"desc":"Remove unused variable 'type'."}]}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":4,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * ACU API Routes\n *\n * Endpoints for managing Atomic Chat Units (ACUs)\n *\n * Routes:\n * - GET    /api/v1/acus              - List ACUs with filtering\n * - GET    /api/v1/acus/:id          - Get single ACU\n * - GET    /api/v1/acus/:id/links    - Get ACU relationships\n * - POST   /api/v1/acus/search       - Semantic search\n * - POST   /api/v1/acus/process      - Process conversation to ACUs\n * - POST   /api/v1/acus/batch        - Batch process conversations\n */\n\nimport express from 'express';\nimport { getPrismaClient } from '../lib/database.js';\nimport { logger } from '../lib/logger.js';\nimport { processConversationToACUs, processAllConversations } from '../services/acu-processor.js';\n\nconst router = express.Router();\n\n/**\n * GET /api/v1/acus\n * List ACUs with filtering and pagination\n */\nrouter.get('/', async (req, res) => {\n  try {\n    const {\n      conversationId,\n      type,\n      category,\n      minQuality = 0,\n      limit = 50,\n      offset = 0,\n      sortBy = 'createdAt',\n      sortOrder = 'desc',\n    } = req.query;\n\n    // Build where clause\n    const where = {};\n    if (conversationId) {\n      where.conversationId = conversationId;\n    }\n    if (type) {\n      where.type = type;\n    }\n    if (category) {\n      where.category = category;\n    }\n    if (minQuality > 0) {\n      where.qualityOverall = { gte: parseFloat(minQuality) };\n    }\n\n    // Build orderBy clause\n    const orderBy = {};\n    orderBy[sortBy] = sortOrder;\n\n    // Fetch ACUs\n    const [acus, total] = await Promise.all([\n      getPrismaClient().atomicChatUnit.findMany({\n        where,\n        orderBy,\n        take: parseInt(limit),\n        skip: parseInt(offset),\n        include: {\n          conversation: {\n            select: {\n              id: true,\n              title: true,\n              provider: true,\n            },\n          },\n          message: {\n            select: {\n              id: true,\n              role: true,\n              messageIndex: true,\n            },\n          },\n        },\n      }),\n      getPrismaClient().atomicChatUnit.count({ where }),\n    ]);\n\n    res.json({\n      success: true,\n      data: acus,\n      pagination: {\n        total,\n        limit: parseInt(limit),\n        offset: parseInt(offset),\n        hasMore: offset + acus.length < total,\n      },\n    });\n  } catch (error) {\n    logger.error('Failed to list ACUs', { error: error.message });\n    res.status(500).json({\n      success: false,\n      error: 'Failed to list ACUs',\n      message: error.message,\n    });\n  }\n});\n\n/**\n * GET /api/v1/acus/:id\n * Get single ACU with full details\n */\nrouter.get('/:id', async (req, res) => {\n  try {\n    const { id } = req.params;\n\n    const acu = await getPrismaClient().atomicChatUnit.findUnique({\n      where: { id },\n      include: {\n        conversation: {\n          select: {\n            id: true,\n            title: true,\n            provider: true,\n            model: true,\n            createdAt: true,\n          },\n        },\n        message: {\n          select: {\n            id: true,\n            role: true,\n            author: true,\n            messageIndex: true,\n            createdAt: true,\n          },\n        },\n        linksFrom: {\n          include: {\n            target: {\n              select: {\n                id: true,\n                content: true,\n                type: true,\n                category: true,\n              },\n            },\n          },\n        },\n        linksTo: {\n          include: {\n            source: {\n              select: {\n                id: true,\n                content: true,\n                type: true,\n                category: true,\n              },\n            },\n          },\n        },\n      },\n    });\n\n    if (!acu) {\n      return res.status(404).json({\n        success: false,\n        error: 'ACU not found',\n      });\n    }\n\n    res.json({\n      success: true,\n      data: acu,\n    });\n  } catch (error) {\n    logger.error('Failed to get ACU', { error: error.message, id: req.params.id });\n    res.status(500).json({\n      success: false,\n      error: 'Failed to get ACU',\n      message: error.message,\n    });\n  }\n});\n\n/**\n * GET /api/v1/acus/:id/links\n * Get ACU relationships (graph)\n */\nrouter.get('/:id/links', async (req, res) => {\n  try {\n    const { id } = req.params;\n    const { depth = 1 } = req.query;\n\n    // Check if ACU exists\n    const acu = await getPrismaClient().atomicChatUnit.findUnique({\n      where: { id },\n    });\n\n    if (!acu) {\n      return res.status(404).json({\n        success: false,\n        error: 'ACU not found',\n      });\n    }\n\n    // Get links (simple implementation - could be optimized with recursive CTE)\n    const links = await getPrismaClient().acuLink.findMany({\n      where: {\n        OR: [{ sourceId: id }, { targetId: id }],\n      },\n      include: {\n        source: {\n          select: {\n            id: true,\n            content: true,\n            type: true,\n            category: true,\n            qualityOverall: true,\n          },\n        },\n        target: {\n          select: {\n            id: true,\n            content: true,\n            type: true,\n            category: true,\n            qualityOverall: true,\n          },\n        },\n      },\n    });\n\n    // Build graph structure\n    const nodes = new Map();\n    const edges = [];\n\n    // Add center node\n    nodes.set(id, {\n      id,\n      content: acu.content,\n      type: acu.type,\n      category: acu.category,\n      qualityOverall: acu.qualityOverall,\n      isCenter: true,\n    });\n\n    // Add linked nodes and edges\n    for (const link of links) {\n      if (!nodes.has(link.source.id)) {\n        nodes.set(link.source.id, {\n          ...link.source,\n          isCenter: false,\n        });\n      }\n      if (!nodes.has(link.target.id)) {\n        nodes.set(link.target.id, {\n          ...link.target,\n          isCenter: false,\n        });\n      }\n\n      edges.push({\n        id: link.id,\n        source: link.sourceId,\n        target: link.targetId,\n        relation: link.relation,\n        weight: link.weight,\n      });\n    }\n\n    res.json({\n      success: true,\n      data: {\n        center: id,\n        nodes: Array.from(nodes.values()),\n        edges,\n      },\n    });\n  } catch (error) {\n    logger.error('Failed to get ACU links', { error: error.message, id: req.params.id });\n    res.status(500).json({\n      success: false,\n      error: 'Failed to get ACU links',\n      message: error.message,\n    });\n  }\n});\n\n/**\n * POST /api/v1/acus/search\n * Semantic search for ACUs\n */\nrouter.post('/search', async (req, res) => {\n  try {\n    const { query, type, category, minQuality = 0, limit = 20 } = req.body;\n\n    if (!query) {\n      return res.status(400).json({\n        success: false,\n        error: 'Query is required',\n      });\n    }\n\n    // Build where clause\n    const where = {};\n    if (type) {\n      where.type = type;\n    }\n    if (category) {\n      where.category = category;\n    }\n    if (minQuality > 0) {\n      where.qualityOverall = { gte: parseFloat(minQuality) };\n    }\n\n    // For now, use simple text search\n    // In production, this would use vector similarity search\n    where.content = {\n      contains: query,\n      mode: 'insensitive',\n    };\n\n    const acus = await getPrismaClient().atomicChatUnit.findMany({\n      where,\n      take: parseInt(limit),\n      orderBy: {\n        qualityOverall: 'desc',\n      },\n      include: {\n        conversation: {\n          select: {\n            id: true,\n            title: true,\n            provider: true,\n          },\n        },\n      },\n    });\n\n    res.json({\n      success: true,\n      data: acus,\n      query,\n      count: acus.length,\n    });\n  } catch (error) {\n    logger.error('Failed to search ACUs', { error: error.message });\n    res.status(500).json({\n      success: false,\n      error: 'Failed to search ACUs',\n      message: error.message,\n    });\n  }\n});\n\n/**\n * POST /api/v1/acus/process\n * Process a conversation into ACUs\n */\nrouter.post('/process', async (req, res) => {\n  try {\n    const {\n      conversationId,\n      generateEmbeddings = false,\n      calculateQuality = true,\n      detectLinks = true,\n    } = req.body;\n\n    if (!conversationId) {\n      return res.status(400).json({\n        success: false,\n        error: 'conversationId is required',\n      });\n    }\n\n    // Start processing (async)\n    const result = await processConversationToACUs(conversationId, {\n      generateEmbeddings,\n      calculateQuality,\n      detectLinks,\n    });\n\n    if (result.success) {\n      res.json({\n        success: true,\n        data: result,\n      });\n    } else {\n      res.status(500).json({\n        success: false,\n        error: 'Processing failed',\n        message: result.error,\n      });\n    }\n  } catch (error) {\n    logger.error('Failed to process conversation', { error: error.message });\n    res.status(500).json({\n      success: false,\n      error: 'Failed to process conversation',\n      message: error.message,\n    });\n  }\n});\n\n/**\n * POST /api/v1/acus/batch\n * Batch process all conversations\n */\nrouter.post('/batch', async (req, res) => {\n  try {\n    const {\n      batchSize = 10,\n      delayMs = 1000,\n      generateEmbeddings = false,\n      calculateQuality = true,\n      detectLinks = true,\n    } = req.body;\n\n    // Start batch processing (this will take a while)\n    // In production, this should be a background job\n    logger.info('Starting batch ACU processing');\n\n    // Send immediate response\n    res.json({\n      success: true,\n      message: 'Batch processing started',\n      note: 'This is a long-running operation. Check logs for progress.',\n    });\n\n    // Process in background (don't await)\n    processAllConversations({\n      batchSize,\n      delayMs,\n      generateEmbeddings,\n      calculateQuality,\n      detectLinks,\n    })\n      .then((result) => {\n        logger.info('Batch processing complete', result);\n      })\n      .catch((error) => {\n        logger.error('Batch processing failed', { error: error.message });\n      });\n  } catch (error) {\n    logger.error('Failed to start batch processing', { error: error.message });\n    res.status(500).json({\n      success: false,\n      error: 'Failed to start batch processing',\n      message: error.message,\n    });\n  }\n});\n\n/**\n * POST /api/v1/acus/quick\n * Quick capture - minimal friction ACU creation\n */\nrouter.post('/quick', async (req, res) => {\n  try {\n    const { content, tags, type, category } = req.body;\n\n    if (!content?.trim()) {\n      return res.status(400).json({\n        success: false,\n        error: 'Content required',\n      });\n    }\n\n    // Auto-classify if not provided\n    const acuType = type || inferType(content);\n    const acuCategory = category || inferCategory(content);\n\n    // Generate ACU ID (content hash)\n    const { Prisma } = await import('@prisma/client');\n    const hash = await import('crypto');\n    const contentHash = hash.default\n      .createHash('sha256')\n      .update(content.trim())\n      .digest('hex')\n      .substring(0, 64);\n\n    const acuId = `acu-${contentHash}`;\n\n    // Check for duplicates\n    const existing = await getPrismaClient().atomicChatUnit.findUnique({\n      where: { id: acuId },\n    });\n\n    if (existing) {\n      return res.json({\n        success: true,\n        data: existing,\n        created: false,\n        reason: 'duplicate',\n      });\n    }\n\n    // Create ACU\n    const acu = await getPrismaClient().atomicChatUnit.create({\n      data: {\n        id: acuId,\n        authorDid: req.auth?.did || 'did:key:anon', // Would use real DID in production\n        signature: Buffer.from('quick-capture'),\n        content: content.trim(),\n        type: acuType,\n        category: acuCategory,\n        origin: 'quick_capture',\n        qualityOverall: calculateQuickQuality(content, acuType),\n        contentRichness: calculateQuickRichness(content),\n        structuralIntegrity: calculateQuickIntegrity(content),\n        uniqueness: 50,\n        tags: tags || [],\n        sharingPolicy: 'self',\n        sharingCircles: [],\n        canView: true,\n        canAnnotate: true,\n        canRemix: true,\n        canReshare: false,\n        metadata: {\n          source: 'quick-capture',\n          capturedAt: new Date().toISOString(),\n        },\n      },\n    });\n\n    res.json({\n      success: true,\n      data: acu,\n      created: true,\n    });\n  } catch (error) {\n    logger.error('Quick capture failed', { error: error.message });\n    res.status(500).json({\n      success: false,\n      error: 'Quick capture failed',\n      message: error.message,\n    });\n  }\n});\n\n/**\n * POST /api/v1/acus/:id/remix\n * Create a remix/derivative of an existing ACU\n */\nrouter.post('/:id/remix', async (req, res) => {\n  try {\n    const { id: parentId } = req.params;\n    const { content, tags, type = 'remix', category } = req.body;\n\n    if (!content?.trim()) {\n      return res.status(400).json({\n        success: false,\n        error: 'Content required',\n      });\n    }\n\n    // Check parent exists\n    const parent = await getPrismaClient().atomicChatUnit.findUnique({\n      where: { id: parentId },\n    });\n\n    if (!parent) {\n      return res.status(404).json({\n        success: false,\n        error: 'Parent ACU not found',\n      });\n    }\n\n    // Generate remix ID\n    const { hash } = await import('crypto');\n    const contentHash = hash.default\n      .createHash('sha256')\n      .update(`${parentId}:${content.trim()}`)\n      .digest('hex')\n      .substring(0, 64);\n\n    const remixId = `remix-${contentHash}`;\n\n    // Check for duplicate remix\n    const existing = await getPrismaClient().atomicChatUnit.findUnique({\n      where: { id: remixId },\n    });\n\n    if (existing) {\n      return res.json({\n        success: true,\n        data: existing,\n        created: false,\n        reason: 'duplicate',\n      });\n    }\n\n    // Create remix\n    const remix = await getPrismaClient().atomicChatUnit.create({\n      data: {\n        id: remixId,\n        authorDid: req.auth?.did || 'did:key:anon',\n        signature: Buffer.from('remix'),\n        content: content.trim(),\n        type,\n        category: category || parent.category || 'conceptual',\n        origin: 'remix',\n        parentId,\n        qualityOverall: 50, // Would calculate properly in production\n        contentRichness: 50,\n        structuralIntegrity: 50,\n        uniqueness: 50,\n        tags: tags || [...(parent.tags || [])],\n        sharingPolicy: parent.sharingPolicy,\n        sharingCircles: parent.sharingCircles,\n        canView: parent.canView,\n        canAnnotate: parent.canAnnotate,\n        canRemix: parent.canRemix,\n        canReshare: parent.canReshare,\n        metadata: {\n          source: 'remix',\n          parentId,\n          parentType: parent.type,\n          createdAt: new Date().toISOString(),\n        },\n      },\n    });\n\n    // Increment parent's quote count\n    await getPrismaClient().atomicChatUnit.update({\n      where: { id: parentId },\n      data: { quoteCount: { increment: 1 } },\n    });\n\n    // Create derivation link\n    await getPrismaClient().acuLink.create({\n      data: {\n        sourceId: remixId,\n        targetId: parentId,\n        relation: 'derived_from',\n        weight: 1.0,\n        createdByDid: req.auth?.did,\n      },\n    });\n\n    res.json({\n      success: true,\n      data: remix,\n      created: true,\n    });\n  } catch (error) {\n    logger.error('Remix failed', { error: error.message });\n    res.status(500).json({\n      success: false,\n      error: 'Remix failed',\n      message: error.message,\n    });\n  }\n});\n\n/**\n * POST /api/v1/acus/:id/annotate\n * Create an annotation on an existing ACU\n */\nrouter.post('/:id/annotate', async (req, res) => {\n  try {\n    const { id: parentId } = req.params;\n    const { content, tags, type = 'annotation', category } = req.body;\n\n    if (!content?.trim()) {\n      return res.status(400).json({\n        success: false,\n        error: 'Content required',\n      });\n    }\n\n    // Check parent exists\n    const parent = await getPrismaClient().atomicChatUnit.findUnique({\n      where: { id: parentId },\n    });\n\n    if (!parent) {\n      return res.status(404).json({\n        success: false,\n        error: 'Parent ACU not found',\n      });\n    }\n\n    // Generate annotation ID\n    const { hash } = await import('crypto');\n    const contentHash = hash.default\n      .createHash('sha256')\n      .update(`${parentId}:${content.trim()}`)\n      .digest('hex')\n      .substring(0, 64);\n\n    const annotationId = `anno-${contentHash}`;\n\n    // Check for duplicate annotation\n    const existing = await getPrismaClient().atomicChatUnit.findUnique({\n      where: { id: annotationId },\n    });\n\n    if (existing) {\n      return res.json({\n        success: true,\n        data: existing,\n        created: false,\n        reason: 'duplicate',\n      });\n    }\n\n    // Create annotation\n    const annotation = await getPrismaClient().atomicChatUnit.create({\n      data: {\n        id: annotationId,\n        authorDid: req.auth?.did || 'did:key:anon',\n        signature: Buffer.from('annotation'),\n        content: content.trim(),\n        type,\n        category: category || parent.category || 'conceptual',\n        origin: 'manual',\n        parentId,\n        qualityOverall: 50,\n        contentRichness: 50,\n        structuralIntegrity: 50,\n        uniqueness: 50,\n        tags: tags || [...(parent.tags || [])],\n        sharingPolicy: parent.sharingPolicy,\n        sharingCircles: parent.sharingCircles,\n        canView: parent.canView,\n        canAnnotate: true,\n        canRemix: parent.canRemix,\n        canReshare: parent.canReshare,\n        metadata: {\n          source: 'annotation',\n          parentId,\n          parentType: parent.type,\n          createdAt: new Date().toISOString(),\n        },\n      },\n    });\n\n    // Create annotation link\n    await getPrismaClient().acuLink.create({\n      data: {\n        sourceId: annotationId,\n        targetId: parentId,\n        relation: 'annotates',\n        weight: 1.0,\n        createdByDid: req.auth?.did,\n      },\n    });\n\n    res.json({\n      success: true,\n      data: annotation,\n      created: true,\n    });\n  } catch (error) {\n    logger.error('Annotation failed', { error: error.message });\n    res.status(500).json({\n      success: false,\n      error: 'Annotation failed',\n      message: error.message,\n    });\n  }\n});\n\n/**\n * POST /api/v1/acus/:id/bookmark\n * Bookmark an existing ACU\n */\nrouter.post('/:id/bookmark', async (req, res) => {\n  try {\n    const { id: acuId } = req.params;\n    const { notebookId } = req.body;\n\n    // Check ACU exists\n    const acu = await getPrismaClient().atomicChatUnit.findUnique({\n      where: { id: acuId },\n    });\n\n    if (!acu) {\n      return res.status(404).json({\n        success: false,\n        error: 'ACU not found',\n      });\n    }\n\n    // If notebookId provided, add to notebook\n    if (notebookId) {\n      const notebook = await getPrismaClient().notebook.findUnique({\n        where: { id: notebookId },\n      });\n\n      if (!notebook) {\n        return res.status(404).json({\n          success: false,\n          error: 'Notebook not found',\n        });\n      }\n\n      // Add to notebook (upsert to avoid duplicates)\n      await getPrismaClient().notebookEntry.upsert({\n        where: {\n          notebookId_acuId: {\n            notebookId,\n            acuId,\n          },\n        },\n        create: {\n          notebookId,\n          acuId,\n          sortOrder: 0,\n        },\n        update: {},\n      });\n    }\n\n    // Create bookmark ACU if not exists\n    const { hash } = await import('crypto');\n    const bookmarkId = `bookmark-${acuId}`;\n\n    const [bookmark] = await getPrismaClient().atomicChatUnit.upsert({\n      where: { id: bookmarkId },\n      create: {\n        id: bookmarkId,\n        authorDid: req.auth?.did || 'did:key:anon',\n        signature: Buffer.from('bookmark'),\n        content: `[Bookmark] ${acu.content.substring(0, 500)}${acu.content.length > 500 ? '...' : ''}`,\n        type: 'bookmark',\n        category: acu.category,\n        origin: 'manual',\n        parentId: acuId,\n        qualityOverall: acu.qualityOverall,\n        contentRichness: 30, // Short bookmark content\n        structuralIntegrity: 50,\n        uniqueness: 50,\n        tags: [...(acu.tags || []), 'bookmark'],\n        sharingPolicy: 'self',\n        canView: true,\n        canAnnotate: true,\n        canRemix: true,\n        canReshare: false,\n        metadata: {\n          source: 'bookmark',\n          originalAcuId: acuId,\n          bookmarkedAt: new Date().toISOString(),\n        },\n      },\n      update: {\n        // Update metadata if already exists\n        metadata: {\n          ...acu.metadata,\n          bookmarkedAt: new Date().toISOString(),\n        },\n      },\n    });\n\n    // Create bookmark link\n    await getPrismaClient().acuLink.upsert({\n      where: {\n        sourceId_targetId_relation: {\n          sourceId: bookmarkId,\n          targetId: acuId,\n          relation: 'bookmarks',\n        },\n      },\n      create: {\n        sourceId: bookmarkId,\n        targetId: acuId,\n        relation: 'bookmarks',\n        weight: 1.0,\n        createdByDid: req.auth?.did,\n      },\n      update: {},\n    });\n\n    res.json({\n      success: true,\n      data: bookmark,\n      created: true,\n    });\n  } catch (error) {\n    logger.error('Bookmark failed', { error: error.message });\n    res.status(500).json({\n      success: false,\n      error: 'Bookmark failed',\n      message: error.message,\n    });\n  }\n});\n\n/**\n * GET /api/v1/acus/stats\n * Get ACU statistics\n */\nrouter.get('/stats', async (req, res) => {\n  try {\n    const [total, byType, byCategory, avgQuality] = await Promise.all([\n      // Total count\n      getPrismaClient().atomicChatUnit.count(),\n\n      // Count by type\n      getPrismaClient().atomicChatUnit.groupBy({\n        by: ['type'],\n        _count: true,\n      }),\n\n      // Count by category\n      getPrismaClient().atomicChatUnit.groupBy({\n        by: ['category'],\n        _count: true,\n      }),\n\n      // Average quality\n      getPrismaClient().atomicChatUnit.aggregate({\n        _avg: {\n          qualityOverall: true,\n          contentRichness: true,\n          structuralIntegrity: true,\n          uniqueness: true,\n        },\n      }),\n    ]);\n\n    res.json({\n      success: true,\n      data: {\n        total,\n        byType: byType.reduce((acc, item) => {\n          acc[item.type] = item._count;\n          return acc;\n        }, {}),\n        byCategory: byCategory.reduce((acc, item) => {\n          acc[item.category] = item._count;\n          return acc;\n        }, {}),\n        avgQuality: {\n          overall: avgQuality._avg.qualityOverall?.toFixed(2),\n          richness: avgQuality._avg.contentRichness?.toFixed(2),\n          integrity: avgQuality._avg.structuralIntegrity?.toFixed(2),\n          uniqueness: avgQuality._avg.uniqueness?.toFixed(2),\n        },\n      },\n    });\n  } catch (error) {\n    logger.error('Failed to get ACU stats', { error: error.message });\n    res.status(500).json({\n      success: false,\n      error: 'Failed to get ACU stats',\n      message: error.message,\n    });\n  }\n});\n\n// ============================================================================\n// HELPER FUNCTIONS FOR NEW ENDPOINTS\n// ============================================================================\n\n/**\n * Infer ACU type from content for quick capture\n */\nfunction inferType(content) {\n  if (content.includes('```')) {\n    return 'code_snippet';\n  }\n  if (content.endsWith('?')) {\n    return 'question';\n  }\n  if (content.length < 140) {\n    return 'thought';\n  }\n  return 'note';\n}\n\n/**\n * Infer ACU category from content\n */\nfunction inferCategory(content) {\n  const techKeywords = /\\b(function|class|api|database|server|code|bug|deploy|git|programming)\\b/i;\n  if (techKeywords.test(content)) {\n    return 'technical';\n  }\n  return 'conceptual';\n}\n\n/**\n * Calculate quality for quick capture\n */\nfunction calculateQuickQuality(content, type) {\n  let score = 50;\n  const words = content.split(/\\s+/).length;\n  score += Math.min(words / 10, 20);\n  if (content.includes('```')) {\n    score += 15;\n  }\n  if (content.includes('?')) {\n    score += 10;\n  }\n  return Math.min(Math.round(score), 100);\n}\n\n/**\n * Calculate richness for quick capture\n */\nfunction calculateQuickRichness(content) {\n  let score = 30;\n  const words = content.split(/\\s+/).length;\n  if (words > 50) {\n    score += 20;\n  }\n  if (words > 100) {\n    score += 15;\n  }\n  if (content.includes('```')) {\n    score += 10;\n  }\n  return Math.min(score, 100);\n}\n\n/**\n * Calculate structural integrity for quick capture\n */\nfunction calculateQuickIntegrity(content) {\n  let score = 70;\n  if (content.length < 20) {\n    score -= 20;\n  }\n  const sentences = content.split(/[.!?]+/).filter((s) => s.trim().length > 0);\n  if (sentences.length > 2) {\n    score += 10;\n  }\n  return Math.min(Math.max(score, 0), 100);\n}\n\nexport default router;\n","usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\routes\\admin\\crdt.js","messages":[{"ruleId":"no-unused-vars","severity":1,"message":"'requireAdminAuth' is defined but never used.","line":8,"column":10,"nodeType":"Identifier","messageId":"unusedVar","endLine":8,"endColumn":26,"suggestions":[{"messageId":"removeVar","data":{"varName":"requireAdminAuth"},"fix":{"range":[120,186],"text":""},"desc":"Remove unused variable 'requireAdminAuth'."}]}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * Admin CRDT Routes\n *\n * CRDT document management and monitoring endpoints\n */\n\nimport { Router } from 'express';\nimport { requireAdminAuth } from '../../middleware/admin-auth.js';\nimport { createRequestLogger } from '../../lib/logger.js';\n\nconst router = Router();\n\n// Mock CRDT document data\nconst mockDocuments = [\n  {\n    id: 'crdt-1',\n    type: 'conversation',\n    version: 5,\n    status: 'SYNCED',\n    activePeers: 3,\n    lastSyncedAt: new Date().toISOString(),\n    createdAt: new Date(Date.now() - 86400000).toISOString(),\n    size: 24576,\n  },\n  {\n    id: 'crdt-2',\n    type: 'circle',\n    version: 12,\n    status: 'SYNCING',\n    activePeers: 5,\n    lastSyncedAt: new Date(Date.now() - 60000).toISOString(),\n    createdAt: new Date(Date.now() - 172800000).toISOString(),\n    size: 15360,\n  },\n  {\n    id: 'crdt-3',\n    type: 'group',\n    version: 3,\n    status: 'CONFLICT',\n    activePeers: 2,\n    lastSyncedAt: new Date(Date.now() - 300000).toISOString(),\n    createdAt: new Date(Date.now() - 259200000).toISOString(),\n    size: 8192,\n    conflicts: [\n      {\n        field: 'title',\n        values: ['Project Alpha', 'Project Beta'],\n        peers: ['peer-1', 'peer-2'],\n      },\n    ],\n  },\n];\n\n// ============================================================================\n// GET CRDT DOCUMENTS\n// ============================================================================\n\n/**\n * GET /api/admin/crdt/documents\n *\n * List all CRDT documents\n */\nrouter.get('/documents', async (req, res, next) => {\n  const log = createRequestLogger(req);\n\n  try {\n    const { type, status } = req.query;\n\n    let filtered = mockDocuments;\n\n    if (type) {\n      filtered = filtered.filter((d) => d.type === type);\n    }\n\n    if (status) {\n      filtered = filtered.filter((d) => d.status === status);\n    }\n\n    log.info({ count: filtered.length, filters: { type, status } }, 'CRDT documents listed');\n\n    res.json(filtered);\n  } catch (error) {\n    next(error);\n  }\n});\n\n// ============================================================================\n// GET DOCUMENT DETAILS\n// ============================================================================\n\n/**\n * GET /api/admin/crdt/documents/:id\n *\n * Get CRDT document details\n */\nrouter.get('/documents/:id', async (req, res, next) => {\n  const log = createRequestLogger(req);\n\n  try {\n    const { id } = req.params;\n    const document = mockDocuments.find((d) => d.id === id);\n\n    if (!document) {\n      return res.status(404).json({ error: 'Document not found' });\n    }\n\n    log.info({ documentId: id }, 'CRDT document retrieved');\n\n    res.json(document);\n  } catch (error) {\n    next(error);\n  }\n});\n\n// ============================================================================\n// GET DOCUMENT SYNC STATUS\n// ============================================================================\n\n/**\n * GET /api/admin/crdt/documents/:id/sync\n *\n * Get CRDT document sync status\n */\nrouter.get('/documents/:id/sync', async (req, res, next) => {\n  const log = createRequestLogger(req);\n\n  try {\n    const { id } = req.params;\n    const document = mockDocuments.find((d) => d.id === id);\n\n    if (!document) {\n      return res.status(404).json({ error: 'Document not found' });\n    }\n\n    const syncStatus = {\n      status: document.status,\n      activePeers: document.activePeers,\n      lastSyncedAt: document.lastSyncedAt,\n      conflicts: document.conflicts || [],\n    };\n\n    log.info({ documentId: id }, 'CRDT sync status retrieved');\n\n    res.json(syncStatus);\n  } catch (error) {\n    next(error);\n  }\n});\n\n// ============================================================================\n// RESOLVE DOCUMENT CONFLICT\n// ============================================================================\n\n/**\n * POST /api/admin/crdt/documents/:id/resolve\n *\n * Resolve CRDT document conflicts\n */\nrouter.post('/documents/:id/resolve', async (req, res, next) => {\n  const log = createRequestLogger(req);\n\n  try {\n    const { id } = req.params;\n    const { resolution } = req.body;\n\n    if (!resolution) {\n      return res.status(400).json({ error: 'Resolution data is required' });\n    }\n\n    // TODO: Integrate with CRDTSyncService to actually resolve conflicts\n    // await crdtService.resolveConflict(id, resolution);\n\n    log.info({ documentId: id, resolution }, 'CRDT conflict resolved');\n\n    res.json({\n      success: true,\n      message: 'Conflict resolved successfully',\n      documentId: id,\n    });\n  } catch (error) {\n    next(error);\n  }\n});\n\nexport default router;\n","usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\routes\\admin\\database.js","messages":[{"ruleId":"no-unused-vars","severity":1,"message":"'next' is defined but never used. Allowed unused args must match /^_/u.","line":115,"column":40,"nodeType":"Identifier","messageId":"unusedVar","endLine":115,"endColumn":44,"suggestions":[{"messageId":"removeVar","data":{"varName":"next"},"fix":{"range":[2806,2812],"text":""},"desc":"Remove unused variable 'next'."}]}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * Admin Database Routes\n *\n * Database exploration and query endpoints\n */\n\nimport { Router } from 'express';\nimport { createRequestLogger } from '../../lib/logger.js';\nimport { getPrismaClient } from '../../lib/database.js';\n\nconst router = Router();\nconst prisma = getPrismaClient();\n\n// Mock table data - will integrate with Prisma introspection\nconst mockTables = [\n  {\n    name: 'conversations',\n    rows: 1524,\n    size: '2.4 MB',\n    lastUpdated: new Date().toISOString(),\n  },\n  {\n    name: 'messages',\n    rows: 8543,\n    size: '12.8 MB',\n    lastUpdated: new Date().toISOString(),\n  },\n  {\n    name: 'users',\n    rows: 234,\n    size: '156 KB',\n    lastUpdated: new Date().toISOString(),\n  },\n  {\n    name: 'collections',\n    rows: 45,\n    size: '89 KB',\n    lastUpdated: new Date().toISOString(),\n  },\n];\n\n// ============================================================================\n// GET DATABASE TABLES\n// ============================================================================\n\n/**\n * GET /api/admin/database/tables\n *\n * List all database tables\n */\nrouter.get('/tables', async (req, res, next) => {\n  const log = createRequestLogger(req);\n\n  try {\n    // TODO: Use Prisma introspection to get real table data\n    // const tables = await prisma._queryRaw(`SELECT ...`);\n\n    log.info({ count: mockTables.length }, 'Database tables listed');\n\n    res.json(mockTables);\n  } catch (error) {\n    next(error);\n  }\n});\n\n// ============================================================================\n// GET TABLE DETAILS\n// ============================================================================\n\n/**\n * GET /api/admin/database/tables/:name\n *\n * Get table schema and details\n */\nrouter.get('/tables/:name', async (req, res, next) => {\n  const log = createRequestLogger(req);\n\n  try {\n    const { name } = req.params;\n\n    // TODO: Get actual table schema from Prisma/Postgres\n    const table = mockTables.find((t) => t.name === name);\n\n    if (!table) {\n      return res.status(404).json({ error: 'Table not found' });\n    }\n\n    // Mock column data\n    const columns = [\n      { name: 'id', type: 'UUID', nullable: false, primary: true },\n      { name: 'createdAt', type: 'TIMESTAMP', nullable: false, primary: false },\n      { name: 'updatedAt', type: 'TIMESTAMP', nullable: false, primary: false },\n    ];\n\n    log.info({ tableName: name }, 'Table details retrieved');\n\n    res.json({\n      ...table,\n      columns,\n    });\n  } catch (error) {\n    next(error);\n  }\n});\n\n// ============================================================================\n// EXECUTE SQL QUERY\n// ============================================================================\n\n/**\n * POST /api/admin/database/query\n *\n * Execute SQL query (READ-ONLY for now)\n */\nrouter.post('/query', async (req, res, next) => {\n  const log = createRequestLogger(req);\n\n  try {\n    const { query } = req.body;\n\n    if (!query) {\n      return res.status(400).json({ error: 'Query is required' });\n    }\n\n    // Basic validation - only allow SELECT queries\n    const trimmedQuery = query.trim().toUpperCase();\n\n    if (!trimmedQuery.startsWith('SELECT')) {\n      return res.status(400).json({\n        error: 'Only SELECT queries are allowed',\n        query,\n      });\n    }\n\n    // Log query for audit\n    log.info({ query }, 'Executing database query');\n\n    // Execute query with Prisma\n    const result = await prisma.$queryRawUnsafe(query);\n\n    // Format result\n    const response = {\n      columns: result.length > 0 ? Object.keys(result[0]) : [],\n      rows: result,\n      rowCount: result.length,\n      executionTime: Math.random() * 100, // Mock execution time\n    };\n\n    res.json(response);\n  } catch (error) {\n    log.error({ error: error.message, query: req.body.query }, 'Query execution failed');\n\n    res.status(500).json({\n      error: 'Query execution failed',\n      message: error.message,\n    });\n  }\n});\n\n// ============================================================================\n// GET DATABASE STATS\n// ============================================================================\n\n/**\n * GET /api/admin/database/stats\n *\n * Get database statistics\n */\nrouter.get('/stats', async (req, res, next) => {\n  const log = createRequestLogger(req);\n\n  try {\n    // TODO: Get real stats from database\n    const stats = {\n      totalTables: mockTables.length,\n      totalRows: mockTables.reduce((sum, t) => sum + t.rows, 0),\n      totalSize: '15.4 MB',\n      performance: {\n        avgQueryTime: 12.5,\n        slowQueries: 3,\n      },\n    };\n\n    log.info('Database stats retrieved');\n\n    res.json(stats);\n  } catch (error) {\n    next(error);\n  }\n});\n\nexport default router;\n","usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\routes\\admin\\dataflow.js","messages":[{"ruleId":"no-unused-vars","severity":1,"message":"'requireAdminAuth' is defined but never used.","line":8,"column":10,"nodeType":"Identifier","messageId":"unusedVar","endLine":8,"endColumn":26,"suggestions":[{"messageId":"removeVar","data":{"varName":"requireAdminAuth"},"fix":{"range":[120,186],"text":""},"desc":"Remove unused variable 'requireAdminAuth'."}]}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * Admin DataFlow Routes\n *\n * Data flow monitoring and statistics endpoints\n */\n\nimport { Router } from 'express';\nimport { requireAdminAuth } from '../../middleware/admin-auth.js';\nimport { createRequestLogger } from '../../lib/logger.js';\n\nconst router = Router();\n\n// Mock data flow data\nconst mockDataFlows = [\n  {\n    id: 'flow-1',\n    type: 'DHT',\n    source: 'node-1',\n    target: 'node-2',\n    status: 'active',\n    messagesPerSecond: 12.5,\n    bytesPerSecond: 51200,\n    totalMessages: 12453,\n    lastActivity: new Date().toISOString(),\n  },\n  {\n    id: 'flow-2',\n    type: 'PubSub',\n    source: 'node-1',\n    target: 'topic-1',\n    status: 'active',\n    messagesPerSecond: 45.2,\n    bytesPerSecond: 128000,\n    totalMessages: 45321,\n    lastActivity: new Date().toISOString(),\n  },\n  {\n    id: 'flow-3',\n    type: 'CRDT',\n    source: 'node-2',\n    target: 'node-3',\n    status: 'syncing',\n    messagesPerSecond: 8.7,\n    bytesPerSecond: 32768,\n    totalMessages: 8765,\n    lastActivity: new Date(Date.now() - 5000).toISOString(),\n  },\n  {\n    id: 'flow-4',\n    type: 'Federation',\n    source: 'instance-1',\n    target: 'instance-2',\n    status: 'active',\n    messagesPerSecond: 23.4,\n    bytesPerSecond: 96000,\n    totalMessages: 23456,\n    lastActivity: new Date().toISOString(),\n  },\n];\n\n// ============================================================================\n// GET DATA FLOWS\n// ============================================================================\n\n/**\n * GET /api/admin/dataflow/flows\n *\n * List all data flows\n */\nrouter.get('/flows', async (req, res, next) => {\n  const log = createRequestLogger(req);\n\n  try {\n    const { type, status } = req.query;\n\n    let filtered = mockDataFlows;\n\n    if (type) {\n      filtered = filtered.filter((f) => f.type === type);\n    }\n\n    if (status) {\n      filtered = filtered.filter((f) => f.status === status);\n    }\n\n    log.info({ count: filtered.length, filters: { type, status } }, 'Data flows listed');\n\n    res.json(filtered);\n  } catch (error) {\n    next(error);\n  }\n});\n\n// ============================================================================\n// GET DATA FLOW STATS\n// ============================================================================\n\n/**\n * GET /api/admin/dataflow/stats\n *\n * Get data flow statistics\n */\nrouter.get('/stats', async (req, res, next) => {\n  const log = createRequestLogger(req);\n\n  try {\n    const totalMessagesPerSecond = mockDataFlows.reduce((sum, f) => sum + f.messagesPerSecond, 0);\n\n    const totalBytesPerSecond = mockDataFlows.reduce((sum, f) => sum + f.bytesPerSecond, 0);\n\n    const stats = {\n      totalFlows: mockDataFlows.length,\n      activeFlows: mockDataFlows.filter((f) => f.status === 'active').length,\n      totalMessagesPerSecond: Math.round(totalMessagesPerSecond * 100) / 100,\n      totalBytesPerSecond: Math.round(totalBytesPerSecond),\n      byType: {\n        DHT: mockDataFlows.filter((f) => f.type === 'DHT').length,\n        PubSub: mockDataFlows.filter((f) => f.type === 'PubSub').length,\n        CRDT: mockDataFlows.filter((f) => f.type === 'CRDT').length,\n        Federation: mockDataFlows.filter((f) => f.type === 'Federation').length,\n      },\n    };\n\n    log.info('Data flow stats retrieved');\n\n    res.json(stats);\n  } catch (error) {\n    next(error);\n  }\n});\n\nexport default router;\n","usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\routes\\admin\\network.js","messages":[{"ruleId":"no-unused-vars","severity":1,"message":"'requireAdminAuth' is defined but never used.","line":8,"column":10,"nodeType":"Identifier","messageId":"unusedVar","endLine":8,"endColumn":26,"suggestions":[{"messageId":"removeVar","data":{"varName":"requireAdminAuth"},"fix":{"range":[117,183],"text":""},"desc":"Remove unused variable 'requireAdminAuth'."}]}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * Admin Network Routes\n *\n * Network monitoring and management endpoints\n */\n\nimport { Router } from 'express';\nimport { requireAdminAuth } from '../../middleware/admin-auth.js';\nimport { createRequestLogger } from '../../lib/logger.js';\n\nconst router = Router();\n\n// Mock network data for now - will integrate with NetworkNode package later\nconst mockNodes = [\n  {\n    id: 'node-1',\n    peerId: '12D3KooW...abc123',\n    status: 'online',\n    role: 'bootstrap',\n    ip: '192.168.1.100',\n    port: 30333,\n    uptime: 86400000,\n    lastSeen: new Date().toISOString(),\n  },\n  {\n    id: 'node-2',\n    peerId: '12D3KooW...def456',\n    status: 'online',\n    role: 'peer',\n    ip: '192.168.1.101',\n    port: 30333,\n    uptime: 43200000,\n    lastSeen: new Date().toISOString(),\n  },\n];\n\nconst mockConnections = [\n  {\n    id: 'conn-1',\n    sourceNodeId: 'node-1',\n    targetNodeId: 'node-2',\n    status: 'active',\n    latency: 25,\n    bandwidth: 1000000,\n    establishedAt: new Date(Date.now() - 3600000).toISOString(),\n  },\n];\n\nconst mockMetrics = [];\n\n// Generate some recent metrics\nfor (let i = 0; i < 50; i++) {\n  mockMetrics.push({\n    timestamp: new Date(Date.now() - i * 60000).toISOString(),\n    peerCount: 7 + Math.floor(Math.random() * 3),\n    connectionCount: 4 + Math.floor(Math.random() * 3),\n    bandwidthIn: 1000000 + Math.random() * 2000000,\n    bandwidthOut: 800000 + Math.random() * 1500000,\n    latencyAvg: 20 + Math.random() * 40,\n    dhtLookupTime: 10 + Math.random() * 30,\n    messageQueueSize: Math.floor(Math.random() * 100),\n    cacheHitRate: 0.7 + Math.random() * 0.25,\n    errorRate: Math.random() * 0.05,\n  });\n}\n\n// ============================================================================\n// GET NETWORK NODES\n// ============================================================================\n\n/**\n * GET /api/admin/network/nodes\n *\n * List all network nodes\n */\nrouter.get('/nodes', async (req, res, next) => {\n  const log = createRequestLogger(req);\n\n  try {\n    // TODO: Integrate with NetworkNode package\n    // const nodes = await adminNetworkService.getNodes();\n\n    log.info({ count: mockNodes.length }, 'Network nodes listed');\n\n    res.json(mockNodes);\n  } catch (error) {\n    next(error);\n  }\n});\n\n// ============================================================================\n// GET NODE DETAILS\n// ============================================================================\n\n/**\n * GET /api/admin/network/nodes/:id\n *\n * Get node details by ID\n */\nrouter.get('/nodes/:id', async (req, res, next) => {\n  const log = createRequestLogger(req);\n\n  try {\n    const { id } = req.params;\n    const node = mockNodes.find((n) => n.id === id);\n\n    if (!node) {\n      return res.status(404).json({ error: 'Node not found' });\n    }\n\n    log.info({ nodeId: id }, 'Node details retrieved');\n\n    res.json(node);\n  } catch (error) {\n    next(error);\n  }\n});\n\n// ============================================================================\n// GET NETWORK CONNECTIONS\n// ============================================================================\n\n/**\n * GET /api/admin/network/connections\n *\n * List all network connections\n */\nrouter.get('/connections', async (req, res, next) => {\n  const log = createRequestLogger(req);\n\n  try {\n    log.info({ count: mockConnections.length }, 'Network connections listed');\n\n    res.json(mockConnections);\n  } catch (error) {\n    next(error);\n  }\n});\n\n// ============================================================================\n// GET NETWORK METRICS\n// ============================================================================\n\n/**\n * GET /api/admin/network/metrics\n *\n * Get network metrics\n */\nrouter.get('/metrics', async (req, res, next) => {\n  const log = createRequestLogger(req);\n\n  try {\n    const limit = parseInt(req.query.limit || '100', 10);\n\n    log.info({ limit }, 'Network metrics retrieved');\n\n    res.json(mockMetrics.slice(0, limit));\n  } catch (error) {\n    next(error);\n  }\n});\n\n// ============================================================================\n// GET LATEST METRICS\n// ============================================================================\n\n/**\n * GET /api/admin/network/metrics/latest\n *\n * Get latest network metrics\n */\nrouter.get('/metrics/latest', async (req, res, next) => {\n  const log = createRequestLogger(req);\n\n  try {\n    log.info('Latest network metrics retrieved');\n\n    res.json(mockMetrics[0]);\n  } catch (error) {\n    next(error);\n  }\n});\n\n// ============================================================================\n// GET NETWORK STATS\n// ============================================================================\n\n/**\n * GET /api/admin/network/stats\n *\n * Get network statistics summary\n */\nrouter.get('/stats', async (req, res, next) => {\n  const log = createRequestLogger(req);\n\n  try {\n    const stats = {\n      totalNodes: mockNodes.length,\n      activeNodes: mockNodes.filter((n) => n.status === 'online').length,\n      totalConnections: mockConnections.length,\n      activeConnections: mockConnections.filter((c) => c.status === 'active').length,\n      avgLatency: mockConnections.reduce((sum, c) => sum + c.latency, 0) / mockConnections.length,\n      totalBandwidth: mockConnections.reduce((sum, c) => sum + c.bandwidth, 0),\n    };\n\n    log.info('Network stats retrieved');\n\n    res.json(stats);\n  } catch (error) {\n    next(error);\n  }\n});\n\nexport default router;\n","usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\routes\\admin\\pubsub.js","messages":[{"ruleId":"no-unused-vars","severity":1,"message":"'requireAdminAuth' is defined but never used.","line":8,"column":10,"nodeType":"Identifier","messageId":"unusedVar","endLine":8,"endColumn":26,"suggestions":[{"messageId":"removeVar","data":{"varName":"requireAdminAuth"},"fix":{"range":[106,172],"text":""},"desc":"Remove unused variable 'requireAdminAuth'."}]}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * Admin PubSub Routes\n *\n * PubSub topic management endpoints\n */\n\nimport { Router } from 'express';\nimport { requireAdminAuth } from '../../middleware/admin-auth.js';\nimport { createRequestLogger } from '../../lib/logger.js';\n\nconst router = Router();\n\n// Mock PubSub topic data\nconst mockTopics = [\n  {\n    id: 'topic-1',\n    name: 'conversations',\n    type: 'broadcast',\n    subscriberCount: 5,\n    messageCount: 1243,\n    lastMessageAt: new Date().toISOString(),\n    createdAt: new Date(Date.now() - 86400000).toISOString(),\n  },\n  {\n    id: 'topic-2',\n    name: 'circles',\n    type: 'topic',\n    subscriberCount: 3,\n    messageCount: 456,\n    lastMessageAt: new Date(Date.now() - 300000).toISOString(),\n    createdAt: new Date(Date.now() - 172800000).toISOString(),\n  },\n  {\n    id: 'topic-3',\n    name: 'sync',\n    type: 'broadcast',\n    subscriberCount: 7,\n    messageCount: 3421,\n    lastMessageAt: new Date(Date.now() - 60000).toISOString(),\n    createdAt: new Date(Date.now() - 259200000).toISOString(),\n  },\n];\n\nconst mockSubscribers = [\n  {\n    id: 'sub-1',\n    peerId: '12D3KooW...abc123',\n    topicId: 'topic-1',\n    subscribedAt: new Date(Date.now() - 3600000).toISOString(),\n    messageReceived: 234,\n  },\n  {\n    id: 'sub-2',\n    peerId: '12D3KooW...def456',\n    topicId: 'topic-1',\n    subscribedAt: new Date(Date.now() - 7200000).toISOString(),\n    messageReceived: 187,\n  },\n];\n\n// ============================================================================\n// GET PUBSUB TOPICS\n// ============================================================================\n\n/**\n * GET /api/admin/pubsub/topics\n *\n * List all PubSub topics\n */\nrouter.get('/topics', async (req, res, next) => {\n  const log = createRequestLogger(req);\n\n  try {\n    const { type } = req.query;\n\n    let filtered = mockTopics;\n\n    if (type) {\n      filtered = filtered.filter((t) => t.type === type);\n    }\n\n    log.info({ count: filtered.length, filters: { type } }, 'PubSub topics listed');\n\n    res.json(filtered);\n  } catch (error) {\n    next(error);\n  }\n});\n\n// ============================================================================\n// GET TOPIC DETAILS\n// ============================================================================\n\n/**\n * GET /api/admin/pubsub/topics/:id\n *\n * Get PubSub topic details\n */\nrouter.get('/topics/:id', async (req, res, next) => {\n  const log = createRequestLogger(req);\n\n  try {\n    const { id } = req.params;\n    const topic = mockTopics.find((t) => t.id === id);\n\n    if (!topic) {\n      return res.status(404).json({ error: 'Topic not found' });\n    }\n\n    log.info({ topicId: id }, 'PubSub topic retrieved');\n\n    res.json(topic);\n  } catch (error) {\n    next(error);\n  }\n});\n\n// ============================================================================\n// GET TOPIC SUBSCRIBERS\n// ============================================================================\n\n/**\n * GET /api/admin/pubsub/topics/:id/subscribers\n *\n * Get topic subscribers\n */\nrouter.get('/topics/:id/subscribers', async (req, res, next) => {\n  const log = createRequestLogger(req);\n\n  try {\n    const { id } = req.params;\n\n    const subscribers = mockSubscribers.filter((s) => s.topicId === id);\n\n    log.info({ topicId: id, count: subscribers.length }, 'Topic subscribers retrieved');\n\n    res.json(subscribers);\n  } catch (error) {\n    next(error);\n  }\n});\n\nexport default router;\n","usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\routes\\admin\\system.js","messages":[{"ruleId":"no-unused-vars","severity":1,"message":"'requireAdminAuth' is defined but never used.","line":8,"column":10,"nodeType":"Identifier","messageId":"unusedVar","endLine":8,"endColumn":26,"suggestions":[{"messageId":"removeVar","data":{"varName":"requireAdminAuth"},"fix":{"range":[118,184],"text":""},"desc":"Remove unused variable 'requireAdminAuth'."}]},{"ruleId":"no-unused-vars","severity":1,"message":"'error' is defined but never used.","line":229,"column":14,"nodeType":"Identifier","messageId":"unusedVar","endLine":229,"endColumn":19}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":2,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * Admin System Routes\n *\n * System monitoring, logs, and health endpoints\n */\n\nimport { Router } from 'express';\nimport { requireAdminAuth } from '../../middleware/admin-auth.js';\nimport { createRequestLogger } from '../../lib/logger.js';\nimport { getPrismaClient } from '../../lib/database.js';\nimport os from 'os';\n\nconst router = Router();\nconst prisma = getPrismaClient();\n\n// ============================================================================\n// GET SYSTEM STATS\n// ============================================================================\n\n/**\n * GET /api/admin/system/stats\n *\n * Get system resource statistics\n */\nrouter.get('/stats', async (req, res, next) => {\n  const log = createRequestLogger(req);\n\n  try {\n    const stats = {\n      cpu: {\n        usage: process.cpuUsage().user / 1000000, // Convert to seconds\n        cores: os.cpus().length,\n        loadAverage: os.loadavg(),\n      },\n      memory: {\n        total: os.totalmem(),\n        free: os.freemem(),\n        used: os.totalmem() - os.freemem(),\n        percentage: ((os.totalmem() - os.freemem()) / os.totalmem()) * 100,\n      },\n      disk: {\n        // TODO: Get actual disk usage\n        total: 1000000000000,\n        used: 500000000000,\n        free: 500000000000,\n        percentage: 50,\n      },\n      uptime: process.uptime(),\n      timestamp: new Date().toISOString(),\n    };\n\n    log.info('System stats retrieved');\n\n    res.json(stats);\n  } catch (error) {\n    next(error);\n  }\n});\n\n// ============================================================================\n// GET USER STATS\n// ============================================================================\n\n/**\n * GET /api/admin/system/users/stats\n *\n * Get user statistics\n */\nrouter.get('/users/stats', async (req, res, next) => {\n  const log = createRequestLogger(req);\n\n  try {\n    // Get user count from database\n    const userCount = await prisma.user.count();\n\n    const stats = {\n      totalUsers: userCount,\n      activeUsers: Math.floor(userCount * 0.7), // Mock active users\n      newUsersToday: Math.floor(Math.random() * 10),\n      newUsersWeek: Math.floor(Math.random() * 50),\n    };\n\n    log.info('User stats retrieved');\n\n    res.json(stats);\n  } catch (error) {\n    next(error);\n  }\n});\n\n// ============================================================================\n// GET CONVERSATION STATS\n// ============================================================================\n\n/**\n * GET /api/admin/system/conversations/stats\n *\n * Get conversation statistics\n */\nrouter.get('/conversations/stats', async (req, res, next) => {\n  const log = createRequestLogger(req);\n\n  try {\n    const conversationCount = await prisma.conversation.count();\n\n    const stats = {\n      totalConversations: conversationCount,\n      publicConversations: Math.floor(conversationCount * 0.3),\n      privateConversations: Math.floor(conversationCount * 0.7),\n      totalMessages: await prisma.message.count(),\n      avgMessagesPerConversation: 5.7,\n    };\n\n    log.info('Conversation stats retrieved');\n\n    res.json(stats);\n  } catch (error) {\n    next(error);\n  }\n});\n\n// ============================================================================\n// GET STORAGE STATS\n// ============================================================================\n\n/**\n * GET /api/admin/system/storage/stats\n *\n * Get storage statistics\n */\nrouter.get('/storage/stats', async (req, res, next) => {\n  const log = createRequestLogger(req);\n\n  try {\n    const stats = {\n      database: {\n        totalSize: '15.4 MB',\n        tables: 4,\n        rows: 10346,\n      },\n      indexedDB: {\n        // PWA local storage\n        totalSize: '8.2 MB',\n        documents: 1524,\n      },\n      cache: {\n        totalSize: '125 MB',\n        entries: 342,\n      },\n      timestamp: new Date().toISOString(),\n    };\n\n    log.info('Storage stats retrieved');\n\n    res.json(stats);\n  } catch (error) {\n    next(error);\n  }\n});\n\n// ============================================================================\n// GET SYSTEM LOGS\n// ============================================================================\n\n/**\n * GET /api/admin/system/logs\n *\n * Get system logs with filtering\n */\nrouter.get('/logs', async (req, res, next) => {\n  const log = createRequestLogger(req);\n\n  try {\n    const { level, source, limit = 100 } = req.query;\n\n    // TODO: Integrate with actual logging system\n    // For now, return mock logs\n    const mockLogs = [];\n\n    for (let i = 0; i < parseInt(limit, 10); i++) {\n      const levels = ['debug', 'info', 'warn', 'error'];\n      const sources = ['server', 'database', 'network', 'api', 'auth'];\n      const messages = [\n        'Request received',\n        'Database query executed',\n        'User authenticated',\n        'Network node connected',\n        'API rate limit checked',\n      ];\n\n      mockLogs.push({\n        id: `log-${i}`,\n        timestamp: new Date(Date.now() - i * 60000).toISOString(),\n        level: level || levels[Math.floor(Math.random() * levels.length)],\n        source: source || sources[Math.floor(Math.random() * sources.length)],\n        message: messages[Math.floor(Math.random() * messages.length)],\n        metadata: {\n          userId: `user-${Math.floor(Math.random() * 100)}`,\n          requestId: `req-${Math.random().toString(36).substring(7)}`,\n        },\n      });\n    }\n\n    log.info({ count: mockLogs.length, filters: { level, source } }, 'System logs retrieved');\n\n    res.json(mockLogs);\n  } catch (error) {\n    next(error);\n  }\n});\n\n// ============================================================================\n// GET SYSTEM HEALTH\n// ============================================================================\n\n/**\n * GET /api/admin/system/health\n *\n * Get system health status\n */\nrouter.get('/health', async (req, res, next) => {\n  const log = createRequestLogger(req);\n\n  try {\n    // Check database connection\n    let dbStatus = 'up';\n    try {\n      await prisma.$queryRaw`SELECT 1`;\n    } catch (error) {\n      dbStatus = 'down';\n    }\n\n    const health = {\n      status: dbStatus === 'up' ? 'healthy' : 'degraded',\n      services: {\n        database: dbStatus,\n        network: 'up', // TODO: Check actual network status\n        storage: 'up', // TODO: Check actual storage\n        api: 'up',\n      },\n      uptime: process.uptime(),\n      timestamp: new Date().toISOString(),\n    };\n\n    log.info('System health retrieved');\n\n    res.json(health);\n  } catch (error) {\n    next(error);\n  }\n});\n\nexport default router;\n","usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\routes\\ai-chat.js","messages":[{"ruleId":"no-useless-escape","severity":2,"message":"Unnecessary escape character: \\/.","line":132,"column":33,"nodeType":"Literal","messageId":"unnecessaryEscape","endLine":132,"endColumn":34,"suggestions":[{"messageId":"removeEscape","fix":{"range":[4070,4071],"text":""},"desc":"Remove the `\\`. This maintains the current functionality."},{"messageId":"escapeBackslash","fix":{"range":[4070,4070],"text":"\\"},"desc":"Replace the `\\` with `\\\\` to include the actual backslash character."}]},{"ruleId":"no-useless-escape","severity":2,"message":"Unnecessary escape character: \\/.","line":140,"column":33,"nodeType":"Literal","messageId":"unnecessaryEscape","endLine":140,"endColumn":34,"suggestions":[{"messageId":"removeEscape","fix":{"range":[4284,4285],"text":""},"desc":"Remove the `\\`. This maintains the current functionality."},{"messageId":"escapeBackslash","fix":{"range":[4284,4284],"text":"\\"},"desc":"Replace the `\\` with `\\\\` to include the actual backslash character."}]}],"suppressedMessages":[],"errorCount":2,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"source":"// apps/server/src/routes/ai-chat.js\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// FRESH AI CHAT - Standalone conversations with optional context system\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n//\n// This route handles FRESH conversations â€” lightweight with optional context.\n// In-memory conversation state for the duration of the session.\n// Supports personas, provider switching, streaming, and context integration.\n\nimport { Router } from 'express';\nimport { unifiedProvider } from '../ai/unified-provider.js';\nimport { systemPromptManager } from '../ai/system-prompts.js';\nimport { unifiedContextService } from '../services/unified-context-service.js';\nimport { logger } from '../lib/logger.js';\nimport { ProviderConfig, getDefaultProvider } from '../types/ai.js';\nimport { freshChatSchema } from '../validators/ai.js';\nimport { executeZAIAction, isMCPConfigured } from '../services/zai-mcp-service.js';\n\nconst router = Router();\n\n// In-memory conversation store (per-session, no persistence)\nconst conversations = new Map();\n\n// Cleanup stale conversations every 30 minutes\nsetInterval(\n  () => {\n    const staleThreshold = Date.now() - 60 * 60 * 1000; // 1 hour\n    for (const [id, conv] of conversations) {\n      if (conv.lastActivity < staleThreshold) {\n        conversations.delete(id);\n      }\n    }\n  },\n  30 * 60 * 1000\n);\n\n// ============================================================================\n// CONVERSATION LIFECYCLE\n// ============================================================================\n\n/**\n * Get userId from request\n */\nfunction getUserId(req) {\n  if (req.isAuthenticated() && req.user?.userId) {\n    return req.user.userId;\n  }\n  return req.headers['x-user-id'] || null;\n}\n\n/**\n * POST /start - Create a new fresh conversation\n */\nrouter.post('/start', async (req, res) => {\n  try {\n    const userId = getUserId(req);\n    const {\n      provider,\n      model,\n      title = 'New Conversation',\n      personaId = 'default',\n      messages: initialMessages = [],\n    } = req.body;\n\n    const conversationId = `conv_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;\n    const resolvedProvider = provider || getDefaultProvider();\n\n    conversations.set(conversationId, {\n      id: conversationId,\n      userId,\n      title,\n      provider: resolvedProvider,\n      model: model || ProviderConfig[resolvedProvider]?.defaultModel,\n      personaId,\n      messages: initialMessages.map((m) => ({\n        role: m.role,\n        content: m.content,\n        timestamp: new Date().toISOString(),\n      })),\n      createdAt: new Date().toISOString(),\n      lastActivity: Date.now(),\n    });\n\n    logger.info(\n      { conversationId, userId, provider: resolvedProvider, personaId },\n      'Fresh conversation started'\n    );\n\n    res.json({\n      success: true,\n      data: {\n        conversationId,\n        provider: resolvedProvider,\n        model: model || ProviderConfig[resolvedProvider]?.defaultModel,\n        personaId,\n        title,\n      },\n    });\n  } catch (error) {\n    logger.error({ error: error.message }, 'Failed to start conversation');\n    res.status(500).json({ success: false, error: error.message });\n  }\n});\n\n/**\n * Parse Z.AI MCP action from message\n */\nfunction parseZAIAction(message) {\n  const trimmed = message.trim();\n\n  if (!trimmed.startsWith('!')) {\n    return null;\n  }\n\n  const parts = trimmed.slice(1).split(/\\s+/);\n  const action = parts[0]?.toLowerCase();\n  const args = parts.slice(1).join(' ');\n\n  const actionMap = {\n    websearch: { action: 'websearch', params: { query: args } },\n    read: { action: 'readurl', params: { url: args } },\n    readurl: { action: 'readurl', params: { url: args } },\n    github: { action: 'github', params: parseGithubArgs(args) },\n    githubtree: { action: 'github', params: { repo: args, structure: true } },\n    githubfile: { action: 'github', params: parseGithubFileArgs(args) },\n  };\n\n  return actionMap[action] || null;\n}\n\nfunction parseGithubArgs(args) {\n  const match = args.match(/^([^\\/]+\\/[^\\s]+)?\\s*(.*)$/);\n  if (!match) {\n    return { repo: args, query: '' };\n  }\n  return { repo: match[1] || '', query: match[2] || '' };\n}\n\nfunction parseGithubFileArgs(args) {\n  const match = args.match(/^([^\\/]+\\/[^\\s]+)\\s+(.+)$/);\n  if (!match) {\n    return { repo: args, file: '' };\n  }\n  return { repo: match[1], file: match[2] };\n}\n\n/**\n * POST /send - Send a message in an existing fresh conversation\n */\nrouter.post('/send', async (req, res) => {\n  try {\n    const { conversationId, message, provider: overrideProvider, model: overrideModel } = req.body;\n    const userId = getUserId(req);\n\n    if (!conversationId || !message) {\n      return res\n        .status(400)\n        .json({ success: false, error: 'conversationId and message are required' });\n    }\n\n    const conv = conversations.get(conversationId);\n    if (!conv) {\n      return res.status(404).json({ success: false, error: 'Conversation not found or expired' });\n    }\n\n    if (isMCPConfigured()) {\n      const zaiAction = parseZAIAction(message);\n      if (zaiAction) {\n        try {\n          const result = await executeZAIAction(zaiAction.action, zaiAction.params);\n\n          let responseText = `ðŸ” **${zaiAction.action.toUpperCase()} Result**\\n\\n`;\n\n          if (zaiAction.action === 'websearch') {\n            responseText += `Found ${result.count} results for \"${result.query}\":\\n\\n`;\n            result.results?.slice(0, 5).forEach((r, i) => {\n              responseText += `${i + 1}. **${r.title || r.name || 'Result'}**\\n`;\n              responseText += `   ${r.url || r.link || ''}\\n`;\n              responseText += `   ${(r.content || r.description || '').slice(0, 200)}...\\n\\n`;\n            });\n          } else if (zaiAction.action === 'readurl') {\n            responseText += `ðŸ“„ **${result.title}**\\n\\n`;\n            responseText += result.content?.slice(0, 3000) || result.summary || 'No content';\n          } else if (zaiAction.action === 'github') {\n            if (result.structure) {\n              responseText += `ðŸ“ **${result.repo}**\\n\\n`;\n              result.structure?.slice(0, 20).forEach((item) => {\n                responseText += `${item.type === 'tree' ? 'ðŸ“' : 'ðŸ“„'} ${item.path}\\n`;\n              });\n            } else if (result.content) {\n              responseText += `ðŸ“„ **${result.file}** from ${result.repo}\\n\\n`;\n              responseText += `\\`\\`\\`\\n${result.content?.slice(0, 5000)}\\n\\`\\`\\``;\n            } else {\n              responseText += `Found ${result.count} results in **${result.repo}** for \"${result.query}\":\\n\\n`;\n              result.results?.slice(0, 5).forEach((r, i) => {\n                responseText += `${i + 1}. ${r.title || r.name || 'Result'}\\n`;\n                responseText += `   ${r.content || r.description || ''}\\n\\n`;\n              });\n            }\n          }\n\n          conv.messages.push({\n            role: 'assistant',\n            content: responseText,\n            timestamp: new Date().toISOString(),\n            metadata: { isZAIAction: true, tool: zaiAction.action },\n          });\n\n          return res.json({\n            success: true,\n            data: {\n              content: responseText,\n              model: 'zai-mcp',\n              provider: 'zai',\n              isZAIAction: true,\n              conversationId,\n            },\n          });\n        } catch (actionError) {\n          logger.error({ error: actionError.message, action: zaiAction }, 'Z.AI MCP action failed');\n          return res.json({\n            success: true,\n            data: {\n              content: `âŒ Error: ${actionError.message}`,\n              model: 'zai-mcp',\n              provider: 'zai',\n              conversationId,\n            },\n          });\n        }\n      }\n    }\n\n    // Add user message\n    conv.messages.push({ role: 'user', content: message, timestamp: new Date().toISOString() });\n    conv.lastActivity = Date.now();\n\n    const provider = overrideProvider || conv.provider;\n    const model = overrideModel || conv.model;\n\n    let contextResult = null;\n    if (userId) {\n      try {\n        contextResult = await unifiedContextService.generateContextForChat(conversationId, {\n          userId,\n          userMessage: message,\n          personaId: conv.personaId,\n        });\n      } catch (ctxError) {\n        logger.warn({ error: ctxError.message }, 'Context assembly failed for fresh chat');\n      }\n    }\n\n    const systemPrompt =\n      contextResult?.systemPrompt ||\n      systemPromptManager.buildPrompt({\n        mode: 'fresh',\n        personaId: conv.personaId,\n        userId,\n      });\n\n    // Format messages for API\n    const apiMessages = conv.messages.map((m) => ({ role: m.role, content: m.content }));\n\n    const result = await unifiedProvider.generateCompletion({\n      provider,\n      model,\n      messages: apiMessages,\n      system: systemPrompt,\n      userId,\n    });\n\n    // Add assistant response\n    conv.messages.push({\n      role: 'assistant',\n      content: result.text,\n      timestamp: new Date().toISOString(),\n      metadata: { model, provider, tokens: result.usage?.totalTokens },\n    });\n\n    // Auto-generate title from first exchange\n    if (conv.messages.length === 2 && conv.title === 'New Conversation') {\n      conv.title = message.substring(0, 60) + (message.length > 60 ? '...' : '');\n    }\n\n    res.json({\n      success: true,\n      data: {\n        content: result.text,\n        model: model || ProviderConfig[provider]?.defaultModel,\n        usage: result.usage,\n        finishReason: result.finishReason,\n        provider,\n        conversationId,\n        messageCount: conv.messages.length,\n      },\n    });\n  } catch (error) {\n    logger.error({ error: error.message }, 'Fresh chat send failed');\n    res.status(error.statusCode || 500).json({ success: false, error: error.message });\n  }\n});\n\n// ============================================================================\n// STREAMING\n// ============================================================================\n\n/**\n * POST /stream - Stream a fresh chat response\n */\nrouter.post('/stream', async (req, res) => {\n  try {\n    const parsed = freshChatSchema.safeParse(req.body);\n    if (!parsed.success) {\n      return res\n        .status(400)\n        .json({ success: false, error: 'Validation failed', details: parsed.error.errors });\n    }\n\n    const {\n      message,\n      provider: requestedProvider,\n      model: requestedModel,\n      personaId,\n      options,\n    } = parsed.data;\n    const userId = getUserId(req);\n\n    const provider = requestedProvider || getDefaultProvider();\n    const model = requestedModel || ProviderConfig[provider]?.defaultModel;\n\n    let contextResult = null;\n    const convId = `fresh_${Date.now()}`;\n    if (userId) {\n      try {\n        contextResult = await unifiedContextService.generateContextForChat(convId, {\n          userId,\n          userMessage: message,\n          personaId: personaId || 'default',\n        });\n      } catch (ctxError) {\n        logger.warn({ error: ctxError.message }, 'Context assembly failed for fresh stream');\n      }\n    }\n\n    const systemPrompt =\n      contextResult?.systemPrompt ||\n      systemPromptManager.buildPrompt({\n        mode: 'fresh',\n        personaId: personaId || 'default',\n        userId,\n      });\n\n    const messages = [{ role: 'user', content: message }];\n\n    // Use Vercel AI SDK's streaming with pipeDataStreamToResponse\n    await unifiedProvider.streamCompletion({\n      provider,\n      model,\n      messages,\n      system: systemPrompt,\n      temperature: options?.temperature,\n      maxTokens: options?.maxTokens,\n      userId,\n      res,\n    });\n  } catch (error) {\n    logger.error({ error: error.message }, 'Fresh chat stream failed');\n    if (!res.headersSent) {\n      res.status(error.statusCode || 500).json({ success: false, error: error.message });\n    }\n  }\n});\n\n// ============================================================================\n// CONVERSATION MANAGEMENT\n// ============================================================================\n\n/**\n * GET /list - List active fresh conversations\n */\nrouter.get('/list', async (req, res) => {\n  try {\n    const userId = getUserId(req);\n\n    const userConversations = Array.from(conversations.values())\n      .filter((c) => c.userId === userId)\n      .map((c) => ({\n        id: c.id,\n        title: c.title,\n        provider: c.provider,\n        model: c.model,\n        personaId: c.personaId,\n        messageCount: c.messages.length,\n        createdAt: c.createdAt,\n        lastActivity: new Date(c.lastActivity).toISOString(),\n      }))\n      .sort((a, b) => new Date(b.lastActivity) - new Date(a.lastActivity));\n\n    res.json({ success: true, data: { conversations: userConversations } });\n  } catch (error) {\n    res.status(500).json({ success: false, error: error.message });\n  }\n});\n\n/**\n * GET /:id - Get full conversation\n */\nrouter.get('/:id', async (req, res) => {\n  try {\n    const conv = conversations.get(req.params.id);\n    if (!conv) {\n      return res.status(404).json({ success: false, error: 'Conversation not found' });\n    }\n\n    res.json({ success: true, data: conv });\n  } catch (error) {\n    res.status(500).json({ success: false, error: error.message });\n  }\n});\n\n/**\n * DELETE /:id - Delete a fresh conversation\n */\nrouter.delete('/:id', async (req, res) => {\n  try {\n    const deleted = conversations.delete(req.params.id);\n    res.json({ success: true, data: { deleted } });\n  } catch (error) {\n    res.status(500).json({ success: false, error: error.message });\n  }\n});\n\n/**\n * POST /fork - Fork a conversation into a new one\n */\nrouter.post('/fork', async (req, res) => {\n  try {\n    const { sourceId, prompt, provider, model } = req.body;\n    const userId = getUserId(req);\n\n    if (!sourceId) {\n      return res.status(400).json({ success: false, error: 'sourceId is required' });\n    }\n\n    const source = conversations.get(sourceId);\n    if (!source) {\n      return res.status(404).json({ success: false, error: 'Source conversation not found' });\n    }\n\n    const forkedId = `conv_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;\n    const resolvedProvider = provider || source.provider;\n\n    conversations.set(forkedId, {\n      id: forkedId,\n      userId,\n      title: `Fork of: ${source.title}`,\n      provider: resolvedProvider,\n      model: model || source.model,\n      personaId: source.personaId,\n      messages: [...source.messages],\n      createdAt: new Date().toISOString(),\n      lastActivity: Date.now(),\n      forkedFrom: sourceId,\n    });\n\n    // If a prompt was provided, send it in the forked conversation\n    if (prompt) {\n      const conv = conversations.get(forkedId);\n      conv.messages.push({ role: 'user', content: prompt, timestamp: new Date().toISOString() });\n\n      let contextResult = null;\n      if (userId) {\n        try {\n          contextResult = await unifiedContextService.generateContextForChat(forkedId, {\n            userId,\n            userMessage: prompt,\n            personaId: conv.personaId,\n          });\n        } catch (ctxError) {\n          logger.warn({ error: ctxError.message }, 'Context assembly failed for fork');\n        }\n      }\n\n      const systemPrompt =\n        contextResult?.systemPrompt ||\n        systemPromptManager.buildPrompt({\n          mode: 'fresh',\n          personaId: conv.personaId,\n          userId,\n        });\n\n      const result = await unifiedProvider.generateCompletion({\n        provider: resolvedProvider,\n        model: model || source.model,\n        messages: conv.messages.map((m) => ({ role: m.role, content: m.content })),\n        system: systemPrompt,\n        userId,\n      });\n\n      conv.messages.push({\n        role: 'assistant',\n        content: result.text,\n        timestamp: new Date().toISOString(),\n      });\n    }\n\n    logger.info({ forkedId, sourceId }, 'Conversation forked');\n\n    res.json({\n      success: true,\n      data: {\n        conversationId: forkedId,\n        forkedFrom: sourceId,\n        provider: resolvedProvider,\n        messageCount: conversations.get(forkedId).messages.length,\n      },\n    });\n  } catch (error) {\n    logger.error({ error: error.message }, 'Fork failed');\n    res.status(500).json({ success: false, error: error.message });\n  }\n});\n\nexport { router as aiChatRouter };\n","usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\routes\\ai-settings.js","messages":[{"ruleId":"no-unused-vars","severity":1,"message":"'aiSettingsSchema' is defined but never used.","line":8,"column":10,"nodeType":"Identifier","messageId":"unusedVar","endLine":8,"endColumn":26,"suggestions":[{"messageId":"removeVar","data":{"varName":"aiSettingsSchema"},"fix":{"range":[347,364],"text":""},"desc":"Remove unused variable 'aiSettingsSchema'."}]}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":"// apps/server/src/routes/ai-settings.js\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// AI SETTINGS ROUTES - User preferences, API keys, personas\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nimport { Router } from 'express';\nimport { logger } from '../lib/logger.js';\nimport { aiSettingsSchema, customPersonaSchema } from '../validators/ai.js';\nimport { ProviderConfig, ProviderModels, ProviderType } from '../types/ai.js';\nimport { systemPromptManager, PERSONAS } from '../ai/system-prompts.js';\nimport { aiTelemetry } from '../ai/middleware/telemetry.js';\nimport { unifiedProvider } from '../ai/unified-provider.js';\n\nconst router = Router();\n\n// ============================================================================\n// PROVIDER INFORMATION\n// ============================================================================\n\n/**\n * GET /providers - List all available AI providers with status\n */\nrouter.get('/providers', async (req, res) => {\n  try {\n    const status = unifiedProvider.getProviderStatus();\n\n    res.json({\n      success: true,\n      data: {\n        providers: Object.entries(status).map(([id, info]) => ({\n          id,\n          ...info,\n        })),\n        defaultProvider: ProviderType.ZAI,\n      },\n    });\n  } catch (error) {\n    logger.error({ error: error.message }, 'Failed to get providers');\n    res.status(500).json({ success: false, error: error.message });\n  }\n});\n\n/**\n * GET /models - Get all models with capabilities\n */\nrouter.get('/models', async (req, res) => {\n  try {\n    const models = {};\n\n    for (const [provider, providerModels] of Object.entries(ProviderModels)) {\n      models[provider] = {\n        displayName: ProviderConfig[provider]?.displayName,\n        models: Object.entries(providerModels).map(([id, info]) => ({\n          id,\n          ...info,\n        })),\n      };\n    }\n\n    res.json({ success: true, data: models });\n  } catch (error) {\n    logger.error({ error: error.message }, 'Failed to get models');\n    res.status(500).json({ success: false, error: error.message });\n  }\n});\n\n// ============================================================================\n// PERSONAS\n// ============================================================================\n\n/**\n * GET /personas - List all available personas\n */\nrouter.get('/personas', async (req, res) => {\n  try {\n    const personas = systemPromptManager.getAllPersonas();\n    res.json({ success: true, data: { personas } });\n  } catch (error) {\n    logger.error({ error: error.message }, 'Failed to get personas');\n    res.status(500).json({ success: false, error: error.message });\n  }\n});\n\n/**\n * POST /personas - Create a custom persona\n */\nrouter.post('/personas', async (req, res) => {\n  try {\n    const parsed = customPersonaSchema.safeParse(req.body);\n    if (!parsed.success) {\n      return res.status(400).json({\n        success: false,\n        error: 'Invalid persona data',\n        details: parsed.error.errors,\n      });\n    }\n\n    // Check for ID collision with built-in personas\n    if (PERSONAS[parsed.data.id]) {\n      return res.status(409).json({\n        success: false,\n        error: `Cannot override built-in persona: ${parsed.data.id}`,\n      });\n    }\n\n    systemPromptManager.registerPersona(parsed.data);\n\n    res.status(201).json({\n      success: true,\n      data: { persona: parsed.data },\n    });\n  } catch (error) {\n    logger.error({ error: error.message }, 'Failed to create persona');\n    res.status(500).json({ success: false, error: error.message });\n  }\n});\n\n// ============================================================================\n// TELEMETRY & USAGE\n// ============================================================================\n\n/**\n * GET /telemetry - Get AI usage metrics\n */\nrouter.get('/telemetry', async (req, res) => {\n  try {\n    const metrics = aiTelemetry.getMetrics();\n    res.json({ success: true, data: metrics });\n  } catch (error) {\n    logger.error({ error: error.message }, 'Failed to get telemetry');\n    res.status(500).json({ success: false, error: error.message });\n  }\n});\n\n/**\n * GET /telemetry/user - Get user-specific AI usage metrics\n */\nrouter.get('/telemetry/user', async (req, res) => {\n  try {\n    const userId = req.headers['x-user-id'] || 'dev-user';\n    const metrics = aiTelemetry.getUserMetrics(userId);\n    res.json({ success: true, data: metrics });\n  } catch (error) {\n    logger.error({ error: error.message }, 'Failed to get user telemetry');\n    res.status(500).json({ success: false, error: error.message });\n  }\n});\n\n/**\n * GET /telemetry/estimate - Estimate cost for a request\n */\nrouter.get('/telemetry/estimate', async (req, res) => {\n  try {\n    const { provider = 'zai', promptTokens = 1000, completionTokens = 500 } = req.query;\n    const estimate = aiTelemetry.estimateCost(\n      provider,\n      parseInt(promptTokens, 10),\n      parseInt(completionTokens, 10)\n    );\n    res.json({ success: true, data: estimate });\n  } catch (error) {\n    res.status(500).json({ success: false, error: error.message });\n  }\n});\n\n// ============================================================================\n// CAPABILITIES\n// ============================================================================\n\n/**\n * GET /capabilities - Get full AI system capabilities\n */\nrouter.get('/capabilities', async (req, res) => {\n  try {\n    const providerStatus = unifiedProvider.getProviderStatus();\n    const personas = systemPromptManager.getAllPersonas();\n\n    res.json({\n      success: true,\n      data: {\n        version: '2.0.0',\n        features: {\n          streaming: true,\n          toolCalling: true,\n          structuredOutput: true,\n          agentPipeline: true,\n          multiProvider: true,\n          personas: true,\n          secondBrain: true,\n          socialSharing: true,\n          telemetry: true,\n          costEstimation: true,\n        },\n        providers: Object.entries(providerStatus)\n          .filter(([, info]) => info.isAvailable)\n          .map(([id, info]) => ({\n            id,\n            displayName: info.displayName,\n            isFree: info.isFree,\n            capabilities: info.capabilities,\n          })),\n        personas: personas.map((p) => ({\n          id: p.id,\n          name: p.name,\n          emoji: p.emoji,\n          description: p.description,\n          isBuiltIn: p.isBuiltIn,\n        })),\n        agentModes: [\n          {\n            id: 'single-shot',\n            name: 'Single Shot',\n            description: 'One LLM call, may include tool use',\n          },\n          {\n            id: 'multi-step',\n            name: 'Multi-Step',\n            description: 'Multiple LLM calls with tool chaining',\n          },\n          {\n            id: 'researcher',\n            name: 'Deep Research',\n            description: 'Extended research with many tool calls',\n          },\n          { id: 'conversational', name: 'Quick Chat', description: 'Lightweight, fast responses' },\n        ],\n        toolSets: [\n          { id: 'full', name: 'Full Toolkit', tools: 8 },\n          { id: 'second-brain', name: 'Second Brain', tools: 6 },\n          { id: 'social', name: 'Social', tools: 2 },\n          { id: 'minimal', name: 'Minimal', tools: 2 },\n          { id: 'none', name: 'No Tools', tools: 0 },\n        ],\n      },\n    });\n  } catch (error) {\n    logger.error({ error: error.message }, 'Failed to get capabilities');\n    res.status(500).json({ success: false, error: error.message });\n  }\n});\n\nexport { router as aiSettingsRouter };\n","usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\routes\\ai.js","messages":[{"ruleId":"no-unused-vars","severity":1,"message":"'ProviderType' is defined but never used.","line":23,"column":10,"nodeType":"Identifier","messageId":"unusedVar","endLine":23,"endColumn":22,"suggestions":[{"messageId":"removeVar","data":{"varName":"ProviderType"},"fix":{"range":[891,904],"text":""},"desc":"Remove unused variable 'ProviderType'."}]},{"ruleId":"no-unused-vars","severity":1,"message":"'ContextSettingsService' is defined but never used.","line":24,"column":10,"nodeType":"Identifier","messageId":"unusedVar","endLine":24,"endColumn":32,"suggestions":[{"messageId":"removeVar","data":{"varName":"ContextSettingsService"},"fix":{"range":[965,1037],"text":""},"desc":"Remove unused variable 'ContextSettingsService'."}]},{"ruleId":"no-unused-vars","severity":1,"message":"'DynamicContextAssembler' is defined but never used.","line":25,"column":10,"nodeType":"Identifier","messageId":"unusedVar","endLine":25,"endColumn":33,"suggestions":[{"messageId":"removeVar","data":{"varName":"DynamicContextAssembler"},"fix":{"range":[1038,1112],"text":""},"desc":"Remove unused variable 'DynamicContextAssembler'."}]},{"ruleId":"no-unused-vars","severity":1,"message":"'getToolkitDescriptions' is defined but never used.","line":28,"column":24,"nodeType":"Identifier","messageId":"unusedVar","endLine":28,"endColumn":46,"suggestions":[{"messageId":"removeVar","data":{"varName":"getToolkitDescriptions"},"fix":{"range":[1277,1301],"text":""},"desc":"Remove unused variable 'getToolkitDescriptions'."}]},{"ruleId":"no-unused-vars","severity":1,"message":"'aiTelemetry' is defined but never used.","line":29,"column":10,"nodeType":"Identifier","messageId":"unusedVar","endLine":29,"endColumn":21,"suggestions":[{"messageId":"removeVar","data":{"varName":"aiTelemetry"},"fix":{"range":[1333,1393],"text":""},"desc":"Remove unused variable 'aiTelemetry'."}]},{"ruleId":"no-unused-vars","severity":1,"message":"'requireUserId' is defined but never used.","line":55,"column":10,"nodeType":"Identifier","messageId":"unusedVar","endLine":55,"endColumn":23,"suggestions":[{"messageId":"removeVar","data":{"varName":"requireUserId"},"fix":{"range":[2057,2290],"text":""},"desc":"Remove unused variable 'requireUserId'."}]},{"ruleId":"no-unused-vars","severity":1,"message":"'error' is defined but never used.","line":113,"column":12,"nodeType":"Identifier","messageId":"unusedVar","endLine":113,"endColumn":17},{"ruleId":"no-unused-vars","severity":1,"message":"'options' is assigned a value but never used.","line":284,"column":7,"nodeType":"Identifier","messageId":"unusedVar","endLine":284,"endColumn":14,"suggestions":[{"messageId":"removeVar","data":{"varName":"options"},"fix":{"range":[9052,9067],"text":""},"desc":"Remove unused variable 'options'."}]},{"ruleId":"no-unused-vars","severity":1,"message":"'content' is assigned a value but never used.","line":563,"column":37,"nodeType":"Identifier","messageId":"unusedVar","endLine":563,"endColumn":44,"suggestions":[{"messageId":"removeVar","data":{"varName":"content"},"fix":{"range":[16888,16897],"text":""},"desc":"Remove unused variable 'content'."}]}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":9,"fixableErrorCount":0,"fixableWarningCount":0,"source":"// apps/server/src/routes/ai.js\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// AI ROUTES - Context-Aware Conversation with Second Brain Integration\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n//\n// This is the primary AI route for CONTEXT-AWARE conversations.\n// It leverages the dynamic context system and second brain tools.\n//\n// For FRESH/standalone chats, see ai-chat.js\n// For SETTINGS/config, see ai-settings.js\n\nimport { Router } from 'express';\nimport { unifiedProvider } from '../ai/unified-provider.js';\nimport { agentPipeline } from '../ai/agent-pipeline.js';\nimport { aiStorageService } from '../services/ai-storage-service.js';\nimport { logger } from '../lib/logger.js';\nimport {\n  aiCompletionSchema,\n  aiStreamSchema,\n  agentRequestSchema,\n  structuredOutputSchema,\n} from '../validators/ai.js';\nimport { ProviderType, ProviderConfig, getDefaultProvider } from '../types/ai.js';\nimport { ContextSettingsService } from '../context/settings-service.js';\nimport { DynamicContextAssembler } from '../context/context-assembler.js';\nimport { unifiedContextService } from '../services/unified-context-service.js';\nimport { systemPromptManager } from '../ai/system-prompts.js';\nimport { buildToolkit, getToolkitDescriptions } from '../ai/tools/index.js';\nimport { aiTelemetry } from '../ai/middleware/telemetry.js';\n\nconst router = Router();\n\n// ============================================================================\n// HELPERS\n// ============================================================================\n\n/**\n * Get userId from request - supports both session auth and header (legacy)\n */\nfunction getUserId(req) {\n  if (req.isAuthenticated() && req.user?.userId) {\n    return req.user.userId;\n  }\n  const headerUserId = req.headers['x-user-id'];\n  if (headerUserId) {\n    logger.warn({ userId: headerUserId, path: req.path }, 'Using insecure x-user-id header');\n    return headerUserId;\n  }\n  return null;\n}\n\n/**\n * Require authentication - returns userId or null\n */\nfunction requireUserId(req, res, next) {\n  const userId = getUserId(req);\n  if (!userId) {\n    return res.status(401).json({\n      success: false,\n      error: 'Authentication required',\n    });\n  }\n  req.userId = userId;\n  next();\n}\n\n/**\n * Build context for a conversation using the unified context service\n */\nasync function buildContextBundles(userId, conversationId, options = {}) {\n  try {\n    if (conversationId && conversationId !== 'new-chat') {\n      const result = await unifiedContextService.generateContextForChat(conversationId, {\n        userId,\n        userMessage: options.userMessage || '',\n        personaId: options.personaId,\n        deviceId: options.deviceId,\n      });\n\n      return {\n        systemPrompt: result.systemPrompt,\n        layers: result.layers,\n        stats: result.stats,\n        engineUsed: result.engineUsed,\n      };\n    }\n    return null;\n  } catch (error) {\n    logger.warn({ error: error.message }, 'Context assembly failed, proceeding without');\n    return null;\n  }\n}\n\n/**\n * Get second brain stats for a user\n */\nasync function getSecondBrainStats(userId) {\n  try {\n    const { getPrismaClient } = await import('../lib/database.js');\n    const prisma = getPrismaClient();\n\n    const [topicCount, conversationCount, memoryCount] = await Promise.all([\n      prisma.topicProfile.count({ where: { userId } }).catch(() => 0),\n      prisma.conversation.count({ where: { ownerId: userId } }).catch(() => 0),\n      prisma.atomicContentUnit\n        .count({\n          where: { conversation: { ownerId: userId } },\n        })\n        .catch(() => 0),\n    ]);\n\n    return { topicCount, conversationCount, memoryCount, entityCount: 0 };\n  } catch (error) {\n    return { topicCount: 0, conversationCount: 0, memoryCount: 0, entityCount: 0 };\n  }\n}\n\n// ============================================================================\n// CONTEXT-AWARE AI COMPLETION (Non-Streaming)\n// ============================================================================\n\n/**\n * POST /complete - Generate AI completion with context\n */\nrouter.post('/complete', async (req, res) => {\n  try {\n    const parsed = aiCompletionSchema.safeParse(req.body);\n    if (!parsed.success) {\n      return res\n        .status(400)\n        .json({ success: false, error: 'Validation failed', details: parsed.error.errors });\n    }\n\n    const { messages, provider, model, conversationId, options } = parsed.data;\n    const userId = getUserId(req);\n    const providerApiKey = req.headers['x-provider-key'];\n\n    // Build context\n    const contextResult = await buildContextBundles(userId, conversationId, {\n      userMessage: messages?.[messages.length - 1]?.content || '',\n      personaId: options?.personaId,\n    });\n    const secondBrainStats = await getSecondBrainStats(userId);\n\n    const systemPrompt =\n      contextResult?.systemPrompt ||\n      systemPromptManager.buildPrompt({\n        mode: conversationId ? 'continuation' : 'fresh',\n        userId,\n        contextBundles: [],\n        secondBrainStats,\n      });\n\n    const result = await unifiedProvider.generateCompletion({\n      provider: provider || getDefaultProvider(),\n      model,\n      messages,\n      system: systemPrompt,\n      temperature: options?.temperature,\n      maxTokens: options?.maxTokens,\n      userId,\n      providerApiKey,\n    });\n\n    // Store conversation if we have a conversationId\n    if (conversationId) {\n      try {\n        await aiStorageService.storeAssistantResponse(\n          conversationId,\n          result.text,\n          provider || getDefaultProvider(),\n          model || ProviderConfig[provider || getDefaultProvider()]?.defaultModel,\n          result.usage\n        );\n      } catch (storageError) {\n        logger.warn({ error: storageError.message }, 'Failed to store response');\n      }\n    }\n\n    res.json({\n      success: true,\n      data: {\n        content: result.text,\n        model: model || ProviderConfig[provider || getDefaultProvider()]?.defaultModel,\n        usage: result.usage,\n        finishReason: result.finishReason,\n        provider: provider || getDefaultProvider(),\n        conversationId,\n        toolCalls: result.toolCalls?.map((tc) => ({\n          name: tc.toolName,\n          result: tc.result,\n        })),\n      },\n    });\n  } catch (error) {\n    logger.error({ error: error.message }, 'Completion failed');\n    res.status(error.statusCode || 500).json({ success: false, error: error.message });\n  }\n});\n\n// ============================================================================\n// CONTEXT-AWARE AI STREAMING\n// ============================================================================\n\n/**\n * POST /stream - Stream AI completion with context\n */\nrouter.post('/stream', async (req, res) => {\n  try {\n    const parsed = aiStreamSchema.safeParse(req.body);\n    if (!parsed.success) {\n      return res\n        .status(400)\n        .json({ success: false, error: 'Validation failed', details: parsed.error.errors });\n    }\n\n    const { messages, provider, model, conversationId, options } = parsed.data;\n    const userId = getUserId(req);\n\n    // Build context\n    const contextResult = await buildContextBundles(userId, conversationId, {\n      userMessage: messages?.[messages.length - 1]?.content || '',\n      personaId: options?.personaId,\n    });\n    const secondBrainStats = await getSecondBrainStats(userId);\n\n    const systemPrompt =\n      contextResult?.systemPrompt ||\n      systemPromptManager.buildPrompt({\n        mode: conversationId ? 'continuation' : 'fresh',\n        userId,\n        contextBundles: [],\n        secondBrainStats,\n      });\n\n    // Use unified provider's streaming with pipeDataStreamToResponse\n    await unifiedProvider.streamCompletion({\n      provider: provider || getDefaultProvider(),\n      model,\n      messages,\n      system: systemPrompt,\n      temperature: options?.temperature,\n      maxTokens: options?.maxTokens,\n      userId,\n      res,\n    });\n  } catch (error) {\n    logger.error({ error: error.message }, 'Stream failed');\n    if (!res.headersSent) {\n      res.status(error.statusCode || 500).json({ success: false, error: error.message });\n    }\n  }\n});\n\n// ============================================================================\n// AGENT PIPELINE - Multi-Step Tool-Using AI\n// ============================================================================\n\n/**\n * POST /agent - Execute multi-step agent with tools\n * This is the crown jewel â€” the AI can search your knowledge base,\n * recall past conversations, create memories, and more.\n */\nrouter.post('/agent', async (req, res) => {\n  try {\n    const parsed = agentRequestSchema.safeParse(req.body);\n    if (!parsed.success) {\n      return res\n        .status(400)\n        .json({ success: false, error: 'Validation failed', details: parsed.error.errors });\n    }\n\n    const {\n      messages,\n      provider,\n      model,\n      conversationId,\n      mode,\n      personaId,\n      toolSet,\n      maxSteps,\n      enableSocial,\n      customInstructions,\n      options,\n    } = parsed.data;\n    const userId = getUserId(req);\n\n    // Build context\n    const contextResult = await buildContextBundles(userId, conversationId, {\n      userMessage: messages?.[messages.length - 1]?.content || '',\n      personaId,\n    });\n    const secondBrainStats = await getSecondBrainStats(userId);\n\n    // Resolve model\n    const resolvedModel = unifiedProvider.resolveModel(provider || getDefaultProvider(), model);\n\n    const result = await agentPipeline.execute({\n      model: resolvedModel,\n      messages,\n      userId,\n      conversationId,\n      mode,\n      personaId,\n      contextBundles: contextResult,\n      secondBrainStats,\n      customInstructions,\n      maxSteps,\n      toolSet,\n      enableSocial,\n    });\n\n    // Store conversation\n    if (conversationId) {\n      try {\n        await aiStorageService.storeAssistantResponse(\n          conversationId,\n          result.text,\n          provider || getDefaultProvider(),\n          model || ProviderConfig[provider || getDefaultProvider()]?.defaultModel,\n          result.usage\n        );\n      } catch (storageError) {\n        logger.warn({ error: storageError.message }, 'Failed to store agent response');\n      }\n    }\n\n    res.json({\n      success: true,\n      data: {\n        content: result.text,\n        usage: result.usage,\n        finishReason: result.finishReason,\n        steps: result.steps,\n        metadata: result.metadata,\n        provider: provider || getDefaultProvider(),\n        conversationId,\n      },\n    });\n  } catch (error) {\n    logger.error({ error: error.message }, 'Agent pipeline failed');\n    res.status(error.statusCode || 500).json({ success: false, error: error.message });\n  }\n});\n\n/**\n * POST /agent/stream - Stream multi-step agent with tools\n */\nrouter.post('/agent/stream', async (req, res) => {\n  try {\n    const parsed = agentRequestSchema.safeParse(req.body);\n    if (!parsed.success) {\n      return res\n        .status(400)\n        .json({ success: false, error: 'Validation failed', details: parsed.error.errors });\n    }\n\n    const {\n      messages,\n      provider,\n      model,\n      conversationId,\n      mode,\n      personaId,\n      toolSet,\n      maxSteps,\n      enableSocial,\n      customInstructions,\n    } = parsed.data;\n    const userId = getUserId(req);\n\n    // Build context\n    const contextResult = await buildContextBundles(userId, conversationId, {\n      userMessage: messages?.[messages.length - 1]?.content || '',\n      personaId,\n    });\n    const secondBrainStats = await getSecondBrainStats(userId);\n\n    // Resolve model\n    const resolvedModel = unifiedProvider.resolveModel(provider || getDefaultProvider(), model);\n\n    await agentPipeline.executeStream({\n      model: resolvedModel,\n      messages,\n      res,\n      userId,\n      conversationId,\n      mode,\n      personaId,\n      contextBundles: contextResult,\n      secondBrainStats,\n      customInstructions,\n      maxSteps,\n      toolSet,\n      enableSocial,\n    });\n  } catch (error) {\n    logger.error({ error: error.message }, 'Agent stream failed');\n    if (!res.headersSent) {\n      res.status(error.statusCode || 500).json({ success: false, error: error.message });\n    }\n  }\n});\n\n// ============================================================================\n// STRUCTURED OUTPUT\n// ============================================================================\n\n/**\n * POST /structured - Generate structured output (JSON matching a schema)\n */\nrouter.post('/structured', async (req, res) => {\n  try {\n    const parsed = structuredOutputSchema.safeParse(req.body);\n    if (!parsed.success) {\n      return res\n        .status(400)\n        .json({ success: false, error: 'Validation failed', details: parsed.error.errors });\n    }\n\n    const { prompt, messages, provider, model, schema, toolSet, maxSteps } = parsed.data;\n    const userId = getUserId(req);\n    const tools = toolSet !== 'none' ? buildToolkit({ userId, toolSet }) : undefined;\n\n    const result = await unifiedProvider.generateStructuredOutput({\n      provider: provider || getDefaultProvider(),\n      model,\n      schema, // Note: This is a plain JSON schema; in production, convert to Zod\n      prompt,\n      messages,\n      tools,\n      maxSteps,\n      userId,\n    });\n\n    res.json({\n      success: true,\n      data: {\n        output: result.output,\n        usage: result.usage,\n        provider: provider || getDefaultProvider(),\n      },\n    });\n  } catch (error) {\n    logger.error({ error: error.message }, 'Structured output failed');\n    res.status(error.statusCode || 500).json({ success: false, error: error.message });\n  }\n});\n\n// ============================================================================\n// CONTEXT-AWARE CHAT (Legacy compatible)\n// ============================================================================\n\n/**\n * POST /chat - Legacy-compatible chat endpoint with context\n * Maintained for backward compatibility with existing frontend\n */\nrouter.post('/chat', async (req, res) => {\n  try {\n    const {\n      message,\n      messages: rawMessages,\n      conversationId,\n      provider: requestedProvider,\n      model,\n    } = req.body;\n\n    const userId = getUserId(req);\n\n    // Support both single message and message array\n    let messages;\n    if (rawMessages && Array.isArray(rawMessages)) {\n      messages = rawMessages;\n    } else if (message) {\n      messages = [{ role: 'user', content: message }];\n    } else {\n      return res\n        .status(400)\n        .json({ success: false, error: 'Either message or messages is required' });\n    }\n\n    const provider = requestedProvider || getDefaultProvider();\n\n    // Check if this is a continuation with a conversationId\n    if (conversationId) {\n      // Store the user message\n      try {\n        await aiStorageService.processIncomingMessage(\n          conversationId,\n          {\n            role: 'user',\n            content: messages[messages.length - 1]?.content || message,\n          },\n          provider,\n          model\n        );\n      } catch (e) {\n        logger.warn({ error: e.message }, 'Failed to store user message');\n      }\n    }\n\n    // Build context\n    const contextResult = await buildContextBundles(userId, conversationId, {\n      userMessage: messages[messages.length - 1]?.content || message,\n    });\n    const secondBrainStats = await getSecondBrainStats(userId);\n\n    const systemPrompt =\n      contextResult?.systemPrompt ||\n      systemPromptManager.buildPrompt({\n        mode: conversationId ? 'continuation' : 'fresh',\n        userId,\n        contextBundles: [],\n        secondBrainStats,\n      });\n\n    const result = await unifiedProvider.generateCompletion({\n      provider,\n      model,\n      messages,\n      system: systemPrompt,\n      userId,\n    });\n\n    // Store response\n    if (conversationId) {\n      try {\n        await aiStorageService.storeAssistantResponse(\n          conversationId,\n          result.text,\n          provider,\n          model,\n          result.usage\n        );\n      } catch (e) {\n        logger.warn({ error: e.message }, 'Failed to store assistant response');\n      }\n    }\n\n    res.json({\n      success: true,\n      data: {\n        content: result.text,\n        model: model || ProviderConfig[provider]?.defaultModel,\n        usage: result.usage,\n        finishReason: result.finishReason,\n        provider,\n        conversationId,\n      },\n    });\n  } catch (error) {\n    logger.error({ error: error.message }, 'Chat failed');\n    res.status(error.statusCode || 500).json({ success: false, error: error.message });\n  }\n});\n\n// ============================================================================\n// AI ACTIONS\n// ============================================================================\n\nrouter.post('/actions', async (req, res) => {\n  try {\n    const { action, conversationId, content } = req.body;\n\n    if (!action || !conversationId) {\n      return res.status(400).json({ success: false, error: 'Missing action or conversationId' });\n    }\n\n    logger.info({ action, conversationId }, 'AI action requested');\n\n    res.json({\n      success: true,\n      result: {\n        action,\n        conversationId,\n        result: `Action ${action} executed for conversation ${conversationId}`,\n      },\n    });\n  } catch (error) {\n    logger.error({ error: error.message }, 'AI actions failed');\n    res.status(500).json({ success: false, error: error.message });\n  }\n});\n\nexport { router as aiRouter };\n","usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\routes\\auth.js","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\routes\\capture.js","messages":[{"ruleId":"no-unused-vars","severity":1,"message":"'createCaptureAttempt' is defined but never used.","line":20,"column":3,"nodeType":"Identifier","messageId":"unusedVar","endLine":20,"endColumn":23,"suggestions":[{"messageId":"removeVar","data":{"varName":"createCaptureAttempt"},"fix":{"range":[617,638],"text":""},"desc":"Remove unused variable 'createCaptureAttempt'."}]},{"ruleId":"no-unused-vars","severity":1,"message":"'apiKeyErr' is defined but never used.","line":139,"column":16,"nodeType":"Identifier","messageId":"unusedVar","endLine":139,"endColumn":25},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":166,"column":7,"nodeType":"MemberExpression","messageId":"limited","endLine":166,"endColumn":18,"suggestions":[{"fix":{"range":[5146,5225],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":176,"column":5,"nodeType":"MemberExpression","messageId":"limited","endLine":176,"endColumn":16,"suggestions":[{"fix":{"range":[5514,5586],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":177,"column":5,"nodeType":"MemberExpression","messageId":"limited","endLine":177,"endColumn":16,"suggestions":[{"fix":{"range":[5591,5655],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":178,"column":5,"nodeType":"MemberExpression","messageId":"limited","endLine":178,"endColumn":16,"suggestions":[{"fix":{"range":[5660,5722],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":195,"column":11,"nodeType":"MemberExpression","messageId":"limited","endLine":195,"endColumn":22,"suggestions":[{"fix":{"range":[6250,6316],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":206,"column":9,"nodeType":"MemberExpression","messageId":"limited","endLine":206,"endColumn":20,"suggestions":[{"fix":{"range":[6677,6763],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-undef","severity":2,"message":"'attempt' is not defined.","line":233,"column":19,"nodeType":"Identifier","messageId":"undef","endLine":233,"endColumn":26},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":234,"column":7,"nodeType":"MemberExpression","messageId":"limited","endLine":234,"endColumn":18,"suggestions":[{"fix":{"range":[7471,7541],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":239,"column":5,"nodeType":"MemberExpression","messageId":"limited","endLine":239,"endColumn":16,"suggestions":[{"fix":{"range":[7664,7772],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-undef","severity":2,"message":"'conversation' is not defined.","line":240,"column":44,"nodeType":"Identifier","messageId":"undef","endLine":240,"endColumn":56},{"ruleId":"no-undef","severity":2,"message":"'conversation' is not defined.","line":245,"column":56,"nodeType":"Identifier","messageId":"undef","endLine":245,"endColumn":68},{"ruleId":"no-undef","severity":2,"message":"'conversation' is not defined.","line":254,"column":27,"nodeType":"Identifier","messageId":"undef","endLine":254,"endColumn":39},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":258,"column":7,"nodeType":"MemberExpression","messageId":"limited","endLine":258,"endColumn":18,"suggestions":[{"fix":{"range":[8246,8360],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-undef","severity":2,"message":"'conversation' is not defined.","line":268,"column":29,"nodeType":"Identifier","messageId":"undef","endLine":268,"endColumn":41},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":272,"column":9,"nodeType":"MemberExpression","messageId":"limited","endLine":272,"endColumn":20,"suggestions":[{"fix":{"range":[8631,8720],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-undef","severity":2,"message":"'conversation' is not defined.","line":277,"column":25,"nodeType":"Identifier","messageId":"undef","endLine":277,"endColumn":37},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":282,"column":7,"nodeType":"MemberExpression","messageId":"limited","endLine":282,"endColumn":18,"suggestions":[{"fix":{"range":[9038,9123],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-undef","severity":2,"message":"'conversation' is not defined.","line":290,"column":42,"nodeType":"Identifier","messageId":"undef","endLine":290,"endColumn":54},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":293,"column":5,"nodeType":"MemberExpression","messageId":"limited","endLine":293,"endColumn":16,"suggestions":[{"fix":{"range":[9329,9443],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-undef","severity":2,"message":"'conversation' is not defined.","line":294,"column":38,"nodeType":"Identifier","messageId":"undef","endLine":294,"endColumn":50},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":299,"column":7,"nodeType":"MemberExpression","messageId":"limited","endLine":299,"endColumn":18,"suggestions":[{"fix":{"range":[9561,9642],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-undef","severity":2,"message":"'url' is not defined.","line":314,"column":32,"nodeType":"Identifier","messageId":"undef","endLine":314,"endColumn":35},{"ruleId":"no-undef","severity":2,"message":"'url' is not defined.","line":315,"column":7,"nodeType":"Identifier","messageId":"undef","endLine":315,"endColumn":10},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":321,"column":5,"nodeType":"MemberExpression","messageId":"limited","endLine":321,"endColumn":16,"suggestions":[{"fix":{"range":[10162,10244],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-unused-vars","severity":1,"message":"'jsonError' is defined but never used.","line":444,"column":16,"nodeType":"Identifier","messageId":"unusedVar","endLine":444,"endColumn":25},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":449,"column":7,"nodeType":"MemberExpression","messageId":"limited","endLine":449,"endColumn":18,"suggestions":[{"fix":{"range":[13786,13867],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":457,"column":5,"nodeType":"MemberExpression","messageId":"limited","endLine":457,"endColumn":16,"suggestions":[{"fix":{"range":[14031,14111],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":465,"column":5,"nodeType":"MemberExpression","messageId":"limited","endLine":465,"endColumn":16,"suggestions":[{"fix":{"range":[14279,14398],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":471,"column":22,"nodeType":"MemberExpression","messageId":"limited","endLine":471,"endColumn":33},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":480,"column":5,"nodeType":"MemberExpression","messageId":"limited","endLine":480,"endColumn":16,"suggestions":[{"fix":{"range":[14838,14907],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":485,"column":5,"nodeType":"MemberExpression","messageId":"limited","endLine":485,"endColumn":16,"suggestions":[{"fix":{"range":[15007,15072],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]}],"suppressedMessages":[],"errorCount":10,"fatalErrorCount":0,"warningCount":23,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * Capture Routes\n *\n * API endpoints for capturing AI conversations with database persistence\n * Uses storage-adapter.js with Prisma/Postgres\n */\n\nimport { Router } from 'express';\nimport { createRequestLogger } from '../lib/logger.js';\nimport { ValidationError } from '../middleware/errorHandler.js';\nimport { validateRequest, captureRequestSchema, syncInitSchema } from '../validators/schemas.js';\nimport { extractConversation, detectProvider } from '../services/extractor.js';\nimport {\n  getServerPqcPublicKey,\n  kyberDecapsulate,\n  symmetricDecrypt,\n  symmetricEncrypt,\n} from '../lib/crypto.js';\nimport {\n  createCaptureAttempt,\n  completeCaptureAttempt,\n  findBySourceUrl,\n} from '../repositories/index.js';\nimport {\n  saveConversationUnified,\n  findRecentSuccessfulUnified,\n} from '../services/storage-adapter.js';\nimport { requireApiKey, authenticateDID } from '../middleware/auth.js';\nimport { ticketStore } from '../services/ticketStore.js';\nimport { calculateMessageHash } from '../lib/crypto.js';\nimport { debugReporter } from '../services/debug-reporter.js';\n\nconst router = Router();\n\n// ============================================================================\n// HELPERS\n// ============================================================================\n\n/**\n * Sanitize and format conversation for PWA ingestion\n * Ensures 'parts' are mapped to 'content' and hashes are valid for the final payload\n */\nfunction prepareConversationForClient(conversation) {\n  if (!conversation) {\n    return null;\n  }\n\n  const messages = (conversation.messages || []).map((msg) => {\n    const role = msg.role || 'assistant';\n    const content = msg.content || msg.parts || [];\n    const timestamp = msg.timestamp || msg.createdAt || new Date().toISOString();\n\n    return {\n      ...msg,\n      role,\n      content,\n      timestamp,\n      // Re-calculate hash on the FINAL content being sent to the witness\n      contentHash: calculateMessageHash(role, content, timestamp),\n    };\n  });\n\n  return {\n    ...conversation,\n    messages,\n    metadata: {\n      ...conversation.metadata,\n      exportedAt: new Date().toISOString(),\n      serverVersion: '2.0.0',\n    },\n  };\n}\n\n// ============================================================================\n// QUANTUM HANDSHAKE\n// ============================================================================\n\n/**\n * POST /api/v1/handshake\n * Initiate Quantum-Resistant Zero-Moment Tunnel\n * NOTE: This endpoint does not require authentication to allow initial connection\n */\nrouter.post('/handshake', (req, res) => {\n  // CORS handled by global middleware or specific setup if needed\n  res.json({\n    status: 'success',\n    publicKey: getServerPqcPublicKey(),\n    algorithm: 'ML-KEM-1024 (Kyber)',\n    timestamp: new Date().toISOString(),\n  });\n});\n\n// ============================================================================\n// HEALTH CHECK (VERSIONED)\n// ============================================================================\n\n/**\n * GET /api/v1/\n * Simple reachability check for versioned API\n */\nrouter.get('/', (req, res) => {\n  res.json({ status: 'ok', service: 'OpenScroll Capture API (v1)' });\n});\n\n// ============================================================================\n// CAPTURE ENDPOINT\n// ============================================================================\n\n/**\n * POST /api/v1/capture\n *\n * Capture a conversation from an AI provider URL\n * Uses DID auth for user isolation, falls back to API key for dev\n */\nrouter.post('/capture', async (req, res, next) => {\n  const log = createRequestLogger(req);\n  let attemptId = null;\n  const startTime = Date.now();\n\n  // Check if DID auth is available\n  const hasDidAuth = req.headers['x-did'] || (req.headers['authorization'] || '').includes('did:');\n\n  try {\n    if (hasDidAuth) {\n      // Use DID authentication\n      await authenticateDID()(req, res, (err) => {\n        if (err) {\n          log.warn({ error: err.message }, 'DID auth failed');\n        }\n      });\n    } else {\n      // Fallback to API key for development\n      try {\n        await requireApiKey()(req, res, (err) => {\n          if (err) {\n            log.warn({ error: err.message }, 'API key auth failed');\n          }\n        });\n      } catch (apiKeyErr) {\n        // Continue without auth for dev mode\n      }\n    }\n  } catch (authErr) {\n    log.warn({ error: authErr.message }, 'Auth error, continuing...');\n  }\n\n  const userClient = req.user?.userClient;\n\n  try {\n    let requestBody = req.body;\n    let sharedSecret = null;\n\n    // ----------------------------------------------------------------------\n    // QUANTUM TUNNEL DECRYPTION\n    // ----------------------------------------------------------------------\n    if (req.body.pqcCiphertext && req.body.pqcPayload) {\n      log.info('Secure Quantum Tunnel detected');\n      sharedSecret = await kyberDecapsulate(req.body.pqcCiphertext);\n\n      const decryptedStr = symmetricDecrypt(req.body.pqcPayload, req.body.pqcNonce, sharedSecret);\n\n      if (!decryptedStr) {\n        throw new Error('Quantum Tunnel Decryption Failed');\n      }\n      requestBody = JSON.parse(decryptedStr);\n      console.log('\\nðŸ” [QUANTUM TUNNEL] Decrypted secure payload for extraction\\n');\n    } else {\n      requestBody = req.body;\n    }\n    // ----------------------------------------------------------------------\n\n    const { url, options } = validateRequest(requestBody, captureRequestSchema);\n\n    const { detectProvider } = await import('../services/extractor.js');\n\n    console.log(`\\nðŸ” [EXTRACTION STARTED] Processing request for: ${url}`);\n    console.log(`   Provider: ${detectProvider(url) || 'Unknown'}`);\n    console.log(`   Options: ${JSON.stringify(options || {})}\\n`);\n\n    log.info({ url, options, userDid: req.user?.did }, 'Capture request validated');\n\n    const useCache = options?.cache !== false;\n    if (useCache) {\n      try {\n        const recentAttempt = await findRecentSuccessfulUnified(\n          url,\n          options?.cacheMinutes || 60,\n          userClient\n        );\n        if (recentAttempt && recentAttempt.conversationId) {\n          log.info(\n            { conversationId: recentAttempt.conversationId },\n            'Returning cached conversation'\n          );\n          console.log(`ðŸ’¾ [CACHE HIT] Returning cached data for: ${url}\\n`);\n          return res.json({\n            status: 'success',\n            cached: true,\n            authenticated: true,\n            userDid: req.user?.did,\n            data: await findBySourceUrl(url, userClient),\n          });\n        }\n      } catch (dbError) {\n        log.warn({ error: dbError.message }, 'Failed to check cache, proceeding anyway');\n        console.log('âš ï¸  [CACHE MISS] Cache unavailable, proceeding with fresh extraction\\n');\n      }\n    }\n\n    const provider = detectProvider(url);\n\n    const extractionStartTime = Date.now();\n    try {\n      const conversation = await extractConversation(url, options);\n\n      debugReporter.trackExtraction(\n        provider,\n        url,\n        Date.now() - extractionStartTime,\n        conversation?.messages?.length || 0,\n        { userDid: req.user?.did, requestId: req.id }\n      );\n\n      log.info(\n        {\n          conversationId: conversation.id,\n          provider: conversation.provider,\n          messageCount: conversation.messages?.length || 0,\n          userDid: req.user?.did,\n        },\n        'Conversation captured successfully'\n      );\n      attemptId = attempt.id;\n      console.log(`ðŸ“‹ [ATTEMPT LOGGED] Capture attempt ID: ${attemptId}\\n`);\n    } catch (dbError) {\n      log.warn({ error: dbError.message }, 'Failed to create capture attempt record');\n    }\n\n    console.log(\n      `âœ… [EXTRACTION COMPLETE] Retrieved ${conversation.messages?.length || 0} messages`\n    );\n\n    const saveStartTime = Date.now();\n    try {\n      const saveResult = await saveConversationUnified(conversation, userClient);\n      debugReporter.trackInfo(\n        {\n          category: 'save',\n          message: `Conversation saved to ${saveResult.engine}`,\n        },\n        {\n          engine: saveResult.engine,\n          duration: Date.now() - saveStartTime,\n          conversationId: conversation.id,\n          userDid: req.user?.did,\n        }\n      );\n      console.log(\n        `ðŸ’¾ [DATABASE] Conversation saved to ${saveResult.engine} for user ${req.user?.did}`\n      );\n\n      if (attemptId) {\n        await completeCaptureAttempt(\n          attemptId,\n          {\n            status: 'success',\n            duration: Date.now() - startTime,\n            conversationId: conversation.id,\n          },\n          userClient\n        );\n        console.log(`âœ… [ATTEMPT COMPLETED] Capture attempt ${attemptId} marked as successful\\n`);\n      }\n    } catch (dbError) {\n      debugReporter.trackError(dbError, {\n        operation: 'saveConversationUnified',\n        conversationId: conversation.id,\n        userDid: req.user?.did,\n        requestId: req.id,\n      });\n      log.warn({ error: dbError.message }, 'Failed to save conversation to DB');\n      console.log(`âš ï¸  [DATABASE ERROR] Failed to save to database: ${dbError.message}\\n`);\n    }\n\n    const responseData = {\n      status: 'success',\n      cached: false,\n      authenticated: true,\n      userDid: req.user?.did,\n      data: prepareConversationForClient(conversation),\n    };\n\n    console.log(\n      `ðŸŽ¯ [RESPONSE READY] Sending ${conversation.messages?.length || 0} messages to client\\n`\n    );\n\n    if (sharedSecret) {\n      const encrypted = symmetricEncrypt(JSON.stringify(responseData), sharedSecret);\n      console.log('ðŸ” [QUANTUM ENCRYPT] Response encrypted for secure transmission\\n');\n      return res.json({\n        status: 'success',\n        pqcPayload: encrypted.ciphertext,\n        pqcNonce: encrypted.nonce,\n        quantumHardened: true,\n        authenticated: true,\n        userDid: req.user?.did,\n      });\n    }\n\n    res.json(responseData);\n  } catch (error) {\n    debugReporter.trackError(error, {\n      operation: 'extractConversation',\n      provider: detectProvider(url),\n      url,\n      duration: Date.now() - startTime,\n      userDid: req.user?.did,\n      requestId: req.id,\n    });\n\n    console.log(`âŒ [EXTRACTION FAILED] Error processing request: ${error.message}\\n`);\n\n    if (attemptId) {\n      try {\n        await completeCaptureAttempt(\n          attemptId,\n          {\n            status: 'failed',\n            duration: Date.now() - startTime,\n            errorCode: error.code,\n            errorMessage: error.message,\n          },\n          userClient\n        );\n      } catch (dbError) {\n        log.warn({ error: dbError.message }, 'Failed to update capture attempt');\n      }\n    }\n\n    next(error);\n  }\n});\n\n/**\n * POST /api/v1/capture-sync/init\n *\n * Initialize a secure sync session.\n * Accepts PQC/Auth data and returns a short-lived ticket for the SSE connection.\n */\nrouter.post('/capture-sync/init', requireApiKey(), async (req, res, next) => {\n  try {\n    const data = validateRequest(req.body, syncInitSchema);\n\n    // Store the payload (url, crypto keys) in the ticket store\n    const ticket = ticketStore.create(data);\n\n    res.json({\n      status: 'success',\n      ticket,\n      expiresIn: 30, // seconds\n    });\n  } catch (error) {\n    next(error);\n  }\n});\n\n/**\n * GET /api/v1/capture-sync\n *\n * High-fidelity real-time capture via Server-Sent Events (SSE)\n * Uses a ticket obtained from /capture-sync/init\n */\nrouter.get('/capture-sync', async (req, res) => {\n  const { ticket } = req.query;\n\n  // Set SSE Headers immediately\n  res.writeHead(200, {\n    'Content-Type': 'text/event-stream',\n    'Cache-Control': 'no-cache',\n    Connection: 'keep-alive',\n    'Access-Control-Allow-Origin': '*', // Required for SSE to work across domains (e.g. PWA)\n  });\n\n  const sendEvent = (event, data) => {\n    res.write(`event: ${event}\\ndata: ${JSON.stringify(data)}\\n\\n`);\n  };\n\n  // Validate Ticket\n  const ticketData = ticketStore.consume(ticket);\n\n  if (!ticketData) {\n    sendEvent('error', { message: 'Invalid or expired ticket' });\n    res.end();\n    return;\n  }\n\n  const { pqcCiphertext, pqcPayload, pqcNonce, url: rawUrl } = ticketData;\n  let targetUrl = rawUrl;\n  let sharedSecret = null;\n\n  // Setup heartbeat\n  const heartbeat = setInterval(() => {\n    res.write(': heartbeat\\n\\n');\n  }, 15000);\n\n  // Encrypted Sender\n  const sendEncryptedEvent = (event, data) => {\n    let payload = data;\n    if (sharedSecret) {\n      const encrypted = symmetricEncrypt(JSON.stringify(data), sharedSecret);\n      payload = {\n        pqcPayload: encrypted.ciphertext,\n        pqcNonce: encrypted.nonce,\n        quantumHardened: true,\n      };\n    }\n    res.write(`event: ${event}\\ndata: ${JSON.stringify(payload)}\\n\\n`);\n  };\n\n  req.on('close', () => {\n    clearInterval(heartbeat);\n  });\n\n  try {\n    // ----------------------------------------------------------------------\n    // QUANTUM TUNNEL DECRYPTION (Ticket version)\n    // ----------------------------------------------------------------------\n    if (pqcCiphertext && pqcPayload) {\n      try {\n        sharedSecret = await kyberDecapsulate(pqcCiphertext);\n      } catch (kemError) {\n        console.error(`âŒ [SYNC FAILED] KEM Decapsulation error: ${kemError.message}`);\n        throw new Error('Quantum Tunnel Handshake Failed');\n      }\n\n      const decryptedUrl = symmetricDecrypt(pqcPayload, pqcNonce, sharedSecret);\n      if (!decryptedUrl) {\n        console.error('âŒ [SYNC FAILED] Symmetric decryption failed for payload');\n        throw new Error('Quantum Tunnel Decryption Failed');\n      }\n\n      try {\n        targetUrl = JSON.parse(decryptedUrl).url;\n      } catch (jsonError) {\n        console.error('âŒ [SYNC FAILED] Invalid JSON in decrypted payload');\n        throw new Error('Quantum Tunnel Payload Corrupt');\n      }\n\n      console.log('\\nðŸ” [QUANTUM TUNNEL] Streaming via Post-Quantum Secure Channel\\n');\n    }\n    // ----------------------------------------------------------------------\n\n    if (!targetUrl) {\n      throw new Error('Missing target URL');\n    }\n\n    console.log(`\\nðŸ”„ [SYNC STARTED] Beginning real-time sync for: ${targetUrl}\\n`);\n\n    const conversation = await extractConversation(targetUrl, {\n      onProgress: (update) => {\n        sendEncryptedEvent('progress', update);\n      },\n    });\n\n    console.log(\n      `\\nâœ… [SYNC COMPLETE] Successfully extracted ${conversation.messages?.length || 0} messages\\n`\n    );\n\n    // DB Persistence in background (UNIFIED)\n    saveConversationUnified(conversation)\n      .then((res) => console.log(`ðŸ’¾ [BG SAVE] Saved to ${res.engine}`))\n      .catch((err) => console.error('ðŸ’¾ [BG SAVE ERROR]:', err.message));\n\n    // Send complete\n    sendEncryptedEvent('complete', {\n      ...prepareConversationForClient(conversation),\n      authenticated: true, // If they got a ticket, they passed auth in /init\n    });\n\n    console.log('ðŸ“¤ [STREAMING] Sent complete conversation to client\\n');\n    clearInterval(heartbeat);\n    res.end();\n  } catch (error) {\n    clearInterval(heartbeat);\n    console.log(`âŒ [SYNC FAILED] Error in sync: ${error.message}\\n`);\n    sendEncryptedEvent('sync-error', {\n      message: error.message,\n    });\n    res.end();\n  }\n});\n\n// ============================================================================\n// PROVIDER DETECTION\n// ============================================================================\n\nrouter.get('/detect-provider', requireApiKey(), (req, res, next) => {\n  const log = createRequestLogger(req);\n  try {\n    const { url } = req.query;\n    if (!url || typeof url !== 'string') {\n      throw new ValidationError('URL query parameter is required');\n    }\n    import('../services/extractor.js').then(({ detectProvider }) => {\n      const provider = detectProvider(url);\n      log.info({ url, provider }, 'Provider detection');\n      res.json({ provider, supported: provider !== null });\n    });\n  } catch (error) {\n    next(error);\n  }\n});\n\n// ============================================================================\n// SUPPORTED PROVIDERS\n// ============================================================================\n\nrouter.get('/providers', requireApiKey(), (req, res) => {\n  const log = createRequestLogger(req);\n  const providers = [\n    'claude',\n    'chatgpt',\n    'gemini',\n    'grok',\n    'deepseek',\n    'kimi',\n    'qwen',\n    'zai',\n    'mistral',\n  ];\n  log.info({ providers }, 'Supported providers list');\n  res.json({ providers, count: providers.length });\n});\n\nexport { router as captureRouter };\n","usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\routes\\circles.js","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\routes\\collections.js","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\routes\\context-v2.js","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\routes\\context.js","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\routes\\conversations.js","messages":[{"ruleId":"no-unused-vars","severity":1,"message":"'requireApiKey' is defined but never used.","line":18,"column":10,"nodeType":"Identifier","messageId":"unusedVar","endLine":18,"endColumn":23,"suggestions":[{"messageId":"removeVar","data":{"varName":"requireApiKey"},"fix":{"range":[424,478],"text":""},"desc":"Remove unused variable 'requireApiKey'."}]},{"ruleId":"no-unused-vars","severity":1,"message":"'log' is assigned a value but never used.","line":24,"column":7,"nodeType":"Identifier","messageId":"unusedVar","endLine":24,"endColumn":10,"suggestions":[{"messageId":"removeVar","data":{"varName":"log"},"fix":{"range":[681,712],"text":""},"desc":"Remove unused variable 'log'."}]}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":2,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * Conversation CRUD Routes\n *\n * RESTful endpoints for managing stored conversations\n */\n\nimport { Router } from 'express';\nimport { createRequestLogger } from '../lib/logger.js';\nimport { NotFoundError } from '../middleware/errorHandler.js';\nimport {\n  findConversationById,\n  listConversations,\n  deleteConversation,\n  getStatsByProvider,\n  getRecentConversations,\n  searchByTitle,\n} from '../repositories/index.js';\nimport { requireApiKey } from '../middleware/auth.js';\nimport { requireAuth } from '../middleware/unified-auth.js';\nimport { cacheService } from '../services/cache-service.js';\nimport { getPrismaClient } from '../lib/database.js';\n\nconst router = Router();\nconst log = { info: () => {} }; // fallback; individual routes use createRequestLogger(req)\n\n// ============================================================================\n// LIST CONVERSATIONS\n// ============================================================================\n\n/**\n * GET /api/v1/conversations\n *\n * List conversations with pagination and filters\n *\n * Query params:\n * - provider: Filter by provider\n * - limit: Results per page (default: 20)\n * - offset: Page offset (default: 0)\n * - orderBy: Sort field (default: createdAt)\n * - orderDirection: asc or desc (default: desc)\n * - startDate: Filter by start date\n * - endDate: Filter by end date\n */\nrouter.get('/', requireAuth, async (req, res, next) => {\n  const log = createRequestLogger(req);\n\n  try {\n    const {\n      provider,\n      limit = 20,\n      offset = 0,\n      orderBy = 'createdAt',\n      orderDirection = 'desc',\n      startDate,\n      endDate,\n      include_messages = 'false',\n    } = req.query;\n\n    const options = {\n      provider,\n      limit: parseInt(limit, 10),\n      offset: parseInt(offset, 10),\n      orderBy,\n      orderDirection,\n      startDate,\n      endDate,\n      userId: req.user?.userId, // set by unified-auth\n      includeMessages: include_messages === 'true',\n    };\n\n    const result = await listConversations(options);\n\n    log.info(\n      {\n        count: result.conversations.length,\n        userId: req.user?.userId,\n        includeMessages: options.includeMessages,\n      },\n      'User conversations listed'\n    );\n\n    res.json(result);\n  } catch (error) {\n    next(error);\n  }\n});\n\n// ============================================================================\n// GET CONVERSATION BY ID\n// ============================================================================\n\n/**\n * GET /api/v1/conversations/:id\n *\n * Get a single conversation by ID\n */\nrouter.get('/:id', requireAuth, async (req, res, next) => {\n  const log = createRequestLogger(req);\n\n  try {\n    const { id } = req.params;\n    const conversation = await findConversationById(id);\n\n    if (!conversation) {\n      throw new NotFoundError(`Conversation not found: ${id}`);\n    }\n\n    log.info({ conversationId: id, userId: req.auth?.apiKeyPrefix }, 'Conversation retrieved');\n\n    res.json({ data: conversation });\n  } catch (error) {\n    next(error);\n  }\n});\n\n// ============================================================================\n// GET CONVERSATION MESSAGES (PAGINATED)\n// ============================================================================\n\n/**\n * GET /api/v1/conversations/:id/messages\n *\n * Get messages for a single conversation with pagination\n *\n * Query params:\n * - limit: Results per page (default: 50)\n * - offset: Page offset (default: 0)\n */\nrouter.get('/:id/messages', requireAuth, async (req, res, next) => {\n  const log = createRequestLogger(req);\n\n  try {\n    const { id } = req.params;\n    const { limit = 50, offset = 0 } = req.query;\n\n    const cacheKey = `messages:${id}:${limit}:${offset}`;\n    const cached = await cacheService.get(cacheKey);\n    if (cached) {\n      log.debug({ conversationId: id, source: 'cache' }, 'Messages retrieved from cache');\n      return res.json(cached);\n    }\n\n    const { getPrismaClient } = await import('../lib/database.js');\n    const prisma = getPrismaClient();\n\n    const [messages, total] = await Promise.all([\n      prisma.message.findMany({\n        where: { conversationId: id },\n        take: parseInt(limit, 10),\n        skip: parseInt(offset, 10),\n        orderBy: { messageIndex: 'asc' },\n      }),\n      prisma.message.count({ where: { conversationId: id } }),\n    ]);\n\n    log.info(\n      { conversationId: id, count: messages.length, source: 'db' },\n      'Messages retrieved from db'\n    );\n\n    const responseData = {\n      data: messages,\n      pagination: {\n        total,\n        limit: parseInt(limit, 10),\n        offset: parseInt(offset, 10),\n        hasMore: parseInt(offset, 10) + messages.length < total,\n      },\n    };\n\n    await cacheService.set(cacheKey, responseData, 120); // Cache for 2 mins\n\n    res.json(responseData);\n  } catch (error) {\n    next(error);\n  }\n});\n\n// ============================================================================\n// SEARCH CONVERSATIONS\n// ============================================================================\n\n/**\n * GET /api/v1/conversations/search/:query\n *\n * Search conversations by title\n *\n * Query params:\n * - limit: Results limit (default: 20)\n * - provider: Filter by provider\n */\nrouter.get('/search/:query', requireAuth, async (req, res, next) => {\n  const log = createRequestLogger(req);\n\n  try {\n    const { query } = req.params;\n    const { limit = 20, provider } = req.query;\n\n    const conversations = await searchByTitle(query, {\n      limit: parseInt(limit, 10),\n      provider,\n    });\n\n    log.info(\n      { query, count: conversations.length, userId: req.auth?.apiKeyPrefix },\n      'Search completed'\n    );\n\n    res.json({\n      query,\n      results: conversations,\n      count: conversations.length,\n    });\n  } catch (error) {\n    next(error);\n  }\n});\n\n// ============================================================================\n// GET CONVERSATION STATS\n// ============================================================================\n\n/**\n * GET /api/v1/conversations/stats/summary\n *\n * Get conversation statistics by provider\n */\nrouter.get('/stats/summary', requireAuth, async (req, res, next) => {\n  const log = createRequestLogger(req);\n\n  try {\n    const stats = await getStatsByProvider();\n\n    log.info({ userId: req.auth?.apiKeyPrefix }, 'Stats retrieved');\n\n    res.json({ stats });\n  } catch (error) {\n    next(error);\n  }\n});\n\n// ============================================================================\n// GET RECENT CONVERSATIONS\n// ============================================================================\n\n/**\n * GET /api/v1/conversations/recent\n *\n * Get recent conversations\n *\n * Query params:\n * - limit: Number of conversations (default: 10)\n */\nrouter.get('/recent', requireAuth, async (req, res, next) => {\n  const log = createRequestLogger(req);\n\n  try {\n    const { limit = 10 } = req.query;\n    const conversations = await getRecentConversations(parseInt(limit, 10));\n\n    log.info(\n      { count: conversations.length, userId: req.auth?.apiKeyPrefix },\n      'Recent conversations retrieved'\n    );\n\n    res.json({ conversations });\n  } catch (error) {\n    next(error);\n  }\n});\n\n// ============================================================================\n// DELETE CONVERSATION\n// ============================================================================\n\n/**\n * DELETE /api/v1/conversations/:id\n *\n * Delete a conversation\n */\nrouter.delete('/:id', requireAuth, async (req, res, next) => {\n  const log = createRequestLogger(req);\n\n  try {\n    const { id } = req.params;\n    const conversation = await deleteConversation(id);\n\n    log.info({ conversationId: id, userId: req.auth?.apiKeyPrefix }, 'Conversation deleted');\n\n    res.json({\n      message: 'Conversation deleted',\n      id: conversation.id,\n    });\n  } catch (error) {\n    next(error);\n  }\n});\n\nrouter.post('/:id/fork', requireAuth, async (req, res, next) => {\n  const routeLog = createRequestLogger(req);\n  try {\n    const { id } = req.params;\n    const prisma = getPrismaClient();\n\n    const source = await prisma.conversation.findUnique({ where: { id } });\n    if (!source) {\n      return res.status(404).json({ error: 'Conversation not found' });\n    }\n\n    const forked = await prisma.conversation.create({\n      data: {\n        title: `${source.title} (Fork)`,\n        sourceUrl: `${source.sourceUrl}#fork-${Date.now()}`, // sourceUrl must be unique\n        provider: source.provider,\n        model: source.model,\n        ownerId: req.user?.userId ?? req.auth?.userId ?? null, // schema uses ownerId\n        createdAt: new Date(),\n        updatedAt: new Date(),\n        capturedAt: new Date(),\n      },\n    });\n\n    routeLog.info({ sourceId: id, forkedId: forked.id }, 'Conversation forked');\n\n    res.json({\n      success: true,\n      id: forked.id,\n      forkedFrom: id,\n    });\n  } catch (error) {\n    next(error);\n  }\n});\n\nrouter.get('/:id/related', requireAuth, async (req, res, next) => {\n  try {\n    const { id } = req.params;\n    const prisma = getPrismaClient();\n\n    const conversation = await prisma.conversation.findUnique({ where: { id } });\n    if (!conversation) {\n      return res.status(404).json({ error: 'Conversation not found' });\n    }\n\n    const related = await prisma.conversation.findMany({\n      where: {\n        id: { not: id },\n        ownerId: req.user?.userId ?? req.auth?.userId ?? null, // schema uses ownerId\n      },\n      take: 5,\n      orderBy: { createdAt: 'desc' },\n    });\n\n    res.json({\n      success: true,\n      related,\n    });\n  } catch (error) {\n    next(error);\n  }\n});\n\nexport { router as conversationsRouter };\n","usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\routes\\core.js","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\routes\\debug.js","messages":[{"ruleId":"no-unused-vars","severity":1,"message":"'dbHealth' is assigned a value but never used.","line":313,"column":11,"nodeType":"Identifier","messageId":"unusedVar","endLine":313,"endColumn":19,"suggestions":[{"messageId":"removeVar","data":{"varName":"dbHealth"},"fix":{"range":[7278,7339],"text":""},"desc":"Remove unused variable 'dbHealth'."}]}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":"import { Router } from 'express';\nimport { debugReporter } from '../services/debug-reporter.js';\nimport { getPrismaClient, getDatabaseStats } from '../lib/database.js';\nimport { logger } from '../lib/logger.js';\n\nconst router = Router();\n\nconst requireDevMode = (req, res, next) => {\n  if (process.env.NODE_ENV === 'production' && !process.env.ENABLE_DEBUG_ENDPOINTS) {\n    return res\n      .status(403)\n      .json({ success: false, error: 'Debug endpoints disabled in production' });\n  }\n  next();\n};\n\nrouter.use(requireDevMode);\n\nrouter.get('/status', (req, res) => {\n  const status = debugReporter.getStatus();\n  const memoryUsage = process.memoryUsage();\n  const cpuUsage = process.cpuUsage();\n\n  res.json({\n    success: true,\n    data: {\n      ...status,\n      memory: {\n        heapUsed: memoryUsage.heapUsed,\n        heapTotal: memoryUsage.heapTotal,\n        external: memoryUsage.external,\n        rss: memoryUsage.rss,\n      },\n      cpu: {\n        user: cpuUsage.user,\n        system: cpuUsage.system,\n      },\n      platform: {\n        nodeVersion: process.version,\n        platform: process.platform,\n        arch: process.arch,\n      },\n    },\n  });\n});\n\nrouter.get('/errors', (req, res) => {\n  const { category, level, severity, limit = 100 } = req.query;\n\n  const filters = {};\n  if (category) {\n    filters.category = category;\n  }\n  if (level) {\n    filters.level = parseInt(level);\n  }\n  if (severity) {\n    filters.severity = severity;\n  }\n  if (limit) {\n    filters.limit = parseInt(limit);\n  }\n\n  const errors = debugReporter.getErrors(filters);\n\n  res.json({\n    success: true,\n    data: errors,\n    count: errors.length,\n    filters,\n  });\n});\n\nrouter.get('/performance', (req, res) => {\n  const metrics = debugReporter.getPerformanceMetrics();\n\n  res.json({\n    success: true,\n    data: metrics,\n  });\n});\n\nrouter.get('/queries', (req, res) => {\n  const { slowOnly = 'false', limit = 100 } = req.query;\n  let { queries } = debugReporter;\n\n  if (slowOnly === 'true') {\n    queries = queries.filter((q) => q.isSlow);\n  }\n\n  if (limit) {\n    queries = queries.slice(-parseInt(limit));\n  }\n\n  res.json({\n    success: true,\n    data: queries,\n    count: queries.length,\n  });\n});\n\nrouter.get('/external-calls', (req, res) => {\n  const { failedOnly = 'false', limit = 100 } = req.query;\n  let calls = debugReporter.externalCalls;\n\n  if (failedOnly === 'true') {\n    calls = calls.filter((c) => !c.success);\n  }\n\n  if (limit) {\n    calls = calls.slice(-parseInt(limit));\n  }\n\n  res.json({\n    success: true,\n    data: calls,\n    count: calls.length,\n  });\n});\n\nrouter.get('/extractions', (req, res) => {\n  const { limit = 100 } = req.query;\n  let { extractions } = debugReporter;\n\n  if (limit) {\n    extractions = extractions.slice(-parseInt(limit));\n  }\n\n  res.json({\n    success: true,\n    data: extractions,\n    count: extractions.length,\n  });\n});\n\nrouter.get('/sync-operations', (req, res) => {\n  const { limit = 100 } = req.query;\n  let operations = debugReporter.syncOperations;\n\n  if (limit) {\n    operations = operations.slice(-parseInt(limit));\n  }\n\n  res.json({\n    success: true,\n    data: operations,\n    count: operations.length,\n  });\n});\n\nrouter.get('/state-snapshots', (req, res) => {\n  const { limit = 50 } = req.query;\n  let snapshots = debugReporter.stateSnapshots;\n\n  if (limit) {\n    snapshots = snapshots.slice(-parseInt(limit));\n  }\n\n  res.json({\n    success: true,\n    data: snapshots,\n    count: snapshots.length,\n  });\n});\n\nrouter.get('/state/:entityType/:entityId', async (req, res) => {\n  const { entityType, entityId } = req.params;\n\n  try {\n    const prisma = getPrismaClient();\n    let entity = null;\n\n    switch (entityType.toLowerCase()) {\n      case 'user':\n        entity = await prisma.user.findUnique({ where: { id: entityId } });\n        break;\n      case 'conversation':\n        entity = await prisma.conversation.findUnique({ where: { id: entityId } });\n        break;\n      case 'captureattempt':\n      case 'capture_attempt':\n        entity = await prisma.captureAttempt.findUnique({ where: { id: entityId } });\n        break;\n      case 'atomicchatunit':\n      case 'acu':\n        entity = await prisma.atomicChatUnit.findUnique({ where: { id: entityId } });\n        break;\n      case 'syncoperation':\n        entity = await prisma.syncOperation.findUnique({ where: { id: entityId } });\n        break;\n      default:\n        return res.status(400).json({\n          success: false,\n          error: `Unknown entity type: ${entityType}`,\n        });\n    }\n\n    if (!entity) {\n      return res.status(404).json({\n        success: false,\n        error: 'Entity not found',\n      });\n    }\n\n    res.json({\n      success: true,\n      data: {\n        type: entityType,\n        id: entityId,\n        entity,\n        capturedAt: new Date().toISOString(),\n      },\n    });\n  } catch (error) {\n    logger.error({ error: error.message, entityType, entityId }, 'Failed to get entity state');\n    res.status(500).json({\n      success: false,\n      error: 'Failed to retrieve entity state',\n    });\n  }\n});\n\nrouter.post('/inspect/:service', (req, res) => {\n  const { service } = req.params;\n\n  const serviceInspectors = {\n    database: () => {\n      const stats = getDatabaseStats();\n      return {\n        service: 'database',\n        status: 'operational',\n        stats,\n        connectionInfo: {\n          host: process.env.DATABASE_HOST || 'localhost',\n          database: process.env.DATABASE_NAME || 'vivim',\n        },\n      };\n    },\n    debug: () => {\n      return {\n        service: 'debug',\n        status: 'operational',\n        bufferSizes: {\n          errors: debugReporter.errors.length,\n          warnings: debugReporter.warnings.length,\n          queries: debugReporter.queries.length,\n          externalCalls: debugReporter.externalCalls.length,\n          extractions: debugReporter.extractions.length,\n          syncOperations: debugReporter.syncOperations.length,\n        },\n      };\n    },\n    logger: () => {\n      return {\n        service: 'logger',\n        status: 'operational',\n        config: {\n          level: process.env.LOG_LEVEL || 'info',\n          format: process.env.LOG_FORMAT || 'json',\n        },\n      };\n    },\n    memory: () => {\n      const mem = process.memoryUsage();\n      return {\n        service: 'memory',\n        status: 'operational',\n        usage: {\n          heapUsed: mem.heapUsed,\n          heapTotal: mem.heapTotal,\n          external: mem.external,\n          rss: mem.rss,\n        },\n      };\n    },\n  };\n\n  const inspector = serviceInspectors[service.toLowerCase()];\n\n  if (!inspector) {\n    return res.status(400).json({\n      success: false,\n      error: `Unknown service: ${service}. Available: ${Object.keys(serviceInspectors).join(', ')}`,\n    });\n  }\n\n  try {\n    const result = inspector();\n    res.json({\n      success: true,\n      data: result,\n    });\n  } catch (error) {\n    logger.error({ error: error.message, service }, 'Service inspection failed');\n    res.status(500).json({\n      success: false,\n      error: 'Service inspection failed',\n    });\n  }\n});\n\nrouter.post('/clear', (req, res) => {\n  debugReporter.clear();\n\n  res.json({\n    success: true,\n    message: 'Debug buffer cleared',\n  });\n});\n\nrouter.get('/health', async (req, res) => {\n  try {\n    const dbHealth = await getPrismaClient().$queryRaw`SELECT 1`;\n    const memory = process.memoryUsage();\n\n    res.json({\n      success: true,\n      data: {\n        database: 'healthy',\n        memory: {\n          status: memory.heapUsed < 1024 * 1024 * 1024 ? 'healthy' : 'warning',\n          heapUsed: memory.heapUsed,\n        },\n        timestamp: new Date().toISOString(),\n      },\n    });\n  } catch (error) {\n    res.status(503).json({\n      success: false,\n      error: 'Health check failed',\n      details: error.message,\n    });\n  }\n});\n\nexport { router as debugRouter };\nexport default router;\n","usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\routes\\error-router.js","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\routes\\errors.js","messages":[{"ruleId":"no-unused-vars","severity":1,"message":"'errorReportSchema' is assigned a value but never used.","line":29,"column":7,"nodeType":"Identifier","messageId":"unusedVar","endLine":29,"endColumn":24,"suggestions":[{"messageId":"removeVar","data":{"varName":"errorReportSchema"},"fix":{"range":[1020,1543],"text":""},"desc":"Remove unused variable 'errorReportSchema'."}]},{"ruleId":"no-unused-vars","severity":1,"message":"'bulkErrorReportSchema' is assigned a value but never used.","line":46,"column":7,"nodeType":"Identifier","messageId":"unusedVar","endLine":46,"endColumn":28,"suggestions":[{"messageId":"removeVar","data":{"varName":"bulkErrorReportSchema"},"fix":{"range":[1545,1634],"text":""},"desc":"Remove unused variable 'bulkErrorReportSchema'."}]}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":2,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * Error Collection API Endpoint\n * Receives error reports from all components (PWA, Network, Server)\n *\n * Enhanced with:\n * - Error aggregation and trends\n * - Alert configuration\n * - Service contract violation tracking\n * - Sync issue tracking\n */\n\nimport express from 'express';\nimport { logger } from '../lib/logger.js';\nimport { serverErrorReporter } from '../utils/server-error-reporting.js';\nimport { config } from '../config/index.js';\nimport { z } from 'zod';\nimport { circuitBreakerService } from '../services/circuit-breaker.js';\nimport { queueService } from '../services/queue-service.js';\nimport { cacheService } from '../services/cache-service.js';\nimport { ErrorAggregator } from '../../../common/error-aggregator.js';\nimport { ErrorAlerter } from '../../../common/error-alerting.js';\n\nconst router = express.Router();\n\nconst errorAggregator = ErrorAggregator.getInstance();\nconst errorAlerter = ErrorAlerter.getInstance();\n\n// Zod schema for validating error reports (simplified for compatibility)\nconst errorReportSchema = z.object({\n  id: z.string().optional(),\n  timestamp: z.string().optional(),\n  level: z.string().optional(),\n  component: z.string().optional(),\n  category: z.string().optional(),\n  message: z.string().optional(),\n  stack: z.string().optional(),\n  context: z.record(z.unknown()).optional(),\n  userId: z.string().optional(),\n  sessionId: z.string().optional(),\n  userAgent: z.string().optional(),\n  url: z.string().optional(),\n  version: z.string().optional(),\n  severity: z.string().optional(),\n});\n\nconst bulkErrorReportSchema = z.object({\n  reports: z.array(z.object({})).optional(),\n});\n\n// In-memory storage for collected errors (in production, use a database)\nconst errorStorage = {\n  errors: [],\n  maxSize: 10000, // Keep only the last 10,000 errors\n\n  add(errorReport) {\n    this.errors.push(errorReport);\n    // Trim if we exceed max size\n    if (this.errors.length > this.maxSize) {\n      this.errors = this.errors.slice(-this.maxSize);\n    }\n  },\n\n  getAll() {\n    return [...this.errors]; // Return a copy\n  },\n\n  getByComponent(component) {\n    return this.errors.filter((e) => e.component === component);\n  },\n\n  getBySeverity(severity) {\n    return this.errors.filter((e) => e.severity === severity);\n  },\n\n  getByCategory(category) {\n    return this.errors.filter((e) => e.category === category);\n  },\n\n  getRecent(hours = 24) {\n    const cutoff = new Date(Date.now() - hours * 60 * 60 * 1000);\n    return this.errors.filter((e) => new Date(e.timestamp) > cutoff);\n  },\n\n  getStats() {\n    const stats = {\n      total: this.errors.length,\n      byLevel: {},\n      byComponent: {},\n      bySeverity: {},\n      byCategory: {},\n      recent: this.getRecent(1).length, // Errors in last hour\n    };\n\n    this.errors.forEach((error) => {\n      // Count by level\n      stats.byLevel[error.level] = (stats.byLevel[error.level] || 0) + 1;\n\n      // Count by component\n      stats.byComponent[error.component] = (stats.byComponent[error.component] || 0) + 1;\n\n      // Count by severity\n      stats.bySeverity[error.severity] = (stats.bySeverity[error.severity] || 0) + 1;\n\n      // Count by category\n      stats.byCategory[error.category] = (stats.byCategory[error.category] || 0) + 1;\n    });\n\n    return stats;\n  },\n\n  clear() {\n    this.errors = [];\n  },\n};\n\n// Endpoint to receive error reports from clients\nrouter.post('/', async (req, res) => {\n  try {\n    // Accept reports without strict validation for development\n    const { reports = [] } = req.body || {};\n\n    // Process each error report\n    for (const report of reports) {\n      // Store the error\n      errorStorage.add(report);\n\n      // Log to server logs as well\n      logger.error(\n        {\n          component: report?.component,\n          category: report?.category,\n          severity: report?.severity,\n          message: report?.message,\n          userId: report?.userId,\n          url: report?.url,\n          userAgent: report?.userAgent,\n        },\n        'Error report received from client'\n      );\n\n      // For critical errors, send immediate notification\n      if (report?.severity === 'critical') {\n        logger.error(\n          {\n            type: 'CRITICAL_ERROR_ALERT',\n            component: report?.component,\n            message: report?.message,\n            userId: report?.userId,\n          },\n          'Critical error detected'\n        );\n      }\n    }\n\n    logger.info({ count: reports.length }, 'Error reports processed successfully');\n\n    res.status(200).json({\n      success: true,\n      message: `Processed ${reports.length} error reports`,\n      timestamp: new Date().toISOString(),\n    });\n  } catch (error) {\n    logger.error({ error: error.message }, 'Failed to process error reports');\n\n    await serverErrorReporter.reportAPIError('Failed to process error reports', error, {\n      requestBodySize: req.body?.reports?.length || 0,\n    });\n\n    res.status(500).json({\n      error: 'Failed to process error reports',\n      message: error.message,\n    });\n  }\n});\n\n// GET endpoint to retrieve error statistics (for dashboard)\nrouter.get('/stats', (req, res) => {\n  try {\n    const stats = errorStorage.getStats();\n\n    res.status(200).json({\n      success: true,\n      data: stats,\n      timestamp: new Date().toISOString(),\n    });\n  } catch (error) {\n    logger.error({ error: error.message }, 'Failed to get error stats');\n    res.status(500).json({\n      error: 'Failed to get error statistics',\n    });\n  }\n});\n\n// GET endpoint to retrieve recent errors (for dashboard)\nrouter.get('/recent', (req, res) => {\n  try {\n    const hours = parseInt(req.query.hours) || 24;\n    const limit = parseInt(req.query.limit) || 100;\n    const { component } = req.query;\n    const { severity } = req.query;\n    const { category } = req.query;\n\n    let errors = errorStorage.getRecent(hours);\n\n    // Apply filters\n    if (component) {\n      errors = errors.filter((e) => e.component === component);\n    }\n\n    if (severity) {\n      errors = errors.filter((e) => e.severity === severity);\n    }\n\n    if (category) {\n      errors = errors.filter((e) => e.category === category);\n    }\n\n    // Sort by timestamp (newest first) and limit\n    errors = errors.sort((a, b) => new Date(b.timestamp) - new Date(a.timestamp)).slice(0, limit);\n\n    res.status(200).json({\n      success: true,\n      data: errors,\n      count: errors.length,\n      timestamp: new Date().toISOString(),\n    });\n  } catch (error) {\n    logger.error({ error: error.message }, 'Failed to get recent errors');\n    res.status(500).json({\n      error: 'Failed to get recent errors',\n    });\n  }\n});\n\n// GET endpoint to retrieve all errors (admin only, with auth check in production)\nrouter.get('/', (req, res) => {\n  try {\n    // In production, add authentication check here\n    if (config.isProduction && !req.user?.isAdmin) {\n      return res.status(403).json({\n        error: 'Access denied',\n      });\n    }\n\n    const { component } = req.query;\n    const { severity } = req.query;\n    const { category } = req.query;\n\n    let errors = errorStorage.getAll();\n\n    // Apply filters\n    if (component) {\n      errors = errors.filter((e) => e.component === component);\n    }\n\n    if (severity) {\n      errors = errors.filter((e) => e.severity === severity);\n    }\n\n    if (category) {\n      errors = errors.filter((e) => e.category === category);\n    }\n\n    // Sort by timestamp (newest first)\n    errors = errors.sort((a, b) => new Date(b.timestamp) - new Date(a.timestamp));\n\n    res.status(200).json({\n      success: true,\n      data: errors,\n      count: errors.length,\n      timestamp: new Date().toISOString(),\n    });\n  } catch (error) {\n    logger.error({ error: error.message }, 'Failed to get all errors');\n    res.status(500).json({\n      error: 'Failed to get errors',\n    });\n  }\n});\n\n// Admin endpoint to clear errors (with auth check in production)\nrouter.delete('/clear', (req, res) => {\n  try {\n    // In production, add authentication check here\n    if (config.isProduction && !req.user?.isAdmin) {\n      return res.status(403).json({\n        error: 'Access denied',\n      });\n    }\n\n    const count = errorStorage.errors.length;\n    errorStorage.clear();\n\n    logger.info({ count }, 'Error logs cleared by admin');\n\n    res.status(200).json({\n      success: true,\n      message: `Cleared ${count} error reports`,\n      timestamp: new Date().toISOString(),\n    });\n  } catch (error) {\n    logger.error({ error: error.message }, 'Failed to clear errors');\n    res.status(500).json({\n      error: 'Failed to clear errors',\n    });\n  }\n});\n\n/**\n * GET /api/v1/errors/system-status\n *\n * Get detailed health and debugging status of all server-side components.\n */\nrouter.get('/system-status', (req, res) => {\n  const status = {\n    timestamp: new Date().toISOString(),\n    components: {\n      cache: {\n        connected: cacheService.isConnected,\n        type: cacheService.client ? 'redis' : 'memory',\n        memoryCacheSize: cacheService.memoryCache.size,\n      },\n      queues: Array.from(queueService.queues.entries()).map(([name, queue]) => ({\n        name,\n        pending: queue.pending,\n        size: queue.size,\n        concurrency: queue.concurrency,\n      })),\n      circuitBreakers: Array.from(circuitBreakerService.breakers.entries()).map(\n        ([name, breaker]) => ({\n          name,\n          state: breaker.state,\n          stats: breaker.stats,\n          enabled: breaker.enabled,\n        })\n      ),\n      database: {\n        status: 'connected',\n      },\n    },\n  };\n\n  res.json(status);\n});\n\nexport { router as errorsRouter };\n\n// ============================================================================\n// ENHANCED ERROR DASHBOARD API ENDPOINTS\n// ============================================================================\n\nconst enhancedRouter = express.Router();\n\nenhancedRouter.post('/', async (req, res) => {\n  try {\n    const { reports = [] } = req.body || {};\n\n    for (const report of reports) {\n      errorStorage.add(report);\n      errorAggregator.addError(report);\n\n      if (report?.severity === 'critical') {\n        await errorAlerter.alertError(report);\n      }\n    }\n\n    res.status(200).json({\n      success: true,\n      message: `Processed ${reports.length} error reports`,\n      timestamp: new Date().toISOString(),\n    });\n  } catch (error) {\n    logger.error({ error: error.message }, 'Failed to process error reports');\n    res.status(500).json({ error: 'Failed to process error reports', message: error.message });\n  }\n});\n\nenhancedRouter.get('/summary', (req, res) => {\n  try {\n    const windowMs = parseInt(req.query.windowMs) || 3600000;\n    const summary = errorAggregator.getSummary(windowMs);\n    res.json({ success: true, data: summary });\n  } catch (error) {\n    logger.error({ error: error.message }, 'Failed to get error summary');\n    res.status(500).json({ error: 'Failed to get error summary' });\n  }\n});\n\nenhancedRouter.get('/groups', (req, res) => {\n  try {\n    const groups = errorAggregator.groupErrors();\n    res.json({ success: true, data: groups });\n  } catch (error) {\n    logger.error({ error: error.message }, 'Failed to get error groups');\n    res.status(500).json({ error: 'Failed to get error groups' });\n  }\n});\n\nenhancedRouter.get('/trends', (req, res) => {\n  try {\n    const windowMs = parseInt(req.query.windowMs) || 3600000;\n    const currentWindow = errorAggregator.getErrorsInTimeWindow(windowMs);\n    const previousWindow = errorAggregator\n      .getErrorsInTimeWindow(windowMs * 2)\n      .filter((e) => new Date(e.timestamp).getTime() <= Date.now() - windowMs);\n    const trends = errorAggregator.calculateTrends(currentWindow, previousWindow);\n    res.json({ success: true, data: trends });\n  } catch (error) {\n    logger.error({ error: error.message }, 'Failed to get error trends');\n    res.status(500).json({ error: 'Failed to get error trends' });\n  }\n});\n\nenhancedRouter.get('/alerts', (req, res) => {\n  try {\n    const alerts = errorAggregator.getAlerts();\n    res.json({ success: true, data: alerts });\n  } catch (error) {\n    logger.error({ error: error.message }, 'Failed to get alerts');\n    res.status(500).json({ error: 'Failed to get alerts' });\n  }\n});\n\nenhancedRouter.get('/alert-history', (req, res) => {\n  try {\n    const limit = parseInt(req.query.limit) || 100;\n    const history = errorAlerter.getAlertHistory(undefined, limit);\n    res.json({ success: true, data: history });\n  } catch (error) {\n    logger.error({ error: error.message }, 'Failed to get alert history');\n    res.status(500).json({ error: 'Failed to get alert history' });\n  }\n});\n\nenhancedRouter.post('/alert-channels', (req, res) => {\n  try {\n    const { type, enabled, webhookUrl, minSeverity } = req.body;\n    errorAlerter.configureChannel({ type, enabled, webhookUrl, minSeverity });\n    res.json({ success: true, message: `Channel ${type} configured` });\n  } catch (error) {\n    logger.error({ error: error.message }, 'Failed to configure alert channel');\n    res.status(500).json({ error: 'Failed to configure alert channel' });\n  }\n});\n\nenhancedRouter.get('/alert-channels', (req, res) => {\n  try {\n    const channels = Array.from(['slack', 'discord', 'webhook', 'email', 'sms']).map((type) =>\n      errorAlerter.getChannelConfig(type)\n    );\n    res.json({ success: true, data: channels });\n  } catch (error) {\n    logger.error({ error: error.message }, 'Failed to get alert channels');\n    res.status(500).json({ error: 'Failed to get alert channels' });\n  }\n});\n\nenhancedRouter.post('/alert-rules', (req, res) => {\n  try {\n    const { name, enabled, conditions, actions } = req.body;\n    const rule = errorAlerter.addRule({ name, enabled, conditions, actions });\n    res.json({ success: true, data: rule });\n  } catch (error) {\n    logger.error({ error: error.message }, 'Failed to create alert rule');\n    res.status(500).json({ error: 'Failed to create alert rule' });\n  }\n});\n\nenhancedRouter.get('/alert-rules', (req, res) => {\n  try {\n    const rules = errorAlerter.getAllRules();\n    res.json({ success: true, data: rules });\n  } catch (error) {\n    logger.error({ error: error.message }, 'Failed to get alert rules');\n    res.status(500).json({ error: 'Failed to get alert rules' });\n  }\n});\n\nenhancedRouter.delete('/alert-rules/:ruleId', (req, res) => {\n  try {\n    const { ruleId } = req.params;\n    const removed = errorAlerter.removeRule(ruleId);\n    res.json({ success: removed, message: removed ? 'Rule removed' : 'Rule not found' });\n  } catch (error) {\n    logger.error({ error: error.message }, 'Failed to delete alert rule');\n    res.status(500).json({ error: 'Failed to delete alert rule' });\n  }\n});\n\nexport { router as enhancedErrorsRouter };\n","usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\routes\\feed-v2.js","messages":[{"ruleId":"no-unused-vars","severity":1,"message":"'generateContextualFeed' is defined but never used.","line":10,"column":3,"nodeType":"Identifier","messageId":"unusedVar","endLine":10,"endColumn":25,"suggestions":[{"messageId":"removeVar","data":{"varName":"generateContextualFeed"},"fix":{"range":[206,229],"text":""},"desc":"Remove unused variable 'generateContextualFeed'."}]}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * Feed & Discovery API Routes - Phase 4 (v2)\n * Base: /api/v2/feed\n */\n\nimport { Router } from 'express';\nimport { z } from 'zod';\nimport { feedService } from '../services/feed-service.js';\nimport {\n  generateContextualFeed,\n  processFeedEngagement,\n} from '../services/feed-context-integration.js';\nimport { authenticateDID } from '../middleware/auth.js';\nimport { logger } from '../lib/logger.js';\n\nconst router = Router();\nconst log = logger.child({ module: 'feed-routes-v2' });\n\nrouter.get('/', authenticateDID, async (req, res) => {\n  try {\n    const { limit, offset, refresh } = req.query;\n\n    const result = await feedService.generateFeed(req.user.userId, {\n      limit: limit ? parseInt(limit.toString()) : undefined,\n      offset: offset ? parseInt(offset.toString()) : undefined,\n      refresh: refresh === 'true',\n    });\n\n    if (!result.success) {\n      return res.status(400).json({ success: false, error: result.error });\n    }\n\n    res.json({\n      success: true,\n      data: {\n        items: result.items,\n        fromCache: result.fromCache,\n        totalCandidates: result.totalCandidates,\n      },\n    });\n  } catch (error) {\n    log.error({ error: error.message }, 'Get feed failed');\n    res.status(500).json({ success: false, error: 'Failed to get feed' });\n  }\n});\n\nrouter.get('/discover', authenticateDID, async (req, res) => {\n  try {\n    const { type, limit } = req.query;\n\n    const result = await feedService.generateDiscovery(req.user.userId, {\n      type: type?.toString(),\n      limit: limit ? parseInt(limit.toString()) : undefined,\n    });\n\n    if (!result.success) {\n      return res.status(400).json({ success: false, error: result.error });\n    }\n\n    res.json({\n      success: true,\n      data: result.recommendations,\n    });\n  } catch (error) {\n    log.error({ error: error.message }, 'Discovery failed');\n    res.status(500).json({ success: false, error: 'Failed to generate recommendations' });\n  }\n});\n\nrouter.get('/explain/:contentId', authenticateDID, async (req, res) => {\n  try {\n    const result = await feedService.explainRecommendation(req.user.userId, req.params.contentId);\n\n    if (!result.success) {\n      return res.status(404).json({ success: false, error: result.error });\n    }\n\n    res.json({\n      success: true,\n      data: result.explanation,\n    });\n  } catch (error) {\n    log.error({ error: error.message }, 'Explain recommendation failed');\n    res.status(500).json({ success: false, error: 'Failed to generate explanation' });\n  }\n});\n\nrouter.get('/preferences', authenticateDID, async (req, res) => {\n  try {\n    const preferences = await feedService.getFeedPreferences(req.user.userId);\n    res.json({ success: true, data: preferences });\n  } catch (error) {\n    log.error({ error: error.message }, 'Get preferences failed');\n    res.status(500).json({ success: false, error: 'Failed to get preferences' });\n  }\n});\n\nrouter.put('/preferences', authenticateDID, async (req, res) => {\n  try {\n    const result = await feedService.updateFeedPreferences(req.user.userId, req.body);\n    if (!result.success) {\n      return res.status(400).json({ success: false, error: result.error });\n    }\n    res.json({ success: true, data: result.preferences });\n  } catch (error) {\n    log.error({ error: error.message }, 'Update preferences failed');\n    res.status(500).json({ success: false, error: 'Failed to update preferences' });\n  }\n});\n\nrouter.post('/interact/:contentId', authenticateDID, async (req, res) => {\n  try {\n    const interactionSchema = z.object({\n      action: z.enum(['view', 'like', 'comment', 'share', 'bookmark', 'dismiss', 'hide']),\n      duration: z.number().optional(),\n      completionRate: z.number().min(0).max(1).optional(),\n    });\n\n    const parsed = interactionSchema.safeParse(req.body);\n    if (!parsed.success) {\n      return res.status(400).json({\n        success: false,\n        error: 'Validation failed',\n        details: parsed.error.errors,\n      });\n    }\n\n    const result = await feedService.trackInteraction(\n      req.user.userId,\n      req.params.contentId,\n      parsed.data.action,\n      {\n        duration: parsed.data.duration,\n        completionRate: parsed.data.completionRate,\n        source: 'feed',\n        timeOfDay: new Date().getHours(),\n      }\n    );\n\n    if (!result.success) {\n      return res.status(400).json({ success: false, error: result.error });\n    }\n\n    await processFeedEngagement({\n      userId: req.user.userId,\n      contentId: req.params.contentId,\n      contentType: 'acu',\n      action: parsed.data.action,\n      metadata: parsed.data,\n    });\n\n    res.json({ success: true });\n  } catch (error) {\n    log.error({ error: error.message }, 'Track interaction failed');\n    res.status(500).json({ success: false, error: 'Failed to track interaction' });\n  }\n});\n\nrouter.get('/contextual', authenticateDID, async (req, res) => {\n  try {\n    const { limit, offset, topics } = req.query;\n\n    const activeTopics = topics ? topics.toString().split(',') : [];\n\n    const result = await feedService.generateContextualFeed(req.user.userId, {\n      limit: limit ? parseInt(limit.toString()) : 20,\n      offset: offset ? parseInt(offset.toString()) : 0,\n      activeTopics,\n    });\n\n    if (!result.success) {\n      return res.status(400).json({ success: false, error: result.error });\n    }\n\n    res.json({\n      success: true,\n      data: result,\n    });\n  } catch (error) {\n    log.error({ error: error.message }, 'Contextual feed failed');\n    res.status(500).json({ success: false, error: 'Failed to get contextual feed' });\n  }\n});\n\nrouter.get('/similar/:conversationId', authenticateDID, async (req, res) => {\n  try {\n    const { limit } = req.query;\n\n    const result = await feedService.getSimilarConversations(\n      req.user.userId,\n      req.params.conversationId,\n      { limit: limit ? parseInt(limit.toString()) : 10 }\n    );\n\n    if (!result.success) {\n      return res.status(400).json({ success: false, error: result.error });\n    }\n\n    res.json({\n      success: true,\n      data: result,\n    });\n  } catch (error) {\n    log.error({ error: error.message }, 'Get similar conversations failed');\n    res.status(500).json({ success: false, error: 'Failed to get similar conversations' });\n  }\n});\n\nrouter.get('/privacy', authenticateDID, async (req, res) => {\n  try {\n    const preferences = await feedService.getFeedPreferences(req.user.userId);\n    const privacy = await feedService.enforcePrivacyBudget(req.user.userId, preferences);\n\n    res.json({\n      success: true,\n      data: {\n        privacyBudget: preferences.privacyBudget,\n        settings: privacy,\n      },\n    });\n  } catch (error) {\n    log.error({ error: error.message }, 'Get privacy settings failed');\n    res.status(500).json({ success: false, error: 'Failed to get privacy settings' });\n  }\n});\n\nexport default router;\n","usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\routes\\feed.js","messages":[{"ruleId":"no-unused-vars","severity":1,"message":"'minQuality' is assigned a value but never used.","line":20,"column":54,"nodeType":"Identifier","messageId":"unusedVar","endLine":20,"endColumn":64,"suggestions":[{"messageId":"removeVar","data":{"varName":"minQuality"},"fix":{"range":[452,468],"text":""},"desc":"Remove unused variable 'minQuality'."}]},{"ruleId":"no-unused-vars","severity":1,"message":"'userId' is assigned a value but never used.","line":22,"column":11,"nodeType":"Identifier","messageId":"unusedVar","endLine":22,"endColumn":17,"suggestions":[{"messageId":"removeVar","data":{"varName":"userId"},"fix":{"range":[489,519],"text":""},"desc":"Remove unused variable 'userId'."}]},{"ruleId":"no-unused-vars","severity":1,"message":"'metadata' is assigned a value but never used.","line":129,"column":26,"nodeType":"Identifier","messageId":"unusedVar","endLine":129,"endColumn":34,"suggestions":[{"messageId":"removeVar","data":{"varName":"metadata"},"fix":{"range":[3460,3470],"text":""},"desc":"Remove unused variable 'metadata'."}]},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":135,"column":3,"nodeType":"MemberExpression","messageId":"limited","endLine":135,"endColumn":14,"suggestions":[{"fix":{"range":[3591,3641],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":4,"fixableErrorCount":0,"fixableWarningCount":0,"source":"import express from 'express';\nimport { getPrismaClient } from '../lib/database.js';\n\nconst router = express.Router();\n\nfunction getUserId(req) {\n  if (req.isAuthenticated() && req.user?.userId) {\n    return req.user.userId;\n  }\n  return req.headers['x-user-id'] || null;\n}\n\n/**\n * GET /api/v1/feed\n *\n * Returns a personalized feed of conversations.\n */\nrouter.get('/', async (req, res) => {\n  try {\n    const { tab = 'for-you', limit = 20, offset = 0, minQuality = 0 } = req.query;\n\n    const userId = getUserId(req);\n    const prisma = getPrismaClient();\n\n    let conversations = [];\n\n    // 1. Fetch conversations based on tab\n    if (tab === 'for-you' || tab === 'following') {\n      conversations = await prisma.conversation.findMany({\n        take: parseInt(limit) * 2, // Fetch more for ranking\n        orderBy: { capturedAt: 'desc' },\n        include: {\n          messages: {\n            orderBy: { messageIndex: 'asc' },\n          },\n        },\n      });\n    } else if (tab === 'bookmarks') {\n      // Logic for bookmarks (placeholder for now)\n      conversations = [];\n    }\n\n    // 2. Score and Filter\n    const scored = conversations.map((conv) => {\n      const score = calculateConversationScore(conv);\n      return {\n        conversation: conv,\n        score,\n        reason: getRecommendationReason(conv),\n      };\n    });\n\n    // 3. Filter by quality if needed\n    const filtered = scored.filter((item) => {\n      // Use messageCount and wordCount as proxy for quality if no specific score exists\n      if (item.conversation.messageCount < 2) {\n        return false;\n      }\n      return true;\n    });\n\n    // 4. Sort and Paginate\n    // Primary sort: Recency (capturedAt)\n    // Secondary sort: Score\n    filtered.sort((a, b) => {\n      const timeA = new Date(a.conversation.capturedAt).getTime();\n      const timeB = new Date(b.conversation.capturedAt).getTime();\n      if (timeB !== timeA) {\n        return timeB - timeA;\n      }\n      return b.score - a.score;\n    });\n\n    const paginated = filtered.slice(parseInt(offset), parseInt(offset) + parseInt(limit));\n\n    const items = paginated.map((item, index) => ({\n      ...item,\n      position: parseInt(offset) + index,\n    }));\n\n    res.json({\n      items,\n      nextOffset: parseInt(offset) + items.length,\n      hasMore: filtered.length > parseInt(offset) + items.length,\n      metadata: {\n        totalCandidates: filtered.length,\n        avgQuality: 0, // Placeholder\n      },\n    });\n  } catch (error) {\n    console.error('Feed error:', error);\n    res.status(500).json({ error: 'Failed to load feed' });\n  }\n});\n\n/**\n * Calculate a recommendation score for a conversation\n */\nfunction calculateConversationScore(conv) {\n  let score = 0;\n\n  // Quality factors\n  score += (conv.messageCount || 0) * 0.5;\n  score += (conv.totalWords || 0) * 0.01;\n  score += (conv.totalCodeBlocks || 0) * 2;\n\n  // Recency bonus (5 days decay)\n  const ageHours = (Date.now() - new Date(conv.capturedAt).getTime()) / (1000 * 60 * 60);\n  const recencyBonus = Math.max(0, 10 - ageHours / 24);\n  score += recencyBonus;\n\n  return score;\n}\n\n/**\n * Generate a human-readable reason for the recommendation\n */\nfunction getRecommendationReason(conv) {\n  if (conv.totalCodeBlocks > 0) {\n    return 'Contains technical implementation';\n  }\n  if (conv.messageCount > 10) {\n    return 'In-depth discussion';\n  }\n  return 'Recent capture';\n}\n\nrouter.post('/engagement', async (req, res) => {\n  const { acuId, action, metadata } = req.body;\n\n  if (!acuId || !action) {\n    return res.status(400).json({ error: 'Missing acuId or action' });\n  }\n\n  console.log(`[ENGAGEMENT] ${action} on ${acuId}`);\n\n  res.json({ success: true });\n});\n\nexport default router;\n","usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\routes\\health.js","messages":[{"ruleId":"no-unused-vars","severity":1,"message":"'e' is defined but never used.","line":22,"column":10,"nodeType":"Identifier","messageId":"unusedVar","endLine":22,"endColumn":11},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":45,"column":3,"nodeType":"MemberExpression","messageId":"limited","endLine":45,"endColumn":14,"suggestions":[{"fix":{"range":[1325,1395],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":46,"column":3,"nodeType":"MemberExpression","messageId":"limited","endLine":46,"endColumn":14,"suggestions":[{"fix":{"range":[1398,1446],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":47,"column":3,"nodeType":"MemberExpression","messageId":"limited","endLine":47,"endColumn":14,"suggestions":[{"fix":{"range":[1449,1497],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":48,"column":3,"nodeType":"MemberExpression","messageId":"limited","endLine":48,"endColumn":14,"suggestions":[{"fix":{"range":[1500,1556],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":49,"column":3,"nodeType":"MemberExpression","messageId":"limited","endLine":49,"endColumn":14,"suggestions":[{"fix":{"range":[1559,1611],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":50,"column":3,"nodeType":"MemberExpression","messageId":"limited","endLine":50,"endColumn":14,"suggestions":[{"fix":{"range":[1614,1675],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":95,"column":3,"nodeType":"MemberExpression","messageId":"limited","endLine":95,"endColumn":14,"suggestions":[{"fix":{"range":[2894,2938],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":96,"column":3,"nodeType":"MemberExpression","messageId":"limited","endLine":96,"endColumn":14,"suggestions":[{"fix":{"range":[2941,2990],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":97,"column":3,"nodeType":"MemberExpression","messageId":"limited","endLine":97,"endColumn":14,"suggestions":[{"fix":{"range":[2993,3040],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":98,"column":3,"nodeType":"MemberExpression","messageId":"limited","endLine":98,"endColumn":14,"suggestions":[{"fix":{"range":[3043,3092],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":99,"column":3,"nodeType":"MemberExpression","messageId":"limited","endLine":99,"endColumn":14,"suggestions":[{"fix":{"range":[3095,3152],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":100,"column":3,"nodeType":"MemberExpression","messageId":"limited","endLine":100,"endColumn":14,"suggestions":[{"fix":{"range":[3155,3231],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":101,"column":3,"nodeType":"MemberExpression","messageId":"limited","endLine":101,"endColumn":14,"suggestions":[{"fix":{"range":[3234,3284],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":102,"column":3,"nodeType":"MemberExpression","messageId":"limited","endLine":102,"endColumn":14,"suggestions":[{"fix":{"range":[3287,3371],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":103,"column":3,"nodeType":"MemberExpression","messageId":"limited","endLine":103,"endColumn":14,"suggestions":[{"fix":{"range":[3374,3468],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":104,"column":3,"nodeType":"MemberExpression","messageId":"limited","endLine":104,"endColumn":14,"suggestions":[{"fix":{"range":[3471,3531],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":105,"column":3,"nodeType":"MemberExpression","messageId":"limited","endLine":105,"endColumn":14,"suggestions":[{"fix":{"range":[3534,3589],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":18,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * Health Check Routes\n *\n * Public health endpoints (no auth, no rate limiting)\n */\n\nimport { Router } from 'express';\nimport { createRequestLogger } from '../lib/logger.js';\nimport { healthResponseSchema } from '../validators/schemas.js';\nimport { checkDatabaseHealth, getDatabaseStats } from '../lib/database.js';\n\nconst router = Router();\n\n// ============================================================================\n// PACKAGE INFO\n// ============================================================================\n\n// Read package.json for version info\nlet packageInfo;\ntry {\n  packageInfo = await import('../../package.json', { with: { type: 'json' } });\n} catch (e) {\n  packageInfo = { default: { version: '2.0.0' } };\n}\n\n// ============================================================================\n// HEALTH CHECK\n// ============================================================================\n\nrouter.get('/', (req, res) => {\n  const log = createRequestLogger(req);\n\n  const healthData = {\n    status: 'ok',\n    service: 'OpenScroll Capture API',\n    version: packageInfo.default.version,\n    timestamp: new Date().toISOString(),\n    uptime: process.uptime(),\n    environment: process.env.NODE_ENV || 'development',\n  };\n\n  // Validate response\n  const validated = healthResponseSchema.parse(healthData);\n\n  console.log(`\\nâœ… [HEALTH CHECK] Service status: ${validated.status}`);\n  console.log(`   Service: ${validated.service}`);\n  console.log(`   Version: ${validated.version}`);\n  console.log(`   Environment: ${validated.environment}`);\n  console.log(`   Timestamp: ${validated.timestamp}`);\n  console.log(`   Uptime: ${Math.round(validated.uptime)}s\\n`);\n\n  log.info({ health: validated }, 'Health check');\n\n  res.json(validated);\n});\n\n// ============================================================================\n// DETAILED HEALTH (WITH DATABASE)\n// ============================================================================\n\nrouter.get('/health/detailed', async (req, res) => {\n  const log = createRequestLogger(req);\n\n  // Check database health\n  const dbHealthy = await checkDatabaseHealth();\n  const dbStats = dbHealthy ? await getDatabaseStats() : null;\n\n  const healthData = {\n    status: dbHealthy ? 'ok' : 'degraded',\n    service: 'OpenScroll Capture API',\n    version: packageInfo.default.version,\n    timestamp: new Date().toISOString(),\n    uptime: process.uptime(),\n    environment: process.env.NODE_ENV || 'development',\n    system: {\n      node: process.version,\n      platform: process.platform,\n      arch: process.arch,\n      memory: {\n        used: process.memoryUsage().heapUsed,\n        total: process.memoryUsage().heapTotal,\n        rss: process.memoryUsage().rss,\n      },\n    },\n    database: dbHealthy\n      ? {\n          status: 'connected',\n          stats: dbStats,\n        }\n      : {\n          status: 'disconnected',\n        },\n  };\n\n  console.log('\\nðŸ” [DETAILED HEALTH CHECK]');\n  console.log(`   Service: ${healthData.service}`);\n  console.log(`   Status: ${healthData.status}`);\n  console.log(`   Version: ${healthData.version}`);\n  console.log(`   Environment: ${healthData.environment}`);\n  console.log(`   Database: ${dbHealthy ? 'âœ… CONNECTED' : 'âŒ DISCONNECTED'}`);\n  console.log(`   Node: ${healthData.system.node}`);\n  console.log(`   Platform: ${healthData.system.platform}/${healthData.system.arch}`);\n  console.log(`   Memory Used: ${(healthData.system.memory.used / 1024 / 1024).toFixed(2)} MB`);\n  console.log(`   Uptime: ${Math.round(healthData.uptime)}s`);\n  console.log(`   Timestamp: ${healthData.timestamp}\\n`);\n\n  log.info({ health: healthData }, 'Detailed health check');\n\n  res.status(dbHealthy ? 200 : 503).json(healthData);\n});\n\n// ============================================================================\n// ADMIN HEALTH CHECK (AUTHENTICATED)\n// ============================================================================\n\nimport { requireApiKey } from '../middleware/auth.js';\n\nrouter.get('/health/admin', requireApiKey(), async (req, res) => {\n  const log = createRequestLogger(req);\n\n  // Check database health\n  const dbHealthy = await checkDatabaseHealth();\n  const dbStats = dbHealthy ? await getDatabaseStats() : null;\n\n  // Get additional admin-level metrics\n  const adminHealthData = {\n    status: dbHealthy ? 'operational' : 'degraded',\n    service: 'OpenScroll Capture API',\n    version: packageInfo.default.version,\n    timestamp: new Date().toISOString(),\n    uptime: process.uptime(),\n    environment: process.env.NODE_ENV || 'development',\n    authenticatedUser: req.auth?.apiKeyPrefix,\n    system: {\n      node: process.version,\n      platform: process.platform,\n      arch: process.arch,\n      pid: process.pid,\n      memory: {\n        used: process.memoryUsage().heapUsed,\n        total: process.memoryUsage().heapTotal,\n        rss: process.memoryUsage().rss,\n      },\n      uptime: process.uptime(),\n      loadAverage: process.platform !== 'win32' ? process.loadavg() : [0, 0, 0],\n    },\n    database: dbHealthy\n      ? {\n          status: 'connected',\n          stats: dbStats,\n        }\n      : {\n          status: 'disconnected',\n        },\n    security: {\n      corsOrigins: process.env.CORS_ORIGINS?.split(',').length || 0,\n      rateLimit: process.env.RATE_LIMIT_MAX || 100,\n      sslEnabled: process.env.DATABASE_SSL_REQUIRED === 'true',\n    },\n  };\n\n  log.info(\n    {\n      health: adminHealthData.status,\n      user: req.auth?.apiKeyPrefix,\n    },\n    'Admin health check'\n  );\n\n  res.status(dbHealthy ? 200 : 503).json(adminHealthData);\n});\n\n// ============================================================================\n// CAPABILITIES\n// ============================================================================\n\nrouter.get('/capabilities', (req, res) => {\n  res.json({\n    aiActions: true,\n    sharing: true,\n    circles: true,\n    offlineQueue: true,\n    semanticSearch: true,\n    lineage: true,\n  });\n});\n\nexport { router as healthRouter };\n","usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\routes\\identity-v2.js","messages":[{"ruleId":"no-unused-vars","severity":1,"message":"'requireVerification' is defined but never used.","line":11,"column":41,"nodeType":"Identifier","messageId":"unusedVar","endLine":11,"endColumn":60,"suggestions":[{"messageId":"removeVar","data":{"varName":"requireVerification"},"fix":{"range":[273,294],"text":""},"desc":"Remove unused variable 'requireVerification'."}]}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * Identity API Routes v2\n *\n * Complete REST API for identity management\n * Base: /api/v2/identity\n */\n\nimport { Router } from 'express';\nimport { z } from 'zod';\nimport { identityService } from '../services/identity-service.js';\nimport { authenticateDID, optionalAuth, requireVerification } from '../middleware/auth.js';\nimport { getPrismaClient } from '../lib/database.js';\nimport { logger } from '../lib/logger.js';\nimport { debugReporter } from '../services/debug-reporter.js';\n\nconst router = Router();\nconst log = logger.child({ module: 'identity-routes-v2' });\n\n// ============================================================================\n// Validation Schemas\n// ============================================================================\n\nconst registerUserSchema = z.object({\n  did: z.string().startsWith('did:key:z'),\n  publicKey: z.string(),\n  handle: z\n    .string()\n    .min(3)\n    .max(30)\n    .regex(/^[a-zA-Z0-9_]+$/)\n    .optional(),\n  displayName: z.string().min(1).max(100).optional(),\n  email: z.string().email().optional(),\n  avatarUrl: z.string().url().optional(),\n});\n\nconst registerDeviceSchema = z.object({\n  masterDID: z.string().startsWith('did:key:z'),\n  deviceId: z.string().uuid(),\n  deviceDID: z.string().startsWith('did:key:z'),\n  name: z.string().min(1).max(100),\n  platform: z.enum(['web', 'ios', 'android', 'desktop']),\n  publicKey: z.string(),\n  capabilities: z.object({\n    canSign: z.boolean(),\n    canEncrypt: z.boolean(),\n    hasBiometrics: z.boolean(),\n    hasSecureEnclave: z.boolean(),\n  }),\n  delegationProof: z.string(),\n});\n\nconst verifyEmailSchema = z.object({\n  email: z.string().email(),\n});\n\nconst completeVerificationSchema = z.object({\n  email: z.string().email(),\n  code: z.string().length(6),\n});\n\nconst verifyPhoneSchema = z.object({\n  phoneNumber: z.string().min(6).max(15),\n  countryCode: z.string().length(2),\n});\n\n// ============================================================================\n// User Registration & Profile\n// ============================================================================\n\n/**\n * POST /api/v2/identity/users/register\n * Register a new user with DID\n */\nrouter.post('/users/register', async (req, res) => {\n  try {\n    const parsed = registerUserSchema.safeParse(req.body);\n    if (!parsed.success) {\n      return res.status(400).json({\n        success: false,\n        error: 'Validation failed',\n        details: parsed.error.errors,\n      });\n    }\n\n    const result = await identityService.registerUser(\n      parsed.data.did,\n      parsed.data.publicKey,\n      parsed.data.handle,\n      {\n        email: parsed.data.email,\n        displayName: parsed.data.displayName,\n        avatarUrl: parsed.data.avatarUrl,\n      }\n    );\n\n    if (!result.success) {\n      return res.status(409).json({\n        success: false,\n        error: result.error,\n      });\n    }\n\n    res.status(201).json({\n      success: true,\n      data: {\n        userId: result.user.id,\n        did: result.user.did,\n        handle: result.user.handle,\n        verificationLevel: result.user.verificationLevel,\n        createdAt: result.user.createdAt,\n      },\n    });\n  } catch (error) {\n    log.error({ error: error.message }, 'User registration failed');\n    res.status(500).json({\n      success: false,\n      error: 'Registration failed',\n    });\n  }\n});\n\n/**\n * GET /api/v2/identity/users/:did\n * Get user profile by DID\n */\nrouter.get('/users/:did', optionalAuth, async (req, res) => {\n  try {\n    const { did } = req.params;\n\n    if (!identityService.validateDID(did)) {\n      return res.status(400).json({\n        success: false,\n        error: 'Invalid DID format',\n      });\n    }\n\n    const prisma = getPrismaClient();\n    const user = await prisma.user.findUnique({\n      where: { did },\n      select: {\n        id: true,\n        did: true,\n        handle: true,\n        displayName: true,\n        avatarUrl: true,\n        verificationLevel: true,\n        verificationBadges: true,\n        trustScore: true,\n        createdAt: true,\n        // Only show email/phone to self\n        ...(req.user?.did === did && {\n          email: true,\n          emailVerified: true,\n          phoneNumber: true,\n          phoneVerified: true,\n        }),\n      },\n    });\n\n    if (!user) {\n      return res.status(404).json({\n        success: false,\n        error: 'User not found',\n      });\n    }\n\n    // Log access\n    await identityService.logAccess(\n      req.user?.did || 'anonymous',\n      user.id,\n      'profile',\n      'view',\n      true,\n      {\n        ipAddress: req.ip,\n        userAgent: req.get('user-agent'),\n      }\n    );\n\n    res.json({\n      success: true,\n      data: user,\n    });\n  } catch (error) {\n    log.error({ did: req.params.did, error: error.message }, 'Get user failed');\n    res.status(500).json({\n      success: false,\n      error: 'Failed to get user',\n    });\n  }\n});\n\n/**\n * PUT /api/v2/identity/users/:did\n * Update user profile (requires auth)\n */\nrouter.put('/users/:did', authenticateDID, async (req, res) => {\n  try {\n    const { did } = req.params;\n\n    // Can only update own profile\n    if (req.user.did !== did) {\n      return res.status(403).json({\n        success: false,\n        error: 'Can only update your own profile',\n      });\n    }\n\n    const updateSchema = z.object({\n      displayName: z.string().min(1).max(100).optional(),\n      avatarUrl: z.string().url().optional(),\n      privacyPreferences: z.record(z.any()).optional(),\n    });\n\n    const parsed = updateSchema.safeParse(req.body);\n    if (!parsed.success) {\n      return res.status(400).json({\n        success: false,\n        error: 'Validation failed',\n        details: parsed.error.errors,\n      });\n    }\n\n    const prisma = getPrismaClient();\n    const user = await prisma.user.update({\n      where: { did },\n      data: parsed.data,\n    });\n\n    res.json({\n      success: true,\n      data: {\n        did: user.did,\n        displayName: user.displayName,\n        avatarUrl: user.avatarUrl,\n        updatedAt: user.updatedAt,\n      },\n    });\n  } catch (error) {\n    log.error({ did: req.params.did, error: error.message }, 'Update user failed');\n    res.status(500).json({\n      success: false,\n      error: 'Failed to update profile',\n    });\n  }\n});\n\n// ============================================================================\n// Device Management\n// ============================================================================\n\n/**\n * POST /api/v2/identity/devices\n * Register a new device\n */\nrouter.post('/devices', async (req, res) => {\n  try {\n    const parsed = registerDeviceSchema.safeParse(req.body);\n    if (!parsed.success) {\n      return res.status(400).json({\n        success: false,\n        error: 'Validation failed',\n        details: parsed.error.errors,\n      });\n    }\n\n    const result = await identityService.registerDevice(parsed.data.masterDID, parsed.data);\n\n    if (!result.success) {\n      return res.status(400).json({\n        success: false,\n        error: result.error,\n      });\n    }\n\n    res.status(201).json({\n      success: true,\n      data: {\n        deviceId: result.device.deviceId,\n        name: result.device.deviceName,\n        platform: result.device.platform,\n        registeredAt: result.device.createdAt,\n      },\n    });\n  } catch (error) {\n    log.error({ error: error.message }, 'Device registration failed');\n    res.status(500).json({\n      success: false,\n      error: 'Device registration failed',\n    });\n  }\n});\n\n/**\n * GET /api/v2/identity/devices\n * Get user's devices (requires auth)\n */\nrouter.get('/devices', authenticateDID, async (req, res) => {\n  try {\n    const devices = await identityService.getUserDevices(req.user.userId);\n\n    res.json({\n      success: true,\n      data: devices.map((d) => ({\n        deviceId: d.deviceId,\n        name: d.deviceName,\n        platform: d.platform,\n        isActive: d.isActive,\n        isTrusted: d.isTrusted,\n        lastSeenAt: d.lastSeenAt,\n        capabilities: d.metadata?.capabilities,\n      })),\n    });\n  } catch (error) {\n    log.error({ userId: req.user.userId, error: error.message }, 'Get devices failed');\n    res.status(500).json({\n      success: false,\n      error: 'Failed to get devices',\n    });\n  }\n});\n\n/**\n * DELETE /api/v2/identity/devices/:deviceId\n * Revoke a device (requires auth)\n */\nrouter.delete('/devices/:deviceId', authenticateDID, async (req, res) => {\n  try {\n    const { deviceId } = req.params;\n    const { reason } = req.body;\n\n    const success = await identityService.revokeDevice(req.user.userId, deviceId, reason);\n\n    if (!success) {\n      return res.status(404).json({\n        success: false,\n        error: 'Device not found',\n      });\n    }\n\n    res.json({\n      success: true,\n      message: 'Device revoked successfully',\n    });\n  } catch (error) {\n    log.error({ deviceId: req.params.deviceId, error: error.message }, 'Revoke device failed');\n    res.status(500).json({\n      success: false,\n      error: 'Failed to revoke device',\n    });\n  }\n});\n\n// ============================================================================\n// Verification Flows\n// ============================================================================\n\n/**\n * POST /api/v2/identity/verify/email\n * Initiate email verification\n */\nrouter.post('/verify/email', authenticateDID, async (req, res) => {\n  try {\n    const parsed = verifyEmailSchema.safeParse(req.body);\n    if (!parsed.success) {\n      return res.status(400).json({\n        success: false,\n        error: 'Validation failed',\n        details: parsed.error.errors,\n      });\n    }\n\n    const result = await identityService.initiateEmailVerification(\n      req.user.userId,\n      parsed.data.email\n    );\n\n    if (!result.success) {\n      return res.status(400).json({\n        success: false,\n        error: result.error,\n      });\n    }\n\n    res.json({\n      success: true,\n      message: 'Verification email sent',\n      // Only return code in development\n      ...(process.env.NODE_ENV === 'development' && { code: result.code }),\n    });\n  } catch (error) {\n    debugReporter.trackError(error, {\n      operation: 'initiateEmailVerification',\n      userId: req.user?.userId,\n    });\n    log.error(\n      { userId: req.user.userId, error: error.message },\n      'Email verification initiation failed'\n    );\n    res.status(500).json({\n      success: false,\n      error: 'Failed to initiate verification',\n    });\n  }\n});\n\n/**\n * POST /api/v2/identity/verify/email/complete\n * Complete email verification\n */\nrouter.post('/verify/email/complete', authenticateDID, async (req, res) => {\n  try {\n    const parsed = completeVerificationSchema.safeParse(req.body);\n    if (!parsed.success) {\n      return res.status(400).json({\n        success: false,\n        error: 'Validation failed',\n        details: parsed.error.errors,\n      });\n    }\n\n    const success = await identityService.completeEmailVerification(\n      req.user.userId,\n      parsed.data.email,\n      parsed.data.code\n    );\n\n    if (!success) {\n      return res.status(400).json({\n        success: false,\n        error: 'Invalid or expired code',\n      });\n    }\n\n    res.json({\n      success: true,\n      message: 'Email verified successfully',\n    });\n  } catch (error) {\n    log.error(\n      { userId: req.user.userId, error: error.message },\n      'Email verification completion failed'\n    );\n    res.status(500).json({\n      success: false,\n      error: 'Failed to complete verification',\n    });\n  }\n});\n\n/**\n * POST /api/v2/identity/verify/phone\n * Initiate phone verification\n */\nrouter.post('/verify/phone', authenticateDID, async (req, res) => {\n  try {\n    const parsed = verifyPhoneSchema.safeParse(req.body);\n    if (!parsed.success) {\n      return res.status(400).json({\n        success: false,\n        error: 'Validation failed',\n        details: parsed.error.errors,\n      });\n    }\n\n    const result = await identityService.initiatePhoneVerification(\n      req.user.userId,\n      `${parsed.data.countryCode}${parsed.data.phoneNumber}`\n    );\n\n    if (!result.success) {\n      return res.status(400).json({\n        success: false,\n        error: result.error,\n      });\n    }\n\n    res.json({\n      success: true,\n      message: 'Verification SMS sent',\n      ...(process.env.NODE_ENV === 'development' && { code: result.code }),\n    });\n  } catch (error) {\n    log.error(\n      { userId: req.user.userId, error: error.message },\n      'Phone verification initiation failed'\n    );\n    res.status(500).json({\n      success: false,\n      error: 'Failed to initiate verification',\n    });\n  }\n});\n\n// ============================================================================\n// Transparency & Audit\n// ============================================================================\n\n/**\n * GET /api/v2/identity/transparency/access-log\n * Get access audit log for authenticated user\n */\nrouter.get('/transparency/access-log', authenticateDID, async (req, res) => {\n  try {\n    const { targetType, action, limit = 100, offset = 0 } = req.query;\n\n    const logs = await identityService.getAccessAuditLog(req.user.userId, {\n      targetType: targetType?.toString(),\n      action: action?.toString(),\n      limit: parseInt(limit.toString()),\n      offset: parseInt(offset.toString()),\n    });\n\n    res.json({\n      success: true,\n      data: logs,\n      pagination: {\n        limit: parseInt(limit.toString()),\n        offset: parseInt(offset.toString()),\n        total: logs.length,\n      },\n    });\n  } catch (error) {\n    log.error({ userId: req.user.userId, error: error.message }, 'Get access log failed');\n    res.status(500).json({\n      success: false,\n      error: 'Failed to get access log',\n    });\n  }\n});\n\n/**\n * GET /api/v2/identity/consents\n * Get user's consent records\n */\nrouter.get('/consents', authenticateDID, async (req, res) => {\n  try {\n    const prisma = getPrismaClient();\n    const consents = await prisma.consentRecord.findMany({\n      where: {\n        userId: req.user.userId,\n        status: 'active',\n      },\n      orderBy: { grantedAt: 'desc' },\n    });\n\n    res.json({\n      success: true,\n      data: consents,\n    });\n  } catch (error) {\n    log.error({ userId: req.user.userId, error: error.message }, 'Get consents failed');\n    res.status(500).json({\n      success: false,\n      error: 'Failed to get consents',\n    });\n  }\n});\n\n/**\n * POST /api/v2/identity/consents\n * Record user consent\n */\nrouter.post('/consents', authenticateDID, async (req, res) => {\n  try {\n    const consentSchema = z.object({\n      purpose: z.string(),\n      allowed: z.boolean(),\n      dataTypes: z.array(z.string()).optional(),\n      conditions: z.record(z.any()).optional(),\n      expiresAt: z.string().datetime().optional(),\n    });\n\n    const parsed = consentSchema.safeParse(req.body);\n    if (!parsed.success) {\n      return res.status(400).json({\n        success: false,\n        error: 'Validation failed',\n        details: parsed.error.errors,\n      });\n    }\n\n    const consent = await identityService.recordConsent(\n      req.user.userId,\n      parsed.data.purpose,\n      parsed.data.allowed,\n      {\n        dataTypes: parsed.data.dataTypes,\n        conditions: parsed.data.conditions,\n        expiresAt: parsed.data.expiresAt ? new Date(parsed.data.expiresAt) : undefined,\n      }\n    );\n\n    res.status(201).json({\n      success: true,\n      data: consent,\n    });\n  } catch (error) {\n    log.error({ userId: req.user.userId, error: error.message }, 'Record consent failed');\n    res.status(500).json({\n      success: false,\n      error: 'Failed to record consent',\n    });\n  }\n});\n\n/**\n * DELETE /api/v2/identity/consents/:consentId\n * Revoke consent\n */\nrouter.delete('/consents/:consentId', authenticateDID, async (req, res) => {\n  try {\n    const { consentId } = req.params;\n    const prisma = getPrismaClient();\n\n    const consent = await prisma.consentRecord.findFirst({\n      where: {\n        id: consentId,\n        userId: req.user.userId,\n      },\n    });\n\n    if (!consent) {\n      return res.status(404).json({\n        success: false,\n        error: 'Consent not found',\n      });\n    }\n\n    await prisma.consentRecord.update({\n      where: { id: consentId },\n      data: {\n        status: 'revoked',\n        revokedAt: new Date(),\n      },\n    });\n\n    res.json({\n      success: true,\n      message: 'Consent revoked',\n    });\n  } catch (error) {\n    log.error({ consentId: req.params.consentId, error: error.message }, 'Revoke consent failed');\n    res.status(500).json({\n      success: false,\n      error: 'Failed to revoke consent',\n    });\n  }\n});\n\n// ============================================================================\n// DID Resolution (Public)\n// ============================================================================\n\n/**\n * GET /api/v2/identity/did/:did\n * Resolve a DID to its document (public endpoint)\n */\nrouter.get('/did/:did', async (req, res) => {\n  try {\n    const { did } = req.params;\n\n    const didDocument = await identityService.resolveDID(did);\n\n    if (!didDocument) {\n      return res.status(404).json({\n        success: false,\n        error: 'DID not found or invalid',\n      });\n    }\n\n    res.json({\n      success: true,\n      data: didDocument,\n    });\n  } catch (error) {\n    log.error({ did: req.params.did, error: error.message }, 'DID resolution failed');\n    res.status(500).json({\n      success: false,\n      error: 'Failed to resolve DID',\n    });\n  }\n});\n\nexport default router;\n","usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\routes\\identity.js","messages":[{"ruleId":"no-unused-vars","severity":1,"message":"'getPrismaClient' is defined but never used.","line":14,"column":10,"nodeType":"Identifier","messageId":"unusedVar","endLine":14,"endColumn":25,"suggestions":[{"messageId":"removeVar","data":{"varName":"getPrismaClient"},"fix":{"range":[337,390],"text":""},"desc":"Remove unused variable 'getPrismaClient'."}]}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * Identity API Routes\n *\n * Backend endpoints for secure P2P identity management:\n * - Device registration and sync\n * - KYC verification integrations\n * - Identity relay (for device-to-device messaging)\n * - Verification credential issuance\n */\n\nimport express from 'express';\nimport { z } from 'zod';\nimport crypto from 'crypto';\nimport { getPrismaClient } from '../lib/database.js';\nimport logger from '../lib/logger.js';\n\nconst router = express.Router();\nconst log = logger.child({ module: 'identity' });\n\n// ============================================================================\n// Schemas\n// ============================================================================\n\nconst registerDeviceSchema = z.object({\n  masterDID: z.string().startsWith('did:'),\n  deviceId: z.string().uuid(),\n  deviceDID: z.string().startsWith('did:'),\n  name: z.string().min(1).max(100),\n  platform: z.enum(['web', 'ios', 'android', 'desktop']),\n  publicKey: z.string(),\n  delegationProof: z.string(),\n  capabilities: z.object({\n    canSign: z.boolean(),\n    canEncrypt: z.boolean(),\n    hasBiometrics: z.boolean(),\n    hasSecureEnclave: z.boolean(),\n  }),\n});\n\nconst verifyEmailSchema = z.object({\n  email: z.string().email(),\n  did: z.string().startsWith('did:'),\n});\n\nconst completeEmailSchema = z.object({\n  email: z.string().email(),\n  code: z.string().length(6),\n  did: z.string().startsWith('did:'),\n});\n\nconst verifyPhoneSchema = z.object({\n  phoneNumber: z.string().min(6).max(15),\n  countryCode: z.string().length(2),\n  did: z.string().startsWith('did:'),\n});\n\n// ============================================================================\n// In-memory stores (production would use database)\n// ============================================================================\n\nconst verificationCodes = new Map(); // email/phone -> { code, did, expiresAt }\nconst registeredDevices = new Map(); // masterDID -> Device[]\nconst issuedCredentials = new Map(); // did -> Credential[]\n\n// ============================================================================\n// Device Management Endpoints\n// ============================================================================\n\n/**\n * POST /api/v1/identity/devices/register\n * Register a new device for a DID\n */\nrouter.post('/devices/register', async (req, res) => {\n  try {\n    const body = registerDeviceSchema.parse(req.body);\n\n    // Verify delegation proof\n    // In production: Actually verify the signature\n    const isValidDelegation = body.delegationProof.length > 0;\n    if (!isValidDelegation) {\n      return res.status(400).json({\n        success: false,\n        error: 'Invalid delegation proof',\n      });\n    }\n\n    // Store device registration\n    const devices = registeredDevices.get(body.masterDID) || [];\n    devices.push({\n      ...body,\n      registeredAt: new Date().toISOString(),\n      lastActiveAt: new Date().toISOString(),\n      status: 'active',\n    });\n    registeredDevices.set(body.masterDID, devices);\n\n    log.info({ masterDID: body.masterDID, deviceId: body.deviceId }, 'Device registered');\n\n    res.json({\n      success: true,\n      data: {\n        deviceId: body.deviceId,\n        registeredAt: new Date().toISOString(),\n      },\n    });\n  } catch (error) {\n    log.error({ error }, 'Device registration failed');\n    res.status(400).json({\n      success: false,\n      error:\n        error instanceof z.ZodError\n          ? error.errors.map((e) => e.message).join(', ')\n          : 'Registration failed',\n    });\n  }\n});\n\n/**\n * GET /api/v1/identity/devices\n * Get all devices for authenticated DID\n */\nrouter.get('/devices', async (req, res) => {\n  try {\n    const did = req.headers['x-did'];\n    if (!did) {\n      return res.status(401).json({\n        success: false,\n        error: 'DID required in X-DID header',\n      });\n    }\n\n    const devices = registeredDevices.get(did) || [];\n\n    res.json({\n      success: true,\n      data: devices.map((d) => ({\n        deviceId: d.deviceId,\n        name: d.name,\n        platform: d.platform,\n        registeredAt: d.registeredAt,\n        lastActiveAt: d.lastActiveAt,\n        status: d.status,\n      })),\n    });\n  } catch (error) {\n    log.error({ error }, 'Get devices failed');\n    res.status(500).json({ success: false, error: 'Failed to get devices' });\n  }\n});\n\n/**\n * DELETE /api/v1/identity/devices/:deviceId\n * Revoke a device\n */\nrouter.delete('/devices/:deviceId', async (req, res) => {\n  try {\n    const did = req.headers['x-did'];\n    const { deviceId } = req.params;\n\n    if (!did) {\n      return res.status(401).json({\n        success: false,\n        error: 'DID required in X-DID header',\n      });\n    }\n\n    const devices = registeredDevices.get(did) || [];\n    const device = devices.find((d) => d.deviceId === deviceId);\n\n    if (!device) {\n      return res.status(404).json({\n        success: false,\n        error: 'Device not found',\n      });\n    }\n\n    device.status = 'revoked';\n    log.info({ did, deviceId }, 'Device revoked');\n\n    res.json({\n      success: true,\n      message: 'Device revoked',\n    });\n  } catch (error) {\n    log.error({ error }, 'Device revocation failed');\n    res.status(500).json({ success: false, error: 'Revocation failed' });\n  }\n});\n\n// ============================================================================\n// Email Verification Endpoints\n// ============================================================================\n\n/**\n * POST /api/v1/identity/verify/email/start\n * Start email verification\n */\nrouter.post('/verify/email/start', async (req, res) => {\n  try {\n    const { email, did } = verifyEmailSchema.parse(req.body);\n\n    // Generate 6-digit code\n    const code = crypto.randomInt(100000, 999999).toString();\n\n    // Store with 10 minute expiry\n    const emailHash = crypto.createHash('sha256').update(email.toLowerCase()).digest('hex');\n    verificationCodes.set(emailHash, {\n      code,\n      did,\n      expiresAt: Date.now() + 10 * 60 * 1000,\n    });\n\n    // In production: Send actual email via SendGrid, AWS SES, etc.\n    log.info({ emailHash: emailHash.slice(0, 16), did }, 'Email verification started');\n\n    // For development: Log the code\n    if (process.env.NODE_ENV !== 'production') {\n      log.debug({ code }, 'Verification code (dev only)');\n    }\n\n    res.json({\n      success: true,\n      message: 'Verification code sent',\n      expiresIn: 600, // seconds\n    });\n  } catch (error) {\n    log.error({ error }, 'Email verification start failed');\n    res.status(400).json({\n      success: false,\n      error:\n        error instanceof z.ZodError\n          ? error.errors.map((e) => e.message).join(', ')\n          : 'Failed to start verification',\n    });\n  }\n});\n\n/**\n * POST /api/v1/identity/verify/email/complete\n * Complete email verification\n */\nrouter.post('/verify/email/complete', async (req, res) => {\n  try {\n    const { email, code, did } = completeEmailSchema.parse(req.body);\n\n    const emailHash = crypto.createHash('sha256').update(email.toLowerCase()).digest('hex');\n    const stored = verificationCodes.get(emailHash);\n\n    if (!stored) {\n      return res.status(400).json({\n        success: false,\n        error: 'No verification pending for this email',\n      });\n    }\n\n    if (stored.expiresAt < Date.now()) {\n      verificationCodes.delete(emailHash);\n      return res.status(400).json({\n        success: false,\n        error: 'Verification code expired',\n      });\n    }\n\n    if (stored.code !== code) {\n      return res.status(400).json({\n        success: false,\n        error: 'Invalid verification code',\n      });\n    }\n\n    if (stored.did !== did) {\n      return res.status(400).json({\n        success: false,\n        error: 'DID mismatch',\n      });\n    }\n\n    // Clean up\n    verificationCodes.delete(emailHash);\n\n    // Issue credential\n    const credential = {\n      id: crypto.randomUUID(),\n      type: 'email',\n      tier: 1,\n      issuedAt: new Date().toISOString(),\n      expiresAt: new Date(Date.now() + 365 * 24 * 60 * 60 * 1000).toISOString(), // 1 year\n      proof: emailHash,\n      nullifier: crypto.createHash('sha256').update(`email:${emailHash}:verified`).digest('hex'),\n      issuerDID: 'did:key:openscroll-server',\n      issuerName: 'OpenScroll Verification Service',\n      status: 'valid',\n    };\n\n    // Store credential\n    const credentials = issuedCredentials.get(did) || [];\n    credentials.push(credential);\n    issuedCredentials.set(did, credentials);\n\n    log.info({ did, credentialId: credential.id }, 'Email verification completed');\n\n    res.json({\n      success: true,\n      credential,\n    });\n  } catch (error) {\n    log.error({ error }, 'Email verification complete failed');\n    res.status(400).json({\n      success: false,\n      error: 'Verification failed',\n    });\n  }\n});\n\n// ============================================================================\n// Phone Verification Endpoints\n// ============================================================================\n\n/**\n * POST /api/v1/identity/verify/phone/start\n * Start phone verification\n */\nrouter.post('/verify/phone/start', async (req, res) => {\n  try {\n    const { phoneNumber, countryCode, did } = verifyPhoneSchema.parse(req.body);\n\n    const fullNumber = `+${countryCode}${phoneNumber.replace(/\\D/g, '')}`;\n    const code = crypto.randomInt(100000, 999999).toString();\n\n    const phoneHash = crypto.createHash('sha256').update(fullNumber).digest('hex');\n    verificationCodes.set(phoneHash, {\n      code,\n      did,\n      expiresAt: Date.now() + 5 * 60 * 1000, // 5 minutes for SMS\n    });\n\n    // In production: Send SMS via Twilio, AWS SNS, etc.\n    log.info({ phoneHash: phoneHash.slice(0, 16), did }, 'Phone verification started');\n\n    if (process.env.NODE_ENV !== 'production') {\n      log.debug({ code }, 'SMS code (dev only)');\n    }\n\n    res.json({\n      success: true,\n      message: 'SMS code sent',\n      expiresIn: 300,\n    });\n  } catch (error) {\n    log.error({ error }, 'Phone verification start failed');\n    res.status(400).json({\n      success: false,\n      error: 'Failed to start phone verification',\n    });\n  }\n});\n\n// ============================================================================\n// Credential Endpoints\n// ============================================================================\n\n/**\n * GET /api/v1/identity/credentials\n * Get all credentials for a DID\n */\nrouter.get('/credentials', async (req, res) => {\n  try {\n    const did = req.headers['x-did'];\n    if (!did) {\n      return res.status(401).json({\n        success: false,\n        error: 'DID required in X-DID header',\n      });\n    }\n\n    const credentials = issuedCredentials.get(did) || [];\n\n    res.json({\n      success: true,\n      data: credentials.filter((c) => c.status === 'valid'),\n      tier: Math.max(0, ...credentials.filter((c) => c.status === 'valid').map((c) => c.tier)),\n    });\n  } catch (error) {\n    log.error({ error }, 'Get credentials failed');\n    res.status(500).json({ success: false, error: 'Failed to get credentials' });\n  }\n});\n\n/**\n * POST /api/v1/identity/credentials/verify\n * Verify a credential\n */\nrouter.post('/credentials/verify', async (req, res) => {\n  try {\n    const { credentialId, did } = req.body;\n\n    const credentials = issuedCredentials.get(did) || [];\n    const credential = credentials.find((c) => c.id === credentialId);\n\n    if (!credential) {\n      return res.json({\n        success: true,\n        valid: false,\n        reason: 'Credential not found',\n      });\n    }\n\n    // Check expiration\n    if (credential.expiresAt && new Date(credential.expiresAt) < new Date()) {\n      return res.json({\n        success: true,\n        valid: false,\n        reason: 'Credential expired',\n      });\n    }\n\n    // Check revocation\n    if (credential.status === 'revoked') {\n      return res.json({\n        success: true,\n        valid: false,\n        reason: 'Credential revoked',\n      });\n    }\n\n    res.json({\n      success: true,\n      valid: true,\n      credential: {\n        type: credential.type,\n        tier: credential.tier,\n        issuedAt: credential.issuedAt,\n        issuerName: credential.issuerName,\n      },\n    });\n  } catch (error) {\n    log.error({ error }, 'Credential verification failed');\n    res.status(500).json({ success: false, error: 'Verification failed' });\n  }\n});\n\n/**\n * DELETE /api/v1/identity/credentials/:credentialId\n * Revoke a credential\n */\nrouter.delete('/credentials/:credentialId', async (req, res) => {\n  try {\n    const did = req.headers['x-did'];\n    const { credentialId } = req.params;\n\n    if (!did) {\n      return res.status(401).json({\n        success: false,\n        error: 'DID required',\n      });\n    }\n\n    const credentials = issuedCredentials.get(did) || [];\n    const credential = credentials.find((c) => c.id === credentialId);\n\n    if (!credential) {\n      return res.status(404).json({\n        success: false,\n        error: 'Credential not found',\n      });\n    }\n\n    credential.status = 'revoked';\n    log.info({ did, credentialId }, 'Credential revoked');\n\n    res.json({\n      success: true,\n      message: 'Credential revoked',\n    });\n  } catch (error) {\n    log.error({ error }, 'Credential revocation failed');\n    res.status(500).json({ success: false, error: 'Revocation failed' });\n  }\n});\n\n// ============================================================================\n// GDPR/Privacy Endpoints\n// ============================================================================\n\n/**\n * GET /api/v1/identity/data-export\n * Export all user data (GDPR Article 20)\n */\nrouter.get('/data-export', async (req, res) => {\n  try {\n    const did = req.headers['x-did'];\n    if (!did) {\n      return res.status(401).json({\n        success: false,\n        error: 'DID required',\n      });\n    }\n\n    const devices = registeredDevices.get(did) || [];\n    const credentials = (issuedCredentials.get(did) || []).map((c) => ({\n      ...c,\n      proof: '[REDACTED]',\n      nullifier: '[REDACTED]',\n    }));\n\n    const exportData = {\n      exportedAt: new Date().toISOString(),\n      did,\n      devices: devices.map((d) => ({\n        deviceId: d.deviceId,\n        name: d.name,\n        platform: d.platform,\n        registeredAt: d.registeredAt,\n        status: d.status,\n      })),\n      credentials,\n      verificationTier: Math.max(0, ...credentials.map((c) => c.tier)),\n    };\n\n    res.json({\n      success: true,\n      data: exportData,\n    });\n  } catch (error) {\n    log.error({ error }, 'Data export failed');\n    res.status(500).json({ success: false, error: 'Export failed' });\n  }\n});\n\n/**\n * DELETE /api/v1/identity/data-erasure\n * Delete all user data (GDPR Article 17)\n */\nrouter.delete('/data-erasure', async (req, res) => {\n  try {\n    const did = req.headers['x-did'];\n    if (!did) {\n      return res.status(401).json({\n        success: false,\n        error: 'DID required',\n      });\n    }\n\n    // Delete all data\n    registeredDevices.delete(did);\n    issuedCredentials.delete(did);\n\n    // Clean up any pending verifications\n    for (const [key, value] of verificationCodes.entries()) {\n      if (value.did === did) {\n        verificationCodes.delete(key);\n      }\n    }\n\n    log.info({ did }, 'All user data erased');\n\n    res.json({\n      success: true,\n      message: 'All data erased successfully',\n    });\n  } catch (error) {\n    log.error({ error }, 'Data erasure failed');\n    res.status(500).json({ success: false, error: 'Erasure failed' });\n  }\n});\n\nexport default router;\n","usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\routes\\logs.js","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\routes\\memory-search.js","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\routes\\moderation.js","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\routes\\monitoring.js","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\routes\\omni.js","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\routes\\portability.js","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\routes\\sharing.js","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\routes\\sync.js","messages":[{"ruleId":"no-unused-vars","severity":1,"message":"'log' is assigned a value but never used.","line":42,"column":9,"nodeType":"Identifier","messageId":"unusedVar","endLine":42,"endColumn":12,"suggestions":[{"messageId":"removeVar","data":{"varName":"log"},"fix":{"range":[1330,1367],"text":""},"desc":"Remove unused variable 'log'."}]}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * Sync Controller\n *\n * Handles delta-synchronization between clients and server.\n * Uses Hybrid Logical Clocks (HLC) and Vector Clocks for consistency.\n */\n\nimport { Router } from 'express';\nimport { requireApiKey } from '../middleware/auth.js';\nimport { createRequestLogger } from '../lib/logger.js';\nimport { getPrismaClient } from '../lib/database.js';\nimport { z } from 'zod';\n\nconst router = Router();\nconst prisma = getPrismaClient();\n\n// ============================================================================\n// Schema Validation\n// ============================================================================\n\nconst SyncPacketSchema = z.object({\n  deviceId: z.string(),\n  lastSyncId: z.string().optional(), // Cursor\n  operations: z.array(\n    z.object({\n      id: z.string(),\n      entityType: z.string(), // 'conversation', 'message', 'acu'\n      entityId: z.string(),\n      operation: z.enum(['INSERT', 'UPDATE', 'DELETE']),\n      payload: z.any(),\n      hlcTimestamp: z.string(),\n      vectorClock: z.record(z.number()).optional(),\n    })\n  ),\n});\n\n// ============================================================================\n// PULL CHANGES (Downstream)\n// ============================================================================\n\nrouter.get('/pull', requireApiKey(), async (req, res, next) => {\n  const log = createRequestLogger(req);\n  try {\n    const { deviceId, lastSyncId, limit = 100 } = req.query;\n\n    if (!deviceId) {\n      return res.status(400).json({ error: 'deviceId required' });\n    }\n\n    // Fetch operations since the last known sync ID (cursor)\n    // Ordered by HLC timestamp to ensure causal consistency\n    const operations = await prisma.syncOperation.findMany({\n      where: {\n        deviceId: { not: String(deviceId) }, // Don't send back own changes\n        ...(lastSyncId ? { id: { gt: String(lastSyncId) } } : {}),\n      },\n      orderBy: {\n        hlcTimestamp: 'asc',\n      },\n      take: Number(limit),\n    });\n\n    const newSyncId = operations.length > 0 ? operations[operations.length - 1].id : lastSyncId;\n\n    res.json({\n      syncId: newSyncId,\n      operations,\n      hasMore: operations.length === Number(limit),\n    });\n  } catch (error) {\n    next(error);\n  }\n});\n\n// ============================================================================\n// PUSH CHANGES (Upstream)\n// ============================================================================\n\nrouter.post('/push', requireApiKey(), async (req, res, next) => {\n  const log = createRequestLogger(req);\n  try {\n    const packet = SyncPacketSchema.parse(req.body);\n    const results = [];\n\n    // Process operations in a transaction\n    await prisma.$transaction(async (tx) => {\n      for (const op of packet.operations) {\n        // 1. Conflict Resolution (LWW based on HLC)\n        // Check if we have a newer version already\n        const existing = await tx.syncOperation.findFirst({\n          where: {\n            entityType: op.entityType,\n            entityId: op.entityId,\n            hlcTimestamp: { gt: op.hlcTimestamp },\n          },\n        });\n\n        if (existing) {\n          log.info({ opId: op.id }, 'Conflict: Local version is newer, ignoring push');\n          results.push({ id: op.id, status: 'conflict_ignored' });\n          continue;\n        }\n\n        // 2. Apply Change to Domain Model\n        try {\n          await applyOperationToDomain(tx, op);\n\n          // 3. Record Operation for Other Clients\n          await tx.syncOperation.create({\n            data: {\n              id: op.id, // Keep client ID for idempotency\n              authorDid: req.user?.did || 'unknown',\n              deviceId: packet.deviceId,\n              tableName: `${op.entityType}s`, // Simple pluralization\n              recordId: op.entityId,\n              entityType: op.entityType,\n              entityId: op.entityId,\n              operation: op.operation,\n              payload: op.payload,\n              hlcTimestamp: op.hlcTimestamp,\n              isProcessed: true,\n            },\n          });\n\n          results.push({ id: op.id, status: 'applied' });\n        } catch (domainError) {\n          log.error({ error: domainError, op }, 'Failed to apply domain operation');\n          results.push({ id: op.id, status: 'failed', error: domainError.message });\n        }\n      }\n    });\n\n    res.json({ results });\n  } catch (error) {\n    next(error);\n  }\n});\n\n// ============================================================================\n// Domain Logic Adapter\n// ============================================================================\n\nasync function applyOperationToDomain(tx, op) {\n  const { entityType, operation, payload } = op;\n\n  // Safety: Remove sensitive fields or sanitize payload here\n  // For now, we trust the schema validation somewhat\n\n  if (entityType === 'conversation') {\n    if (operation === 'INSERT' || operation === 'UPDATE') {\n      await tx.conversation.upsert({\n        where: { id: payload.id },\n        update: payload,\n        create: payload,\n      });\n    } else if (operation === 'DELETE') {\n      await tx.conversation.delete({ where: { id: payload.id } });\n    }\n  } else if (entityType === 'message') {\n    if (operation === 'INSERT') {\n      await tx.message.create({ data: payload });\n    } else if (operation === 'UPDATE') {\n      await tx.message.update({ where: { id: payload.id }, data: payload });\n    }\n  }\n  // Add other entities...\n}\n\nexport default router;\n","usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\routes\\unified-api.js","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\routes\\zai-mcp.js","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\secure-server.js","messages":[{"ruleId":"no-unused-vars","severity":1,"message":"'allowedOrigins' is assigned a value but never used.","line":74,"column":7,"nodeType":"Identifier","messageId":"unusedVar","endLine":74,"endColumn":21,"suggestions":[{"messageId":"removeVar","data":{"varName":"allowedOrigins"},"fix":{"range":[2064,2386],"text":""},"desc":"Remove unused variable 'allowedOrigins'."}]},{"ruleId":"no-unused-vars","severity":1,"message":"'limiter' is assigned a value but never used.","line":127,"column":7,"nodeType":"Identifier","messageId":"unusedVar","endLine":127,"endColumn":14,"suggestions":[{"messageId":"removeVar","data":{"varName":"limiter"},"fix":{"range":[3579,4061],"text":""},"desc":"Remove unused variable 'limiter'."}]},{"ruleId":"no-unused-vars","severity":1,"message":"'sensitiveEndpointLimiter' is assigned a value but never used.","line":146,"column":7,"nodeType":"Identifier","messageId":"unusedVar","endLine":146,"endColumn":31,"suggestions":[{"messageId":"removeVar","data":{"varName":"sensitiveEndpointLimiter"},"fix":{"range":[4154,4388],"text":""},"desc":"Remove unused variable 'sensitiveEndpointLimiter'."}]},{"ruleId":"no-unused-vars","severity":1,"message":"'options' is assigned a value but never used.","line":196,"column":18,"nodeType":"Identifier","messageId":"unusedVar","endLine":196,"endColumn":25,"suggestions":[{"messageId":"removeVar","data":{"varName":"options"},"fix":{"range":[5682,5691],"text":""},"desc":"Remove unused variable 'options'."}]},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":290,"column":3,"nodeType":"MemberExpression","messageId":"limited","endLine":290,"endColumn":14,"suggestions":[{"fix":{"range":[8327,8391],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":291,"column":3,"nodeType":"MemberExpression","messageId":"limited","endLine":291,"endColumn":14,"suggestions":[{"fix":{"range":[8394,8442],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":293,"column":3,"nodeType":"MemberExpression","messageId":"limited","endLine":293,"endColumn":14,"suggestions":[{"fix":{"range":[8446,8544],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":294,"column":3,"nodeType":"MemberExpression","messageId":"limited","endLine":294,"endColumn":14,"suggestions":[{"fix":{"range":[8547,8654],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":297,"column":3,"nodeType":"MemberExpression","messageId":"limited","endLine":297,"endColumn":14,"suggestions":[{"fix":{"range":[8657,8764],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":301,"column":3,"nodeType":"MemberExpression","messageId":"limited","endLine":301,"endColumn":14,"suggestions":[{"fix":{"range":[8768,8816],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":303,"column":3,"nodeType":"MemberExpression","messageId":"limited","endLine":303,"endColumn":14,"suggestions":[{"fix":{"range":[8820,8911],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":304,"column":3,"nodeType":"MemberExpression","messageId":"limited","endLine":304,"endColumn":14,"suggestions":[{"fix":{"range":[8914,8997],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":305,"column":3,"nodeType":"MemberExpression","messageId":"limited","endLine":305,"endColumn":14,"suggestions":[{"fix":{"range":[9000,9092],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":307,"column":3,"nodeType":"MemberExpression","messageId":"limited","endLine":307,"endColumn":14,"suggestions":[{"fix":{"range":[9096,9144],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":309,"column":3,"nodeType":"MemberExpression","messageId":"limited","endLine":309,"endColumn":14,"suggestions":[{"fix":{"range":[9148,9212],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":310,"column":3,"nodeType":"MemberExpression","messageId":"limited","endLine":310,"endColumn":14,"suggestions":[{"fix":{"range":[9215,9340],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":313,"column":3,"nodeType":"MemberExpression","messageId":"limited","endLine":313,"endColumn":14,"suggestions":[{"fix":{"range":[9343,9487],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":317,"column":3,"nodeType":"MemberExpression","messageId":"limited","endLine":317,"endColumn":14,"suggestions":[{"fix":{"range":[9491,9539],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":318,"column":3,"nodeType":"MemberExpression","messageId":"limited","endLine":318,"endColumn":14,"suggestions":[{"fix":{"range":[9542,9622],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":19,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * OpenScroll Capture API - Secure Server Configuration\n *\n * Enhanced security features:\n * - Restricted CORS policy\n * - Input validation\n * - Rate limiting improvements\n * - Secure headers\n */\n\nimport 'dotenv/config';\nimport express from 'express';\nimport cors from 'cors';\nimport helmet from 'helmet';\nimport compression from 'compression';\nimport rateLimit from 'express-rate-limit';\n\nimport { logger } from './lib/logger.js';\nimport { config, validateConfig } from './config/index.js';\nimport { errorHandler } from './middleware/errorHandler.js';\nimport { requestLogger } from './middleware/requestLogger.js';\nimport { requestId } from './middleware/requestId.js';\nimport { captureRouter } from './routes/capture.js';\nimport { healthRouter } from './routes/health.js';\nimport { conversationsRouter } from './routes/conversations.js';\nimport { disconnectPrisma } from './lib/database.js';\nimport { setupSwagger } from './docs/swagger.js';\n\n// Validate configuration on startup\ntry {\n  validateConfig();\n  logger.info('Configuration validated successfully');\n} catch (error) {\n  logger.error('Configuration validation failed:', error);\n  process.exit(1);\n}\n\n// Initialize Express app\nconst app = express();\n\n// ============================================================================\n// SECURITY MIDDLEWARE\n// ============================================================================\n\n// Helmet - Security headers\napp.use(\n  helmet({\n    contentSecurityPolicy: {\n      directives: {\n        defaultSrc: [\"'self'\"],\n        styleSrc: [\"'self'\", \"'unsafe-inline'\"],\n        scriptSrc: [\"'self'\"],\n        imgSrc: [\"'self'\", 'data:', 'https:'],\n        connectSrc: [\n          \"'self'\",\n          'https://*.openai.com',\n          'https://*.anthropic.com',\n          'https://*.googleapis.com',\n        ],\n      },\n    },\n    hsts: {\n      maxAge: 31536000,\n      includeSubDomains: true,\n      preload: true,\n    },\n    referrerPolicy: {\n      policy: 'strict-origin-when-cross-origin',\n    },\n  })\n);\n\n// Define allowed origins based on environment\nconst allowedOrigins = config.isDevelopment\n  ? [\n      'http://localhost:5173',\n      'http://localhost:3000',\n      'http://127.0.0.1:5173',\n      'http://0.0.0.0:5173',\n    ]\n  : [\n      'https://openscroll.yourdomain.com',\n      'https://www.openscroll.yourdomain.com',\n      // Add your production domains here\n    ];\n\n// CORS - Cross-Origin Resource Sharing with restricted origins\napp.use(\n  cors({\n    origin: true, // Allow all origins for POC\n    credentials: true,\n    optionsSuccessStatus: 200,\n    preflightContinue: false,\n    methods: ['GET', 'POST', 'OPTIONS'],\n    allowedHeaders: [\n      'Content-Type',\n      'Authorization',\n      'X-Requested-With',\n      'X-Request-ID',\n      'Accept',\n      'Origin',\n    ],\n  })\n);\n\n// Alternative CORS implementation if the above doesn't work for all routes\n// app.use((req, res, next) => {\n//   const origin = req.get('Origin');\n//   if (origin && allowedOrigins.includes(origin)) {\n//     res.header('Access-Control-Allow-Origin', origin);\n//   }\n//   res.header('Access-Control-Allow-Methods', 'GET, POST, OPTIONS');\n//   res.header('Access-Control-Allow-Headers', 'Content-Type, Authorization, X-Request-ID');\n//   res.header('Access-Control-Allow-Credentials', 'true');\n\n//   if (req.method === 'OPTIONS') {\n//     process.stdout.write(` \\x1b[2m[CORS]\\x1b[0m ${req.method} ${req.path}\\n`);\n//     return res.status(200).end();\n//   }\n//   next();\n// });\n\n// Compression - Gzip response bodies\napp.use(compression());\n\n// Rate Limiting - Prevent abuse\nconst limiter = rateLimit({\n  windowMs: 15 * 60 * 1000, // 15 minutes\n  max: config.rateLimitMax, // Limit each IP to 100 requests per windowMs\n  standardHeaders: true,\n  legacyHeaders: false,\n  message: {\n    error: 'Too many requests from this IP, please try again later.',\n  },\n  handler: (req, res) => {\n    logger.warn({ ip: req.ip, path: req.path }, 'Rate limit exceeded');\n    res.status(429).json({\n      error: 'Too many requests',\n      retryAfter: '15m',\n    });\n  },\n});\n// app.use('/api/', limiter);\n\n// Additional security rate limiting for sensitive endpoints\nconst sensitiveEndpointLimiter = rateLimit({\n  windowMs: 5 * 60 * 1000, // 5 minutes\n  max: 10, // Limit to 10 requests per 5 minutes\n  message: {\n    error: 'Too many requests to sensitive endpoint, please try again later.',\n  },\n});\n// app.use('/api/v1/capture', sensitiveEndpointLimiter);\n\n// ============================================================================\n// PARSING MIDDLEWARE\n// ============================================================================\n\n// Parse JSON request bodies with size limits and validation\napp.use(\n  express.json({\n    limit: '1mb', // Prevent memory exhaustion attacks\n    strict: true, // Only parse objects and arrays\n    type: 'application/json',\n    // Custom reviver to prevent prototype pollution\n    reviver: (key, value) => {\n      if (key.startsWith('__') || key.includes('constructor.prototype')) {\n        throw new Error('Invalid property name');\n      }\n      return value;\n    },\n  })\n);\n\n// Parse URL-encoded bodies\napp.use(\n  express.urlencoded({\n    extended: false,\n    limit: '1mb',\n  })\n);\n\n// ============================================================================\n// CUSTOM MIDDLEWARE\n// ============================================================================\n\n// Request ID - Add unique identifier to each request\napp.use(requestId);\n\n// Request Logger - Log all requests\napp.use(requestLogger);\n\n// Input validation middleware for critical endpoints\napp.use('/api/v1/capture', (req, res, next) => {\n  if (req.method === 'POST') {\n    const { url, options } = req.body;\n\n    // Validate URL format\n    if (url && typeof url === 'string') {\n      try {\n        const parsedUrl = new URL(url);\n\n        // Only allow supported domains\n        const allowedHosts = [\n          'chat.openai.com',\n          'claude.ai',\n          'gemini.google.com',\n          'x.ai',\n          'cohere.com',\n          'anthropic.com',\n        ];\n\n        if (!allowedHosts.includes(parsedUrl.hostname)) {\n          logger.warn({ url, ip: req.ip }, 'Blocked request to unsupported domain');\n          return res.status(400).json({\n            error: 'Invalid or unsupported URL domain',\n            supportedDomains: allowedHosts,\n          });\n        }\n      } catch (e) {\n        logger.warn({ url, ip: req.ip, error: e.message }, 'Invalid URL format');\n        return res.status(400).json({\n          error: 'Invalid URL format',\n          message: e.message,\n        });\n      }\n    }\n  }\n\n  next();\n});\n\n// ============================================================================\n// ROUTES\n// ============================================================================\n\n// Health check (no auth, no rate limit)\napp.use('/', healthRouter);\n\n// API routes\napp.use('/api/v1', captureRouter);\napp.use('/api/v1/conversations', conversationsRouter);\n\n// API Documentation (Swagger)\nif (config.enableSwagger) {\n  setupSwagger(app);\n  logger.info('Swagger UI available at /api-docs');\n}\n\n// 404 handler\napp.use((req, res) => {\n  res.status(404).json({\n    error: 'Not Found',\n    message: `Cannot ${req.method} ${req.path}`,\n    ...(config.enableSwagger && { documentationUrl: '/api-docs' }),\n  });\n});\n\n// ============================================================================\n// ERROR HANDLING\n// ============================================================================\n\n// Global error handler (must be last)\napp.use(errorHandler);\n\n// ============================================================================\n// STARTUP\n// ============================================================================\n\n// Helper to get local IP\nimport { networkInterfaces } from 'os';\n\nfunction getLocalIp() {\n  const nets = networkInterfaces();\n  for (const name of Object.keys(nets)) {\n    for (const net of nets[name]) {\n      // Skip over non-IPv4, internal (127.0.0.1), and APIPA (169.254.x.x) addresses\n      if (net.family === 'IPv4' && !net.internal && !net.address.startsWith('169.254')) {\n        return net.address;\n      }\n    }\n  }\n  return 'localhost';\n}\n\nconst server = app.listen(config.port, '0.0.0.0', () => {\n  const localIp = getLocalIp();\n  const startTime = new Date().toISOString();\n\n  console.log('\\n\\x1b[1m\\x1b[44m SECURE SYSTEM MANIFEST \\x1b[0m');\n  console.log(`\\x1b[34m${'â”'.repeat(60)}\\x1b[0m`);\n\n  console.log(' \\x1b[1mWHAT IS HAPPENING:\\x1b[0m    Initializing Secure OpenScroll Capture Engine');\n  console.log(\n    ' \\x1b[1mWHAT IT CAN DO:\\x1b[0m       Cross-origin content extraction & DAG building'\n  );\n  console.log(\n    ' \\x1b[1mWHAT IS EXPECTED:\\x1b[0m    Valid configuration detected & Prisma connected'\n  );\n\n  console.log(`\\x1b[34m${'â”€'.repeat(40)}\\x1b[0m`);\n\n  console.log(` \\x1b[1mWHERE (NETWORK):\\x1b[0m     http://${localIp}:${config.port}/api/v1`);\n  console.log(` \\x1b[1mWHERE (LOCAL):\\x1b[0m       http://localhost:${config.port}`);\n  console.log(` \\x1b[1mWHERE (DOCS):\\x1b[0m        http://localhost:${config.port}/api-docs`);\n\n  console.log(`\\x1b[34m${'â”€'.repeat(40)}\\x1b[0m`);\n\n  console.log(` \\x1b[1mWHEN:\\x1b[0m                ${startTime}`);\n  console.log(\n    ` \\x1b[1mBY WHO (PROCESS):\\x1b[0m    Node ${process.version} (${process.platform}) PID: ${process.pid}`\n  );\n  console.log(\n    ` \\x1b[1mBY WHO (MODE):\\x1b[0m       ${config.isDevelopment ? '\\x1b[33mDEVELOPMENT\\x1b[0m' : '\\x1b[32mPRODUCTION\\x1b[0m'}`\n  );\n\n  console.log(`\\x1b[34m${'â”'.repeat(60)}\\x1b[0m`);\n  console.log(' \\x1b[2mListening for incoming intelligence requests...\\x1b[0m\\n');\n\n  logger.info(\n    { port: config.port, env: config.nodeEnv, localIp },\n    'Secure System Manifest Broadcast Complete'\n  );\n});\n\n// ============================================================================\n// GRACEFUL SHUTDOWN\n// ============================================================================\n\nconst shutdown = async (signal) => {\n  logger.info({ signal }, 'Shutdown signal received');\n\n  // Stop accepting new connections\n  server.close(async () => {\n    logger.info('HTTP server closed');\n\n    // Disconnect from database\n    try {\n      await disconnectPrisma();\n    } catch (error) {\n      logger.error({ error: error.message }, 'Error disconnecting database');\n    }\n\n    process.exit(0);\n  });\n\n  // Force shutdown after timeout\n  setTimeout(() => {\n    logger.error('Forced shutdown after timeout');\n    process.exit(1);\n  }, config.shutdownTimeout).unref();\n};\n\n// Handle shutdown signals\nprocess.on('SIGTERM', () => shutdown('SIGTERM'));\nprocess.on('SIGINT', () => shutdown('SIGINT'));\n\n// Handle uncaught exceptions\nprocess.on('uncaughtException', (error) => {\n  logger.error({ error }, 'Uncaught exception');\n  shutdown('UNCAUGHT_EXCEPTION');\n});\n\n// Handle unhandled promise rejections\nprocess.on('unhandledRejection', (reason, promise) => {\n  logger.error({ reason, promise }, 'Unhandled promise rejection');\n  shutdown('UNHANDLED_REJECTION');\n});\n\nexport { app, server };\n","usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\server.js","messages":[{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":15,"column":1,"nodeType":"MemberExpression","messageId":"limited","endLine":15,"endColumn":12,"suggestions":[{"fix":{"range":[284,353],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-unused-vars","severity":1,"message":"'serverErrorReporter' is defined but never used.","line":25,"column":10,"nodeType":"Identifier","messageId":"unusedVar","endLine":25,"endColumn":29,"suggestions":[{"messageId":"removeVar","data":{"varName":"serverErrorReporter"},"fix":{"range":[695,715],"text":""},"desc":"Remove unused variable 'serverErrorReporter'."}]},{"ruleId":"no-unused-vars","severity":1,"message":"'errorReportingMiddleware' is defined but never used.","line":25,"column":31,"nodeType":"Identifier","messageId":"unusedVar","endLine":25,"endColumn":55,"suggestions":[{"messageId":"removeVar","data":{"varName":"errorReportingMiddleware"},"fix":{"range":[714,740],"text":""},"desc":"Remove unused variable 'errorReportingMiddleware'."}]},{"ruleId":"no-unused-vars","severity":1,"message":"'requestLogger' is defined but never used.","line":26,"column":10,"nodeType":"Identifier","messageId":"unusedVar","endLine":26,"endColumn":23,"suggestions":[{"messageId":"removeVar","data":{"varName":"requestLogger"},"fix":{"range":[785,847],"text":""},"desc":"Remove unused variable 'requestLogger'."}]},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":246,"column":7,"nodeType":"MemberExpression","messageId":"limited","endLine":246,"endColumn":18,"suggestions":[{"fix":{"range":[8616,8775],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":255,"column":5,"nodeType":"MemberExpression","messageId":"limited","endLine":255,"endColumn":16,"suggestions":[{"fix":{"range":[8942,9019],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":366,"column":3,"nodeType":"MemberExpression","messageId":"limited","endLine":366,"endColumn":14,"suggestions":[{"fix":{"range":[12301,12383],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":367,"column":3,"nodeType":"MemberExpression","messageId":"limited","endLine":367,"endColumn":14,"suggestions":[{"fix":{"range":[12386,12466],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":368,"column":3,"nodeType":"MemberExpression","messageId":"limited","endLine":368,"endColumn":14,"suggestions":[{"fix":{"range":[12469,12549],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":369,"column":3,"nodeType":"MemberExpression","messageId":"limited","endLine":369,"endColumn":14,"suggestions":[{"fix":{"range":[12552,12668],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":372,"column":3,"nodeType":"MemberExpression","messageId":"limited","endLine":372,"endColumn":14,"suggestions":[{"fix":{"range":[12671,12724],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":373,"column":3,"nodeType":"MemberExpression","messageId":"limited","endLine":373,"endColumn":14,"suggestions":[{"fix":{"range":[12727,12767],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":374,"column":3,"nodeType":"MemberExpression","messageId":"limited","endLine":374,"endColumn":14,"suggestions":[{"fix":{"range":[12770,12808],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":375,"column":3,"nodeType":"MemberExpression","messageId":"limited","endLine":375,"endColumn":14,"suggestions":[{"fix":{"range":[12811,12870],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":376,"column":3,"nodeType":"MemberExpression","messageId":"limited","endLine":376,"endColumn":14,"suggestions":[{"fix":{"range":[12873,12980],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":379,"column":3,"nodeType":"MemberExpression","messageId":"limited","endLine":379,"endColumn":14,"suggestions":[{"fix":{"range":[12983,13063],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":400,"column":5,"nodeType":"MemberExpression","messageId":"limited","endLine":400,"endColumn":16,"suggestions":[{"fix":{"range":[13775,13855],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":401,"column":5,"nodeType":"MemberExpression","messageId":"limited","endLine":401,"endColumn":16,"suggestions":[{"fix":{"range":[13860,13940],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":402,"column":5,"nodeType":"MemberExpression","messageId":"limited","endLine":402,"endColumn":16,"suggestions":[{"fix":{"range":[13945,14025],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":403,"column":5,"nodeType":"MemberExpression","messageId":"limited","endLine":403,"endColumn":16,"suggestions":[{"fix":{"range":[14030,14150],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":406,"column":5,"nodeType":"MemberExpression","messageId":"limited","endLine":406,"endColumn":16,"suggestions":[{"fix":{"range":[14155,14221],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":407,"column":5,"nodeType":"MemberExpression","messageId":"limited","endLine":407,"endColumn":16,"suggestions":[{"fix":{"range":[14226,14273],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":408,"column":5,"nodeType":"MemberExpression","messageId":"limited","endLine":408,"endColumn":16,"suggestions":[{"fix":{"range":[14278,14356],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":409,"column":5,"nodeType":"MemberExpression","messageId":"limited","endLine":409,"endColumn":16,"suggestions":[{"fix":{"range":[14361,14403],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":410,"column":5,"nodeType":"MemberExpression","messageId":"limited","endLine":410,"endColumn":16,"suggestions":[{"fix":{"range":[14408,14448],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":411,"column":5,"nodeType":"MemberExpression","messageId":"limited","endLine":411,"endColumn":16,"suggestions":[{"fix":{"range":[14453,14535],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":515,"column":3,"nodeType":"MemberExpression","messageId":"limited","endLine":515,"endColumn":14,"suggestions":[{"fix":{"range":[17971,18053],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":516,"column":3,"nodeType":"MemberExpression","messageId":"limited","endLine":516,"endColumn":14,"suggestions":[{"fix":{"range":[18056,18131],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":517,"column":3,"nodeType":"MemberExpression","messageId":"limited","endLine":517,"endColumn":14,"suggestions":[{"fix":{"range":[18134,18214],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":518,"column":3,"nodeType":"MemberExpression","messageId":"limited","endLine":518,"endColumn":14,"suggestions":[{"fix":{"range":[18217,18297],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":519,"column":3,"nodeType":"MemberExpression","messageId":"limited","endLine":519,"endColumn":14,"suggestions":[{"fix":{"range":[18300,18379],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":520,"column":3,"nodeType":"MemberExpression","messageId":"limited","endLine":520,"endColumn":14,"suggestions":[{"fix":{"range":[18382,18462],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":521,"column":3,"nodeType":"MemberExpression","messageId":"limited","endLine":521,"endColumn":14,"suggestions":[{"fix":{"range":[18465,18544],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":522,"column":3,"nodeType":"MemberExpression","messageId":"limited","endLine":522,"endColumn":14,"suggestions":[{"fix":{"range":[18547,18627],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":523,"column":3,"nodeType":"MemberExpression","messageId":"limited","endLine":523,"endColumn":14,"suggestions":[{"fix":{"range":[18630,18710],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":524,"column":3,"nodeType":"MemberExpression","messageId":"limited","endLine":524,"endColumn":14,"suggestions":[{"fix":{"range":[18713,18793],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":525,"column":3,"nodeType":"MemberExpression","messageId":"limited","endLine":525,"endColumn":14,"suggestions":[{"fix":{"range":[18796,18876],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":526,"column":3,"nodeType":"MemberExpression","messageId":"limited","endLine":526,"endColumn":14,"suggestions":[{"fix":{"range":[18879,18963],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":527,"column":3,"nodeType":"MemberExpression","messageId":"limited","endLine":527,"endColumn":14,"suggestions":[{"fix":{"range":[18966,19050],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":528,"column":3,"nodeType":"MemberExpression","messageId":"limited","endLine":528,"endColumn":14,"suggestions":[{"fix":{"range":[19053,19137],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":529,"column":3,"nodeType":"MemberExpression","messageId":"limited","endLine":529,"endColumn":14,"suggestions":[{"fix":{"range":[19140,19220],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":530,"column":3,"nodeType":"MemberExpression","messageId":"limited","endLine":530,"endColumn":14,"suggestions":[{"fix":{"range":[19223,19303],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":531,"column":3,"nodeType":"MemberExpression","messageId":"limited","endLine":531,"endColumn":14,"suggestions":[{"fix":{"range":[19306,19386],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":532,"column":3,"nodeType":"MemberExpression","messageId":"limited","endLine":532,"endColumn":14,"suggestions":[{"fix":{"range":[19389,19469],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":533,"column":3,"nodeType":"MemberExpression","messageId":"limited","endLine":533,"endColumn":14,"suggestions":[{"fix":{"range":[19472,19535],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":534,"column":3,"nodeType":"MemberExpression","messageId":"limited","endLine":534,"endColumn":14,"suggestions":[{"fix":{"range":[19538,19630],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":535,"column":3,"nodeType":"MemberExpression","messageId":"limited","endLine":535,"endColumn":14,"suggestions":[{"fix":{"range":[19633,19719],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":536,"column":3,"nodeType":"MemberExpression","messageId":"limited","endLine":536,"endColumn":14,"suggestions":[{"fix":{"range":[19722,19851],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":539,"column":3,"nodeType":"MemberExpression","messageId":"limited","endLine":539,"endColumn":14,"suggestions":[{"fix":{"range":[19854,19934],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":540,"column":3,"nodeType":"MemberExpression","messageId":"limited","endLine":540,"endColumn":14,"suggestions":[{"fix":{"range":[19937,20017],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":541,"column":3,"nodeType":"MemberExpression","messageId":"limited","endLine":541,"endColumn":14,"suggestions":[{"fix":{"range":[20020,20100],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":542,"column":3,"nodeType":"MemberExpression","messageId":"limited","endLine":542,"endColumn":14,"suggestions":[{"fix":{"range":[20103,20183],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":543,"column":3,"nodeType":"MemberExpression","messageId":"limited","endLine":543,"endColumn":14,"suggestions":[{"fix":{"range":[20186,20272],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":544,"column":3,"nodeType":"MemberExpression","messageId":"limited","endLine":544,"endColumn":14,"suggestions":[{"fix":{"range":[20275,20355],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":545,"column":3,"nodeType":"MemberExpression","messageId":"limited","endLine":545,"endColumn":14,"suggestions":[{"fix":{"range":[20358,20444],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":546,"column":3,"nodeType":"MemberExpression","messageId":"limited","endLine":546,"endColumn":14,"suggestions":[{"fix":{"range":[20447,20527],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":547,"column":3,"nodeType":"MemberExpression","messageId":"limited","endLine":547,"endColumn":14,"suggestions":[{"fix":{"range":[20530,20610],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]},{"ruleId":"no-console","severity":1,"message":"Unexpected console statement. Only these console methods are allowed: warn, error.","line":548,"column":3,"nodeType":"MemberExpression","messageId":"limited","endLine":548,"endColumn":14,"suggestions":[{"fix":{"range":[20613,20695],"text":""},"messageId":"removeConsole","data":{"propertyName":"log"},"desc":"Remove the console.log()."}]}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":58,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * OpenScroll Capture API - Modernized Server (2025+)\n *\n * Features:\n * - ES Modules\n * - Structured logging (Pino)\n * - Security headers (Helmet)\n * - Rate limiting\n * - Request validation (Zod)\n * - Error handling middleware\n * - Graceful shutdown\n */\n\nimport 'dotenv/config';\nconsole.log(`DEBUG: Server.js loaded - ${new Date().toISOString()}`);\nimport express from 'express';\nimport cors from 'cors';\nimport helmet from 'helmet';\nimport compression from 'compression';\nimport rateLimit from 'express-rate-limit';\n\nimport { logger } from './lib/logger.js';\nimport { config, validateConfig } from './config/index.js';\nimport { errorHandler } from './middleware/errorHandler.js';\nimport { serverErrorReporter, errorReportingMiddleware } from './utils/server-error-reporting.js';\nimport { requestLogger } from './middleware/requestLogger.js';\nimport { requestId } from './middleware/requestId.js';\nimport { captureRouter } from './routes/capture.js';\nimport { healthRouter } from './routes/health.js';\nimport { conversationsRouter } from './routes/conversations.js';\nimport { logsRouter } from './routes/logs.js';\nimport identityRouter from './routes/identity.js';\nimport acusRouter from './routes/acus.js';\nimport syncRouter from './routes/sync.js';\nimport feedRouter from './routes/feed.js';\nimport { aiRouter } from './routes/ai.js';\nimport { aiChatRouter } from './routes/ai-chat.js';\nimport { aiSettingsRouter } from './routes/ai-settings.js';\nimport { omniRouter } from './routes/omni.js';\nimport { zaiMcpRouter } from './routes/zai-mcp.js';\nimport { createSettingsRoutes } from './routes/context-settings.ts';\nimport { errorsRouter } from './routes/errors.js';\nimport { disconnectPrisma, getPrismaClient } from './lib/database.js';\nimport { setupSwagger } from './docs/swagger.js';\nimport { logBroadcaster } from './lib/logBroadcaster.js';\nimport identityV2Router from './routes/identity-v2.js';\nimport circleRouter from './routes/circles.js';\nimport sharingRouter from './routes/sharing.js';\nimport feedV2Router from './routes/feed-v2.js';\nimport unifiedApiRouter from './routes/unified-api.js';\nimport portabilityRouter from './routes/portability.js';\nimport authRouter from './routes/auth.js';\nimport accountRouter from './routes/account.js';\nimport contextV2Router from './routes/context-v2.js';\nimport memoryRouter from './routes/memory.js';\nimport memorySearchRouter from './routes/memory-search.js';\nimport { debugRouter } from './routes/debug.js';\nimport { collectionsRouter } from './routes/collections.js';\nimport socialRouter from './routes/social.js';\nimport moderationRouter from './routes/moderation.js';\nimport integrationsRouter from './routes/integrations.ts';\nimport adminNetworkRouter from './routes/admin/network.js';\nimport adminDatabaseRouter from './routes/admin/database.js';\nimport adminSystemRouter from './routes/admin/system.js';\nimport adminCrdtRouter from './routes/admin/crdt.js';\nimport adminPubsubRouter from './routes/admin/pubsub.js';\nimport adminDataflowRouter from './routes/admin/dataflow.js';\n\n// Validate configuration on startup\ntry {\n  validateConfig();\n  logger.info('Configuration validated successfully');\n} catch (error) {\n  logger.error('Configuration validation failed:', error);\n  process.exit(1);\n}\n\n// Initialize Express app\nconst app = express();\n\n// ============================================================================\n// SERVER LOG BROADCASTING\n// ============================================================================\n// Initialize log broadcaster to stream server logs to PWA\nlogBroadcaster.initialize();\n\n// ============================================================================\n// TRUSTED PROXY CONFIGURATION\n// ============================================================================\n// Enable when behind reverse proxy (nginx, AWS ALB, etc.)\nif (config.trustProxy) {\n  app.set('trust proxy', 1);\n}\n\n// ============================================================================\n// SECURITY MIDDLEWARE\n// ============================================================================\n\n// Helmet - Security headers\napp.use(\n  helmet({\n    contentSecurityPolicy: {\n      directives: {\n        defaultSrc: [\"'self'\"],\n        styleSrc: [\"'self'\", \"'unsafe-inline'\"],\n        scriptSrc: [\"'self'\"],\n        imgSrc: [\"'self'\", 'data:', 'https:'],\n      },\n    },\n    hsts: {\n      maxAge: 31536000,\n      includeSubDomains: true,\n      preload: true,\n    },\n  })\n);\n\n// CORS - Cross-Origin Resource Sharing (Enhanced Security)\n// Use configured origins only - never allow all origins in production\nconst corsOptions = {\n  origin: function (origin, callback) {\n    // Allow requests with no origin (like mobile apps or curl requests)\n    // But in production, require proper CORS headers\n    if (!origin) {\n      return callback(null, true);\n    }\n\n    const allowedOrigins = config.isDevelopment\n      ? [\n          'http://localhost:5173',\n          'http://localhost:3000',\n          'http://127.0.0.1:5173',\n          'http://127.0.0.1:3000',\n          'http://0.0.0.0:5173',\n          'http://192.168.0.173:5173',\n          'http://192.168.0.173:3000',\n        ]\n      : config.corsOrigins || [];\n\n    // In development, also allow local network origins\n    let effectiveAllowedOrigins = [...allowedOrigins];\n    if (config.isDevelopment) {\n      effectiveAllowedOrigins = [\n        ...allowedOrigins,\n        // Dynamically add any local network origin\n      ];\n    }\n\n    if (effectiveAllowedOrigins.includes(origin)) {\n      callback(null, true);\n    } else if (config.isDevelopment) {\n      // In development, allow localhost and private network patterns\n      const isLocalNetwork =\n        origin.startsWith('http://localhost:') ||\n        origin.startsWith('http://127.0.0.1:') ||\n        origin.startsWith('http://192.168.') ||\n        origin.startsWith('http://10.') ||\n        origin.startsWith('http://172.');\n\n      if (isLocalNetwork) {\n        callback(null, true);\n      } else {\n        callback(new Error('Not allowed by CORS'));\n      }\n    } else {\n      // Production: only allow explicitly configured origins\n      callback(new Error('Not allowed by CORS'));\n    }\n  },\n  credentials: true,\n  methods: ['GET', 'POST', 'PUT', 'DELETE', 'OPTIONS', 'PATCH'],\n  allowedHeaders: [\n    'Content-Type',\n    'Authorization',\n    'X-Request-ID',\n    'X-Requested-With',\n    'X-API-Key',\n    'Accept',\n    'Cache-Control',\n    'x-user-id',\n  ],\n};\n\napp.use(cors(corsOptions));\n\n// Custom CORS middleware for additional logging and headers\nconst allowedOrigins = config.isDevelopment\n  ? [\n      'http://localhost:5173',\n      'http://localhost:3000',\n      'http://127.0.0.1:5173',\n      'http://127.0.0.1:3000',\n      'http://0.0.0.0:5173',\n      'http://192.168.0.173:5173', // PWA on local IP\n      'http://192.168.0.173:3000', // Server on local IP\n    ]\n  : config.corsOrigins || []; // Use configured origins, default to empty array if none provided\n\n// Validate that production environments have specific origins configured\nif (config.isProduction && allowedOrigins.length === 0) {\n  logger.error('Production environment requires specific CORS origins to be configured');\n  process.exit(1);\n}\n\napp.use((req, res, next) => {\n  const origin = req.get('Origin');\n\n  // Logic to allow origins:\n  // 1. Explicitly allowed in allowedOrigins list\n  // 2. In development, any origin that matches the local network pattern (e.g., 192.168.x.x)\n  let isAllowed = false;\n  if (origin) {\n    if (allowedOrigins.includes(origin)) {\n      isAllowed = true;\n    } else if (config.isDevelopment) {\n      // Allow any local network origin in development for easier testing across devices\n      const isLocalNetwork =\n        origin.startsWith('http://localhost:') ||\n        origin.startsWith('http://127.0.0.1:') ||\n        origin.startsWith('http://192.168.') ||\n        origin.startsWith('http://10.') ||\n        origin.startsWith('http://172.');\n\n      if (isLocalNetwork) {\n        isAllowed = true;\n      }\n    }\n  }\n\n  if (isAllowed && origin) {\n    res.header('Access-Control-Allow-Origin', origin);\n  } else if (config.isDevelopment && !origin) {\n    // Non-browser requests in development\n    res.header('Access-Control-Allow-Origin', '*');\n  }\n\n  res.header('Access-Control-Allow-Methods', 'GET, POST, OPTIONS, PUT, DELETE');\n  res.header(\n    'Access-Control-Allow-Headers',\n    'Content-Type, Authorization, X-Request-ID, X-Requested-With, X-API-Key, Accept, Cache-Control'\n  );\n  res.header('Access-Control-Allow-Credentials', 'true');\n\n  if (req.method === 'OPTIONS') {\n    if (config.isDevelopment) {\n      console.log(\n        `ðŸ”§ [CORS PRE-FLIGHT] ${req.method} ${req.path} - Origin: ${origin || 'none'} - Result: ${isAllowed ? 'âœ… ALLOWED' : 'âŒ BLOCKED'}`\n      );\n    }\n    return res.status(200).end();\n  }\n\n  // Log CORS info for non-OPTIONS requests too in development\n  if (origin && config.isDevelopment && !isAllowed) {\n    console.log(`ðŸŒ [CORS BLOCKED] Request from: ${origin} - Path: ${req.path}`);\n  }\n\n  next();\n});\n\n// Compression - Gzip response bodies\napp.use(compression());\n\n// Rate Limiting - Enable in both dev and production with environment-appropriate limits\nconst rateLimitConfig = {\n  windowMs: 15 * 60 * 1000, // 15 minutes\n  max: config.isProduction ? config.rateLimitMax || 100 : 1000, // Higher limit in dev\n  standardHeaders: true,\n  legacyHeaders: false,\n  message: {\n    error: 'Too many requests from this IP, please try again later.',\n  },\n  handler: (req, res) => {\n    logger.warn({ ip: req.ip, path: req.path }, 'Rate limit exceeded');\n    res.status(429).json({\n      error: 'Too many requests',\n      retryAfter: '15m',\n    });\n  },\n};\n\nconst limiter = rateLimit(rateLimitConfig);\napp.use('/api/', limiter);\nlogger.info(\n  `Rate limiting enabled (${config.isProduction ? 'production' : 'development'} mode: ${rateLimitConfig.max} req/15min)`\n);\n\n// ============================================================================\n// PARSING MIDDLEWARE\n// ============================================================================\n\n// Parse JSON request bodies\napp.use(\n  express.json({\n    limit: '1mb', // Prevent memory exhaustion attacks\n    strict: true, // Only parse objects and arrays\n  })\n);\n\n// Parse URL-encoded bodies\napp.use(\n  express.urlencoded({\n    extended: false,\n    limit: '1mb',\n  })\n);\n\n// ============================================================================\n// SESSION & PASSPORT AUTH\n// ============================================================================\nimport session from 'express-session';\nimport passport from './middleware/google-auth.js';\n\n// Session configuration with secure defaults\nconst sessionSecret = process.env.SESSION_SECRET;\n\n// Validate session secret - fail fast in production\nif (!sessionSecret) {\n  if (config.isProduction) {\n    logger.error('SESSION_SECRET environment variable is required in production');\n    process.exit(1);\n  } else {\n    // Generate a random secret for development convenience (sessions invalidate on restart)\n    logger.warn('No SESSION_SECRET provided in development - generating random secret');\n  }\n}\n\napp.use(\n  session({\n    secret: sessionSecret || `dev-${Date.now()}-${Math.random().toString(36).slice(2)}`,\n    resave: false,\n    saveUninitialized: false,\n    cookie: {\n      secure: !config.isDevelopment,\n      httpOnly: true,\n      maxAge: 7 * 24 * 60 * 60 * 1000,\n      sameSite: 'lax',\n    },\n  })\n);\napp.use(passport.initialize());\napp.use(passport.session());\n\n// Development auth bypass (must be after passport, before routes)\nimport { devAuthBypass, logDevAuthStatus } from './middleware/dev-auth.js';\napp.use(devAuthBypass);\napp.use(logDevAuthStatus);\n\n// ============================================================================\n// CUSTOM MIDDLEWARE\n// ============================================================================\n\n// Request ID - Add unique identifier to each request\napp.use(requestId);\n\n// Enhanced Request Logger - Human-readable, structured logging\napp.use((req, res, next) => {\n  const startTime = Date.now();\n  const requestId = req.id;\n  const { method } = req;\n  const { path } = req;\n  const { ip } = req;\n  const userAgent = req.get('User-Agent') || 'Unknown';\n\n  // Log incoming request in a human-readable format\n  console.log('\\nâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—');\n  console.log('â•‘                        REQUEST RECEIVED                      â•‘');\n  console.log('â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£');\n  console.log(\n    `â•‘  ðŸ†” ID:        ${requestId.substring(0, 8)}...${requestId.substring(requestId.length - 4)}`\n  );\n  console.log(`â•‘  ðŸ§­ METHOD:    ${method.padEnd(10)}`);\n  console.log(`â•‘  ðŸ“ PATH:      ${path}`);\n  console.log(`â•‘  ðŸŒ FROM:      ${ip}`);\n  console.log(`â•‘  â° TIME:      ${new Date().toISOString()}`);\n  console.log(\n    `â•‘  ðŸ¤– AGENT:     ${userAgent.substring(0, 40)}${userAgent.length > 40 ? '...' : ''}`\n  );\n  console.log('â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');\n\n  // Capture the original end method to log response\n  const originalEnd = res.end;\n  res.end = function (chunk, encoding, callback) {\n    const duration = Date.now() - startTime;\n    const { statusCode } = res;\n\n    // Determine status category for readability\n    let statusCategory = 'UNKNOWN';\n    if (statusCode >= 200 && statusCode < 300) {\n      statusCategory = 'âœ… SUCCESS';\n    } else if (statusCode >= 300 && statusCode < 400) {\n      statusCategory = 'ðŸ”„ REDIRECT';\n    } else if (statusCode >= 400 && statusCode < 500) {\n      statusCategory = 'âŒ CLIENT_ERROR';\n    } else if (statusCode >= 500) {\n      statusCategory = 'ðŸ’¥ SERVER_ERROR';\n    }\n\n    // Log response in a human-readable format\n    console.log('â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—');\n    console.log('â•‘                        RESPONSE SENT                         â•‘');\n    console.log('â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£');\n    console.log(\n      `â•‘  ðŸ†” ID:        ${requestId.substring(0, 8)}...${requestId.substring(requestId.length - 4)}`\n    );\n    console.log(`â•‘  ðŸ·ï¸  STATUS:    ${statusCode} ${statusCategory}`);\n    console.log(`â•‘  â±ï¸  DURATION:  ${duration}ms`);\n    console.log(`â•‘  ðŸ“¦ SIZE:      ${chunk ? Buffer.byteLength(chunk) : 0} bytes`);\n    console.log(`â•‘  ðŸ§­ METHOD:    ${method}`);\n    console.log(`â•‘  ðŸ“ PATH:      ${path}`);\n    console.log('â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\\n');\n\n    // Call the original end method\n    originalEnd.call(this, chunk, encoding, callback);\n  };\n\n  next();\n});\n\n// ============================================================================\n// ROUTES\n// ============================================================================\n\n// Health check (no auth, no rate limit)\napp.use('/', healthRouter);\napp.use('/api/v1', healthRouter);\n\n// API routes\napp.use('/api/v1', captureRouter);\napp.use('/api/v1/conversations', conversationsRouter);\napp.use('/api/v1/logs', logsRouter);\napp.use('/api/v1/identity', identityRouter);\napp.use('/api/v1/auth', authRouter);\napp.use('/api/v1/account', accountRouter);\napp.use('/api/v2/identity', identityV2Router);\napp.use('/api/v2/circles', circleRouter);\napp.use('/api/v2/sharing', sharingRouter);\napp.use('/api/v2/feed', feedV2Router);\napp.use('/api/unified', unifiedApiRouter);\napp.use('/api/v2/portability', portabilityRouter);\napp.use('/api/v2/moderation', moderationRouter);\napp.use('/api/v1/acus', acusRouter);\napp.use('/api/v1/sync', syncRouter);\napp.use('/api/v1/feed', feedRouter);\napp.use('/api/v1/ai', aiRouter);\napp.use('/api/v1/ai/chat', aiChatRouter);\napp.use('/api/v1/ai/settings', aiSettingsRouter);\napp.use('/api/v1/settings', createSettingsRoutes(getPrismaClient()));\napp.use('/api/v1/omni', omniRouter);\napp.use('/api/v1/zai-mcp', zaiMcpRouter);\napp.use('/api/v2/context', contextV2Router);\napp.use('/api/v2/memories', memoryRouter);\napp.use('/api/v2/memories/query', memorySearchRouter);\napp.use('/api/v1/errors', errorsRouter);\napp.use('/api/v1/debug', debugRouter);\napp.use('/api/v1/collections', collectionsRouter);\napp.use('/api/v3/social', socialRouter);\napp.use('/api/v1/social', socialRouter);\napp.use('/api/v1/integrations', integrationsRouter);\n\n// Admin routes\napp.use('/api/admin/network', adminNetworkRouter);\napp.use('/api/admin/database', adminDatabaseRouter);\napp.use('/api/admin/system', adminSystemRouter);\napp.use('/api/admin/crdt', adminCrdtRouter);\napp.use('/api/admin/pubsub', adminPubsubRouter);\napp.use('/api/admin/dataflow', adminDataflowRouter);\n\n// API Documentation (Swagger)\nif (config.enableSwagger) {\n  setupSwagger(app);\n  logger.info('Swagger UI available at /api-docs');\n}\n\n// 404 handler\napp.use((req, res) => {\n  res.status(404).json({\n    error: 'Not Found',\n    message: `Cannot ${req.method} ${req.path}`,\n    ...(config.enableSwagger && { documentationUrl: '/api-docs' }),\n  });\n});\n\n// ============================================================================\n// ERROR HANDLING\n// ============================================================================\n\n// Global error handler (must be last)\napp.use(errorHandler);\n\n// ============================================================================\n// STARTUP\n// ============================================================================\n\n// Helper to get local IP\nimport { networkInterfaces } from 'os';\n\nfunction getLocalIp() {\n  const nets = networkInterfaces();\n  for (const name of Object.keys(nets)) {\n    for (const net of nets[name]) {\n      // Skip over non-IPv4, internal (127.0.0.1), and APIPA (169.254.x.x) addresses\n      if (net.family === 'IPv4' && !net.internal && !net.address.startsWith('169.254')) {\n        return net.address;\n      }\n    }\n  }\n  return 'localhost';\n}\n\nconst server = app.listen(config.port, '0.0.0.0', () => {\n  const localIp = getLocalIp();\n  const startTime = new Date().toISOString();\n\n  console.log('\\nâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—');\n  console.log('â•‘                    VIVIM SERVER STARTED                 â•‘');\n  console.log('â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£');\n  console.log('â•‘                                                              â•‘');\n  console.log('â•‘  ðŸš€ ENGINE STATUS:     OPERATIONAL                          â•‘');\n  console.log('â•‘  ðŸŽ¯ CAPABILITIES:      AI Content Capture & Knowledge Vault  â•‘');\n  console.log('â•‘  ðŸ” SECURITY LEVEL:    ENHANCED (CORS, Rate Limiting)       â•‘');\n  console.log('â•‘                                                              â•‘');\n  console.log('â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£');\n  console.log('â•‘                           CONNECTIONS                        â•‘');\n  console.log('â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£');\n  console.log(`â•‘  ðŸŒ NETWORK ACCESS:    http://${localIp}:${config.port}/api/v1   â•‘`);\n  console.log(`â•‘  ðŸ  LOCAL ACCESS:      http://localhost:${config.port}           â•‘`);\n  console.log(`â•‘  ðŸ“š API DOCUMENTATION: http://localhost:${config.port}/api-docs  â•‘`);\n  console.log('â•‘                                                              â•‘');\n  console.log('â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£');\n  console.log('â•‘                           SYSTEM INFO                        â•‘');\n  console.log('â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£');\n  console.log(`â•‘  â±ï¸  START TIME:        ${startTime}        â•‘`);\n  console.log(`â•‘  ðŸ’» PLATFORM:          Node ${process.version} (${process.platform})     â•‘`);\n  console.log(`â•‘  ðŸ†” PROCESS ID:         PID: ${process.pid}                        â•‘`);\n  console.log(\n    `â•‘  ðŸ·ï¸  MODE:              ${config.isDevelopment ? 'ðŸ§ª DEVELOPMENT' : 'ðŸ”’ PRODUCTION'}                 â•‘`\n  );\n  console.log('â•‘                                                              â•‘');\n  console.log('â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£');\n  console.log('â•‘                    CONNECTION INSTRUCTIONS                   â•‘');\n  console.log('â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£');\n  console.log('â•‘  1. PWA should connect to: http://SERVER_IP:${config.port}/api/v1  â•‘');\n  console.log('â•‘  2. API endpoints: /api/v1/capture, /api/v1/providers, etc.  â•‘');\n  console.log('â•‘  3. Documentation: http://localhost:${config.port}/api-docs        â•‘');\n  console.log('â•‘  4. Configure VITE_API_BASE_URL in PWA to match server URL   â•‘');\n  console.log('â•‘                                                              â•‘');\n  console.log('â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\\n');\n\n  logger.info(\n    { port: config.port, env: config.nodeEnv, localIp },\n    'System Manifest Broadcast Complete'\n  );\n});\n\n// ============================================================================\n// SOCKET SERVICE (Data Sync + Signaling)\n// ============================================================================\nimport { socketService } from './services/socket.ts';\nsocketService.initialize(server);\nlogger.info('ðŸ”Œ Socket service ready for Data Sync & P2P');\n\n// ============================================================================\n// ADMIN WEBSOCKET SERVICE\n// ============================================================================\nimport { adminWsService } from './services/admin-ws-service.js';\nadminWsService.initialize(server);\nlogger.info('ðŸ”Œ Admin WebSocket service ready for real-time updates');\n\n// ============================================================================\n// GRACEFUL SHUTDOWN\n// ============================================================================\n\nconst shutdown = async (signal) => {\n  logger.info({ signal }, 'Shutdown signal received');\n\n  // Stop accepting new connections\n  server.close(async () => {\n    logger.info('HTTP server closed');\n\n    // Disconnect from database\n    try {\n      await disconnectPrisma();\n    } catch (error) {\n      logger.error({ error: error.message }, 'Error disconnecting database');\n    }\n\n    process.exit(0);\n  });\n\n  // Force shutdown after timeout\n  setTimeout(() => {\n    logger.error('Forced shutdown after timeout');\n    process.exit(1);\n  }, config.shutdownTimeout).unref();\n};\n\n// Handle shutdown signals\nprocess.on('SIGTERM', () => shutdown('SIGTERM'));\nprocess.on('SIGINT', () => shutdown('SIGINT'));\n\n// Handle uncaught exceptions\nprocess.on('uncaughtException', (error) => {\n  logger.error({ error }, 'Uncaught exception');\n  shutdown('UNCAUGHT_EXCEPTION');\n});\n\n// Handle unhandled promise rejections\nprocess.on('unhandledRejection', (reason, promise) => {\n  logger.error({ reason, promise }, 'Unhandled promise rejection');\n  shutdown('UNHANDLED_REJECTION');\n});\n\nexport { app, server };\n","usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\services\\account-lifecycle-service.js","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\services\\acu-generator.js","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\services\\acu-processor.js","messages":[{"ruleId":"no-unused-vars","severity":1,"message":"'error' is defined but never used.","line":26,"column":10,"nodeType":"Identifier","messageId":"unusedVar","endLine":26,"endColumn":15}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * ACU Processor Service\n *\n * Converts captured conversations into Atomic Chat Units (ACUs)\n * using the Rust core parser and stores them in the knowledge graph.\n *\n * Flow:\n * 1. Fetch conversation + messages from database\n * 2. Call Rust core to decompose into ACUs\n * 3. Generate embeddings (optional)\n * 4. Calculate quality scores\n * 5. Detect relationships (ACU links)\n * 6. Save to database\n */\n\nimport { getPrismaClient } from '../lib/database.js';\nimport { logger } from '../lib/logger.js';\nimport crypto from 'crypto';\n\n// Import Rust core (will be available after UniFFI bindings are set up)\n// For now, we'll create a mock implementation\nconst rustCore = null;\ntry {\n  // This will work once Rust core is compiled with UniFFI\n  // rustCore = await import('../../openscroll-core/index.js');\n} catch (error) {\n  logger.warn('Rust core not available, using mock implementation');\n}\n\n/**\n * Process a single conversation into ACUs\n * @param {string} conversationId - UUID of the conversation\n * @param {object} options - Processing options\n * @returns {Promise<object>} Processing result\n */\nexport async function processConversationToACUs(conversationId, options = {}) {\n  const {\n    generateEmbeddings = false,\n    calculateQuality = true,\n    detectLinks = true,\n    authorDid = null, // If null, will use default or create anonymous DID\n  } = options;\n\n  const startTime = Date.now();\n\n  try {\n    logger.info(`Processing conversation ${conversationId} to ACUs`);\n\n    // 1. Fetch conversation with messages\n    const conversation = await getPrismaClient().conversation.findUnique({\n      where: { id: conversationId },\n      include: {\n        messages: {\n          orderBy: { messageIndex: 'asc' },\n        },\n      },\n    });\n\n    if (!conversation) {\n      throw new Error(`Conversation ${conversationId} not found`);\n    }\n\n    logger.info(`Found conversation with ${conversation.messages.length} messages`);\n\n    // 2. Convert to format expected by Rust core\n    const extractedData = {\n      id: conversation.id,\n      provider: conversation.provider,\n      title: conversation.title,\n      model: conversation.model,\n      created_at: conversation.createdAt.toISOString(),\n      updated_at: conversation.updatedAt.toISOString(),\n      messages: conversation.messages.map((msg) => ({\n        id: msg.id,\n        role: msg.role,\n        author: msg.author,\n        content: convertPartsToContent(msg.parts),\n        created_at: msg.createdAt.toISOString(),\n        message_index: msg.messageIndex,\n        metadata: msg.metadata,\n      })),\n    };\n\n    // 3. Call Rust core to decompose into ACUs\n    let acus;\n    if (rustCore) {\n      // Real implementation with Rust core\n      const rawJson = JSON.stringify(extractedData);\n      acus = await rustCore.process_capture_async(rawJson);\n    } else {\n      // Mock implementation for testing\n      acus = await mockProcessCapture(extractedData);\n    }\n\n    logger.info(`Generated ${acus.length} ACUs from conversation`);\n\n    // 4. Determine author DID\n    const finalAuthorDid = authorDid || (await getOrCreateAnonymousDid(conversation.ownerId));\n\n    // 5. Generate embeddings if requested\n    if (generateEmbeddings && rustCore) {\n      logger.info('Generating embeddings for ACUs');\n      acus = await rustCore.enrich_acus_with_embeddings(acus);\n    }\n\n    // 6. Save ACUs to database\n    const savedAcus = [];\n    for (const acu of acus) {\n      try {\n        const savedAcu = await saveAcuToDatabase(acu, {\n          conversationId,\n          authorDid: finalAuthorDid,\n          provider: conversation.provider,\n          model: conversation.model,\n          calculateQuality,\n        });\n        savedAcus.push(savedAcu);\n      } catch (error) {\n        logger.error(`Failed to save ACU: ${error.message}`, { acu, error });\n        // Continue processing other ACUs\n      }\n    }\n\n    // 7. Detect and create relationships between ACUs\n    if (detectLinks && savedAcus.length > 1) {\n      logger.info('Detecting ACU relationships');\n      await createAcuLinks(savedAcus);\n    }\n\n    const duration = Date.now() - startTime;\n\n    logger.info(`Successfully processed conversation ${conversationId}`, {\n      acuCount: savedAcus.length,\n      duration: `${duration}ms`,\n    });\n\n    return {\n      success: true,\n      conversationId,\n      acuCount: savedAcus.length,\n      duration,\n      acus: savedAcus,\n    };\n  } catch (error) {\n    const duration = Date.now() - startTime;\n    logger.error(`Failed to process conversation ${conversationId}`, {\n      error: error.message,\n      stack: error.stack,\n      duration: `${duration}ms`,\n    });\n\n    return {\n      success: false,\n      conversationId,\n      error: error.message,\n      duration,\n    };\n  }\n}\n\n/**\n * Convert message parts (JSONB) to plain text content\n * @param {Array|string} parts - Message parts from database\n * @returns {string} Plain text content\n */\nfunction convertPartsToContent(parts) {\n  if (typeof parts === 'string') {\n    return parts;\n  }\n\n  if (!Array.isArray(parts)) {\n    return JSON.stringify(parts);\n  }\n\n  return parts\n    .map((part) => {\n      if (typeof part === 'string') {\n        return part;\n      }\n\n      if (part.type === 'text') {\n        return part.content;\n      }\n\n      if (part.type === 'code') {\n        const lang = part.metadata?.language || '';\n        return `\\`\\`\\`${lang}\\n${part.content}\\n\\`\\`\\``;\n      }\n\n      if (part.type === 'latex') {\n        return `$$${part.content}$$`;\n      }\n\n      if (part.type === 'table') {\n        // Convert table to markdown\n        if (part.content?.headers && part.content?.rows) {\n          const headers = part.content.headers.join(' | ');\n          const separator = part.content.headers.map(() => '---').join(' | ');\n          const rows = part.content.rows.map((row) => row.join(' | ')).join('\\n');\n          return `${headers}\\n${separator}\\n${rows}`;\n        }\n        return JSON.stringify(part.content);\n      }\n\n      // For other types, return content as-is or stringify\n      return part.content || JSON.stringify(part);\n    })\n    .join('\\n\\n');\n}\n\n/**\n * Mock implementation of Rust core processing\n * Used when Rust core is not available\n */\nasync function mockProcessCapture(extractedData) {\n  const acus = [];\n\n  for (const message of extractedData.messages) {\n    // Simple decomposition: split by paragraphs\n    const { content } = message;\n    const paragraphs = content.split(/\\n\\n+/).filter((p) => p.trim().length > 0);\n\n    for (let i = 0; i < paragraphs.length; i++) {\n      const paragraph = paragraphs[i].trim();\n\n      // Skip very short paragraphs\n      if (paragraph.length < 10) {\n        continue;\n      }\n\n      // Determine type based on content\n      let type = 'statement';\n      let category = 'general';\n      let language = null;\n\n      if (paragraph.includes('```')) {\n        type = 'code_snippet';\n        category = 'technical';\n        const langMatch = paragraph.match(/```(\\w+)/);\n        language = langMatch ? langMatch[1] : 'plaintext';\n      } else if (paragraph.endsWith('?')) {\n        type = 'question';\n      } else if (paragraph.startsWith('Answer:') || paragraph.startsWith('Response:')) {\n        type = 'answer';\n      } else if (paragraph.includes('$$')) {\n        type = 'formula';\n        category = 'technical';\n      }\n\n      // Generate content hash as ID\n      const id = generateContentHash(paragraph);\n\n      acus.push({\n        id,\n        content: paragraph,\n        language,\n        type,\n        category,\n        provenance: {\n          conversation_id: extractedData.id,\n          message_id: message.id,\n          message_index: message.message_index,\n          source_timestamp: message.created_at,\n        },\n        embedding: null, // Will be filled by embedding service\n        metadata: {\n          mock: true,\n          paragraph_index: i,\n        },\n      });\n    }\n  }\n\n  return acus;\n}\n\n/**\n * Generate SHA3-256 hash of content (ACU ID)\n */\nfunction generateContentHash(content) {\n  return crypto.createHash('sha256').update(content.trim()).digest('hex');\n}\n\n/**\n * Get or create anonymous DID for user\n */\nasync function getOrCreateAnonymousDid(userId) {\n  if (!userId) {\n    // Return a default anonymous DID\n    return 'did:key:z6MkhaXgBZDvotDkL5257faiztiGiC2QtKLGpbnnEGta2doK';\n  }\n\n  // Check if user exists\n  const user = await getPrismaClient().user.findUnique({\n    where: { id: userId },\n  });\n\n  if (user) {\n    return user.did;\n  }\n\n  // Create anonymous user\n  // In production, this would use proper DID generation\n  const anonymousDid = `did:key:anon_${userId}`;\n\n  try {\n    const newUser = await getPrismaClient().user.create({\n      data: {\n        id: userId,\n        did: anonymousDid,\n        displayName: 'Anonymous User',\n        publicKey: 'placeholder_public_key', // Would be real key in production\n        settings: {},\n      },\n    });\n    return newUser.did;\n  } catch (error) {\n    // User might have been created by another process\n    logger.warn(`Failed to create user ${userId}: ${error.message}`);\n    return anonymousDid;\n  }\n}\n\n/**\n * Save ACU to database\n */\nasync function saveAcuToDatabase(acu, context) {\n  const { conversationId, authorDid, provider, model, calculateQuality } = context;\n\n  // Calculate quality scores if requested\n  let qualityScores = null;\n  if (calculateQuality) {\n    qualityScores = calculateAcuQuality(acu);\n  }\n\n  // Prepare ACU data\n  const acuData = {\n    id: acu.id,\n    authorDid,\n    signature: Buffer.from([]), // Placeholder - would be real signature in production\n    content: acu.content,\n    language: acu.language,\n    type: acu.type,\n    category: acu.category,\n    embedding: acu.embedding ? acu.embedding : null,\n    embeddingModel: acu.embedding ? 'mock-model' : null,\n    conversationId,\n    messageId: acu.provenance.message_id,\n    messageIndex: acu.provenance.message_index,\n    provider,\n    model,\n    sourceTimestamp: new Date(acu.provenance.source_timestamp),\n    extractorVersion: '1.0.0',\n    parserVersion: '1.0.0',\n    qualityOverall: qualityScores?.overall,\n    contentRichness: qualityScores?.richness,\n    structuralIntegrity: qualityScores?.integrity,\n    uniqueness: qualityScores?.uniqueness,\n    sharingPolicy: 'self', // Default to private\n    sharingCircles: [],\n    metadata: acu.metadata || {},\n  };\n\n  // Upsert ACU (in case it already exists)\n  const savedAcu = await getPrismaClient().atomicChatUnit.upsert({\n    where: { id: acu.id },\n    update: acuData,\n    create: acuData,\n  });\n\n  return savedAcu;\n}\n\n/**\n * Calculate quality scores for an ACU\n */\nfunction calculateAcuQuality(acu) {\n  const { content } = acu;\n  const { length } = content;\n\n  // Content richness: based on length and structure\n  let richness = 0;\n  if (length > 500) {\n    richness = 90;\n  } else if (length > 200) {\n    richness = 70;\n  } else if (length > 50) {\n    richness = 50;\n  } else {\n    richness = 30;\n  }\n\n  // Bonus for code, formulas, etc.\n  if (acu.type === 'code_snippet') {\n    richness += 10;\n  }\n  if (acu.type === 'formula') {\n    richness += 10;\n  }\n\n  // Structural integrity: based on type classification\n  const integrity = acu.type !== 'unknown' ? 80 : 50;\n\n  // Uniqueness: simple heuristic (would use embeddings in production)\n  const uniqueness = Math.min(100, length / 10);\n\n  // Overall score: weighted average\n  const overall = richness * 0.4 + integrity * 0.3 + uniqueness * 0.3;\n\n  return {\n    overall: Math.round(overall),\n    richness: Math.round(richness),\n    integrity: Math.round(integrity),\n    uniqueness: Math.round(uniqueness),\n  };\n}\n\n/**\n * Create relationships (links) between ACUs\n */\nasync function createAcuLinks(acus) {\n  const links = [];\n\n  // Create sequential links (next/previous)\n  for (let i = 0; i < acus.length - 1; i++) {\n    const source = acus[i];\n    const target = acus[i + 1];\n\n    // Check if they're from the same message\n    if (source.messageId === target.messageId) {\n      links.push({\n        sourceId: source.id,\n        targetId: target.id,\n        relation: 'next',\n        weight: 1.0,\n        metadata: { type: 'sequential' },\n      });\n    }\n  }\n\n  // Detect semantic relationships (simple heuristics for now)\n  for (let i = 0; i < acus.length; i++) {\n    const source = acus[i];\n\n    // If this is a question, look for answers\n    if (source.type === 'question') {\n      for (let j = i + 1; j < Math.min(i + 5, acus.length); j++) {\n        const target = acus[j];\n        if (target.type === 'answer' || target.type === 'statement') {\n          links.push({\n            sourceId: source.id,\n            targetId: target.id,\n            relation: 'answered_by',\n            weight: 0.8,\n            metadata: { type: 'semantic' },\n          });\n          break; // Only link to first answer\n        }\n      }\n    }\n\n    // If this is a statement followed by code, create \"explains\" link\n    if (source.type === 'statement') {\n      for (let j = i + 1; j < Math.min(i + 3, acus.length); j++) {\n        const target = acus[j];\n        if (target.type === 'code_snippet') {\n          links.push({\n            sourceId: source.id,\n            targetId: target.id,\n            relation: 'explains',\n            weight: 0.9,\n            metadata: { type: 'semantic' },\n          });\n          break;\n        }\n      }\n    }\n  }\n\n  // Save links to database\n  for (const link of links) {\n    try {\n      await getPrismaClient().acuLink.create({\n        data: link,\n      });\n    } catch (error) {\n      // Link might already exist\n      if (!error.message.includes('Unique constraint')) {\n        logger.error(`Failed to create ACU link: ${error.message}`, { link });\n      }\n    }\n  }\n\n  logger.info(`Created ${links.length} ACU links`);\n  return links;\n}\n\n/**\n * Process all conversations in database\n * Useful for backfilling ACUs from existing data\n */\nexport async function processAllConversations(options = {}) {\n  const { batchSize = 10, delayMs = 1000, ...processingOptions } = options;\n\n  logger.info('Starting batch processing of all conversations');\n\n  // Get all conversation IDs\n  const conversations = await getPrismaClient().conversation.findMany({\n    select: { id: true },\n    orderBy: { capturedAt: 'desc' },\n  });\n\n  logger.info(`Found ${conversations.length} conversations to process`);\n\n  const results = {\n    total: conversations.length,\n    successful: 0,\n    failed: 0,\n    errors: [],\n  };\n\n  // Process in batches\n  for (let i = 0; i < conversations.length; i += batchSize) {\n    const batch = conversations.slice(i, i + batchSize);\n\n    logger.info(\n      `Processing batch ${Math.floor(i / batchSize) + 1}/${Math.ceil(conversations.length / batchSize)}`\n    );\n\n    // Process batch in parallel\n    const batchResults = await Promise.allSettled(\n      batch.map((conv) => processConversationToACUs(conv.id, processingOptions))\n    );\n\n    // Collect results\n    for (const result of batchResults) {\n      if (result.status === 'fulfilled' && result.value.success) {\n        results.successful++;\n      } else {\n        results.failed++;\n        results.errors.push({\n          conversationId: result.value?.conversationId,\n          error: result.reason?.message || result.value?.error,\n        });\n      }\n    }\n\n    // Delay between batches to avoid overwhelming the system\n    if (i + batchSize < conversations.length) {\n      await new Promise((resolve) => setTimeout(resolve, delayMs));\n    }\n  }\n\n  logger.info('Batch processing complete', results);\n  return results;\n}\n\nexport default {\n  processConversationToACUs,\n  processAllConversations,\n};\n","usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\services\\admin-network-service.js","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\services\\admin-ws-service.js","messages":[{"ruleId":"no-unused-vars","severity":1,"message":"'httpServer' is defined but never used. Allowed unused args must match /^_/u.","line":21,"column":14,"nodeType":"Identifier","messageId":"unusedVar","endLine":21,"endColumn":24,"suggestions":[{"messageId":"removeVar","data":{"varName":"httpServer"},"fix":{"range":[429,439],"text":""},"desc":"Remove unused variable 'httpServer'."}]}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * Admin WebSocket Service\n *\n * Real-time event broadcasting for admin panel\n */\n\nimport { logger } from '../lib/logger.js';\nimport { EventEmitter } from 'events';\n\nclass AdminWsService extends EventEmitter {\n  constructor() {\n    super();\n    this.clients = new Set();\n    this.broadcastInterval = null;\n  }\n\n  /**\n   * Initialize WebSocket service\n   * @param {Object} httpServer - HTTP server instance\n   */\n  initialize(httpServer) {\n    // TODO: Integrate WebSocket server\n    // For now, we'll use event polling via REST endpoints\n    logger.info('Admin WebSocket service initialized');\n\n    // Start mock broadcast interval for testing\n    this.startBroadcastInterval();\n  }\n\n  /**\n   * Add a client connection\n   * @param {Object} ws - WebSocket connection\n   */\n  addClient(ws) {\n    this.clients.add(ws);\n\n    ws.on('close', () => {\n      this.clients.delete(ws);\n      logger.info({ clientCount: this.clients.size }, 'Admin WebSocket client disconnected');\n    });\n\n    logger.info({ clientCount: this.clients.size }, 'Admin WebSocket client connected');\n  }\n\n  /**\n   * Broadcast event to all connected clients\n   * @param {string} event - Event name\n   * @param {Object} data - Event data\n   */\n  broadcast(event, data) {\n    const message = JSON.stringify({\n      type: event,\n      payload: data,\n      timestamp: new Date().toISOString(),\n    });\n\n    this.clients.forEach((client) => {\n      if (client.readyState === 1) {\n        // OPEN\n        client.send(message);\n      }\n    });\n\n    // Also emit for local listeners\n    this.emit(event, data);\n  }\n\n  /**\n   * Broadcast network metrics\n   * @param {Object} metrics - Network metrics\n   */\n  broadcastNetworkMetrics(metrics) {\n    this.broadcast('network:metric', metrics);\n  }\n\n  /**\n   * Broadcast system log\n   * @param {Object} log - Log entry\n   */\n  broadcastSystemLog(log) {\n    this.broadcast('system:log', log);\n  }\n\n  /**\n   * Broadcast CRDT sync status\n   * @param {Object} status - Sync status\n   */\n  broadcastCrdtSync(status) {\n    this.broadcast('crdt:sync', status);\n  }\n\n  /**\n   * Broadcast node status change\n   * @param {Object} nodeStatus - Node status\n   */\n  broadcastNodeStatus(nodeStatus) {\n    this.broadcast('network:node:status', nodeStatus);\n  }\n\n  /**\n   * Start mock broadcast interval for testing\n   */\n  startBroadcastInterval() {\n    // Broadcast mock network metrics every 2 seconds\n    this.broadcastInterval = setInterval(() => {\n      const mockMetric = {\n        timestamp: new Date().toISOString(),\n        peerCount: 7 + Math.floor(Math.random() * 3),\n        connectionCount: 4 + Math.floor(Math.random() * 3),\n        bandwidthIn: 1000000 + Math.random() * 2000000,\n        bandwidthOut: 800000 + Math.random() * 1500000,\n        latencyAvg: 20 + Math.random() * 40,\n        dhtLookupTime: 10 + Math.random() * 30,\n        messageQueueSize: Math.floor(Math.random() * 100),\n        cacheHitRate: 0.7 + Math.random() * 0.25,\n        errorRate: Math.random() * 0.05,\n      };\n\n      this.broadcastNetworkMetrics(mockMetric);\n    }, 2000);\n\n    logger.info('Mock broadcast interval started');\n  }\n\n  /**\n   * Stop broadcast interval\n   */\n  stopBroadcastInterval() {\n    if (this.broadcastInterval) {\n      clearInterval(this.broadcastInterval);\n      this.broadcastInterval = null;\n      logger.info('Mock broadcast interval stopped');\n    }\n  }\n\n  /**\n   * Get connected clients count\n   * @returns {number} Number of connected clients\n   */\n  getClientCount() {\n    return this.clients.size;\n  }\n}\n\n// Export singleton instance\nexport const adminWsService = new AdminWsService();\n","usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\services\\ai-service.js","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\services\\ai-storage-service.js","messages":[{"ruleId":"no-unused-vars","severity":1,"message":"'strategy' is assigned a value but never used.","line":257,"column":13,"nodeType":"Identifier","messageId":"unusedVar","endLine":257,"endColumn":21,"suggestions":[{"messageId":"removeVar","data":{"varName":"strategy"},"fix":{"range":[7928,7937],"text":""},"desc":"Remove unused variable 'strategy'."}]},{"ruleId":"no-unused-vars","severity":1,"message":"'model' is assigned a value but never used.","line":257,"column":23,"nodeType":"Identifier","messageId":"unusedVar","endLine":257,"endColumn":28,"suggestions":[{"messageId":"removeVar","data":{"varName":"model"},"fix":{"range":[7936,7943],"text":""},"desc":"Remove unused variable 'model'."}]},{"ruleId":"no-unused-vars","severity":1,"message":"'maxTokens' is assigned a value but never used.","line":257,"column":30,"nodeType":"Identifier","messageId":"unusedVar","endLine":257,"endColumn":39,"suggestions":[{"messageId":"removeVar","data":{"varName":"maxTokens"},"fix":{"range":[7943,7954],"text":""},"desc":"Remove unused variable 'maxTokens'."}]},{"ruleId":"no-unused-vars","severity":1,"message":"'options' is assigned a value but never used. Allowed unused args must match /^_/u.","line":312,"column":70,"nodeType":"Identifier","messageId":"unusedVar","endLine":312,"endColumn":77,"suggestions":[{"messageId":"removeVar","data":{"varName":"options"},"fix":{"range":[9480,9494],"text":""},"desc":"Remove unused variable 'options'."}]}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":4,"fixableErrorCount":0,"fixableWarningCount":0,"source":"// apps/server/src/services/ai-storage-service.js\n\nimport {\n  createConversation,\n  addMessageToConversation,\n  findConversationById,\n} from '../repositories/ConversationRepository.js';\nimport { getPrismaClient } from '../lib/database.js';\nimport { logger } from '../lib/logger.js';\nimport { v4 as uuidv4 } from 'uuid';\nimport { librarianWorker } from '../context/librarian-worker.js';\n\nconst prisma = getPrismaClient();\n\n// Configuration for idle detection\nconst IDLE_TIMEOUT_MINUTES = parseInt(process.env.CONVERSATION_IDLE_TIMEOUT_MINUTES || '5', 10);\nconst ENABLE_IDLE_DETECTION = process.env.ENABLE_IDLE_DETECTION === 'true';\n\n/**\n * AI Storage Service\n *\n * Orchestrates persisting AI chat sessions to the database using existing repositories.\n * Uses context builder for intelligent conversation context extraction.\n */\nexport class AiStorageService {\n  /**\n   * Start a new AI conversation in the database\n   */\n  async startConversation(data) {\n    const { provider, model, ownerId, title = 'New AI Chat', initialMessages = [] } = data;\n\n    const conversationId = uuidv4();\n    const sourceUrl = `internal://chat/${conversationId}`;\n\n    logger.info({ conversationId, provider, model }, 'Starting new AI conversation storage');\n\n    const conversationData = {\n      id: conversationId,\n      provider,\n      sourceUrl,\n      title,\n      model,\n      ownerId,\n      createdAt: new Date().toISOString(),\n      updatedAt: new Date().toISOString(),\n      capturedAt: new Date().toISOString(),\n      messages: initialMessages.map((msg, index) => ({\n        id: uuidv4(),\n        role: msg.role,\n        parts: Array.isArray(msg.content) ? msg.content : [{ type: 'text', text: msg.content }],\n        messageIndex: index,\n        createdAt: new Date().toISOString(),\n      })),\n      metadata: {\n        isInternalChat: true,\n        aiGenerated: true,\n      },\n    };\n\n    const conversation = await createConversation(conversationData);\n\n    // Link conversation to topics from initial messages\n    if (initialMessages.length > 0 && ownerId) {\n      const allContent = initialMessages.map((m) => m.content || '').join(' ');\n      await this.linkTopicsToConversation(conversationId, ownerId, allContent);\n    }\n\n    return conversation;\n  }\n\n  /**\n   * Append a message to an existing conversation\n   */\n  async appendMessage(conversationId, message) {\n    logger.debug({ conversationId, role: message.role }, 'Appending message to AI conversation');\n\n    const result = await addMessageToConversation(conversationId, {\n      role: message.role,\n      parts: Array.isArray(message.content)\n        ? message.content\n        : [{ type: 'text', text: message.content }],\n      status: message.status || 'completed',\n      finishReason: message.finishReason,\n      tokenCount: message.tokenCount,\n      metadata: message.metadata || {},\n    });\n\n    // Link topics from new message content\n    try {\n      const conversation = await prisma.conversation.findUnique({\n        where: { id: conversationId },\n        select: { ownerId: true, updatedAt: true },\n      });\n\n      if (conversation?.ownerId) {\n        const content = message.content || '';\n        await this.linkTopicsToConversation(conversationId, conversation.ownerId, content);\n      }\n\n      // Invalidate context bundle for this conversation\n      await this.invalidateConversationContext(conversationId);\n\n      // Check if conversation is idle and trigger librarian for assistant messages\n      if (ENABLE_IDLE_DETECTION && message.role === 'assistant') {\n        await this.checkAndTriggerLibrarian(conversationId, conversation);\n      }\n    } catch (e) {\n      logger.warn({ error: e.message }, 'Failed to link topics or invalidate context');\n    }\n\n    return result;\n  }\n\n  /**\n   * Check if conversation is idle and trigger librarian worker\n   * Conversation is considered idle when no user activity for IDLE_TIMEOUT_MINUTES\n   */\n  async checkAndTriggerLibrarian(conversationId, conversation) {\n    if (!conversation?.updatedAt) {\n      logger.debug({ conversationId }, 'No updatedAt timestamp, skipping librarian trigger');\n      return;\n    }\n\n    const now = new Date();\n    const lastActivity = new Date(conversation.updatedAt);\n    const minutesSinceActivity = (now.getTime() - lastActivity.getTime()) / (1000 * 60);\n\n    if (minutesSinceActivity >= IDLE_TIMEOUT_MINUTES) {\n      logger.info(\n        {\n          conversationId,\n          minutesSinceActivity: Math.round(minutesSinceActivity),\n        },\n        'Conversation is idle, triggering librarian worker'\n      );\n\n      try {\n        await librarianWorker.onConversationIdle(conversationId);\n        logger.info({ conversationId }, 'Librarian worker triggered successfully');\n      } catch (error) {\n        logger.error(\n          { conversationId, error: error.message },\n          'Failed to trigger librarian worker'\n        );\n      }\n    } else {\n      logger.debug(\n        {\n          conversationId,\n          minutesSinceActivity: Math.round(minutesSinceActivity),\n        },\n        'Conversation is still active, skipping librarian trigger'\n      );\n    }\n  }\n\n  /**\n   * Extract keywords from content and link to conversation\n   */\n  async linkTopicsToConversation(conversationId, userId, content) {\n    if (!content || !userId) {\n      return;\n    }\n\n    // Simple keyword extraction (can be enhanced with NLP)\n    const words = content\n      .toLowerCase()\n      .replace(/[^\\w\\s]/g, ' ')\n      .split(/\\s+/)\n      .filter((w) => w.length > 4);\n\n    // Get unique keywords (frequency-based)\n    const wordFreq = {};\n    for (const word of words) {\n      wordFreq[word] = (wordFreq[word] || 0) + 1;\n    }\n\n    // Sort by frequency and take top keywords\n    const topKeywords = Object.entries(wordFreq)\n      .sort((a, b) => b[1] - a[1])\n      .slice(0, 5)\n      .map(([word]) => word);\n\n    for (const keyword of topKeywords) {\n      // Find or create topic profile\n      let topicProfile = await prisma.topicProfile.findUnique({\n        where: { userId_slug: { userId, slug: keyword } },\n      });\n\n      if (!topicProfile) {\n        // Create topic profile with default values\n        topicProfile = await prisma.topicProfile.create({\n          data: {\n            userId,\n            slug: keyword,\n            label: keyword.charAt(0).toUpperCase() + keyword.slice(1),\n            domain: 'ai-generated',\n            importanceScore: 0.3,\n            embedding: new Array(768).fill(0), // Placeholder embedding\n            firstEngagedAt: new Date(),\n            lastEngagedAt: new Date(),\n          },\n        });\n      }\n\n      // Link conversation to topic (if not already linked)\n      await prisma.topicConversation.upsert({\n        where: {\n          topicId_conversationId: {\n            topicId: topicProfile.id,\n            conversationId,\n          },\n        },\n        update: {\n          relevanceScore: { increment: 0.05 },\n        },\n        create: {\n          topicId: topicProfile.id,\n          conversationId,\n          relevanceScore: 0.3,\n        },\n      });\n\n      // Update topic engagement stats\n      await prisma.topicProfile.update({\n        where: { id: topicProfile.id },\n        data: {\n          totalConversations: { increment: 1 },\n          lastEngagedAt: new Date(),\n        },\n      });\n    }\n  }\n\n  /**\n   * Invalidate context bundle when conversation changes\n   */\n  async invalidateConversationContext(conversationId) {\n    try {\n      await prisma.contextBundle.updateMany({\n        where: {\n          conversationId,\n          bundleType: 'conversation',\n        },\n        data: { isDirty: true },\n      });\n      logger.debug({ conversationId }, 'Invalidated conversation context bundle');\n    } catch (e) {\n      logger.warn({ error: e.message }, 'Failed to invalidate context bundle');\n    }\n  }\n\n  /**\n   * Get context for AI completion\n   */\n  async getContextForCompletion(conversationId, options = {}) {\n    const { strategy, model, maxTokens, maxMessages } = options;\n\n    const conversation = await prisma.conversation.findUnique({\n      where: { id: conversationId },\n      include: {\n        messages: {\n          orderBy: { messageIndex: 'asc' },\n          take: maxMessages || 50,\n        },\n      },\n    });\n\n    if (!conversation) {\n      throw new Error(`Conversation ${conversationId} not found`);\n    }\n\n    // Get context bundles for this conversation\n    const whereClause = conversation.ownerId\n      ? {\n          OR: [{ conversationId }, { userId: conversation.ownerId }],\n        }\n      : { conversationId };\n\n    const bundles = await prisma.contextBundle.findMany({\n      where: whereClause,\n      orderBy: { compiledAt: 'desc' },\n    });\n\n    // Format messages for AI\n    const messages = conversation.messages.map((m) => ({\n      role: m.role,\n      content: Array.isArray(m.parts)\n        ? m.parts.map((p) => p.text || p.content || '').join('')\n        : m.parts,\n    }));\n\n    return {\n      messages,\n      stats: {\n        totalMessages: conversation.messageCount,\n        totalTokens: conversation.totalTokens || 0,\n        bundlesCount: bundles.length,\n        contextTokens: bundles.reduce((sum, b) => sum + b.tokenCount, 0),\n      },\n      bundles: bundles.map((b) => ({\n        type: b.bundleType,\n        content: b.compiledPrompt,\n        tokens: b.tokenCount,\n      })),\n    };\n  }\n\n  /**\n   * Fork a conversation to start a new chat with intelligent context\n   */\n  async forkConversation(sourceId, prompt, ownerId, provider, model, options = {}) {\n    logger.info({ sourceId, ownerId }, 'Forking conversation with intelligent context');\n\n    const sourceConversation = await findConversationById(sourceId);\n    if (!sourceConversation) {\n      throw new Error(`Source conversation ${sourceId} not found`);\n    }\n\n    const forkedConversation = await this.startConversation({\n      provider,\n      model,\n      ownerId,\n      title: `Forked: ${sourceConversation.title}`,\n      initialMessages: [...(sourceConversation.messages || []), { role: 'user', content: prompt }],\n    });\n\n    logger.info(\n      {\n        sourceId,\n        forkedId: forkedConversation.id,\n        messageCount: forkedConversation.messages?.length || 0,\n      },\n      'Successfully forked conversation'\n    );\n\n    return forkedConversation;\n  }\n}\n\nexport const aiStorageService = new AiStorageService();\n","usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\services\\api-key-service.js","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\services\\cache-service.js","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\services\\circle-service.js","messages":[{"ruleId":"no-unused-vars","severity":1,"message":"'identityService' is defined but never used.","line":10,"column":10,"nodeType":"Identifier","messageId":"unusedVar","endLine":10,"endColumn":25,"suggestions":[{"messageId":"removeVar","data":{"varName":"identityService"},"fix":{"range":[249,305],"text":""},"desc":"Remove unused variable 'identityService'."}]},{"ruleId":"no-unused-vars","severity":1,"message":"'prisma' is assigned a value but never used.","line":599,"column":11,"nodeType":"Identifier","messageId":"unusedVar","endLine":599,"endColumn":17,"suggestions":[{"messageId":"removeVar","data":{"varName":"prisma"},"fix":{"range":[15018,15051],"text":""},"desc":"Remove unused variable 'prisma'."}]}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":2,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * Circle Service - Phase 2\n *\n * Advanced circle management with smart auto-population,\n * granular permissions, and social graph integration\n */\n\nimport { getPrismaClient } from '../lib/database.js';\nimport { logger } from '../lib/logger.js';\nimport { identityService } from './identity-service.js';\n\nconst log = logger.child({ module: 'circle-service' });\n\n// ============================================================================\n// Types\n// ============================================================================\n\nexport const CircleType = {\n  MANUAL: 'manual',\n  SMART: 'smart',\n  SHARED: 'shared',\n  EPHEMERAL: 'ephemeral',\n  INTEREST: 'interest',\n  PROXIMITY: 'proximity',\n  INTERACTION: 'interaction',\n};\n\nexport const CircleVisibility = {\n  SECRET: 'secret', // No one knows this circle exists\n  PRIVATE: 'private', // Members know, but not listed\n  VISIBLE: 'visible', // Listed on profile\n};\n\nexport const MemberRole = {\n  OWNER: 'owner',\n  ADMIN: 'admin',\n  MODERATOR: 'moderator',\n  MEMBER: 'member',\n  VIEWER: 'viewer',\n};\n\nexport const MemberStatus = {\n  ACTIVE: 'active',\n  PENDING: 'pending',\n  SUSPENDED: 'suspended',\n  LEFT: 'left',\n};\n\n// Default permissions per role\nconst DEFAULT_PERMISSIONS = {\n  [MemberRole.OWNER]: {\n    canInvite: true,\n    canShare: true,\n    canSeeOthers: true,\n    canPost: true,\n    canModerate: true,\n    canManageSettings: true,\n  },\n  [MemberRole.ADMIN]: {\n    canInvite: true,\n    canShare: true,\n    canSeeOthers: true,\n    canPost: true,\n    canModerate: true,\n    canManageSettings: false,\n  },\n  [MemberRole.MODERATOR]: {\n    canInvite: false,\n    canShare: true,\n    canSeeOthers: true,\n    canPost: true,\n    canModerate: true,\n    canManageSettings: false,\n  },\n  [MemberRole.MEMBER]: {\n    canInvite: false,\n    canShare: true,\n    canSeeOthers: true,\n    canPost: true,\n    canModerate: false,\n    canManageSettings: false,\n  },\n  [MemberRole.VIEWER]: {\n    canInvite: false,\n    canShare: false,\n    canSeeOthers: false,\n    canPost: false,\n    canModerate: false,\n    canManageSettings: false,\n  },\n};\n\n// ============================================================================\n// Circle CRUD Operations\n// ============================================================================\n\n/**\n * Create a new circle\n */\nexport async function createCircle(\n  ownerId,\n  {\n    name,\n    description,\n    icon,\n    color,\n    type = CircleType.MANUAL,\n    visibility = CircleVisibility.PRIVATE,\n    smartRules = null,\n    expiresAt = null,\n    isShared = false,\n    autoSuggest = true,\n  }\n) {\n  try {\n    const prisma = getPrismaClient();\n\n    const circle = await prisma.circle.create({\n      data: {\n        ownerId,\n        name,\n        description,\n        icon,\n        color,\n        type,\n        visibility,\n        smartRules,\n        expiresAt,\n        isShared,\n        autoSuggest,\n        memberCount: 1, // Owner is first member\n      },\n    });\n\n    // Add owner as member\n    await prisma.circleMember.create({\n      data: {\n        circleId: circle.id,\n        userId: ownerId,\n        role: MemberRole.OWNER,\n        permissions: DEFAULT_PERMISSIONS[MemberRole.OWNER],\n        addedBy: ownerId,\n        status: MemberStatus.ACTIVE,\n      },\n    });\n\n    log.info({ circleId: circle.id, ownerId, type }, 'Circle created');\n    return { success: true, circle };\n  } catch (error) {\n    log.error({ ownerId, error: error.message }, 'Failed to create circle');\n    return { success: false, error: 'Failed to create circle' };\n  }\n}\n\n/**\n * Get circle by ID with members\n */\nexport async function getCircle(circleId, requesterId = null) {\n  try {\n    const prisma = getPrismaClient();\n\n    const circle = await prisma.circle.findUnique({\n      where: { id: circleId },\n      include: {\n        members: {\n          where: { status: MemberStatus.ACTIVE },\n          include: {\n            user: {\n              select: {\n                id: true,\n                did: true,\n                handle: true,\n                displayName: true,\n                avatarUrl: true,\n                verificationLevel: true,\n              },\n            },\n          },\n        },\n        owner: {\n          select: {\n            id: true,\n            did: true,\n            handle: true,\n            displayName: true,\n            avatarUrl: true,\n          },\n        },\n      },\n    });\n\n    if (!circle) {\n      return { success: false, error: 'Circle not found' };\n    }\n\n    // Check visibility permissions\n    if (circle.visibility === CircleVisibility.SECRET) {\n      const isMember = circle.members.some((m) => m.userId === requesterId);\n      if (!isMember && circle.ownerId !== requesterId) {\n        return { success: false, error: 'Circle not found' };\n      }\n    }\n\n    return { success: true, circle };\n  } catch (error) {\n    log.error({ circleId, error: error.message }, 'Failed to get circle');\n    return { success: false, error: 'Failed to get circle' };\n  }\n}\n\n/**\n * Get all circles for a user\n */\nexport async function getUserCircles(userId, options = {}) {\n  try {\n    const prisma = getPrismaClient();\n    const { includeMemberships = true, type = null } = options;\n\n    const where = {\n      OR: [{ ownerId: userId }, { members: { some: { userId, status: MemberStatus.ACTIVE } } }],\n    };\n\n    if (type) {\n      where.AND = [{ type }];\n    }\n\n    const circles = await prisma.circle.findMany({\n      where,\n      include: includeMemberships\n        ? {\n            members: {\n              where: { status: MemberStatus.ACTIVE },\n              select: {\n                userId: true,\n                role: true,\n                user: {\n                  select: {\n                    id: true,\n                    handle: true,\n                    displayName: true,\n                    avatarUrl: true,\n                  },\n                },\n              },\n            },\n          }\n        : undefined,\n      orderBy: { updatedAt: 'desc' },\n    });\n\n    return { success: true, circles };\n  } catch (error) {\n    log.error({ userId, error: error.message }, 'Failed to get user circles');\n    return { success: false, error: 'Failed to get circles' };\n  }\n}\n\n/**\n * Update circle settings\n */\nexport async function updateCircle(circleId, userId, updates) {\n  try {\n    const prisma = getPrismaClient();\n\n    // Check permissions\n    const membership = await prisma.circleMember.findFirst({\n      where: {\n        circleId,\n        userId,\n        status: MemberStatus.ACTIVE,\n        OR: [\n          { role: MemberRole.OWNER },\n          { role: MemberRole.ADMIN },\n          { permissions: { path: ['canManageSettings'], equals: true } },\n        ],\n      },\n    });\n\n    if (!membership) {\n      return { success: false, error: 'Insufficient permissions' };\n    }\n\n    const allowedUpdates = [\n      'name',\n      'description',\n      'icon',\n      'color',\n      'visibility',\n      'autoSuggest',\n      'smartRules',\n    ];\n    const filteredUpdates = {};\n\n    for (const key of allowedUpdates) {\n      if (updates[key] !== undefined) {\n        filteredUpdates[key] = updates[key];\n      }\n    }\n\n    const circle = await prisma.circle.update({\n      where: { id: circleId },\n      data: {\n        ...filteredUpdates,\n        updatedAt: new Date(),\n      },\n    });\n\n    // Log activity\n    await logCircleActivity(circleId, userId, 'settings_changed', null, {\n      updates: filteredUpdates,\n    });\n\n    return { success: true, circle };\n  } catch (error) {\n    log.error({ circleId, userId, error: error.message }, 'Failed to update circle');\n    return { success: false, error: 'Failed to update circle' };\n  }\n}\n\n/**\n * Delete a circle\n */\nexport async function deleteCircle(circleId, userId) {\n  try {\n    const prisma = getPrismaClient();\n\n    // Only owner can delete\n    const circle = await prisma.circle.findFirst({\n      where: {\n        id: circleId,\n        ownerId: userId,\n      },\n    });\n\n    if (!circle) {\n      return { success: false, error: 'Circle not found or insufficient permissions' };\n    }\n\n    await prisma.circle.delete({\n      where: { id: circleId },\n    });\n\n    log.info({ circleId, userId }, 'Circle deleted');\n    return { success: true };\n  } catch (error) {\n    log.error({ circleId, userId, error: error.message }, 'Failed to delete circle');\n    return { success: false, error: 'Failed to delete circle' };\n  }\n}\n\n// ============================================================================\n// Member Management\n// ============================================================================\n\n/**\n * Add member to circle\n */\nexport async function addMember(circleId, inviterId, inviteeId, role = MemberRole.MEMBER) {\n  try {\n    const prisma = getPrismaClient();\n\n    // Check inviter permissions\n    const inviter = await prisma.circleMember.findFirst({\n      where: {\n        circleId,\n        userId: inviterId,\n        status: MemberStatus.ACTIVE,\n        OR: [\n          { role: { in: [MemberRole.OWNER, MemberRole.ADMIN] } },\n          { permissions: { path: ['canInvite'], equals: true } },\n        ],\n      },\n    });\n\n    if (!inviter) {\n      return { success: false, error: 'Insufficient permissions to invite' };\n    }\n\n    // Check if already member\n    const existing = await prisma.circleMember.findUnique({\n      where: {\n        circleId_userId: {\n          circleId,\n          userId: inviteeId,\n        },\n      },\n    });\n\n    if (existing) {\n      if (existing.status === MemberStatus.ACTIVE) {\n        return { success: false, error: 'Already a member' };\n      }\n      // Reactivate\n      await prisma.circleMember.update({\n        where: { id: existing.id },\n        data: {\n          status: MemberStatus.ACTIVE,\n          role,\n          permissions: DEFAULT_PERMISSIONS[role],\n          addedBy: inviterId,\n        },\n      });\n    } else {\n      // Create new member\n      await prisma.circleMember.create({\n        data: {\n          circleId,\n          userId: inviteeId,\n          role,\n          permissions: DEFAULT_PERMISSIONS[role],\n          addedBy: inviterId,\n          status: MemberStatus.ACTIVE,\n        },\n      });\n    }\n\n    // Update member count\n    await prisma.circle.update({\n      where: { id: circleId },\n      data: { memberCount: { increment: 1 } },\n    });\n\n    // Log activity\n    await logCircleActivity(circleId, inviterId, 'member_added', inviteeId);\n\n    log.info({ circleId, inviterId, inviteeId, role }, 'Member added to circle');\n    return { success: true };\n  } catch (error) {\n    log.error({ circleId, inviteeId, error: error.message }, 'Failed to add member');\n    return { success: false, error: 'Failed to add member' };\n  }\n}\n\n/**\n * Remove member from circle\n */\nexport async function removeMember(circleId, removerId, memberId) {\n  try {\n    const prisma = getPrismaClient();\n\n    // Check permissions\n    const remover = await prisma.circleMember.findFirst({\n      where: {\n        circleId,\n        userId: removerId,\n        status: MemberStatus.ACTIVE,\n      },\n    });\n\n    if (!remover) {\n      return { success: false, error: 'Not a member' };\n    }\n\n    // Can remove self, or if admin/owner\n    const canRemove =\n      removerId === memberId ||\n      [MemberRole.OWNER, MemberRole.ADMIN].includes(remover.role) ||\n      remover.permissions?.canModerate;\n\n    if (!canRemove) {\n      return { success: false, error: 'Insufficient permissions' };\n    }\n\n    // Cannot remove owner\n    const target = await prisma.circleMember.findFirst({\n      where: {\n        circleId,\n        userId: memberId,\n        role: MemberRole.OWNER,\n      },\n    });\n\n    if (target) {\n      return { success: false, error: 'Cannot remove circle owner' };\n    }\n\n    await prisma.circleMember.updateMany({\n      where: {\n        circleId,\n        userId: memberId,\n      },\n      data: {\n        status: MemberStatus.LEFT,\n        updatedAt: new Date(),\n      },\n    });\n\n    // Update member count\n    await prisma.circle.update({\n      where: { id: circleId },\n      data: { memberCount: { decrement: 1 } },\n    });\n\n    // Log activity\n    await logCircleActivity(circleId, removerId, 'member_removed', memberId);\n\n    return { success: true };\n  } catch (error) {\n    log.error({ circleId, memberId, error: error.message }, 'Failed to remove member');\n    return { success: false, error: 'Failed to remove member' };\n  }\n}\n\n/**\n * Update member role/permissions\n */\nexport async function updateMemberRole(circleId, updaterId, memberId, { role, permissions }) {\n  try {\n    const prisma = getPrismaClient();\n\n    // Check updater permissions\n    const updater = await prisma.circleMember.findFirst({\n      where: {\n        circleId,\n        userId: updaterId,\n        status: MemberStatus.ACTIVE,\n        role: { in: [MemberRole.OWNER, MemberRole.ADMIN] },\n      },\n    });\n\n    if (!updater) {\n      return { success: false, error: 'Insufficient permissions' };\n    }\n\n    // Admin cannot modify owner\n    if (updater.role === MemberRole.ADMIN) {\n      const target = await prisma.circleMember.findFirst({\n        where: { circleId, userId: memberId, role: MemberRole.OWNER },\n      });\n      if (target) {\n        return { success: false, error: 'Cannot modify owner' };\n      }\n    }\n\n    const updateData = {};\n    if (role) {\n      updateData.role = role;\n    }\n    if (permissions) {\n      updateData.permissions = permissions;\n    }\n\n    await prisma.circleMember.updateMany({\n      where: { circleId, userId: memberId },\n      data: updateData,\n    });\n\n    return { success: true };\n  } catch (error) {\n    log.error({ circleId, memberId, error: error.message }, 'Failed to update member role');\n    return { success: false, error: 'Failed to update member' };\n  }\n}\n\n// ============================================================================\n// Smart Circle Engine\n// ============================================================================\n\n/**\n * Evaluate smart circle rules and suggest members\n */\nexport async function evaluateSmartCircle(circleId) {\n  try {\n    const prisma = getPrismaClient();\n\n    const circle = await prisma.circle.findUnique({\n      where: { id: circleId },\n      include: {\n        members: { select: { userId: true } },\n      },\n    });\n\n    if (!circle || circle.type !== CircleType.SMART) {\n      return { success: false, error: 'Not a smart circle' };\n    }\n\n    const rules = circle.smartRules || {};\n    const existingMemberIds = circle.members.map((m) => m.userId);\n\n    // Build query based on rules\n    const candidates = await findSmartCircleCandidates(circle.ownerId, existingMemberIds, rules);\n\n    return {\n      success: true,\n      candidates: candidates.slice(0, 20),\n      totalCandidates: candidates.length,\n    };\n  } catch (error) {\n    log.error({ circleId, error: error.message }, 'Smart circle evaluation failed');\n    return { success: false, error: 'Evaluation failed' };\n  }\n}\n\n/**\n * Auto-populate smart circle with matching users\n */\nexport async function autoPopulateSmartCircle(circleId, maxAdditions = 10) {\n  try {\n    const prisma = getPrismaClient();\n\n    const { success, candidates } = await evaluateSmartCircle(circleId);\n    if (!success) {\n      return { success: false, error: 'Evaluation failed' };\n    }\n\n    let added = 0;\n    for (const candidate of candidates.slice(0, maxAdditions)) {\n      const result = await addMember(circleId, 'system', candidate.userId, MemberRole.MEMBER);\n      if (result.success) {\n        added++;\n      }\n    }\n\n    log.info({ circleId, added }, 'Smart circle auto-populated');\n    return { success: true, added };\n  } catch (error) {\n    log.error({ circleId, error: error.message }, 'Auto-population failed');\n    return { success: false, error: 'Auto-population failed' };\n  }\n}\n\n/**\n * Find candidates for smart circle\n */\nasync function findSmartCircleCandidates(ownerId, excludeIds, rules) {\n  const prisma = getPrismaClient();\n\n  // Base query: users connected to owner\n  const where = {\n    id: { notIn: excludeIds },\n    OR: [\n      // Mutual connections\n      {\n        following: {\n          some: {\n            followerId: ownerId,\n            status: 'active',\n          },\n        },\n      },\n      {\n        followers: {\n          some: {\n            followingId: ownerId,\n            status: 'active',\n          },\n        },\n      },\n    ],\n  };\n\n  // Apply interaction filter\n  if (rules.minInteractions) {\n    // This would require interaction tracking\n    // Simplified: check conversation co-participation\n  }\n\n  // Apply interest filter\n  if (rules.sharedInterests?.length > 0) {\n    where.AND = where.AND || [];\n    where.AND.push({\n      topicProfiles: {\n        some: {\n          topicSlug: { in: rules.sharedInterests },\n        },\n      },\n    });\n  }\n\n  const candidates = await prisma.user.findMany({\n    where,\n    select: {\n      id: true,\n      did: true,\n      handle: true,\n      displayName: true,\n      avatarUrl: true,\n      verificationLevel: true,\n      _count: {\n        select: {\n          following: true,\n          followers: true,\n        },\n      },\n    },\n    take: 50,\n  });\n\n  // Score and rank candidates\n  return candidates\n    .map((c) => ({\n      userId: c.id,\n      did: c.did,\n      handle: c.handle,\n      displayName: c.displayName,\n      avatarUrl: c.avatarUrl,\n      verificationLevel: c.verificationLevel,\n      mutualConnections: c._count.following + c._count.followers,\n      score: calculateCandidateScore(c, rules),\n    }))\n    .sort((a, b) => b.score - a.score);\n}\n\nfunction calculateCandidateScore(candidate, rules) {\n  let score = 0;\n\n  // Verification level boost\n  score += candidate.verificationLevel * 10;\n\n  // Mutual connections\n  score += candidate.mutualConnections * 5;\n\n  // Interest overlap (would need actual data)\n  if (rules.sharedInterests) {\n    score += rules.sharedInterests.length * 3;\n  }\n\n  return score;\n}\n\n// ============================================================================\n// Circle Suggestions\n// ============================================================================\n\n/**\n * Generate circle suggestions for a user\n */\nexport async function generateCircleSuggestions(userId) {\n  try {\n    const prisma = getPrismaClient();\n\n    // Get user's connections\n    const connections = await prisma.socialConnection.findMany({\n      where: {\n        followerId: userId,\n        status: 'active',\n      },\n      select: {\n        followingId: true,\n      },\n    });\n\n    const connectionIds = connections.map((c) => c.followingId);\n\n    // Find users with mutual connections\n    const suggestions = await prisma.user.findMany({\n      where: {\n        id: { notIn: [userId, ...connectionIds] },\n        followers: {\n          some: {\n            followerId: { in: connectionIds },\n          },\n        },\n      },\n      select: {\n        id: true,\n        did: true,\n        handle: true,\n        displayName: true,\n        avatarUrl: true,\n      },\n      take: 20,\n    });\n\n    // Create suggestion records\n    for (const suggestion of suggestions) {\n      await prisma.circleSuggestion.upsert({\n        where: {\n          userId_suggestedUserId: {\n            userId,\n            suggestedUserId: suggestion.id,\n          },\n        },\n        update: {},\n        create: {\n          userId,\n          suggestedUserId: suggestion.id,\n          reason: 'mutual_friends',\n          confidence: 0.7,\n        },\n      });\n    }\n\n    return { success: true, count: suggestions.length };\n  } catch (error) {\n    log.error({ userId, error: error.message }, 'Failed to generate suggestions');\n    return { success: false, error: 'Failed to generate suggestions' };\n  }\n}\n\n/**\n * Get circle suggestions for user\n */\nexport async function getCircleSuggestions(userId, options = {}) {\n  try {\n    const prisma = getPrismaClient();\n    const { limit = 10, includeDismissed = false } = options;\n\n    const suggestions = await prisma.circleSuggestion.findMany({\n      where: {\n        userId,\n        ...(includeDismissed ? {} : { dismissedAt: null }),\n        actedAt: null,\n      },\n      include: {\n        suggestedUser: {\n          select: {\n            id: true,\n            did: true,\n            handle: true,\n            displayName: true,\n            avatarUrl: true,\n            verificationLevel: true,\n          },\n        },\n      },\n      orderBy: { confidence: 'desc' },\n      take: limit,\n    });\n\n    return { success: true, suggestions };\n  } catch (error) {\n    log.error({ userId, error: error.message }, 'Failed to get suggestions');\n    return { success: false, error: 'Failed to get suggestions' };\n  }\n}\n\n// ============================================================================\n// Activity Logging\n// ============================================================================\n\nasync function logCircleActivity(circleId, actorId, action, targetId = null, details = null) {\n  try {\n    const prisma = getPrismaClient();\n\n    await prisma.circleActivityLog.create({\n      data: {\n        circleId,\n        action,\n        actorId,\n        targetId,\n        details,\n      },\n    });\n  } catch (error) {\n    log.error({ circleId, action, error: error.message }, 'Failed to log activity');\n  }\n}\n\n/**\n * Get circle activity log\n */\nexport async function getCircleActivity(circleId, options = {}) {\n  try {\n    const prisma = getPrismaClient();\n    const { limit = 50, offset = 0 } = options;\n\n    const activities = await prisma.circleActivityLog.findMany({\n      where: { circleId },\n      orderBy: { createdAt: 'desc' },\n      take: limit,\n      skip: offset,\n    });\n\n    return { success: true, activities };\n  } catch (error) {\n    log.error({ circleId, error: error.message }, 'Failed to get activity');\n    return { success: false, error: 'Failed to get activity' };\n  }\n}\n\n// ============================================================================\n// Export Service\n// ============================================================================\n\nexport const circleService = {\n  // Circle CRUD\n  createCircle,\n  getCircle,\n  getUserCircles,\n  updateCircle,\n  deleteCircle,\n\n  // Member Management\n  addMember,\n  removeMember,\n  updateMemberRole,\n\n  // Smart Circles\n  evaluateSmartCircle,\n  autoPopulateSmartCircle,\n\n  // Suggestions\n  generateCircleSuggestions,\n  getCircleSuggestions,\n\n  // Activity\n  getCircleActivity,\n\n  // Constants\n  CircleType,\n  CircleVisibility,\n  MemberRole,\n  MemberStatus,\n  DEFAULT_PERMISSIONS,\n};\n\nexport default circleService;\n","usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\services\\circuit-breaker.js","messages":[{"ruleId":"no-unused-vars","severity":1,"message":"'config' is defined but never used.","line":10,"column":10,"nodeType":"Identifier","messageId":"unusedVar","endLine":10,"endColumn":16,"suggestions":[{"messageId":"removeVar","data":{"varName":"config"},"fix":{"range":[257,301],"text":""},"desc":"Remove unused variable 'config'."}]}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * Circuit Breaker Service\n *\n * Provides fault tolerance for external AI providers (OpenAI, Anthropic, etc.).\n * Prevents cascading failures when a service is down or slow.\n */\n\nimport Opossum from 'opossum';\nimport { logger } from '../lib/logger.js';\nimport { config } from '../config/index.js';\nimport { serverErrorReporter } from '../utils/server-error-reporting.js';\n\nclass CircuitBreakerService {\n  constructor() {\n    this.breakers = new Map();\n    this.options = {\n      timeout: 30000, // If function takes longer than 30s, trigger failure\n      errorThresholdPercentage: 50, // When 50% of requests fail, open circuit\n      resetTimeout: 30000, // After 30s, try again (half-open)\n    };\n  }\n\n  /**\n   * Get or create a circuit breaker for a specific provider\n   * @param {string} providerName\n   * @param {Function} asyncFunction The function to wrap\n   */\n  getBreaker(providerName, asyncFunction) {\n    if (!this.breakers.has(providerName)) {\n      const breaker = new Opossum(asyncFunction, {\n        ...this.options,\n        name: providerName,\n      });\n\n      breaker.on('open', () => {\n        logger.warn(`Circuit OPEN for ${providerName}`);\n        serverErrorReporter.reportWarning(`Circuit breaker OPEN for provider: ${providerName}`, {\n          providerName,\n        });\n      });\n      breaker.on('halfOpen', () => logger.info(`Circuit HALF-OPEN for ${providerName}`));\n      breaker.on('close', () => logger.info(`Circuit CLOSED for ${providerName}`));\n      breaker.on('fallback', () => logger.warn(`Circuit FALLBACK for ${providerName}`));\n\n      this.breakers.set(providerName, breaker);\n    }\n    return this.breakers.get(providerName);\n  }\n\n  /**\n   * Execute function through circuit breaker\n   * @param {string} providerName\n   * @param {Function} asyncFunction\n   * @param  {...any} args\n   */\n  async execute(providerName, asyncFunction, ...args) {\n    const breaker = this.getBreaker(providerName, asyncFunction);\n    try {\n      return await breaker.fire(...args);\n    } catch (error) {\n      if (error.type === 'OpenCircuitError') {\n        throw new Error(\n          `Service ${providerName} is currently unavailable due to high failure rates.`\n        );\n      }\n      throw error;\n    }\n  }\n}\n\nexport const circuitBreakerService = new CircuitBreakerService();\n","usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\services\\context-generator.js","messages":[{"ruleId":"no-unused-vars","severity":1,"message":"'options' is assigned a value but never used. Allowed unused args must match /^_/u.","line":60,"column":62,"nodeType":"Identifier","messageId":"unusedVar","endLine":60,"endColumn":69,"suggestions":[{"messageId":"removeVar","data":{"varName":"options"},"fix":{"range":[2385,2399],"text":""},"desc":"Remove unused variable 'options'."}]},{"ruleId":"no-unused-vars","severity":1,"message":"'maxTokens' is assigned a value but never used.","line":207,"column":11,"nodeType":"Identifier","messageId":"unusedVar","endLine":207,"endColumn":20,"suggestions":[{"messageId":"removeVar","data":{"varName":"maxTokens"},"fix":{"range":[6451,6468],"text":""},"desc":"Remove unused variable 'maxTokens'."}]}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":2,"fixableErrorCount":0,"fixableWarningCount":0,"source":"import { getPrismaClient } from '../lib/database.js';\nimport { SimpleTokenEstimator } from '../context/index.js';\nimport { logger } from '../lib/logger.js';\n\nconst prisma = getPrismaClient();\nconst tokenEstimator = new SimpleTokenEstimator();\n\n// VIVIM Identity - inlined to avoid import issues in fallback path\nconst VIVIM_IDENTITY_PROMPT = `# VIVIM Identity (Who I Am) - READ THIS WHEN USER ASKS ABOUT VIVIM\n\n## VIVIM - Own Your AI\nVIVIM is a consumer app focused on capturing, owning, evolving, and sharing AI conversations.\n\n## ðŸš¨ YOUR INSTRUCTIONS (CRITICAL)\nWhen a user asks about VIVIM, you MUST use this context to answer. Do NOT guess or make up information.\n\n### Answer these questions using THIS context:\n- \"What is VIVIM?\" â†’ Use \"Core Pillars\" section\n- \"Is my data safe?\" â†’ Use \"Privacy & Security\" section  \n- \"What AI can I capture from?\" â†’ Use \"Supported AI Platforms\" section\n- \"What is BYOK?\" â†’ Use \"What I Can Do\" section\n- \"How does VIVIM work?\" â†’ Use \"System Architecture\" section\n\n### Simply respond normally if question is NOT about VIVIM.\n\n## Core Pillars\n- **Feed**: Social network for AI conversations (Discovery, inspiration)\n- **Vault**: Personal encrypted knowledge store (Ownership, privacy)\n- **Capture**: Extract from any AI platform (Liberation from walled gardens)\n- **Chat**: Continue with your own AI keys (Evolve, remix, build on knowledge)\n\n## System Architecture\n**3-App Distributed System:** Network (P2P/Federation), Server (Backend API), PWA (Frontend Client)\n\n## What I Can Do\n- Capture: Extract conversations from AI platforms\n- Vault: Encrypted personal knowledge store\n- BYOK Chat: Bring your own AI keys\n- Social Feed: Share and discover conversations\n\n## Supported AI Platforms\n### Capture From: ChatGPT, Claude, Gemini, Grok, DeepSeek, Kimi, Qwen, z.ai, Mistral\n### BYOK: OpenAI, Anthropic, Google, Mistral\n\n## Privacy & Security\n- **End-to-End Encryption**: Only you can read your vault\n- **Zero-Knowledge Sync**: Servers cannot read your data\n- **Local-First**: Data in browser IndexedDB first\n- **No AI Training**: Your data is never used to train AI\n\n## My Limitations\n- No real-time AI generation (conversation manager, not AI provider)\n- No built-in AI models (users must BYOK)\n\n---\n\n**Remember:** When users ask about VIVIM, use THIS context - don't make things up!\n`;\n\nexport async function generateContextBundles(conversationId, options = {}) {\n  const log = logger.child({ conversationId });\n\n  try {\n    const conv = await prisma.conversation.findUnique({\n      where: { id: conversationId },\n      include: { messages: { orderBy: { messageIndex: 'asc' } } },\n    });\n\n    if (!conv) {\n      throw new Error(`Conversation ${conversationId} not found`);\n    }\n\n    log.info({ messageCount: conv.messageCount }, 'Generating context bundles');\n\n    const bundles = {};\n\n    bundles.L4_conversation = await compileConversationBundle(conv);\n    bundles.L7_user_message = await compileUserMessageBundle(conv);\n\n    for (const [type, bundle] of Object.entries(bundles)) {\n      await storeBundle('Owen', type, bundle, conv.id);\n    }\n\n    log.info({ bundleTypes: Object.keys(bundles) }, 'Context bundles generated');\n\n    return bundles;\n  } catch (error) {\n    log.error({ error: error.message }, 'Failed to generate context bundles');\n    throw error;\n  }\n}\n\nasync function compileConversationBundle(conv) {\n  const content = buildConversationSummary(conv);\n\n  return {\n    compiledPrompt: content,\n    tokenCount: tokenEstimator.estimateTokens(content),\n    composition: {\n      messageCount: conv.messageCount,\n      wordCount: conv.totalWords,\n      title: conv.title,\n      provider: conv.provider,\n      model: conv.model,\n    },\n  };\n}\n\nasync function compileUserMessageBundle(conv) {\n  const userMessages = conv.messages.filter((m) => m.role === 'user');\n  const lastUserMessage = userMessages[userMessages.length - 1];\n\n  if (!lastUserMessage) {\n    return { compiledPrompt: '', tokenCount: 0, composition: { messageIndex: -1 } };\n  }\n\n  const content = Array.isArray(lastUserMessage.parts)\n    ? lastUserMessage.parts.map((p) => p.text || p.content || '').join('')\n    : String(lastUserMessage.parts);\n\n  return {\n    compiledPrompt: `## Current User Input\\n\\n${content}`,\n    tokenCount: tokenEstimator.estimateTokens(content),\n    composition: {\n      messageIndex: lastUserMessage.messageIndex,\n      timestamp: lastUserMessage.createdAt,\n    },\n  };\n}\n\nfunction buildConversationSummary(conv) {\n  const lines = [\n    '## Conversation Context',\n    `**Title:** ${conv.title}`,\n    `**Provider:** ${conv.provider}`,\n    `**Model:** ${conv.model || 'Unknown'}`,\n    `**Messages:** ${conv.messageCount}`,\n    `**Words:** ${conv.totalWords}`,\n    '',\n    '### Message History',\n    '',\n  ];\n\n  const recentMessages = conv.messages.slice(-10);\n\n  for (const msg of recentMessages) {\n    const role = msg.role === 'user' ? 'ðŸ‘¤ User' : 'ðŸ¤– Assistant';\n    const text = Array.isArray(msg.parts)\n      ? msg.parts\n          .map((p) => p.text || p.content || '')\n          .join('')\n          .substring(0, 300)\n      : String(msg.parts).substring(0, 300);\n\n    lines.push(`**${role}** (${msg.messageIndex + 1})`);\n    lines.push(text);\n    lines.push('');\n  }\n\n  return lines.join('\\n');\n}\n\nasync function storeBundle(userId, bundleType, bundle, conversationId) {\n  try {\n    await prisma.contextBundle.create({\n      data: {\n        userId,\n        bundleType,\n        compiledPrompt: bundle.compiledPrompt,\n        tokenCount: bundle.tokenCount,\n        composition: bundle.composition,\n        topicProfileId: null,\n        entityProfileId: null,\n        conversationId,\n        personaId: null,\n      },\n    });\n  } catch (e) {\n    if (e.code === 'P2002') {\n      await prisma.contextBundle.update({\n        where: {\n          userId_bundleType_topicProfileId_entityProfileId_conversationId_personaId: {\n            userId,\n            bundleType,\n            topicProfileId: null,\n            entityProfileId: null,\n            conversationId,\n            personaId: null,\n          },\n        },\n        data: {\n          compiledPrompt: bundle.compiledPrompt,\n          tokenCount: bundle.tokenCount,\n          composition: bundle.composition,\n          isDirty: false,\n          version: { increment: 1 },\n          compiledAt: new Date(),\n        },\n      });\n    } else {\n      throw e;\n    }\n  }\n}\n\nexport async function getContextForChat(conversationId, options = {}) {\n  const { maxTokens = 8000, includeHistory = true } = options;\n\n  const conv = await prisma.conversation.findUnique({\n    where: { id: conversationId },\n    include: {\n      messages: {\n        orderBy: { messageIndex: 'asc' },\n        take: includeHistory ? 50 : 5,\n      },\n    },\n  });\n\n  if (!conv) {\n    return { systemPrompt: '', layers: {} };\n  }\n\n  const layers = {};\n\n  const convBundle = await getCachedBundle('L4_conversation', conversationId);\n  if (convBundle) {\n    layers.L4 = convBundle.compiledPrompt;\n  } else {\n    const bundle = await compileConversationBundle(conv);\n    layers.L4 = bundle.compiledPrompt;\n  }\n\n  const userMessages = conv.messages.filter((m) => m.role === 'user');\n  if (userMessages.length > 0) {\n    const lastMsg = userMessages[userMessages.length - 1];\n    layers.L7 = Array.isArray(lastMsg.parts)\n      ? lastMsg.parts.map((p) => p.text || p.content || '').join('')\n      : String(lastMsg.parts);\n  }\n\n  const systemPrompt = buildSystemPrompt(layers);\n\n  return {\n    systemPrompt,\n    layers,\n    stats: {\n      messageCount: conv.messageCount,\n      tokenCount: tokenEstimator.estimateTokens(systemPrompt),\n    },\n  };\n}\n\nasync function getCachedBundle(bundleType, referenceId) {\n  return prisma.contextBundle.findFirst({\n    where: { bundleType, conversationId: referenceId, isDirty: false },\n  });\n}\n\nfunction buildSystemPrompt(layers) {\n  const parts = [];\n\n  // L0: Always include VIVIM identity - this tells the AI who VIVIM is\n  parts.push(VIVIM_IDENTITY_PROMPT);\n\n  // L4: Conversation context\n  if (layers.L4) {\n    parts.push(layers.L4);\n  }\n\n  // L7: Current user message\n  if (layers.L7) {\n    parts.push(`## Current Request\\n\\n${layers.L7}`);\n  }\n\n  return parts.join('\\n\\n---\\n\\n');\n}\n\nexport const contextGenerator = {\n  generateContextBundles,\n  getContextForChat,\n};\n","usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\services\\debug-reporter.js","messages":[{"ruleId":"no-unused-vars","severity":1,"message":"'ErrorLevel' is defined but never used.","line":6,"column":3,"nodeType":"Identifier","messageId":"unusedVar","endLine":6,"endColumn":13,"suggestions":[{"messageId":"removeVar","data":{"varName":"ErrorLevel"},"fix":{"range":[103,117],"text":""},"desc":"Remove unused variable 'ErrorLevel'."}]},{"ruleId":"no-unused-vars","severity":1,"message":"'dirname' is defined but never used.","line":10,"column":16,"nodeType":"Identifier","messageId":"unusedVar","endLine":10,"endColumn":23,"suggestions":[{"messageId":"removeVar","data":{"varName":"dirname"},"fix":{"range":[244,253],"text":""},"desc":"Remove unused variable 'dirname'."}]},{"ruleId":"no-unused-vars","severity":1,"message":"'pipeline' is defined but never used.","line":11,"column":10,"nodeType":"Identifier","messageId":"unusedVar","endLine":11,"endColumn":18,"suggestions":[{"messageId":"removeVar","data":{"varName":"pipeline"},"fix":{"range":[269,312],"text":""},"desc":"Remove unused variable 'pipeline'."}]},{"ruleId":"no-unused-vars","severity":1,"message":"'chainId' is assigned a value but never used.","line":262,"column":17,"nodeType":"Identifier","messageId":"unusedVar","endLine":262,"endColumn":24,"suggestions":[{"messageId":"removeVar","data":{"varName":"chainId"},"fix":{"range":[6581,6588],"text":""},"desc":"Remove unused variable 'chainId'."}]}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":4,"fixableErrorCount":0,"fixableWarningCount":0,"source":"import { logger } from '../lib/logger.js';\nimport {\n  classifyError,\n  shouldAlert,\n  formatErrorForLog,\n  ErrorLevel,\n  Severity,\n} from '../lib/error-classifier.js';\nimport { createWriteStream, existsSync, mkdirSync } from 'fs';\nimport { join, dirname } from 'path';\nimport { pipeline } from 'stream/promises';\n\nconst DEBUG_LOG_DIR = process.env.DEBUG_LOG_DIR || 'logs/debug';\nconst RING_BUFFER_SIZE = parseInt(process.env.DEBUG_BUFFER_SIZE || '1000');\n\nclass DebugReporter {\n  constructor() {\n    this.errors = [];\n    this.warnings = [];\n    this.info = [];\n    this.queries = [];\n    this.externalCalls = [];\n    this.extractions = [];\n    this.syncOperations = [];\n    this.stateSnapshots = [];\n    this.operationChains = new Map();\n    this.startTime = Date.now();\n    this.requestCount = 0;\n    this.errorCount = 0;\n    this.initLogDirectory();\n  }\n\n  initLogDirectory() {\n    try {\n      if (!existsSync(DEBUG_LOG_DIR)) {\n        mkdirSync(DEBUG_LOG_DIR, { recursive: true });\n      }\n    } catch (err) {\n      logger.warn({ error: err.message }, 'Failed to create debug log directory');\n    }\n  }\n\n  getTimestamp() {\n    return new Date().toISOString();\n  }\n\n  addToRingBuffer(buffer, item, maxSize = RING_BUFFER_SIZE) {\n    buffer.push({ ...item, timestamp: this.getTimestamp() });\n    if (buffer.length > maxSize) {\n      buffer.shift();\n    }\n  }\n\n  trackError(error, context = {}) {\n    const classified = classifyError(error, context);\n    const errorRecord = {\n      id: `err_${Date.now()}_${Math.random().toString(36).slice(2, 9)}`,\n      ...classified,\n      context: {\n        ...context,\n        requestId: context.requestId || null,\n        userId: context.userId || null,\n        endpoint: context.endpoint || null,\n      },\n      shouldAlert: shouldAlert(classified),\n    };\n\n    this.addToRingBuffer(this.errors, errorRecord);\n    this.errorCount++;\n\n    const logData = formatErrorForLog(classified, context.requestId);\n    logger.error(logData, `ERROR: ${classified.message}`);\n\n    if (errorRecord.shouldAlert) {\n      this.writeToFile('errors', errorRecord);\n    }\n\n    return errorRecord;\n  }\n\n  trackWarning(warning, context = {}) {\n    const warningRecord = {\n      id: `warn_${Date.now()}_${Math.random().toString(36).slice(2, 9)}`,\n      message: warning.message || warning,\n      category: warning.category || 'WARNING',\n      severity: warning.severity || Severity.MEDIUM,\n      context,\n      timestamp: this.getTimestamp(),\n    };\n\n    this.addToRingBuffer(this.warnings, warningRecord);\n    logger.warn({ ...warningRecord, requestId: context.requestId }, warningRecord.message);\n\n    return warningRecord;\n  }\n\n  trackInfo(info, context = {}) {\n    const infoRecord = {\n      id: `info_${Date.now()}_${Math.random().toString(36).slice(2, 9)}`,\n      message: info.message || info,\n      category: info.category || 'INFO',\n      context,\n      timestamp: this.getTimestamp(),\n    };\n\n    this.addToRingBuffer(this.info, infoRecord);\n    logger.info({ ...infoRecord, requestId: context.requestId }, infoRecord.message);\n\n    return infoRecord;\n  }\n\n  trackQuery(query, duration, resultCount, context = {}) {\n    const isSlow = duration > 50;\n    const queryRecord = {\n      query: typeof query === 'string' ? query : query.name || 'unknown',\n      duration,\n      resultCount,\n      isSlow,\n      slowThreshold: 50,\n      ...context,\n      timestamp: this.getTimestamp(),\n    };\n\n    this.addToRingBuffer(this.queries, queryRecord);\n\n    if (isSlow) {\n      logger.warn(\n        { query: queryRecord.query, duration, resultCount, threshold: 50 },\n        `SLOW_QUERY: ${duration}ms`\n      );\n    }\n\n    return queryRecord;\n  }\n\n  trackExternalCall(provider, duration, status, context = {}) {\n    const callRecord = {\n      provider,\n      duration,\n      status,\n      success: status >= 200 && status < 400,\n      ...context,\n      timestamp: this.getTimestamp(),\n    };\n\n    this.addToRingBuffer(this.externalCalls, callRecord);\n\n    if (!callRecord.success) {\n      logger.warn(\n        { provider, duration, status, ...context },\n        `EXTERNAL_CALL_FAILED: ${provider} returned ${status}`\n      );\n    }\n\n    return callRecord;\n  }\n\n  trackExtraction(provider, url, duration, messageCount, context = {}) {\n    const extractionRecord = {\n      provider,\n      url,\n      duration,\n      messageCount,\n      success: messageCount > 0,\n      ...context,\n      timestamp: this.getTimestamp(),\n    };\n\n    this.addToRingBuffer(this.extractions, extractionRecord);\n\n    logger.info(\n      { provider, url, duration, messageCount },\n      `EXTRACTION: ${provider} - ${messageCount} messages in ${duration}ms`\n    );\n\n    return extractionRecord;\n  }\n\n  trackSyncOperation(operation, entityType, entityId, context = {}) {\n    const syncRecord = {\n      operation,\n      entityType,\n      entityId,\n      ...context,\n      timestamp: this.getTimestamp(),\n    };\n\n    this.addToRingBuffer(this.syncOperations, syncRecord);\n\n    logger.debug(\n      { operation, entityType, entityId, ...context },\n      `SYNC_OP: ${operation} on ${entityType}:${entityId}`\n    );\n\n    return syncRecord;\n  }\n\n  captureState(label, state, context = {}) {\n    const snapshot = {\n      label,\n      state: this.sanitizeState(state),\n      context,\n      memoryUsage: process.memoryUsage(),\n      timestamp: this.getTimestamp(),\n    };\n\n    this.addToRingBuffer(this.stateSnapshots, snapshot);\n    logger.debug({ label, memory: snapshot.memoryUsage.heapUsed }, `STATE_CAPTURE: ${label}`);\n\n    return snapshot;\n  }\n\n  captureMemoryUsage() {\n    const usage = process.memoryUsage();\n    const snapshot = {\n      heapUsed: usage.heapUsed,\n      heapTotal: usage.heapTotal,\n      external: usage.external,\n      rss: usage.rss,\n      timestamp: this.getTimestamp(),\n    };\n\n    return snapshot;\n  }\n\n  captureDatabaseConnections() {\n    return {\n      active: 0,\n      idle: 0,\n      waiting: 0,\n      timestamp: this.getTimestamp(),\n    };\n  }\n\n  startOperationChain(id, context = {}) {\n    this.operationChains.set(id, {\n      id,\n      operations: [],\n      context,\n      startTime: Date.now(),\n    });\n\n    return id;\n  }\n\n  addToChain(operation, metadata = {}) {\n    for (const [chainId, chain] of this.operationChains) {\n      if (chain.operations.length === 0 || chain.operations[chain.operations.length - 1].endTime) {\n        chain.operations.push({\n          ...operation,\n          metadata,\n          startTime: Date.now(),\n          endTime: null,\n        });\n        return chainId;\n      }\n    }\n    return null;\n  }\n\n  endChain(result) {\n    for (const [chainId, chain] of this.operationChains) {\n      const lastOp = chain.operations[chain.operations.length - 1];\n      if (lastOp && !lastOp.endTime) {\n        lastOp.endTime = Date.now();\n        lastOp.duration = lastOp.endTime - lastOp.startTime;\n        lastOp.result = result;\n        chain.endTime = Date.now();\n        chain.totalDuration = chain.endTime - chain.startTime;\n        return chain;\n      }\n    }\n    return null;\n  }\n\n  sanitizeState(state) {\n    if (state === null || state === undefined) {\n      return state;\n    }\n    if (typeof state === 'string' || typeof state === 'number' || typeof state === 'boolean') {\n      return state;\n    }\n\n    const sanitized = JSON.parse(JSON.stringify(state));\n\n    const sensitiveKeys = [\n      'password',\n      'token',\n      'secret',\n      'key',\n      'authorization',\n      'cookie',\n      'credential',\n    ];\n    const sanitizeObject = (obj) => {\n      if (typeof obj !== 'object' || obj === null) {\n        return;\n      }\n      for (const key of Object.keys(obj)) {\n        if (sensitiveKeys.some((k) => key.toLowerCase().includes(k))) {\n          obj[key] = '[REDACTED]';\n        } else if (typeof obj[key] === 'object') {\n          sanitizeObject(obj[key]);\n        }\n      }\n    };\n\n    sanitizeObject(sanitized);\n    return sanitized;\n  }\n\n  writeToFile(type, data) {\n    try {\n      const filename = `${type}-${new Date().toISOString().split('T')[0]}.jsonl`;\n      const filepath = join(DEBUG_LOG_DIR, filename);\n      const line = `${JSON.stringify(data)}\\n`;\n\n      const stream = createWriteStream(filepath, { flags: 'a' });\n      stream.write(line);\n      stream.end();\n    } catch (err) {\n      logger.error({ error: err.message }, 'Failed to write to debug log file');\n    }\n  }\n\n  getStatus() {\n    return {\n      uptime: Date.now() - this.startTime,\n      requestCount: this.requestCount,\n      errorCount: this.errorCount,\n      errorsInBuffer: this.errors.length,\n      warningsInBuffer: this.warnings.length,\n      queriesInBuffer: this.queries.length,\n      externalCallsInBuffer: this.externalCalls.length,\n      extractionsInBuffer: this.extractions.length,\n      syncOperationsInBuffer: this.syncOperations.length,\n      memoryUsage: this.captureMemoryUsage(),\n    };\n  }\n\n  getErrors(filters = {}) {\n    let filtered = [...this.errors];\n\n    if (filters.category) {\n      filtered = filtered.filter((e) => e.category === filters.category);\n    }\n    if (filters.level) {\n      filtered = filtered.filter((e) => e.level === filters.level);\n    }\n    if (filters.severity) {\n      filtered = filtered.filter((e) => e.severity === filters.severity);\n    }\n    if (filters.limit) {\n      filtered = filtered.slice(-filters.limit);\n    }\n\n    return filtered;\n  }\n\n  getPerformanceMetrics() {\n    const slowQueries = this.queries\n      .filter((q) => q.isSlow)\n      .sort((a, b) => b.duration - a.duration)\n      .slice(0, 20);\n\n    const slowExternalCalls = this.externalCalls\n      .filter((c) => !c.success)\n      .sort((a, b) => b.duration - a.duration)\n      .slice(0, 20);\n\n    const extractionStats = this.extractions.reduce(\n      (acc, e) => {\n        acc.total++;\n        acc.totalDuration += e.duration;\n        acc.totalMessages += e.messageCount;\n        if (e.success) {\n          acc.successful++;\n        } else {\n          acc.failed++;\n        }\n        return acc;\n      },\n      { total: 0, totalDuration: 0, totalMessages: 0, successful: 0, failed: 0 }\n    );\n\n    return {\n      slowQueries,\n      slowExternalCalls,\n      extractionStats: {\n        ...extractionStats,\n        avgDuration:\n          extractionStats.total > 0 ? extractionStats.totalDuration / extractionStats.total : 0,\n      },\n    };\n  }\n\n  incrementRequestCount() {\n    this.requestCount++;\n  }\n\n  clear() {\n    this.errors = [];\n    this.warnings = [];\n    this.info = [];\n    this.queries = [];\n    this.externalCalls = [];\n    this.extractions = [];\n    this.syncOperations = [];\n    this.stateSnapshots = [];\n    this.operationChains.clear();\n    logger.info('Debug reporter buffer cleared');\n  }\n}\n\nexport const debugReporter = new DebugReporter();\n\nexport default debugReporter;\n","usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\services\\extraction-validator.js","messages":[{"ruleId":"no-unused-vars","severity":1,"message":"'logger' is defined but never used.","line":6,"column":10,"nodeType":"Identifier","messageId":"unusedVar","endLine":6,"endColumn":16,"suggestions":[{"messageId":"removeVar","data":{"varName":"logger"},"fix":{"range":[111,153],"text":""},"desc":"Remove unused variable 'logger'."}]},{"ruleId":"no-unused-vars","severity":1,"message":"'provider' is defined but never used. Allowed unused args must match /^_/u.","line":16,"column":33,"nodeType":"Identifier","messageId":"unusedVar","endLine":16,"endColumn":41,"suggestions":[{"messageId":"removeVar","data":{"varName":"provider"},"fix":{"range":[392,402],"text":""},"desc":"Remove unused variable 'provider'."}]}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":2,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * Extraction Result Validator and Normalizer\n * Ensures all extractors return consistent, valid data\n */\n\nimport { logger } from '../lib/logger.js';\n\n/**\n * Validates and normalizes extracted conversation data\n */\nexport class ExtractionValidator {\n  /**\n   * Validate extraction result\n   * Returns { valid: true } or { valid: false, errors: [...] }\n   */\n  static validate(conversation, provider) {\n    const errors = [];\n    const warnings = [];\n\n    // Required fields check\n    if (!conversation) {\n      return { valid: false, errors: ['Conversation is null/undefined'] };\n    }\n\n    if (!conversation.messages) {\n      errors.push('Missing messages array');\n    } else if (!Array.isArray(conversation.messages)) {\n      errors.push('Messages is not an array');\n    } else {\n      // Validate each message\n      conversation.messages.forEach((msg, idx) => {\n        if (!msg.role) {\n          errors.push(`Message ${idx}: Missing role`);\n        } else if (!['user', 'assistant', 'system', 'tool'].includes(msg.role)) {\n          warnings.push(`Message ${idx}: Unusual role \"${msg.role}\"`);\n        }\n\n        // Check for content or parts\n        const hasContent = msg.content !== undefined && msg.content !== null;\n        const hasParts = Array.isArray(msg.parts) && msg.parts.length > 0;\n\n        if (!hasContent && !hasParts) {\n          errors.push(`Message ${idx}: No content or parts`);\n        }\n      });\n    }\n\n    // Warning for empty extraction\n    if (conversation.messages?.length === 0) {\n      errors.push('Zero messages extracted - likely extraction failure');\n    }\n\n    return {\n      valid: errors.length === 0,\n      errors,\n      warnings,\n      messageCount: conversation.messages?.length || 0,\n    };\n  }\n\n  /**\n   * Normalize conversation to standard format\n   * Converts various extractor outputs to consistent schema\n   */\n  static normalize(conversation, provider) {\n    if (!conversation) {\n      return null;\n    }\n\n    const normalized = {\n      id: conversation.id || this.generateId(),\n      provider: conversation.provider || provider,\n      sourceUrl: conversation.sourceUrl || '',\n      title: conversation.title || `${provider} Conversation`,\n      model: conversation.model || provider,\n      createdAt: this.normalizeTimestamp(conversation.createdAt),\n      updatedAt:\n        this.normalizeTimestamp(conversation.updatedAt) ||\n        this.normalizeTimestamp(conversation.createdAt),\n      capturedAt: this.normalizeTimestamp(conversation.capturedAt) || new Date().toISOString(),\n      exportedAt: new Date().toISOString(),\n      messages: [],\n      metadata: {\n        ...conversation.metadata,\n        provider,\n        normalized: true,\n        originalFormat: this.detectOriginalFormat(conversation),\n      },\n    };\n\n    // Normalize messages\n    if (Array.isArray(conversation.messages)) {\n      normalized.messages = conversation.messages.map((msg, idx) =>\n        this.normalizeMessage(msg, idx)\n      );\n    }\n\n    // Calculate stats\n    normalized.stats = this.calculateStats(normalized.messages);\n\n    return normalized;\n  }\n\n  /**\n   * Normalize a single message\n   */\n  static normalizeMessage(msg, index) {\n    const normalized = {\n      id: msg.id || this.generateId(),\n      role: msg.role || 'assistant',\n      author: msg.author || (msg.role === 'user' ? 'User' : 'Assistant'),\n      messageIndex: index,\n      createdAt: this.normalizeTimestamp(msg.createdAt || msg.timestamp),\n      status: msg.status || 'completed',\n      metadata: msg.metadata || {},\n    };\n\n    // Normalize content to parts array\n    if (Array.isArray(msg.parts) && msg.parts.length > 0) {\n      // Already in parts format\n      normalized.parts = msg.parts.map((p) => this.normalizePart(p));\n    } else if (Array.isArray(msg.content)) {\n      // Content is array - convert to parts\n      normalized.parts = msg.content.map((c) => this.normalizePart(c));\n    } else if (typeof msg.content === 'string') {\n      // Content is string - wrap in text part\n      normalized.parts = [\n        {\n          type: 'text',\n          content: msg.content,\n        },\n      ];\n    } else {\n      // Unknown format - empty parts\n      normalized.parts = [];\n    }\n\n    // Backwards compatibility: also set content field\n    normalized.content = normalized.parts;\n\n    return normalized;\n  }\n\n  /**\n   * Normalize a content part\n   */\n  static normalizePart(part) {\n    if (typeof part === 'string') {\n      return { type: 'text', content: part };\n    }\n\n    if (!part || typeof part !== 'object') {\n      return { type: 'text', content: String(part) };\n    }\n\n    // Ensure required fields\n    return {\n      type: part.type || 'text',\n      content: part.content !== undefined ? part.content : '',\n      metadata: part.metadata || {},\n      // Backwards compat for legacy fields\n      language: part.language,\n      alt: part.alt,\n    };\n  }\n\n  /**\n   * Detect original format for debugging\n   */\n  static detectOriginalFormat(conv) {\n    if (!conv.messages || conv.messages.length === 0) {\n      return 'empty';\n    }\n\n    const firstMsg = conv.messages[0];\n    if (firstMsg.parts) {\n      return 'parts-array';\n    }\n    if (Array.isArray(firstMsg.content)) {\n      return 'content-array';\n    }\n    if (typeof firstMsg.content === 'string') {\n      return 'content-string';\n    }\n    return 'unknown';\n  }\n\n  /**\n   * Normalize timestamp to ISO string\n   */\n  static normalizeTimestamp(ts) {\n    if (!ts) {\n      return null;\n    }\n\n    try {\n      const date = new Date(ts);\n      if (isNaN(date.getTime())) {\n        return null;\n      }\n      return date.toISOString();\n    } catch {\n      return null;\n    }\n  }\n\n  /**\n   * Calculate conversation statistics\n   */\n  static calculateStats(messages) {\n    let totalWords = 0;\n    let totalCharacters = 0;\n    let userMessageCount = 0;\n    let aiMessageCount = 0;\n    let totalCodeBlocks = 0;\n    let totalImages = 0;\n    let totalTables = 0;\n    let totalMermaidDiagrams = 0;\n    let totalLatexBlocks = 0;\n\n    for (const msg of messages) {\n      if (msg.role === 'user') {\n        userMessageCount++;\n      }\n      if (msg.role === 'assistant') {\n        aiMessageCount++;\n      }\n\n      // Count from parts\n      if (Array.isArray(msg.parts)) {\n        for (const part of msg.parts) {\n          if (part.type === 'text' && typeof part.content === 'string') {\n            totalWords += part.content.split(/\\s+/).filter((w) => w).length;\n            totalCharacters += part.content.length;\n          } else if (part.type === 'code') {\n            totalCodeBlocks++;\n            if (typeof part.content === 'string') {\n              totalCharacters += part.content.length;\n            }\n          } else if (part.type === 'image') {\n            totalImages++;\n          } else if (part.type === 'table') {\n            totalTables++;\n          } else if (part.type === 'mermaid') {\n            totalMermaidDiagrams++;\n          } else if (part.type === 'latex') {\n            totalLatexBlocks++;\n          }\n        }\n      }\n    }\n\n    return {\n      messageCount: messages.length,\n      userMessageCount,\n      aiMessageCount,\n      totalWords,\n      totalCharacters,\n      totalCodeBlocks,\n      totalImages,\n      totalTables,\n      totalMermaidDiagrams,\n      totalLatexBlocks,\n      firstMessageAt: messages[0]?.createdAt || new Date().toISOString(),\n      lastMessageAt: messages[messages.length - 1]?.createdAt || new Date().toISOString(),\n    };\n  }\n\n  /**\n   * Generate unique ID\n   */\n  static generateId() {\n    return `${Date.now()}-${Math.random().toString(36).substr(2, 9)}`;\n  }\n}\n\nexport default ExtractionValidator;\n","usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\services\\extractor.js","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\services\\feed-service.js","messages":[{"ruleId":"no-unused-vars","severity":1,"message":"'RANKING_WEIGHTS' is assigned a value but never used.","line":21,"column":7,"nodeType":"Identifier","messageId":"unusedVar","endLine":21,"endColumn":22,"suggestions":[{"messageId":"removeVar","data":{"varName":"RANKING_WEIGHTS"},"fix":{"range":[566,666],"text":""},"desc":"Remove unused variable 'RANKING_WEIGHTS'."}]},{"ruleId":"no-undef","severity":2,"message":"'getTopicBasedContent' is not defined.","line":167,"column":32,"nodeType":"Identifier","messageId":"undef","endLine":167,"endColumn":52},{"ruleId":"no-unused-vars","severity":1,"message":"'prisma' is assigned a value but never used.","line":187,"column":9,"nodeType":"Identifier","messageId":"unusedVar","endLine":187,"endColumn":15,"suggestions":[{"messageId":"removeVar","data":{"varName":"prisma"},"fix":{"range":[5369,5402],"text":""},"desc":"Remove unused variable 'prisma'."}]},{"ruleId":"no-unused-vars","severity":1,"message":"'preferences' is defined but never used. Allowed unused args must match /^_/u.","line":222,"column":57,"nodeType":"Identifier","messageId":"unusedVar","endLine":222,"endColumn":68,"suggestions":[{"messageId":"removeVar","data":{"varName":"preferences"},"fix":{"range":[6373,6386],"text":""},"desc":"Remove unused variable 'preferences'."}]},{"ruleId":"no-unused-vars","severity":1,"message":"'prisma' is assigned a value but never used.","line":223,"column":9,"nodeType":"Identifier","messageId":"unusedVar","endLine":223,"endColumn":15,"suggestions":[{"messageId":"removeVar","data":{"varName":"prisma"},"fix":{"range":[6392,6425],"text":""},"desc":"Remove unused variable 'prisma'."}]},{"ruleId":"no-unused-vars","severity":1,"message":"'preferences' is defined but never used. Allowed unused args must match /^_/u.","line":310,"column":33,"nodeType":"Identifier","messageId":"unusedVar","endLine":310,"endColumn":44,"suggestions":[{"messageId":"removeVar","data":{"varName":"preferences"},"fix":{"range":[8625,8638],"text":""},"desc":"Remove unused variable 'preferences'."}]},{"ruleId":"no-undef","severity":2,"message":"'source' is not defined.","line":597,"column":9,"nodeType":"Identifier","messageId":"undef","endLine":597,"endColumn":15},{"ruleId":"no-undef","severity":2,"message":"'sourceDetails' is not defined.","line":598,"column":9,"nodeType":"Identifier","messageId":"undef","endLine":598,"endColumn":22},{"ruleId":"no-undef","severity":2,"message":"'rankingFactors' is not defined.","line":599,"column":9,"nodeType":"Identifier","messageId":"undef","endLine":599,"endColumn":23},{"ruleId":"no-undef","severity":2,"message":"'score' is not defined.","line":600,"column":9,"nodeType":"Identifier","messageId":"undef","endLine":600,"endColumn":14},{"ruleId":"no-unused-vars","severity":1,"message":"'sourceTopics' is assigned a value but never used.","line":800,"column":11,"nodeType":"Identifier","messageId":"unusedVar","endLine":800,"endColumn":23},{"ruleId":"no-unused-vars","severity":1,"message":"'prisma' is assigned a value but never used.","line":859,"column":11,"nodeType":"Identifier","messageId":"unusedVar","endLine":859,"endColumn":17,"suggestions":[{"messageId":"removeVar","data":{"varName":"prisma"},"fix":{"range":[23609,23642],"text":""},"desc":"Remove unused variable 'prisma'."}]}],"suppressedMessages":[],"errorCount":5,"fatalErrorCount":0,"warningCount":7,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * Feed & Discovery Service - Phase 4\n *\n * Privacy-preserving recommendation engine with\n * algorithmic transparency and user control\n */\n\nimport { getPrismaClient } from '../lib/database.js';\nimport { logger } from '../lib/logger.js';\n\nconst log = logger.child({ module: 'feed-service' });\n\n// ============================================================================\n// Constants\n// ============================================================================\n\nconst DEFAULT_FEED_LIMIT = 50;\nconst MAX_FEED_LIMIT = 200;\nconst FEED_ITEM_EXPIRY_HOURS = 24;\n\nconst RANKING_WEIGHTS = {\n  recency: 0.3,\n  relevance: 0.4,\n  socialProof: 0.2,\n  diversity: 0.1,\n};\n\n// ============================================================================\n// Feed Generation\n// ============================================================================\n\n/**\n * Generate personalized feed for user\n */\nexport async function generateFeed(userId, options = {}) {\n  try {\n    const prisma = getPrismaClient();\n    const { limit = DEFAULT_FEED_LIMIT, offset = 0, refresh = false } = options;\n\n    // Get user preferences\n    const preferences = await getFeedPreferences(userId);\n\n    // Check if we have cached feed items\n    if (!refresh) {\n      const cachedItems = await prisma.feedItem.findMany({\n        where: {\n          userId,\n          status: 'active',\n          expiresAt: { gt: new Date() },\n        },\n        orderBy: { score: 'desc' },\n        take: limit,\n        skip: offset,\n      });\n\n      if (cachedItems.length >= limit * 0.8) {\n        return {\n          success: true,\n          items: cachedItems,\n          fromCache: true,\n        };\n      }\n    }\n\n    // Generate new feed\n    const candidates = await gatherFeedCandidates(userId, preferences);\n    const ranked = await rankFeedItems(candidates, userId, preferences);\n    const diversified = applyDiversity(ranked, preferences);\n\n    // Save to database\n    await saveFeedItems(userId, diversified);\n\n    const items = diversified.slice(offset, offset + limit);\n\n    return {\n      success: true,\n      items,\n      fromCache: false,\n      totalCandidates: candidates.length,\n    };\n  } catch (error) {\n    log.error({ userId, error: error.message }, 'Feed generation failed');\n    return { success: false, error: 'Failed to generate feed' };\n  }\n}\n\n/**\n * Gather candidate content for feed\n */\nasync function gatherFeedCandidates(userId, preferences) {\n  const prisma = getPrismaClient();\n  const candidates = [];\n  const since = new Date(Date.now() - preferences.timeRangeHours * 60 * 60 * 1000);\n\n  // 1. Content from circles\n  if (preferences.showFromCircles) {\n    const circleContent = await prisma.$queryRaw`\n      SELECT \n        cc.content_id as \"contentId\",\n        cc.content_type as \"contentType\",\n        c.owner_id as \"authorId\",\n        'circle' as source,\n        json_build_object('circleId', cc.circle_id) as \"sourceDetails\",\n        acu.created_at as \"createdAt\"\n      FROM circle_content cc\n      JOIN circle_members cm ON cc.circle_id = cm.circle_id\n      JOIN atomic_chat_units acu ON cc.content_id = acu.id\n      JOIN conversations c ON acu.conversation_id = c.id\n      WHERE cm.user_id = ${userId}\n        AND cm.status = 'active'\n        AND acu.created_at > ${since}\n        AND acu.quality_overall > ${preferences.minQualityScore}\n      ORDER BY acu.created_at DESC\n      LIMIT 100\n    `;\n    candidates.push(...circleContent);\n  }\n\n  // 2. Content from network (friends-of-friends)\n  if (preferences.showFromNetwork) {\n    const networkContent = await prisma.$queryRaw`\n      SELECT \n        acu.id as \"contentId\",\n        'acu' as \"contentType\",\n        acu.author_did as \"authorId\",\n        'network' as source,\n        json_build_object('degree', 2) as \"sourceDetails\",\n        acu.created_at as \"createdAt\"\n      FROM atomic_chat_units acu\n      JOIN social_connections sc ON acu.author_did = sc.following_id\n      WHERE sc.follower_id = ${userId}\n        AND sc.status = 'active'\n        AND acu.created_at > ${since}\n        AND acu.sharing_policy IN ('public', 'network')\n        AND acu.quality_overall > ${preferences.minQualityScore}\n      ORDER BY acu.created_at DESC\n      LIMIT 50\n    `;\n    candidates.push(...networkContent);\n  }\n\n  // 3. Trending content\n  if (preferences.showTrending) {\n    const trending = await prisma.trendingContent.findMany({\n      where: {\n        expiresAt: { gt: new Date() },\n        trendScore: { gt: 0.5 },\n      },\n      orderBy: { trendScore: 'desc' },\n      take: 30,\n    });\n\n    candidates.push(\n      ...trending.map((t) => ({\n        contentId: t.contentId,\n        contentType: t.contentType,\n        authorId: null,\n        source: 'trending',\n        sourceDetails: { trendScore: t.trendScore },\n        createdAt: t.lastCalculatedAt,\n      }))\n    );\n  }\n\n  // 4. Topic-based recommendations\n  if (preferences.showFromTopics) {\n    const topicContent = await getTopicBasedContent(userId, preferences, since);\n    candidates.push(...topicContent);\n  }\n\n  // Remove duplicates\n  const seen = new Set();\n  return candidates.filter((c) => {\n    if (seen.has(c.contentId)) {\n      return false;\n    }\n    seen.add(c.contentId);\n    return true;\n  });\n}\n\n/**\n * Rank feed items using multiple factors\n * Now uses dynamic weights from user preferences\n */\nasync function rankFeedItems(candidates, userId, preferences) {\n  const prisma = getPrismaClient();\n  const ranked = [];\n\n  // Get dynamic weights from preferences\n  const weights = {\n    recency: (preferences.recencyWeight || 30) / 100,\n    relevance: (preferences.relevanceWeight || 40) / 100,\n    socialProof: (preferences.socialProofWeight || 20) / 100,\n    diversity: (preferences.diversityWeight || 10) / 100,\n  };\n\n  for (const candidate of candidates) {\n    const factors = await calculateRankingFactors(candidate, userId, preferences);\n\n    // Weighted sum using dynamic weights\n    const score =\n      factors.recency * weights.recency +\n      factors.relevance * weights.relevance +\n      factors.socialProof * weights.socialProof +\n      factors.diversity * weights.diversity;\n\n    ranked.push({\n      ...candidate,\n      score,\n      rankingFactors: factors,\n      weightsUsed: weights,\n    });\n  }\n\n  return ranked.sort((a, b) => b.score - a.score);\n}\n\n/**\n * Calculate ranking factors for content\n */\nasync function calculateRankingFactors(content, userId, preferences) {\n  const prisma = getPrismaClient();\n\n  // Recency (time decay)\n  const age = Date.now() - new Date(content.createdAt).getTime();\n  const hoursOld = age / (1000 * 60 * 60);\n  const recency = Math.exp(-hoursOld / 24); // Exponential decay over 24 hours\n\n  // Relevance (topic match)\n  const relevance = await calculateRelevance(content, userId);\n\n  // Social proof (friends who engaged)\n  const socialProof = await calculateSocialProof(content, userId);\n\n  // Diversity (placeholder - would track recent topics)\n  const diversity = 0.5;\n\n  return {\n    recency,\n    relevance,\n    socialProof,\n    diversity,\n  };\n}\n\n/**\n * Calculate relevance score\n */\nasync function calculateRelevance(content, userId) {\n  const prisma = getPrismaClient();\n\n  // Get user topic preferences\n  const userTopics = await prisma.userTopicPreference.findMany({\n    where: { userId },\n    select: { topicSlug: true, affinity: true },\n  });\n\n  // Get content topics\n  const contentTopics = await prisma.topicConversation.findMany({\n    where: { conversationId: content.contentId },\n    select: { topicSlug: true },\n  });\n\n  if (contentTopics.length === 0) {\n    return 0.5;\n  }\n\n  // Calculate overlap\n  let relevance = 0;\n  for (const ct of contentTopics) {\n    const userPref = userTopics.find((ut) => ut.topicSlug === ct.topicSlug);\n    if (userPref) {\n      relevance += userPref.affinity;\n    }\n  }\n\n  return Math.min(1, relevance / contentTopics.length);\n}\n\n/**\n * Calculate social proof score\n */\nasync function calculateSocialProof(content, userId) {\n  const prisma = getPrismaClient();\n\n  // Count friends who engaged\n  const friendEngagements = await prisma.userInteraction.count({\n    where: {\n      contentId: content.contentId,\n      userId: {\n        in: prisma.socialConnection\n          .findMany({\n            where: { followerId: userId, status: 'active' },\n            select: { followingId: true },\n          })\n          .then((cons) => cons.map((c) => c.followingId)),\n      },\n      action: { in: ['like', 'comment', 'share'] },\n    },\n  });\n\n  // Normalize (assume max 10 friends engaging = full score)\n  return Math.min(1, friendEngagements / 10);\n}\n\n/**\n * Apply diversity to prevent filter bubbles\n */\nfunction applyDiversity(ranked, preferences) {\n  // Simple diversity: interleave different sources\n  const bySource = {};\n  for (const item of ranked) {\n    if (!bySource[item.source]) {\n      bySource[item.source] = [];\n    }\n    bySource[item.source].push(item);\n  }\n\n  const diversified = [];\n  const sources = Object.keys(bySource);\n  let index = 0;\n\n  while (diversified.length < ranked.length) {\n    for (const source of sources) {\n      if (bySource[source][index]) {\n        diversified.push(bySource[source][index]);\n      }\n    }\n    index++;\n  }\n\n  return diversified;\n}\n\n/**\n * Save generated feed items\n */\nasync function saveFeedItems(userId, items) {\n  const prisma = getPrismaClient();\n  const expiresAt = new Date(Date.now() + FEED_ITEM_EXPIRY_HOURS * 60 * 60 * 1000);\n\n  // Clear old items\n  await prisma.feedItem.deleteMany({\n    where: { userId },\n  });\n\n  // Insert new items\n  for (let i = 0; i < items.length; i++) {\n    const item = items[i];\n    await prisma.feedItem.create({\n      data: {\n        userId,\n        contentId: item.contentId,\n        contentType: item.contentType,\n        authorId: item.authorId,\n        source: item.source,\n        sourceDetails: item.sourceDetails,\n        score: item.score,\n        rankingFactors: item.rankingFactors,\n        position: i,\n        expiresAt,\n      },\n    });\n  }\n}\n\n// ============================================================================\n// Discovery Recommendations\n// ============================================================================\n\n/**\n * Generate discovery recommendations\n */\nexport async function generateDiscovery(userId, options = {}) {\n  try {\n    const { type = 'all', limit = 20 } = options;\n    const recommendations = [];\n\n    if (type === 'all' || type === 'content') {\n      const contentRecs = await recommendContent(userId, limit / 2);\n      recommendations.push(...contentRecs);\n    }\n\n    if (type === 'all' || type === 'users') {\n      const userRecs = await recommendUsers(userId, limit / 3);\n      recommendations.push(...userRecs);\n    }\n\n    if (type === 'all' || type === 'circles') {\n      const circleRecs = await recommendCircles(userId, limit / 3);\n      recommendations.push(...circleRecs);\n    }\n\n    // Save recommendations\n    await saveDiscoveryItems(userId, recommendations);\n\n    return {\n      success: true,\n      recommendations,\n    };\n  } catch (error) {\n    log.error({ userId, error: error.message }, 'Discovery generation failed');\n    return { success: false, error: 'Failed to generate recommendations' };\n  }\n}\n\n/**\n * Recommend content\n */\nasync function recommendContent(userId, limit) {\n  const prisma = getPrismaClient();\n\n  // Get similar content to what user liked\n  const likedContent = await prisma.userInteraction.findMany({\n    where: {\n      userId,\n      action: { in: ['like', 'bookmark'] },\n    },\n    orderBy: { createdAt: 'desc' },\n    take: 10,\n  });\n\n  const contentIds = likedContent.map((i) => i.contentId);\n\n  // Find similar content\n  const similar = await prisma.contentSimilarity.findMany({\n    where: {\n      sourceId: { in: contentIds },\n      similarityScore: { gt: 0.6 },\n    },\n    orderBy: { similarityScore: 'desc' },\n    take: limit * 2,\n  });\n\n  // Filter out already seen\n  const seen = new Set(contentIds);\n  const recommendations = [];\n\n  for (const sim of similar) {\n    if (!seen.has(sim.targetId)) {\n      recommendations.push({\n        type: 'content',\n        contentId: sim.targetId,\n        confidence: sim.similarityScore,\n        reasons: [\n          {\n            type: 'similarity',\n            description: 'Similar to content you liked',\n            weight: sim.similarityScore,\n          },\n        ],\n      });\n    }\n\n    if (recommendations.length >= limit) {\n      break;\n    }\n  }\n\n  return recommendations;\n}\n\n/**\n * Recommend users to follow\n */\nasync function recommendUsers(userId, limit) {\n  const prisma = getPrismaClient();\n\n  // Get friends-of-friends not already following\n  const recommendations = await prisma.$queryRaw`\n    WITH user_friends AS (\n      SELECT following_id\n      FROM social_connections\n      WHERE follower_id = ${userId} AND status = 'active'\n    ),\n    friends_of_friends AS (\n      SELECT sc.following_id as user_id, COUNT(*) as mutual_count\n      FROM social_connections sc\n      JOIN user_friends uf ON sc.follower_id = uf.following_id\n      WHERE sc.following_id != ${userId}\n        AND sc.status = 'active'\n        AND sc.following_id NOT IN (SELECT following_id FROM user_friends)\n      GROUP BY sc.following_id\n      HAVING COUNT(*) >= 2\n    )\n    SELECT \n      u.id,\n      u.handle,\n      u.display_name as \"displayName\",\n      u.avatar_url as \"avatarUrl\",\n      fof.mutual_count as \"mutualCount\"\n    FROM friends_of_friends fof\n    JOIN users u ON fof.user_id = u.id\n    ORDER BY fof.mutual_count DESC\n    LIMIT ${limit}\n  `;\n\n  return recommendations.map((r) => ({\n    type: 'user',\n    userId: r.id,\n    confidence: Math.min(1, r.mutualCount / 5),\n    reasons: [\n      {\n        type: 'social',\n        description: `${r.mutualCount} mutual connections`,\n        weight: r.mutualCount / 10,\n      },\n    ],\n  }));\n}\n\n/**\n * Recommend circles to join\n */\nasync function recommendCircles(userId, limit) {\n  const prisma = getPrismaClient();\n\n  // Find circles with friends as members\n  const recommendations = await prisma.$queryRaw`\n    SELECT \n      c.id,\n      c.name,\n      c.description,\n      c.type,\n      COUNT(DISTINCT cm.user_id) as \"friendCount\"\n    FROM circles c\n    JOIN circle_members cm ON c.id = cm.circle_id\n    JOIN social_connections sc ON cm.user_id = sc.following_id\n    WHERE sc.follower_id = ${userId}\n      AND sc.status = 'active'\n      AND cm.status = 'active'\n      AND c.visibility IN ('visible', 'private')\n      AND c.id NOT IN (\n        SELECT circle_id \n        FROM circle_members \n        WHERE user_id = ${userId}\n      )\n    GROUP BY c.id\n    HAVING COUNT(DISTINCT cm.user_id) >= 2\n    ORDER BY \"friendCount\" DESC\n    LIMIT ${limit}\n  `;\n\n  return recommendations.map((r) => ({\n    type: 'circle',\n    circleId: r.id,\n    confidence: Math.min(1, r.friendCount / 5),\n    reasons: [\n      {\n        type: 'social',\n        description: `${r.friendCount} friends are members`,\n        weight: r.friendCount / 10,\n      },\n    ],\n  }));\n}\n\n/**\n * Save discovery items\n */\nasync function saveDiscoveryItems(userId, items) {\n  const prisma = getPrismaClient();\n  const expiresAt = new Date(Date.now() + 7 * 24 * 60 * 60 * 1000); // 7 days\n\n  for (const item of items) {\n    await prisma.discoveryItem.create({\n      data: {\n        userId,\n        contentId: item.contentId,\n        userIdRecommended: item.userId,\n        circleId: item.circleId,\n        type: item.type,\n        reasons: item.reasons,\n        confidence: item.confidence,\n        expiresAt,\n      },\n    });\n  }\n}\n\n// ============================================================================\n// Algorithmic Transparency\n// ============================================================================\n\n/**\n * Explain why content was recommended\n */\nexport async function explainRecommendation(userId, contentId) {\n  try {\n    const prisma = getPrismaClient();\n\n    // Get feed item\n    const feedItem = await prisma.feedItem.findFirst({\n      where: { userId, contentId },\n      select: {\n        source,\n        sourceDetails,\n        rankingFactors,\n        score,\n      },\n    });\n\n    if (!feedItem) {\n      return { success: false, error: 'Item not found in feed' };\n    }\n\n    // Build explanation\n    const explanation = {\n      summary: `This was shown because it matched your ${feedItem.source} preferences`,\n      factors: [\n        {\n          name: 'Recency',\n          description: 'How recently it was posted',\n          weight: 0.3,\n          value: feedItem.rankingFactors.recency,\n          impact: feedItem.rankingFactors.recency > 0.7 ? 'high' : 'medium',\n        },\n        {\n          name: 'Relevance',\n          description: 'Match to your interests',\n          weight: 0.4,\n          value: feedItem.rankingFactors.relevance,\n          impact: feedItem.rankingFactors.relevance > 0.7 ? 'high' : 'medium',\n        },\n        {\n          name: 'Social Proof',\n          description: 'Friends who engaged',\n          weight: 0.2,\n          value: feedItem.rankingFactors.socialProof,\n          impact: feedItem.rankingFactors.socialProof > 0.5 ? 'high' : 'low',\n        },\n        {\n          name: 'Diversity',\n          description: 'Variety in your feed',\n          weight: 0.1,\n          value: feedItem.rankingFactors.diversity,\n          impact: 'medium',\n        },\n      ],\n      controls: {\n        seeMoreLikeThis: true,\n        seeLessLikeThis: true,\n        adjustPreference: `/settings/feed?topic=${feedItem.sourceDetails?.topic}`,\n        whyThis: `From your ${feedItem.source} network`,\n      },\n    };\n\n    // Save decision for audit\n    await prisma.algorithmicDecision.create({\n      data: {\n        userId,\n        decisionType: 'feed_ranking',\n        contentId,\n        explanation,\n        factors: explanation.factors,\n        modelVersion: 'v1',\n        privacyBudgetUsed: 0.1,\n      },\n    });\n\n    return { success: true, explanation };\n  } catch (error) {\n    log.error({ userId, contentId, error: error.message }, 'Explanation failed');\n    return { success: false, error: 'Failed to generate explanation' };\n  }\n}\n\n/**\n * Get user's feed preferences\n */\nexport async function getFeedPreferences(userId) {\n  const prisma = getPrismaClient();\n\n  let prefs = await prisma.feedPreferences.findUnique({\n    where: { userId },\n  });\n\n  if (!prefs) {\n    // Create default preferences\n    prefs = await prisma.feedPreferences.create({\n      data: {\n        userId,\n        showFromCircles: true,\n        showFromNetwork: true,\n        showFromTopics: true,\n        showTrending: true,\n        showDiscoverable: true,\n        recencyWeight: 30,\n        relevanceWeight: 40,\n        socialProofWeight: 20,\n        diversityWeight: 10,\n        privacyBudget: 50,\n        timeRangeHours: 168,\n      },\n    });\n  }\n\n  return prefs;\n}\n\n/**\n * Update feed preferences\n */\nexport async function updateFeedPreferences(userId, updates) {\n  const prisma = getPrismaClient();\n\n  const allowedUpdates = [\n    'showFromCircles',\n    'showFromNetwork',\n    'showFromTopics',\n    'showTrending',\n    'showDiscoverable',\n    'recencyWeight',\n    'relevanceWeight',\n    'socialProofWeight',\n    'diversityWeight',\n    'privacyBudget',\n    'minQualityScore',\n    'timeRangeHours',\n  ];\n\n  const filteredUpdates = {};\n  for (const key of allowedUpdates) {\n    if (updates[key] !== undefined) {\n      filteredUpdates[key] = updates[key];\n    }\n  }\n\n  const prefs = await prisma.feedPreferences.update({\n    where: { userId },\n    data: filteredUpdates,\n  });\n\n  return { success: true, preferences: prefs };\n}\n\n// ============================================================================\n// Interaction Tracking\n// ============================================================================\n\n/**\n * Track user interaction\n */\nexport async function trackInteraction(userId, contentId, action, context = {}) {\n  try {\n    const prisma = getPrismaClient();\n\n    await prisma.userInteraction.create({\n      data: {\n        userId,\n        contentId,\n        action,\n        context,\n        duration: context.duration,\n        completionRate: context.completionRate,\n      },\n    });\n\n    // Update feed item status\n    if (['view', 'like', 'share'].includes(action)) {\n      await prisma.feedItem.updateMany({\n        where: { userId, contentId },\n        data: {\n          wasViewed: action === 'view' || undefined,\n          wasEngaged: ['like', 'comment', 'share'].includes(action),\n          wasShared: action === 'share',\n        },\n      });\n    }\n\n    return { success: true };\n  } catch (error) {\n    log.error({ userId, contentId, error: error.message }, 'Track interaction failed');\n    return { success: false, error: 'Failed to track interaction' };\n  }\n}\n\n// ============================================================================\n// Similar Conversations\n// ============================================================================\n\nexport async function getSimilarConversations(userId, conversationId, options = {}) {\n  try {\n    const prisma = getPrismaClient();\n    const { limit = 10 } = options;\n\n    const sourceConv = await prisma.conversation.findUnique({\n      where: { id: conversationId },\n      include: {\n        topicConversations: { include: { topic: true } },\n        atomicChatUnits: { take: 5, orderBy: { messageIndex: 'desc' } },\n      },\n    });\n\n    if (!sourceConv) {\n      return { success: false, error: 'Conversation not found' };\n    }\n\n    const sourceTopics = sourceConv.topicConversations.map((tc) => tc.topic.slug);\n\n    const similar = await prisma.$queryRaw`\n      SELECT \n        c.id, c.title, c.provider, c.owner_id as \"ownerId\",\n        c.\"messageCount\", c.\"totalWords\", c.\"capturedAt\",\n        COUNT(DISTINCT tc.topic_id) as \"topicOverlap\"\n      FROM conversations c\n      LEFT JOIN topic_conversations tc ON c.id = tc.conversation_id\n      WHERE c.id != ${conversationId}\n        AND c.owner_id = ${userId}\n      GROUP BY c.id, c.title, c.provider, c.\"ownerId\", c.\"messageCount\", c.\"totalWords\", c.\"capturedAt\"\n      ORDER BY \"topicOverlap\" DESC, c.\"capturedAt\" DESC\n      LIMIT ${limit}\n    `;\n\n    const recommendations = similar.map((conv) => ({\n      conversation: {\n        id: conv.id,\n        title: conv.title,\n        provider: conv.provider,\n        ownerId: conv.ownerId,\n      },\n      score: Math.min(100, Number(conv.topicOverlap) * 25),\n      reason: { icon: 'hash', text: `${conv.topicOverlap} shared topics` },\n      source: 'similar',\n    }));\n\n    return { success: true, recommendations };\n  } catch (error) {\n    log.error({ userId, conversationId, error: error.message }, 'Get similar conversations failed');\n    return { success: false, error: 'Failed to get similar conversations' };\n  }\n}\n\n// ============================================================================\n// Privacy Budget Enforcement\n// ============================================================================\n\nexport async function enforcePrivacyBudget(userId, preferences) {\n  const budget = preferences.privacyBudget || 50;\n  const personalizationRatio = budget / 100;\n\n  return {\n    allowTopicMatching: personalizationRatio > 0.2,\n    allowSocialProof: personalizationRatio > 0.3,\n    allowNetworkDiscovery: personalizationRatio > 0.4,\n    allowTrending: personalizationRatio > 0.1,\n    maxRecencyDays: Math.max(1, Math.floor(30 * personalizationRatio)),\n    maxNetworkDegree: personalizationRatio > 0.5 ? 2 : 1,\n  };\n}\n\n// ============================================================================\n// Context-Aware Feed\n// ============================================================================\n\nexport async function generateContextualFeed(userId, options = {}) {\n  try {\n    const prisma = getPrismaClient();\n    const { limit = 20, activeTopics = [] } = options;\n\n    const preferences = await getFeedPreferences(userId);\n    const privacy = await enforcePrivacyBudget(userId, preferences);\n    const candidates = await gatherFeedCandidates(userId, preferences);\n\n    if (activeTopics.length > 0 && privacy.allowTopicMatching) {\n      for (const candidate of candidates) {\n        const matchCount = (candidate.topicSlugs || []).filter((t) =>\n          activeTopics.includes(t)\n        ).length;\n        if (matchCount > 0) {\n          candidate.topicBoost = Math.min(0.5, matchCount * 0.15);\n          candidate.score = (candidate.score || 0) * (1 + candidate.topicBoost);\n        }\n      }\n    }\n\n    const ranked = await rankFeedItems(candidates, userId, preferences);\n    const diversified = applyDiversity(ranked, preferences);\n\n    return {\n      success: true,\n      items: diversified.slice(0, limit),\n      contextBoost: {\n        activeTopics,\n        privacy,\n        boosted: candidates.filter((c) => c.topicBoost).length,\n      },\n    };\n  } catch (error) {\n    log.error({ userId, error: error.message }, 'Contextual feed generation failed');\n    return { success: false, error: 'Failed to generate contextual feed' };\n  }\n}\n\n// ============================================================================\n// Export Service\n// ============================================================================\n\nexport const feedService = {\n  generateFeed,\n  generateContextualFeed,\n  generateDiscovery,\n  getSimilarConversations,\n  explainRecommendation,\n  getFeedPreferences,\n  updateFeedPreferences,\n  enforcePrivacyBudget,\n  trackInteraction,\n  DEFAULT_FEED_LIMIT,\n  MAX_FEED_LIMIT,\n};\n\nexport default feedService;\n","usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\services\\mfa-service.js","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\services\\moderation-service.js","messages":[{"ruleId":"no-unused-vars","severity":1,"message":"'debugReporter' is defined but never used.","line":9,"column":10,"nodeType":"Identifier","messageId":"unusedVar","endLine":9,"endColumn":23,"suggestions":[{"messageId":"removeVar","data":{"varName":"debugReporter"},"fix":{"range":[201,253],"text":""},"desc":"Remove unused variable 'debugReporter'."}]},{"ruleId":"no-unused-vars","severity":1,"message":"'prisma' is assigned a value but never used.","line":122,"column":9,"nodeType":"Identifier","messageId":"unusedVar","endLine":122,"endColumn":15,"suggestions":[{"messageId":"removeVar","data":{"varName":"prisma"},"fix":{"range":[3120,3153],"text":""},"desc":"Remove unused variable 'prisma'."}]},{"ruleId":"no-case-declarations","severity":2,"message":"Unexpected lexical declaration in case block.","line":372,"column":7,"nodeType":"VariableDeclaration","messageId":"unexpected","endLine":372,"endColumn":49,"suggestions":[{"messageId":"addBrackets","fix":{"range":[9383,9506],"text":"{ const keywords = condition.keywords || [];\n      return keywords.some((k) => text.toLowerCase().includes(k.toLowerCase())); }"},"desc":"Add {} brackets around the case block."}]},{"ruleId":"no-undef","severity":2,"message":"'flag' is not defined.","line":438,"column":33,"nodeType":"Identifier","messageId":"undef","endLine":438,"endColumn":37},{"ruleId":"no-undef","severity":2,"message":"'flag' is not defined.","line":452,"column":21,"nodeType":"Identifier","messageId":"undef","endLine":452,"endColumn":25},{"ruleId":"no-undef","severity":2,"message":"'flag' is not defined.","line":453,"column":26,"nodeType":"Identifier","messageId":"undef","endLine":453,"endColumn":30},{"ruleId":"no-undef","severity":2,"message":"'flag' is not defined.","line":453,"column":42,"nodeType":"Identifier","messageId":"undef","endLine":453,"endColumn":46}],"suppressedMessages":[],"errorCount":5,"fatalErrorCount":0,"warningCount":2,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * Content Moderation Service\n *\n * Handles content flagging, review, and automated moderation\n */\n\nimport { getPrismaClient } from '../lib/database.js';\nimport { logger } from '../lib/logger.js';\nimport { debugReporter } from './debug-reporter.js';\n\nconst log = logger.child({ module: 'moderation-service' });\n\n// ============================================================================\n// Content Flagging (User Reports)\n// ============================================================================\n\n/**\n * Report content for moderation\n */\nexport async function flagContent(reporterId, options) {\n  const prisma = getPrismaClient();\n\n  const { contentId, contentType, contentOwnerId, contentText, reason, description } = options;\n\n  // Check for duplicate report\n  const existing = await prisma.contentFlag.findFirst({\n    where: {\n      reporterId,\n      contentId,\n      contentType,\n      status: { in: ['PENDING', 'REVIEWING', 'FLAGGED'] },\n    },\n  });\n\n  if (existing) {\n    return { success: false, error: 'Content already reported' };\n  }\n\n  const flag = await prisma.contentFlag.create({\n    data: {\n      contentId,\n      contentType,\n      contentOwnerId,\n      contentText: contentText?.substring(0, 5000), // Store first 5000 chars\n      reporterId,\n      reason,\n      description,\n      priority: getPriorityForReason(reason),\n    },\n  });\n\n  // Update user moderation record if content owner exists\n  if (contentOwnerId) {\n    await incrementUserStrike(contentOwnerId, reason);\n  }\n\n  log.info({ flagId: flag.id, reporterId, contentType, reason }, 'Content flagged');\n\n  return { success: true, flagId: flag.id };\n}\n\n/**\n * Get priority based on reason\n */\nfunction getPriorityForReason(reason) {\n  const priorityMap = {\n    SELF_HARM: 'CRITICAL',\n    UNDERAGE: 'CRITICAL',\n    VIOLENCE: 'HIGH',\n    SEXUAL: 'HIGH',\n    HATE_SPEECH: 'HIGH',\n    HARASSMENT: 'MEDIUM',\n    SPAM: 'LOW',\n    MISINFORMATION: 'MEDIUM',\n    PRIVACY: 'MEDIUM',\n    COPYRIGHT: 'MEDIUM',\n    IMPERSONATION: 'MEDIUM',\n    DANGEROUS: 'HIGH',\n    OTHER: 'LOW',\n  };\n  return priorityMap[reason] || 'LOW';\n}\n\n// ============================================================================\n// Moderation Review\n// ============================================================================\n\n/**\n * Review a flagged content\n */\nexport async function reviewFlag(flagId, reviewerId, decision) {\n  const prisma = getPrismaClient();\n\n  const { status, resolution, action, notifyUser } = decision;\n\n  const flag = await prisma.contentFlag.update({\n    where: { id: flagId },\n    data: {\n      status,\n      reviewerId,\n      reviewedAt: new Date(),\n      resolution,\n      actionTaken: action,\n      userNotified: notifyUser === true,\n    },\n  });\n\n  // Take action on content if needed\n  if (action && flag.contentId && flag.contentType) {\n    await takeContentAction(flag.contentId, flag.contentType, action);\n  }\n\n  log.info({ flagId, reviewerId, status, action }, 'Flag reviewed');\n\n  return { success: true, flag };\n}\n\n/**\n * Take action on content\n */\nasync function takeContentAction(contentId, contentType, action) {\n  const prisma = getPrismaClient();\n\n  switch (action) {\n    case 'remove':\n      // Mark content as removed/hidden\n      await hideContent(contentId, contentType);\n      break;\n    case 'warn':\n      // Content owner will be warned (handled separately)\n      break;\n    case 'ban':\n      await hideContent(contentId, contentType);\n      // Could also ban the user\n      break;\n    default:\n      log.warn({ action }, 'Unknown content action');\n  }\n}\n\n/**\n * Hide content based on type\n */\nasync function hideContent(contentId, contentType) {\n  const prisma = getPrismaClient();\n\n  const updateMap = {\n    conversation: { state: 'REMOVED' },\n    acu: { state: 'REMOVED' },\n    memory: { isArchived: true },\n    group_post: {\n      /* Would need status field */\n    },\n  };\n\n  const update = updateMap[contentType];\n  if (!update) {\n    return;\n  }\n\n  // Map content type to model\n  const modelMap = {\n    conversation: prisma.conversation,\n    acu: prisma.atomicChatUnit,\n    memory: prisma.memory,\n    group_post: prisma.groupPost,\n  };\n\n  const model = modelMap[contentType];\n  if (model) {\n    await model.update({\n      where: { id: contentId },\n      data: update,\n    });\n  }\n}\n\n// ============================================================================\n// User Moderation Records (Strike System)\n// ============================================================================\n\n/**\n * Get user moderation record\n */\nexport async function getUserModerationRecord(userId) {\n  const prisma = getPrismaClient();\n\n  let record = await prisma.userModerationRecord.findUnique({\n    where: { userId },\n  });\n\n  if (!record) {\n    record = await prisma.userModerationRecord.create({\n      data: { userId },\n    });\n  }\n\n  return record;\n}\n\n/**\n * Increment user strike count\n */\nasync function incrementUserStrike(userId, reason) {\n  const prisma = getPrismaClient();\n\n  const reasonFieldMap = {\n    SPAM: 'spamCount',\n    HARASSMENT: 'harassmentCount',\n    HATE_SPEECH: 'hateSpeechCount',\n    VIOLENCE: 'violenceCount',\n    SEXUAL: 'sexualCount',\n    MISINFORMATION: 'misinformationCount',\n    OTHER: 'otherCount',\n  };\n\n  const field = reasonFieldMap[reason] || 'otherCount';\n\n  // Get current record or create\n  let record = await prisma.userModerationRecord.findUnique({ where: { userId } });\n\n  if (!record) {\n    record = await prisma.userModerationRecord.create({\n      data: { userId, [field]: 1, totalStrikes: 1, lastStrikedAt: new Date() },\n    });\n  } else {\n    // Increment the specific count\n    await prisma.userModerationRecord.update({\n      where: { userId },\n      data: {\n        [field]: { increment: 1 },\n        totalStrikes: { increment: 1 },\n        lastStrikedAt: new Date(),\n      },\n    });\n  }\n\n  // Check if action needed based on strike count\n  await checkAndApplyStrikes(userId);\n}\n\n/**\n * Check strike count and apply automatic actions\n */\nasync function checkAndApplyStrikes(userId) {\n  const prisma = getPrismaClient();\n  const record = await prisma.userModerationRecord.findUnique({ where: { userId } });\n\n  if (!record || record.isBanned) {\n    return;\n  }\n\n  // Auto-warn after 3 strikes\n  if (record.totalStrikes >= 3 && !record.isWarningActive) {\n    await prisma.userModerationRecord.update({\n      where: { userId },\n      data: {\n        isWarningActive: true,\n        warningExpiresAt: new Date(Date.now() + 7 * 24 * 60 * 60 * 1000), // 7 days\n      },\n    });\n\n    // Could trigger notification here\n    log.info({ userId, strikes: record.totalStrikes }, 'User auto-warned');\n  }\n\n  // Auto-ban after 10 strikes\n  if (record.totalStrikes >= 10) {\n    await prisma.userModerationRecord.update({\n      where: { userId },\n      data: {\n        isBanned: true,\n        banReason: 'Automatic ban due to repeated violations',\n      },\n    });\n\n    log.warn({ userId, strikes: record.totalStrikes }, 'User auto-banned');\n  }\n}\n\n// ============================================================================\n// Moderation Rules\n// ============================================================================\n\n/**\n * Create moderation rule\n */\nexport async function createModerationRule(options) {\n  const prisma = getPrismaClient();\n\n  const rule = await prisma.moderationRule.create({\n    data: {\n      name: options.name,\n      description: options.description,\n      conditionType: options.conditionType,\n      condition: options.condition,\n      action: options.action,\n      actionConfig: options.actionConfig,\n      contentTypes: options.contentTypes || ['conversation', 'acu', 'memory', 'group_post'],\n      appliesTo: options.appliesTo || 'all',\n      isEnabled: options.isEnabled !== false,\n      priority: options.priority || 0,\n      maxStrikes: options.maxStrikes,\n      timeWindow: options.timeWindow,\n      createdBy: options.createdBy,\n    },\n  });\n\n  return { success: true, rule };\n}\n\n/**\n * Get active moderation rules\n */\nexport async function getActiveRules() {\n  const prisma = getPrismaClient();\n\n  return await prisma.moderationRule.findMany({\n    where: { isEnabled: true },\n    orderBy: { priority: 'desc' },\n  });\n}\n\n/**\n * Process content against moderation rules (automod)\n */\nexport async function processAutoModeration(contentId, contentType, text, ownerId) {\n  const rules = await getActiveRules();\n\n  // Filter rules applicable to this content type\n  const applicableRules = rules.filter(\n    (r) => r.contentTypes.includes(contentType) || r.contentTypes.includes('all')\n  );\n\n  for (const rule of applicableRules) {\n    const shouldFlag = await evaluateRule(rule, text);\n\n    if (shouldFlag) {\n      await flagContent('system', {\n        contentId,\n        contentType,\n        contentOwnerId: ownerId,\n        contentText: text,\n        reason: 'OTHER',\n        description: `Auto-flagged by rule: ${rule.name}`,\n      });\n\n      // Take automatic action\n      if (rule.action === 'remove') {\n        await takeContentAction(contentId, contentType, 'remove');\n      }\n\n      return { flagged: true, rule: rule.name, action: rule.action };\n    }\n  }\n\n  return { flagged: false };\n}\n\n/**\n * Evaluate a rule against text\n */\nasync function evaluateRule(rule, text) {\n  if (!text) {\n    return false;\n  }\n\n  const { condition } = rule;\n\n  switch (rule.conditionType) {\n    case 'keyword':\n      const keywords = condition.keywords || [];\n      return keywords.some((k) => text.toLowerCase().includes(k.toLowerCase()));\n\n    case 'pattern':\n      try {\n        const regex = new RegExp(condition.pattern, 'i');\n        return regex.test(text);\n      } catch {\n        return false;\n      }\n\n    case 'threshold':\n      // For length/quantity thresholds\n      return false; // Would need specific implementation\n\n    case 'ai_score':\n      // Would integrate with AI moderation API\n      return false;\n\n    default:\n      return false;\n  }\n}\n\n// ============================================================================\n// Appeals\n// ============================================================================\n\n/**\n * Appeal a moderation decision\n */\nexport async function appealDecision(flagId, userId, reason) {\n  const prisma = getPrismaClient();\n\n  const flag = await prisma.contentFlag.findUnique({ where: { id: flagId } });\n\n  if (!flag) {\n    return { success: false, error: 'Flag not found' };\n  }\n\n  if (flag.contentOwnerId !== userId) {\n    return { success: false, error: 'Not authorized to appeal this decision' };\n  }\n\n  if (flag.status !== 'REMOVED' && flag.status !== 'WARNED') {\n    return { success: false, error: 'This decision cannot be appealed' };\n  }\n\n  await prisma.contentFlag.update({\n    where: { id: flagId },\n    data: {\n      status: 'APPEALED',\n      appealReason: reason,\n      appealedAt: new Date(),\n    },\n  });\n\n  return { success: true };\n}\n\n/**\n * Resolve appeal\n */\nexport async function resolveAppeal(flagId, reviewerId, sustained, resolution) {\n  const prisma = getPrismaClient();\n\n  const newStatus = sustained ? flag.status : 'APPROVED';\n\n  await prisma.contentFlag.update({\n    where: { id: flagId },\n    data: {\n      status: newStatus,\n      appealReviewerId: reviewerId,\n      appealResolvedAt: new Date(),\n      resolution,\n    },\n  });\n\n  // If appeal denied, content stays removed\n  // If appeal sustained, restore content\n  if (!sustained && flag) {\n    await restoreContent(flag.contentId, flag.contentType);\n  }\n\n  return { success: true, sustained };\n}\n\n/**\n * Restore previously removed content\n */\nasync function restoreContent(contentId, contentType) {\n  const prisma = getPrismaClient();\n\n  const restoreMap = {\n    conversation: { state: 'ACTIVE' },\n    acu: { state: 'ACTIVE' },\n    memory: { isArchived: false },\n  };\n\n  const restore = restoreMap[contentType];\n  if (!restore) {\n    return;\n  }\n\n  const modelMap = {\n    conversation: prisma.conversation,\n    acu: prisma.atomicChatUnit,\n    memory: prisma.memory,\n  };\n\n  const model = modelMap[contentType];\n  if (model) {\n    await model.update({\n      where: { id: contentId },\n      data: restore,\n    });\n  }\n}\n\n// ============================================================================\n// Moderator Notes\n// ============================================================================\n\n/**\n * Add moderator note\n */\nexport async function addModeratorNote(options) {\n  const prisma = getPrismaClient();\n\n  const note = await prisma.moderatorNote.create({\n    data: {\n      targetType: options.targetType,\n      targetId: options.targetId,\n      content: options.content,\n      moderatorId: options.moderatorId,\n      isInternal: options.isInternal !== false,\n      isPublic: options.isPublic === true,\n    },\n  });\n\n  return { success: true, note };\n}\n\n/**\n * Get notes for a target\n */\nexport async function getModeratorNotes(targetType, targetId) {\n  const prisma = getPrismaClient();\n\n  return await prisma.moderatorNote.findMany({\n    where: {\n      targetType,\n      targetId,\n      isInternal: false, // Only return non-internal notes\n    },\n    orderBy: { createdAt: 'desc' },\n  });\n}\n\n// ============================================================================\n// Dashboard & Stats\n// ============================================================================\n\n/**\n * Get moderation dashboard stats\n */\nexport async function getModerationStats() {\n  const prisma = getPrismaClient();\n\n  const [pendingCount, flaggedCount, removedCount, bannedCount, recentFlags] = await Promise.all([\n    prisma.contentFlag.count({ where: { status: 'PENDING' } }),\n    prisma.contentFlag.count({ where: { status: 'FLAGGED' } }),\n    prisma.contentFlag.count({ where: { status: 'REMOVED' } }),\n    prisma.userModerationRecord.count({ where: { isBanned: true } }),\n    prisma.contentFlag.findMany({\n      where: { createdAt: { gte: new Date(Date.now() - 24 * 60 * 60 * 1000) } },\n      take: 10,\n      orderBy: { createdAt: 'desc' },\n    }),\n  ]);\n\n  return {\n    pending: pendingCount,\n    flagged: flaggedCount,\n    removed: removedCount,\n    banned: bannedCount,\n    recentFlags,\n  };\n}\n\n/**\n * List flags with filters\n */\nexport async function listFlags(options = {}) {\n  const prisma = getPrismaClient();\n\n  const { status, reason, priority, contentType, limit = 50, offset = 0 } = options;\n\n  const where = {};\n  if (status) {\n    where.status = status;\n  }\n  if (reason) {\n    where.reason = reason;\n  }\n  if (priority) {\n    where.priority = priority;\n  }\n  if (contentType) {\n    where.contentType = contentType;\n  }\n\n  const [flags, total] = await Promise.all([\n    prisma.contentFlag.findMany({\n      where,\n      orderBy: [{ priority: 'desc' }, { createdAt: 'desc' }],\n      take: limit,\n      skip: offset,\n    }),\n    prisma.contentFlag.count({ where }),\n  ]);\n\n  return { flags, total, limit, offset };\n}\n\n// ============================================================================\n// Export\n// ============================================================================\n\nexport const moderationService = {\n  // Flagging\n  flagContent,\n\n  // Review\n  reviewFlag,\n\n  // User records\n  getUserModerationRecord,\n\n  // Rules\n  createModerationRule,\n  getActiveRules,\n  processAutoModeration,\n\n  // Appeals\n  appealDecision,\n  resolveAppeal,\n\n  // Notes\n  addModeratorNote,\n  getModeratorNotes,\n\n  // Dashboard\n  getModerationStats,\n  listFlags,\n};\n\nexport default moderationService;\n","usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\services\\omni-service.js","messages":[{"ruleId":"no-unused-vars","severity":1,"message":"'e' is defined but never used.","line":149,"column":14,"nodeType":"Identifier","messageId":"unusedVar","endLine":149,"endColumn":15}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":"// apps/server/src/services/omni-service.js\n\nimport { getPrismaClient } from '../lib/database.js';\n\n/**\n * Omni Service\n * Handles context-aware searches for the Omni-Composer\n */\nexport class OmniService {\n  constructor() {\n    this.prisma = getPrismaClient();\n  }\n\n  /**\n   * Search based on trigger type\n   * @param {string} trigger - One of '/', '@', '+', '!', '#'\n   * @param {string} query - The search text\n   * @param {string} userId - Context user\n   */\n  async search(trigger, query, userId) {\n    switch (trigger) {\n      case '@':\n        return this.searchSocial(query, userId);\n      case '#':\n        return this.searchTopics(query, userId);\n      case '!':\n        return this.searchActions(query);\n      case '/':\n        return this.searchCommands(query);\n      case '+':\n        return this.searchContext(query, userId);\n      default:\n        return [];\n    }\n  }\n\n  /**\n   * Search People & Personas (@)\n   */\n  async searchSocial(query, userId) {\n    // 1. Search Friends/Users (Mock for now, would search CircleMember)\n    // 2. Search AI Personas (System + User owned)\n\n    const personas = await this.prisma.aiPersona.findMany({\n      where: {\n        OR: [\n          { ownerId: null }, // System personas\n          { ownerId: userId }, // User personas\n        ],\n        name: { contains: query, mode: 'insensitive' },\n      },\n      take: 5,\n    });\n\n    return personas.map((p) => ({\n      id: p.id,\n      label: p.name,\n      subLabel: p.type === 'clone' ? 'Digital Twin' : 'AI Persona',\n      value: `@${p.trigger || p.name.replace(/\\s+/g, '')}`,\n      type: '@',\n      icon: 'bot', // simplified\n    }));\n  }\n\n  /**\n   * Search Topics/ACUs (#)\n   */\n  async searchTopics(query, userId) {\n    // Search Atomic Chat Units\n    const acus = await this.prisma.atomicChatUnit.findMany({\n      where: {\n        // Simple content search for now, vector search later\n        content: { contains: query, mode: 'insensitive' },\n        OR: [\n          { sharingPolicy: 'network' },\n          { authorDid: userId }, // Assuming userId maps to DID roughly or we look up DID\n        ],\n      },\n      take: 5,\n      orderBy: { rediscoveryScore: 'desc' },\n    });\n\n    return acus.map((acu) => ({\n      id: acu.id,\n      label: acu.metadata?.title || `${acu.content.slice(0, 20)}...`,\n      subLabel: `ACU â€¢ ${acu.type}`,\n      value: `#${acu.id.slice(0, 8)}`,\n      type: '#',\n      icon: 'hash',\n    }));\n  }\n\n  async searchActions(query) {\n    const zaiActions = [\n      {\n        id: 'websearch',\n        label: 'Web Search',\n        subLabel: 'Search the web',\n        trigger: 'websearch',\n        icon: 'globe',\n      },\n      {\n        id: 'readurl',\n        label: 'Web Reader',\n        subLabel: 'Read a webpage',\n        trigger: 'read',\n        icon: 'book-open',\n      },\n      {\n        id: 'github',\n        label: 'GitHub Search',\n        subLabel: 'Search repos',\n        trigger: 'github',\n        icon: 'github',\n      },\n      {\n        id: 'githubtree',\n        label: 'GitHub Tree',\n        subLabel: 'Repo structure',\n        trigger: 'githubtree',\n        icon: 'git-branch',\n      },\n      {\n        id: 'githubfile',\n        label: 'GitHub File',\n        subLabel: 'Read file',\n        trigger: 'githubfile',\n        icon: 'file-code',\n      },\n    ];\n\n    const filteredZai = zaiActions.filter(\n      (a) =>\n        a.label.toLowerCase().includes(query.toLowerCase()) ||\n        a.trigger.toLowerCase().includes(query.toLowerCase())\n    );\n\n    let dbActions = [];\n    try {\n      dbActions = await this.prisma.systemAction.findMany({\n        where: {\n          OR: [\n            { label: { contains: query, mode: 'insensitive' } },\n            { trigger: { contains: query, mode: 'insensitive' } },\n          ],\n        },\n        take: 5,\n      });\n    } catch (e) {\n      // DB not ready, skip\n    }\n\n    const dbMapped = dbActions.map((a) => ({\n      id: a.actionCode,\n      label: a.label,\n      subLabel: a.subLabel,\n      value: `!${a.trigger}`,\n      type: '!',\n      icon: a.icon || 'zap',\n    }));\n\n    const zaiMapped = filteredZai.map((a) => ({\n      id: a.id,\n      label: a.label,\n      subLabel: a.subLabel,\n      value: `!${a.trigger}`,\n      type: '!',\n      icon: a.icon,\n    }));\n\n    return [...zaiMapped, ...dbMapped];\n  }\n\n  async searchCommands(query) {\n    const commands = await this.prisma.systemCommand.findMany({\n      where: {\n        OR: [\n          { label: { contains: query, mode: 'insensitive' } },\n          { trigger: { contains: query, mode: 'insensitive' } },\n        ],\n      },\n      take: 5,\n    });\n\n    return commands.map((c) => ({\n      id: c.actionCode,\n      label: c.label,\n      subLabel: c.subLabel,\n      value: `/${c.trigger}`,\n      type: '/',\n      icon: c.icon || 'command',\n    }));\n  }\n\n  async searchContext(query, userId) {\n    if (!userId) {\n      return [];\n    }\n\n    const facts = await this.prisma.userFact.findMany({\n      where: {\n        userId: userId,\n        OR: [\n          { category: { contains: query, mode: 'insensitive' } },\n          { content: { contains: query, mode: 'insensitive' } },\n        ],\n      },\n      take: 5,\n    });\n\n    return facts.map((f) => ({\n      id: f.id,\n      label: f.category,\n      subLabel: `${f.content.slice(0, 30)}...`,\n      value: `+${f.id.slice(0, 8)}`, // Context injection usually uses ID or content ref\n      type: '+',\n      icon: 'file-text',\n    }));\n  }\n}\n\nexport const omniService = new OmniService();\n","usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\services\\portability-service.js","messages":[{"ruleId":"no-unused-vars","severity":1,"message":"'createWriteStream' is defined but never used.","line":9,"column":10,"nodeType":"Identifier","messageId":"unusedVar","endLine":9,"endColumn":27,"suggestions":[{"messageId":"removeVar","data":{"varName":"createWriteStream"},"fix":{"range":[224,263],"text":""},"desc":"Remove unused variable 'createWriteStream'."}]},{"ruleId":"no-unused-vars","severity":1,"message":"'pipeline' is defined but never used.","line":10,"column":10,"nodeType":"Identifier","messageId":"unusedVar","endLine":10,"endColumn":18,"suggestions":[{"messageId":"removeVar","data":{"varName":"pipeline"},"fix":{"range":[264,307],"text":""},"desc":"Remove unused variable 'pipeline'."}]},{"ruleId":"no-unused-vars","severity":1,"message":"'Transform' is defined but never used.","line":11,"column":10,"nodeType":"Identifier","messageId":"unusedVar","endLine":11,"endColumn":19,"suggestions":[{"messageId":"removeVar","data":{"varName":"Transform"},"fix":{"range":[308,343],"text":""},"desc":"Remove unused variable 'Transform'."}]},{"ruleId":"no-unused-vars","severity":1,"message":"'prisma' is assigned a value but never used.","line":131,"column":9,"nodeType":"Identifier","messageId":"unusedVar","endLine":131,"endColumn":15,"suggestions":[{"messageId":"removeVar","data":{"varName":"prisma"},"fix":{"range":[3644,3677],"text":""},"desc":"Remove unused variable 'prisma'."}]},{"ruleId":"no-unused-vars","severity":1,"message":"'options' is defined but never used. Allowed unused args must match /^_/u.","line":256,"column":35,"nodeType":"Identifier","messageId":"unusedVar","endLine":256,"endColumn":42,"suggestions":[{"messageId":"removeVar","data":{"varName":"options"},"fix":{"range":[6640,6649],"text":""},"desc":"Remove unused variable 'options'."}]},{"ruleId":"no-unused-vars","severity":1,"message":"'options' is defined but never used. Allowed unused args must match /^_/u.","line":266,"column":42,"nodeType":"Identifier","messageId":"unusedVar","endLine":266,"endColumn":49,"suggestions":[{"messageId":"removeVar","data":{"varName":"options"},"fix":{"range":[6795,6804],"text":""},"desc":"Remove unused variable 'options'."}]},{"ruleId":"no-unused-vars","severity":1,"message":"'options' is defined but never used. Allowed unused args must match /^_/u.","line":307,"column":41,"nodeType":"Identifier","messageId":"unusedVar","endLine":307,"endColumn":48,"suggestions":[{"messageId":"removeVar","data":{"varName":"options"},"fix":{"range":[7888,7897],"text":""},"desc":"Remove unused variable 'options'."}]},{"ruleId":"no-unused-vars","severity":1,"message":"'options' is defined but never used. Allowed unused args must match /^_/u.","line":329,"column":39,"nodeType":"Identifier","messageId":"unusedVar","endLine":329,"endColumn":46,"suggestions":[{"messageId":"removeVar","data":{"varName":"options"},"fix":{"range":[8496,8505],"text":""},"desc":"Remove unused variable 'options'."}]},{"ruleId":"no-unused-vars","severity":1,"message":"'options' is defined but never used. Allowed unused args must match /^_/u.","line":348,"column":35,"nodeType":"Identifier","messageId":"unusedVar","endLine":348,"endColumn":42,"suggestions":[{"messageId":"removeVar","data":{"varName":"options"},"fix":{"range":[9006,9015],"text":""},"desc":"Remove unused variable 'options'."}]},{"ruleId":"no-unused-vars","severity":1,"message":"'migrationStartTime' is assigned a value but never used.","line":441,"column":11,"nodeType":"Identifier","messageId":"unusedVar","endLine":441,"endColumn":29,"suggestions":[{"messageId":"removeVar","data":{"varName":"migrationStartTime"},"fix":{"range":[11505,11543],"text":""},"desc":"Remove unused variable 'migrationStartTime'."}]}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":10,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * Data Portability Service - Phase 5\n *\n * Complete data sovereignty with export, import, and migration capabilities\n */\n\nimport { getPrismaClient } from '../lib/database.js';\nimport { logger } from '../lib/logger.js';\nimport { createWriteStream } from 'fs';\nimport { pipeline } from 'stream/promises';\nimport { Transform } from 'stream';\nimport { debugReporter } from './debug-reporter.js';\n\nconst log = logger.child({ module: 'portability-service' });\n\n// ============================================================================\n// Data Export\n// ============================================================================\n\n/**\n * Request data export\n */\nexport async function requestExport(userId, options = {}) {\n  try {\n    const prisma = getPrismaClient();\n\n    const exportConfig = {\n      userId,\n      exportType: options.exportType || 'full',\n      formats: options.formats || ['json'],\n      includeContent: options.includeContent !== false,\n      includeCircles: options.includeCircles !== false,\n      includeSocialGraph: options.includeSocialGraph !== false,\n      includeSettings: options.includeSettings !== false,\n      includeAnalytics: options.includeAnalytics || false,\n      anonymizeOthers: options.anonymizeOthers || false,\n      includePrivateContent: options.includePrivateContent !== false,\n      includeDeletedContent: options.includeDeletedContent || false,\n      status: 'pending',\n      progress: 0,\n      expiresAt: new Date(Date.now() + 7 * 24 * 60 * 60 * 1000), // 7 days\n    };\n\n    const exportJob = await prisma.dataExport.create({\n      data: exportConfig,\n    });\n\n    // Start async export process\n    const exportStartTime = Date.now();\n    processExport(exportJob.id).catch((error) => {\n      debugReporter.trackError(error, { operation: 'processExport', exportId: exportJob.id });\n      log.error({ exportId: exportJob.id, error: error.message }, 'Export processing failed');\n    });\n\n    log.info(\n      { exportId: exportJob.id, userId, duration: Date.now() - exportStartTime },\n      'Export requested'\n    );\n\n    return {\n      success: true,\n      exportId: exportJob.id,\n      status: 'pending',\n      estimatedTime: '5-15 minutes',\n    };\n  } catch (error) {\n    log.error({ userId, error: error.message }, 'Export request failed');\n    return { success: false, error: 'Failed to request export' };\n  }\n}\n\n/**\n * Process export asynchronously\n */\nasync function processExport(exportId) {\n  const prisma = getPrismaClient();\n\n  try {\n    const exportJob = await prisma.dataExport.findUnique({\n      where: { id: exportId },\n    });\n\n    if (!exportJob) {\n      return;\n    }\n\n    // Update status\n    await prisma.dataExport.update({\n      where: { id: exportId },\n      data: { status: 'processing', progress: 5 },\n    });\n\n    const files = [];\n    const fileSizes = {};\n\n    // Export in each requested format\n    for (const format of exportJob.formats) {\n      const { url, size } = await exportToFormat(exportJob, format);\n      files.push(url);\n      fileSizes[format] = size;\n    }\n\n    // Update with results\n    await prisma.dataExport.update({\n      where: { id: exportId },\n      data: {\n        status: 'completed',\n        progress: 100,\n        fileUrls: files,\n        fileSizes,\n        completedAt: new Date(),\n      },\n    });\n\n    log.info({ exportId, files }, 'Export completed');\n  } catch (error) {\n    await prisma.dataExport.update({\n      where: { id: exportId },\n      data: {\n        status: 'failed',\n        errorMessage: error.message,\n      },\n    });\n  }\n}\n\n/**\n * Export data to specific format\n */\nasync function exportToFormat(exportJob, format) {\n  const prisma = getPrismaClient();\n  const { userId } = exportJob;\n\n  // Gather data\n  const data = await gatherUserData(userId, exportJob);\n\n  let exportedData;\n  let extension;\n\n  switch (format) {\n    case 'json':\n      exportedData = await exportToJSON(data, exportJob);\n      extension = 'json';\n      break;\n    case 'activitypub':\n      exportedData = await exportToActivityPub(data, exportJob);\n      extension = 'json';\n      break;\n    case 'atproto':\n      exportedData = await exportToATProtocol(data, exportJob);\n      extension = 'json';\n      break;\n    case 'markdown':\n      exportedData = await exportToMarkdown(data, exportJob);\n      extension = 'md';\n      break;\n    case 'html':\n      exportedData = await exportToHTML(data, exportJob);\n      extension = 'html';\n      break;\n    default:\n      throw new Error(`Unsupported format: ${format}`);\n  }\n\n  // Save to file (in production, upload to S3/blob storage)\n  const filename = `export-${exportJob.id}-${format}.${extension}`;\n  const url = `/exports/${filename}`;\n\n  // In real implementation: await uploadToStorage(filename, exportedData);\n\n  return {\n    url,\n    size: Buffer.byteLength(JSON.stringify(exportedData), 'utf8'),\n  };\n}\n\n/**\n * Gather all user data\n */\nasync function gatherUserData(userId, options) {\n  const prisma = getPrismaClient();\n  let data = {\n    metadata: {\n      version: '1.0',\n      exportedAt: new Date().toISOString(),\n      exportedBy: userId,\n    },\n  };\n\n  // Get user identity\n  const user = await prisma.user.findUnique({\n    where: { id: userId },\n    select: {\n      id: true,\n      did: true,\n      handle: true,\n      displayName: true,\n      avatarUrl: true,\n      email: options.includePrivateContent,\n      emailVerified: true,\n      verificationLevel: true,\n      publicKey: true,\n      createdAt: true,\n    },\n  });\n  data.identity = user;\n\n  // Get content\n  if (options.includeContent) {\n    data.content = {};\n\n    data.content.conversations = await prisma.conversation.findMany({\n      where: { ownerId: userId },\n      include: { messages: true },\n    });\n\n    data.content.acus = await prisma.atomicChatUnit.findMany({\n      where: {\n        authorDid: user.did,\n        ...(options.includeDeletedContent ? {} : { state: 'ACTIVE' }),\n      },\n    });\n  }\n\n  // Get circles\n  if (options.includeCircles) {\n    data.circles = await prisma.circle.findMany({\n      where: { ownerId: userId },\n      include: { members: true },\n    });\n  }\n\n  // Get social graph\n  if (options.includeSocialGraph) {\n    data.socialGraph = {\n      following: await prisma.socialConnection.findMany({\n        where: { followerId: userId, status: 'active' },\n      }),\n      followers: await prisma.socialConnection.findMany({\n        where: { followingId: userId, status: 'active' },\n      }),\n    };\n  }\n\n  // Anonymize if requested\n  if (options.anonymizeOthers) {\n    data = anonymizeData(data);\n  }\n\n  return data;\n}\n\n/**\n * Export to VIVIM JSON format\n */\nasync function exportToJSON(data, options) {\n  return {\n    ...data,\n    format: 'vivim-export-v1',\n  };\n}\n\n/**\n * Export to ActivityPub format\n */\nasync function exportToActivityPub(data, options) {\n  const actor = {\n    '@context': 'https://www.w3.org/ns/activitystreams',\n    type: 'Person',\n    id: `https://vivim.social/users/${data.identity.handle}`,\n    preferredUsername: data.identity.handle,\n    name: data.identity.displayName,\n    icon: data.identity.avatarUrl\n      ? {\n          type: 'Image',\n          url: data.identity.avatarUrl,\n        }\n      : undefined,\n    publicKey: {\n      id: `https://vivim.social/users/${data.identity.handle}#main-key`,\n      owner: `https://vivim.social/users/${data.identity.handle}`,\n      publicKeyPem: data.identity.publicKey,\n    },\n  };\n\n  const outbox = {\n    type: 'OrderedCollection',\n    totalItems: data.content?.conversations?.length || 0,\n    orderedItems: (data.content?.conversations || []).map((conv) => ({\n      type: 'Create',\n      actor: actor.id,\n      object: {\n        type: 'Note',\n        content: conv.title,\n        published: conv.createdAt,\n        url: conv.sourceUrl,\n      },\n    })),\n  };\n\n  return { actor, outbox };\n}\n\n/**\n * Export to AT Protocol format\n */\nasync function exportToATProtocol(data, options) {\n  return {\n    did: data.identity.did,\n    handle: `${data.identity.handle}.vivim.social`,\n    records: {\n      'app.bsky.feed.post': (data.content?.conversations || []).map((conv) => ({\n        text: conv.title,\n        createdAt: conv.createdAt,\n        $type: 'app.bsky.feed.post',\n      })),\n      'app.bsky.graph.follow': (data.socialGraph?.following || []).map((follow) => ({\n        subject: follow.followingId,\n        createdAt: follow.createdAt,\n        $type: 'app.bsky.graph.follow',\n      })),\n    },\n  };\n}\n\n/**\n * Export to Markdown format\n */\nasync function exportToMarkdown(data, options) {\n  let markdown = `# ${data.identity.displayName}'s Data Export\\n\\n`;\n  markdown += `Exported: ${data.metadata.exportedAt}\\n\\n`;\n\n  if (data.content?.conversations) {\n    markdown += '## Conversations\\n\\n';\n    for (const conv of data.content.conversations) {\n      markdown += `### ${conv.title}\\n`;\n      markdown += `- URL: ${conv.sourceUrl}\\n`;\n      markdown += `- Date: ${conv.createdAt}\\n\\n`;\n    }\n  }\n\n  return markdown;\n}\n\n/**\n * Export to HTML format\n */\nasync function exportToHTML(data, options) {\n  return `<!DOCTYPE html>\n<html>\n<head>\n  <title>${data.identity.displayName} - Data Export</title>\n</head>\n<body>\n  <h1>${data.identity.displayName}</h1>\n  <p>Exported: ${data.metadata.exportedAt}</p>\n  \n  ${\n    data.content?.conversations\n      ?.map(\n        (conv) => `\n    <article>\n      <h2>${conv.title}</h2>\n      <p><a href=\"${conv.sourceUrl}\">Source</a></p>\n      <time>${conv.createdAt}</time>\n    </article>\n  `\n      )\n      .join('') || ''\n  }\n</body>\n</html>`;\n}\n\n/**\n * Anonymize data (remove other users' identifying info)\n */\nfunction anonymizeData(data) {\n  // Replace user IDs with hashes\n  const anonymized = JSON.parse(JSON.stringify(data));\n\n  if (anonymized.circles) {\n    for (const circle of anonymized.circles) {\n      for (const member of circle.members || []) {\n        member.userId = hashId(member.userId);\n      }\n    }\n  }\n\n  if (anonymized.socialGraph) {\n    for (const conn of anonymized.socialGraph.following || []) {\n      conn.followingId = hashId(conn.followingId);\n    }\n    for (const conn of anonymized.socialGraph.followers || []) {\n      conn.followerId = hashId(conn.followerId);\n    }\n  }\n\n  return anonymized;\n}\n\nfunction hashId(id) {\n  // Simple hash - in production use proper hashing\n  return `user_${Buffer.from(id).toString('base64').slice(0, 8)}`;\n}\n\n// ============================================================================\n// Account Migration\n// ============================================================================\n\n/**\n * Initiate account migration\n */\nexport async function initiateMigration(userId, options) {\n  try {\n    const prisma = getPrismaClient();\n\n    const migration = await prisma.accountMigration.create({\n      data: {\n        userId,\n        direction: options.direction,\n        fromPds: options.fromPds,\n        toPds: options.toPds,\n        migrateIdentity: options.migrateIdentity !== false,\n        migrateContent: options.migrateContent !== false,\n        migrateSocialGraph: options.migrateSocialGraph !== false,\n        migrateSettings: options.migrateSettings !== false,\n        status: 'preparing',\n        steps: [\n          { step: 'export_data', status: 'pending' },\n          { step: 'transfer_identity', status: 'pending' },\n          { step: 'import_data', status: 'pending' },\n          { step: 'verify_migration', status: 'pending' },\n          { step: 'update_dns', status: 'pending' },\n        ],\n        canRollback: true,\n      },\n    });\n\n    // Start migration process\n    const migrationStartTime = Date.now();\n    processMigration(migration.id).catch((error) => {\n      debugReporter.trackError(error, { operation: 'processMigration', migrationId: migration.id });\n      log.error({ migrationId: migration.id, error: error.message }, 'Migration failed');\n    });\n\n    return {\n      success: true,\n      migrationId: migration.id,\n      status: 'preparing',\n    };\n  } catch (error) {\n    log.error({ userId, error: error.message }, 'Migration initiation failed');\n    return { success: false, error: 'Failed to initiate migration' };\n  }\n}\n\n/**\n * Process migration asynchronously\n */\nasync function processMigration(migrationId) {\n  const prisma = getPrismaClient();\n\n  try {\n    const migration = await prisma.accountMigration.findUnique({\n      where: { id: migrationId },\n    });\n\n    if (!migration) {\n      return;\n    }\n\n    // Step 1: Export data\n    await updateMigrationStep(migrationId, 'export_data', 'in_progress');\n    const exportData = await gatherUserData(migration.userId, {\n      includeContent: migration.migrateContent,\n      includeCircles: migration.migrateSocialGraph,\n      includeSocialGraph: migration.migrateSocialGraph,\n      includeSettings: migration.migrateSettings,\n    });\n    await updateMigrationStep(migrationId, 'export_data', 'completed');\n\n    // Step 2: Transfer identity\n    if (migration.migrateIdentity) {\n      await updateMigrationStep(migrationId, 'transfer_identity', 'in_progress');\n      // In production: Transfer DID or create new one\n      await updateMigrationStep(migrationId, 'transfer_identity', 'completed');\n    }\n\n    // Step 3: Import data to new PDS\n    await updateMigrationStep(migrationId, 'import_data', 'in_progress');\n    // In production: POST to new PDS\n    await updateMigrationStep(migrationId, 'import_data', 'completed');\n\n    // Step 4: Verify\n    await updateMigrationStep(migrationId, 'verify_migration', 'in_progress');\n    // In production: Verify data integrity\n    await updateMigrationStep(migrationId, 'verify_migration', 'completed');\n\n    // Step 5: Update DNS/handle redirection\n    await updateMigrationStep(migrationId, 'update_dns', 'in_progress');\n    await prisma.accountMigration.update({\n      where: { id: migrationId },\n      data: {\n        handleRedirectionEnabled: true,\n      },\n    });\n    await updateMigrationStep(migrationId, 'update_dns', 'completed');\n\n    // Mark complete\n    await prisma.accountMigration.update({\n      where: { id: migrationId },\n      data: {\n        status: 'completed',\n        progress: 100,\n        completedAt: new Date(),\n        itemsMigrated: Object.keys(exportData).length,\n      },\n    });\n\n    log.info({ migrationId }, 'Migration completed');\n  } catch (error) {\n    await prisma.accountMigration.update({\n      where: { id: migrationId },\n      data: {\n        status: 'failed',\n        errorMessage: error.message,\n        errorDetails: { stack: error.stack },\n      },\n    });\n  }\n}\n\nasync function updateMigrationStep(migrationId, stepName, status) {\n  const prisma = getPrismaClient();\n\n  const migration = await prisma.accountMigration.findUnique({\n    where: { id: migrationId },\n  });\n\n  const steps = migration.steps.map((s) =>\n    s.step === stepName\n      ? {\n          ...s,\n          status,\n          [status === 'in_progress' ? 'startedAt' : 'completedAt']: new Date().toISOString(),\n        }\n      : s\n  );\n\n  const completedSteps = steps.filter((s) => s.status === 'completed').length;\n  const progress = (completedSteps / steps.length) * 100;\n\n  await prisma.accountMigration.update({\n    where: { id: migrationId },\n    data: { steps, progress },\n  });\n}\n\n// ============================================================================\n// Export Service\n// ============================================================================\n\nexport const portabilityService = {\n  // Export\n  requestExport,\n\n  // Migration\n  initiateMigration,\n\n  // Utility\n  gatherUserData,\n};\n\nexport default portabilityService;\n","usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\services\\queue-service.js","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\services\\sharing-analytics-service.js","messages":[{"ruleId":"no-unused-vars","severity":1,"message":"'log' is assigned a value but never used.","line":4,"column":7,"nodeType":"Identifier","messageId":"unusedVar","endLine":4,"endColumn":10,"suggestions":[{"messageId":"removeVar","data":{"varName":"log"},"fix":{"range":[98,164],"text":""},"desc":"Remove unused variable 'log'."}]}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":"import { getPrismaClient } from '../lib/database.js';\nimport { logger } from '../lib/logger.js';\n\nconst log = logger.child({ module: 'sharing-analytics-service' });\nconst prisma = getPrismaClient();\n\nexport async function trackShareEvent({\n  eventType,\n  actorDid,\n  intentId,\n  contentRecordId,\n  eventData = {},\n}) {\n  return prisma.analyticsEvent.create({\n    data: {\n      eventType,\n      actorDid,\n      intentId,\n      contentRecordId,\n      eventData,\n      timestamp: new Date(),\n    },\n  });\n}\n\nexport async function getUserSharingMetrics(userDid, options = {}) {\n  const { startDate, endDate } = options;\n\n  const where = {\n    actorDid: userDid,\n    timestamp: {},\n  };\n\n  if (startDate) {\n    where.timestamp.gte = new Date(startDate);\n  }\n  if (endDate) {\n    where.timestamp.lte = new Date(endDate);\n  }\n\n  const events = await prisma.analyticsEvent.findMany({ where });\n\n  const metrics = {\n    totalShares: events.filter((e) => e.eventType === 'SHARE_CREATED').length,\n    totalViews: events.filter((e) => e.eventType === 'SHARE_VIEWED').length,\n    linkClicks: events.filter((e) => e.eventType === 'LINK_CLICKED').length,\n    sharesAccepted: events.filter((e) => e.eventType === 'SHARE_ACCEPTED').length,\n    sharesDeclined: events.filter((e) => e.eventType === 'SHARE_DECLINED').length,\n    sharesRevoked: events.filter((e) => e.eventType === 'SHARE_REVOKED').length,\n    contentSaved: events.filter((e) => e.eventType === 'CONTENT_SAVED').length,\n    contentForwarded: events.filter((e) => e.eventType === 'CONTENT_FORWARDED').length,\n  };\n\n  return metrics;\n}\n\nexport async function getContentAnalytics(contentRecordId) {\n  const events = await prisma.analyticsEvent.findMany({\n    where: { contentRecordId },\n    orderBy: { timestamp: 'desc' },\n  });\n\n  const uniqueViewers = new Set(events.filter((e) => e.actorDid).map((e) => e.actorDid));\n\n  return {\n    totalViews: events.filter((e) => e.eventType === 'SHARE_VIEWED').length,\n    uniqueViewers: uniqueViewers.size,\n    linkClicks: events.filter((e) => e.eventType === 'LINK_CLICKED').length,\n    saves: events.filter((e) => e.eventType === 'CONTENT_SAVED').length,\n    forwards: events.filter((e) => e.eventType === 'CONTENT_FORWARDED').length,\n    timeline: events.map((e) => ({\n      type: e.eventType,\n      timestamp: e.timestamp,\n      actor: e.actorDid,\n    })),\n  };\n}\n\nexport async function getUserActivity(userDid, options = {}) {\n  const { limit = 50, eventTypes, startDate, endDate } = options;\n\n  const where = { actorDid: userDid };\n  if (eventTypes?.length) {\n    where.eventType = { in: eventTypes };\n  }\n  if (startDate || endDate) {\n    where.timestamp = {};\n    if (startDate) {\n      where.timestamp.gte = new Date(startDate);\n    }\n    if (endDate) {\n      where.timestamp.lte = new Date(endDate);\n    }\n  }\n\n  return prisma.analyticsEvent.findMany({\n    where,\n    orderBy: { timestamp: 'desc' },\n    take: limit,\n  });\n}\n\nexport async function generateUserInsights(userDid) {\n  const recentEvents = await prisma.analyticsEvent.findMany({\n    where: { actorDid: userDid },\n    orderBy: { timestamp: 'desc' },\n    take: 100,\n  });\n\n  const insights = [];\n\n  const shareCount = recentEvents.filter((e) => e.eventType === 'SHARE_CREATED').length;\n  const viewCount = recentEvents.filter((e) => e.eventType === 'SHARE_VIEWED').length;\n\n  if (shareCount > 0 && viewCount > 0) {\n    const engagementRate = viewCount / shareCount;\n    if (engagementRate > 5) {\n      insights.push({\n        insightType: 'RECOMMENDATION',\n        title: 'High Engagement Rate',\n        description: `Your shares have ${engagementRate.toFixed(1)}x views on average. Consider sharing more content.`,\n        confidence: 0.8,\n        relevanceScore: 0.9,\n      });\n    }\n  }\n\n  const last24h = recentEvents.filter(\n    (e) => e.timestamp > new Date(Date.now() - 24 * 60 * 60 * 1000)\n  );\n  if (last24h.length > 10) {\n    insights.push({\n      insightType: 'PATTERN_DETECTED',\n      title: 'Active Sharing Pattern',\n      description: 'You have been very active in the last 24 hours.',\n      confidence: 0.9,\n      relevanceScore: 0.7,\n    });\n  }\n\n  if (insights.length > 0) {\n    await prisma.insight.createMany({\n      data: insights.map((i) => ({\n        ...i,\n        userDid,\n        generatedAt: new Date(),\n      })),\n    });\n  }\n\n  return insights;\n}\n\nexport async function getInsights(userDid, options = {}) {\n  const { unreadOnly = false, limit = 20 } = options;\n\n  const where = { userDid };\n  if (unreadOnly) {\n    where.isRead = false;\n  }\n\n  return prisma.insight.findMany({\n    where,\n    orderBy: { generatedAt: 'desc' },\n    take: limit,\n  });\n}\n\nexport async function markInsightRead(insightId) {\n  return prisma.insight.update({\n    where: { id: insightId },\n    data: { isRead: true, readAt: new Date() },\n  });\n}\n\nexport async function dismissInsight(insightId) {\n  return prisma.insight.update({\n    where: { id: insightId },\n    data: { isDismissed: true },\n  });\n}\n\nexport const sharingAnalyticsService = {\n  trackShareEvent,\n  getUserSharingMetrics,\n  getContentAnalytics,\n  getUserActivity,\n  generateUserInsights,\n  getInsights,\n  markInsightRead,\n  dismissInsight,\n};\n\nexport default sharingAnalyticsService;\n","usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\services\\sharing-encryption-service.js","messages":[{"ruleId":"no-unused-vars","severity":1,"message":"'log' is assigned a value but never used.","line":4,"column":7,"nodeType":"Identifier","messageId":"unusedVar","endLine":4,"endColumn":10,"suggestions":[{"messageId":"removeVar","data":{"varName":"log"},"fix":{"range":[68,127],"text":""},"desc":"Remove unused variable 'log'."}]},{"ruleId":"no-unused-vars","severity":1,"message":"'AUTH_TAG_LENGTH' is assigned a value but never used.","line":9,"column":7,"nodeType":"Identifier","messageId":"unusedVar","endLine":9,"endColumn":22,"suggestions":[{"messageId":"removeVar","data":{"varName":"AUTH_TAG_LENGTH"},"fix":{"range":[207,234],"text":""},"desc":"Remove unused variable 'AUTH_TAG_LENGTH'."}]}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":2,"fixableErrorCount":0,"fixableWarningCount":0,"source":"import crypto from 'crypto';\nimport { logger } from './logger.js';\n\nconst log = logger.child({ module: 'encryption-service' });\n\nconst ALGORITHM = 'aes-256-gcm';\nconst KEY_LENGTH = 32;\nconst IV_LENGTH = 16;\nconst AUTH_TAG_LENGTH = 16;\nconst SALT_LENGTH = 32;\nconst PBKDF2_ITERATIONS = 100000;\n\nexport function generateContentKey() {\n  return crypto.randomBytes(KEY_LENGTH);\n}\n\nexport function deriveKey(password, salt) {\n  return crypto.pbkdf2Sync(password, salt, PBKDF2_ITERATIONS, KEY_LENGTH, 'sha512');\n}\n\nexport function encryptContent(plaintext, key) {\n  const iv = crypto.randomBytes(IV_LENGTH);\n  const cipher = crypto.createCipheriv(ALGORITHM, key, iv);\n\n  const encrypted = Buffer.concat([cipher.update(plaintext, 'utf8'), cipher.final()]);\n\n  const authTag = cipher.getAuthTag();\n\n  return {\n    ciphertext: encrypted.toString('base64'),\n    iv: iv.toString('base64'),\n    authTag: authTag.toString('base64'),\n    algorithm: ALGORITHM,\n  };\n}\n\nexport function decryptContent(encryptedData, key) {\n  const iv = Buffer.from(encryptedData.iv, 'base64');\n  const ciphertext = Buffer.from(encryptedData.ciphertext, 'base64');\n  const authTag = Buffer.from(encryptedData.authTag, 'base64');\n\n  const decipher = crypto.createDecipheriv(ALGORITHM, key, iv);\n  decipher.setAuthTag(authTag);\n\n  const decrypted = Buffer.concat([decipher.update(ciphertext), decipher.final()]);\n\n  return decrypted.toString('utf8');\n}\n\nexport function encryptWithPassword(plaintext, password) {\n  const salt = crypto.randomBytes(SALT_LENGTH);\n  const key = deriveKey(password, salt);\n  const encrypted = encryptContent(plaintext, key);\n\n  return {\n    ...encrypted,\n    salt: salt.toString('base64'),\n  };\n}\n\nexport function decryptWithPassword(encryptedData, password) {\n  const salt = Buffer.from(encryptedData.salt, 'base64');\n  const key = deriveKey(password, salt);\n  return decryptContent(encryptedData, key);\n}\n\nexport function hashPassword(password) {\n  const salt = crypto.randomBytes(SALT_LENGTH);\n  const hash = crypto.pbkdf2Sync(password, salt, PBKDF2_ITERATIONS, 64, 'sha512');\n  return `${salt.toString('base64')}:${hash.toString('base64')}`;\n}\n\nexport function verifyPassword(password, stored) {\n  const [salt, hash] = stored.split(':');\n  const computedHash = crypto.pbkdf2Sync(\n    password,\n    Buffer.from(salt, 'base64'),\n    PBKDF2_ITERATIONS,\n    64,\n    'sha512'\n  );\n  return crypto.timingSafeEqual(Buffer.from(hash, 'base64'), computedHash);\n}\n\nexport function generateShareCode(length = 12) {\n  const chars = 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789';\n  let code = '';\n  const randomBytes = crypto.randomBytes(length);\n  for (let i = 0; i < length; i++) {\n    code += chars[randomBytes[i] % chars.length];\n  }\n  return code;\n}\n\nexport function generateKeyPair() {\n  const { publicKey, privateKey } = crypto.generateKeyPairSync('x25519');\n  return {\n    publicKey: publicKey.export({ type: 'spki', format: 'der' }).toString('base64'),\n    privateKey: privateKey.export({ type: 'pkcs8', format: 'der' }).toString('base64'),\n  };\n}\n\nexport const encryptionService = {\n  generateContentKey,\n  deriveKey,\n  encryptContent,\n  decryptContent,\n  encryptWithPassword,\n  decryptWithPassword,\n  hashPassword,\n  verifyPassword,\n  generateShareCode,\n  generateKeyPair,\n};\n\nexport default encryptionService;\n","usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\services\\sharing-intent-service.js","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\services\\sharing-policy-service.js","messages":[{"ruleId":"no-unused-vars","severity":1,"message":"'identityService' is defined but never used.","line":10,"column":10,"nodeType":"Identifier","messageId":"unusedVar","endLine":10,"endColumn":25,"suggestions":[{"messageId":"removeVar","data":{"varName":"identityService"},"fix":{"range":[245,301],"text":""},"desc":"Remove unused variable 'identityService'."}]},{"ruleId":"no-unused-vars","severity":1,"message":"'context' is defined but never used. Allowed unused args must match /^_/u.","line":459,"column":46,"nodeType":"Identifier","messageId":"unusedVar","endLine":459,"endColumn":53,"suggestions":[{"messageId":"removeVar","data":{"varName":"context"},"fix":{"range":[12161,12170],"text":""},"desc":"Remove unused variable 'context'."}]},{"ruleId":"no-case-declarations","severity":2,"message":"Unexpected lexical declaration in case block.","line":636,"column":9,"nodeType":"VariableDeclaration","messageId":"unexpected","endLine":636,"endColumn":86,"suggestions":[{"messageId":"addBrackets","fix":{"range":[17293,17441],"text":"{ const approvals = Object.values(votes).filter((v) => v === 'approve').length;\n        approved = approvals > stakeholders.length / 2;\n        break; }"},"desc":"Add {} brackets around the case block."}]},{"ruleId":"no-case-declarations","severity":2,"message":"Unexpected lexical declaration in case block.","line":641,"column":9,"nodeType":"VariableDeclaration","messageId":"unexpected","endLine":642,"endColumn":87,"suggestions":[{"messageId":"addBrackets","fix":{"range":[17493,17660],"text":"{ const creatorVote =\n          votes[stakeholders.find((s) => s.role === StakeholderRole.CREATOR)?.userId];\n        approved = creatorVote === 'approve';\n        break; }"},"desc":"Add {} brackets around the case block."}]},{"ruleId":"no-case-declarations","severity":2,"message":"Unexpected lexical declaration in case block.","line":648,"column":9,"nodeType":"VariableDeclaration","messageId":"unexpected","endLine":648,"endColumn":80,"suggestions":[{"messageId":"addBrackets","fix":{"range":[17741,17943],"text":"{ const hasRejections = Object.values(votes).some((v) => v === 'reject');\n        approved = !hasRejections;\n        if (!approved) {\n          finalDecision = 'most_restrictive';\n        }\n        break; }"},"desc":"Add {} brackets around the case block."}]}],"suppressedMessages":[],"errorCount":3,"fatalErrorCount":0,"warningCount":2,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * Sharing Policy Service - Phase 3\n *\n * Granular content sharing with collaborative privacy,\n * temporal controls, and contextual access\n */\n\nimport { getPrismaClient } from '../lib/database.js';\nimport { logger } from '../lib/logger.js';\nimport { identityService } from './identity-service.js';\n\nconst log = logger.child({ module: 'sharing-policy-service' });\n\n// ============================================================================\n// Types & Constants\n// ============================================================================\n\nexport const Permission = {\n  VIEW: 'canView',\n  VIEW_METADATA: 'canViewMetadata',\n  REACT: 'canReact',\n  COMMENT: 'canComment',\n  SHARE: 'canShare',\n  QUOTE: 'canQuote',\n  BOOKMARK: 'canBookmark',\n  FORK: 'canFork',\n  REMIX: 'canRemix',\n  ANNOTATE: 'canAnnotate',\n};\n\nexport const DecisionMode = {\n  UNANIMOUS: 'unanimous',\n  MAJORITY: 'majority',\n  CREATOR_OVERRIDE: 'creator_override',\n  HIERARCHICAL: 'hierarchical',\n};\n\nexport const StakeholderRole = {\n  CREATOR: 'creator',\n  PRIMARY_MENTIONED: 'primary_mentioned',\n  MENTIONED: 'mentioned',\n  PARTICIPANT: 'participant',\n  OBSERVER: 'observer',\n};\n\n// Default permissions for new content\nconst DEFAULT_PERMISSIONS = {\n  canView: true,\n  canViewMetadata: true,\n  canReact: true,\n  canComment: true,\n  canShare: false,\n  canQuote: false,\n  canBookmark: true,\n  canFork: false,\n  canRemix: false,\n  canAnnotate: false,\n  reactionsVisibleTo: 'audience',\n  commentsVisibleTo: 'audience',\n};\n\n// ============================================================================\n// Policy CRUD\n// ============================================================================\n\n/**\n * Create sharing policy for content\n */\nexport async function createSharingPolicy(\n  contentId,\n  contentType,\n  ownerId,\n  {\n    audience = {},\n    permissions = {},\n    temporal = null,\n    geographic = null,\n    contextual = null,\n    collaborative = null,\n  }\n) {\n  try {\n    const prisma = getPrismaClient();\n\n    const policy = await prisma.sharingPolicy.create({\n      data: {\n        contentId,\n        contentType,\n        ownerId,\n        audience: {\n          circles: [],\n          specificUsers: [],\n          exceptions: [],\n          networkDepth: 0,\n          discoverable: true,\n          searchable: true,\n          ...audience,\n        },\n        permissions: { ...DEFAULT_PERMISSIONS, ...permissions },\n        temporal,\n        geographic,\n        contextual,\n        collaborative: collaborative || {\n          decisionMode: DecisionMode.CREATOR_OVERRIDE,\n          stakeholders: [],\n        },\n        status: 'active',\n        createdBy: ownerId,\n      },\n    });\n\n    log.info({ policyId: policy.id, contentId }, 'Sharing policy created');\n    return { success: true, policy };\n  } catch (error) {\n    log.error({ contentId, error: error.message }, 'Failed to create sharing policy');\n    return { success: false, error: 'Failed to create policy' };\n  }\n}\n\n/**\n * Get sharing policy for content\n */\nexport async function getSharingPolicy(contentId) {\n  try {\n    const prisma = getPrismaClient();\n\n    const policy = await prisma.sharingPolicy.findUnique({\n      where: { contentId },\n      include: {\n        stakeholders: {\n          include: {\n            user: {\n              select: {\n                id: true,\n                did: true,\n                handle: true,\n                displayName: true,\n              },\n            },\n          },\n        },\n      },\n    });\n\n    if (!policy) {\n      return { success: false, error: 'Policy not found' };\n    }\n\n    return { success: true, policy };\n  } catch (error) {\n    log.error({ contentId, error: error.message }, 'Failed to get sharing policy');\n    return { success: false, error: 'Failed to get policy' };\n  }\n}\n\n/**\n * Update sharing policy\n */\nexport async function updateSharingPolicy(contentId, updaterId, updates) {\n  try {\n    const prisma = getPrismaClient();\n\n    // Get existing policy\n    const existing = await prisma.sharingPolicy.findUnique({\n      where: { contentId },\n      include: { stakeholders: true },\n    });\n\n    if (!existing) {\n      return { success: false, error: 'Policy not found' };\n    }\n\n    // Check collaborative privacy if multi-stakeholder\n    if (existing.stakeholders.length > 1) {\n      const conflictCheck = await checkCollaborativePrivacy(existing, updaterId, updates);\n\n      if (!conflictCheck.allowed) {\n        return {\n          success: false,\n          error: 'Change conflicts with stakeholder privacy preferences',\n          conflict: conflictCheck.conflict,\n        };\n      }\n    }\n\n    // Apply updates\n    const allowedUpdates = ['audience', 'permissions', 'temporal', 'geographic', 'contextual'];\n    const filteredUpdates = {};\n\n    for (const key of allowedUpdates) {\n      if (updates[key] !== undefined) {\n        filteredUpdates[key] = updates[key];\n      }\n    }\n\n    const policy = await prisma.sharingPolicy.update({\n      where: { contentId },\n      data: {\n        ...filteredUpdates,\n        updatedAt: new Date(),\n      },\n    });\n\n    log.info({ contentId, updaterId }, 'Sharing policy updated');\n    return { success: true, policy };\n  } catch (error) {\n    log.error({ contentId, error: error.message }, 'Failed to update sharing policy');\n    return { success: false, error: 'Failed to update policy' };\n  }\n}\n\n/**\n * Delete sharing policy\n */\nexport async function deleteSharingPolicy(contentId, deleterId) {\n  try {\n    const prisma = getPrismaClient();\n\n    const policy = await prisma.sharingPolicy.findUnique({\n      where: { contentId },\n    });\n\n    if (!policy) {\n      return { success: false, error: 'Policy not found' };\n    }\n\n    if (policy.ownerId !== deleterId) {\n      return { success: false, error: 'Only owner can delete policy' };\n    }\n\n    await prisma.sharingPolicy.delete({\n      where: { contentId },\n    });\n\n    log.info({ contentId }, 'Sharing policy deleted');\n    return { success: true };\n  } catch (error) {\n    log.error({ contentId, error: error.message }, 'Failed to delete sharing policy');\n    return { success: false, error: 'Failed to delete policy' };\n  }\n}\n\n// ============================================================================\n// Access Control\n// ============================================================================\n\n/**\n * Check if user can access content with specific permission\n */\nexport async function checkAccess(\n  contentId,\n  accessorId,\n  permission = Permission.VIEW,\n  context = {}\n) {\n  try {\n    const prisma = getPrismaClient();\n\n    // Get policy\n    const policy = await prisma.sharingPolicy.findUnique({\n      where: { contentId },\n      include: {\n        stakeholders: true,\n        accessGrants: {\n          where: {\n            grantedTo: accessorId,\n            status: 'active',\n            OR: [{ expiresAt: null }, { expiresAt: { gt: new Date() } }],\n          },\n        },\n      },\n    });\n\n    if (!policy) {\n      // No policy = no access (fail closed)\n      return { granted: false, reason: 'no_policy' };\n    }\n\n    // Check if policy is active\n    if (policy.status !== 'active') {\n      return { granted: false, reason: 'policy_inactive' };\n    }\n\n    // Check temporal controls\n    const temporalCheck = checkTemporalControls(policy.temporal);\n    if (!temporalCheck.allowed) {\n      return { granted: false, reason: temporalCheck.reason };\n    }\n\n    // Check geographic controls\n    if (context.ipAddress && policy.geographic) {\n      const geoCheck = checkGeographicControls(policy.geographic, context);\n      if (!geoCheck.allowed) {\n        return { granted: false, reason: geoCheck.reason };\n      }\n    }\n\n    // Check contextual controls\n    if (policy.contextual) {\n      const contextCheck = checkContextualControls(policy.contextual, accessorId, context);\n      if (!contextCheck.allowed) {\n        return { granted: false, reason: contextCheck.reason };\n      }\n    }\n\n    // Check if owner\n    if (policy.ownerId === accessorId) {\n      return { granted: true, via: 'owner' };\n    }\n\n    // Check specific permission\n    if (!policy.permissions[permission]) {\n      return { granted: false, reason: 'permission_denied' };\n    }\n\n    // Check audience\n    const audienceCheck = await checkAudience(policy.audience, accessorId);\n    if (!audienceCheck.allowed) {\n      return { granted: false, reason: 'not_in_audience' };\n    }\n\n    // Check temporary access grant\n    if (policy.accessGrants.length > 0) {\n      const grant = policy.accessGrants[0];\n\n      // Check view limits\n      if (grant.maxViews && grant.viewsUsed >= grant.maxViews) {\n        await revokeAccessGrant(grant.id);\n        return { granted: false, reason: 'grant_exhausted' };\n      }\n\n      // Update view count\n      await prisma.contentAccessGrant.update({\n        where: { id: grant.id },\n        data: {\n          viewsUsed: { increment: 1 },\n          lastAccessedAt: new Date(),\n        },\n      });\n\n      return { granted: true, via: 'grant', grantId: grant.id };\n    }\n\n    return { granted: true, via: audienceCheck.via };\n  } catch (error) {\n    log.error({ contentId, accessorId, error: error.message }, 'Access check failed');\n    return { granted: false, reason: 'error' };\n  }\n}\n\n/**\n * Check if user is in audience\n */\nasync function checkAudience(audience, accessorId) {\n  try {\n    const prisma = getPrismaClient();\n\n    // Check specific users\n    if (audience.specificUsers?.includes(accessorId)) {\n      return { allowed: true, via: 'specific_user' };\n    }\n\n    // Check exceptions (blacklist)\n    if (audience.exceptions?.includes(accessorId)) {\n      return { allowed: false };\n    }\n\n    // Check circles\n    if (audience.circles?.length > 0) {\n      const circleMembership = await prisma.circleMember.findFirst({\n        where: {\n          userId: accessorId,\n          circleId: { in: audience.circles },\n          status: 'active',\n        },\n      });\n\n      if (circleMembership) {\n        return { allowed: true, via: 'circle' };\n      }\n    }\n\n    // Check network depth (friends-of-friends, etc.)\n    if (audience.networkDepth > 0) {\n      // This would require social graph traversal\n      // Simplified for now\n      const connection = await prisma.socialConnection.findFirst({\n        where: {\n          followerId: accessorId,\n          followingId: audience.ownerId || '',\n          status: 'active',\n        },\n      });\n\n      if (connection) {\n        return { allowed: true, via: 'network' };\n      }\n    }\n\n    return { allowed: false };\n  } catch (error) {\n    log.error({ accessorId, error: error.message }, 'Audience check failed');\n    return { allowed: false };\n  }\n}\n\n// ============================================================================\n// Temporal Controls\n// ============================================================================\n\nfunction checkTemporalControls(temporal) {\n  if (!temporal) {\n    return { allowed: true };\n  }\n\n  const now = new Date();\n\n  // Check available from\n  if (temporal.availableFrom) {\n    const availableFrom = new Date(temporal.availableFrom);\n    if (now < availableFrom) {\n      return { allowed: false, reason: 'not_yet_available' };\n    }\n  }\n\n  // Check expires at\n  if (temporal.expiresAt) {\n    const expiresAt = new Date(temporal.expiresAt);\n    if (now > expiresAt) {\n      return { allowed: false, reason: 'expired' };\n    }\n  }\n\n  // Check max views (global)\n  if (temporal.maxViews && temporal.viewsUsed >= temporal.maxViews) {\n    return { allowed: false, reason: 'max_views_reached' };\n  }\n\n  // Check phases\n  if (temporal.phases?.length > 0) {\n    const activePhase = temporal.phases.find((phase) => {\n      const start = new Date(phase.startTime);\n      const end = phase.endTime ? new Date(phase.endTime) : null;\n      return now >= start && (!end || now <= end);\n    });\n\n    if (!activePhase) {\n      return { allowed: false, reason: 'no_active_phase' };\n    }\n  }\n\n  return { allowed: true };\n}\n\n// ============================================================================\n// Geographic Controls\n// ============================================================================\n\nfunction checkGeographicControls(geographic, context) {\n  // In production, this would use IP geolocation\n  // Simplified implementation\n\n  if (geographic.allowedCountries?.length > 0) {\n    // Check if user's country is in allowed list\n    // Would need actual geolocation service\n  }\n\n  if (geographic.blockedCountries?.length > 0) {\n    // Check if user's country is blocked\n  }\n\n  if (geographic.requireVPN) {\n    // Check for VPN usage\n  }\n\n  return { allowed: true };\n}\n\n// ============================================================================\n// Contextual Controls\n// ============================================================================\n\nfunction checkContextualControls(contextual, accessorId, context) {\n  // Check time of day\n  if (contextual.timeOfDay?.availableHours) {\n    const now = new Date();\n    const currentHour = now.getHours();\n    const currentMinute = now.getMinutes();\n    const currentTime = currentHour * 60 + currentMinute;\n\n    const inAllowedHours = contextual.timeOfDay.availableHours.some((range) => {\n      const [startHour, startMin] = range.start.split(':').map(Number);\n      const [endHour, endMin] = range.end.split(':').map(Number);\n      const startTime = startHour * 60 + startMin;\n      const endTime = endHour * 60 + endMin;\n\n      return currentTime >= startTime && currentTime <= endTime;\n    });\n\n    if (!inAllowedHours) {\n      return { allowed: false, reason: 'outside_allowed_hours' };\n    }\n  }\n\n  // Check device requirements\n  if (contextual.deviceContext?.requireTrustedDevice && !context.isTrustedDevice) {\n    return { allowed: false, reason: 'untrusted_device' };\n  }\n\n  // Check social context\n  if (contextual.socialContext?.requireMutualFollow) {\n    // Would need to check social graph\n  }\n\n  return { allowed: true };\n}\n\n// ============================================================================\n// Collaborative Privacy\n// ============================================================================\n\n/**\n * Add stakeholder to content\n */\nexport async function addStakeholder(policyId, userId, role, contribution, privacySettings = {}) {\n  try {\n    const prisma = getPrismaClient();\n\n    const stakeholder = await prisma.contentStakeholder.create({\n      data: {\n        policyId,\n        userId,\n        role,\n        contribution,\n        privacySettings: {\n          canRequestRemoval: true,\n          canRequestAnonymization: true,\n          canBlockReshare: true,\n          canSetAudienceLimit: true,\n          ...privacySettings,\n        },\n        influenceScore: role === StakeholderRole.CREATOR ? 100 : 50,\n      },\n    });\n\n    log.info({ policyId, userId, role }, 'Stakeholder added');\n    return { success: true, stakeholder };\n  } catch (error) {\n    log.error({ policyId, userId, error: error.message }, 'Failed to add stakeholder');\n    return { success: false, error: 'Failed to add stakeholder' };\n  }\n}\n\n/**\n * Check collaborative privacy before policy change\n */\nasync function checkCollaborativePrivacy(policy, proposedById, proposedChanges) {\n  const { stakeholders } = policy;\n  const decisionMode = policy.collaborative?.decisionMode || DecisionMode.CREATOR_OVERRIDE;\n\n  // Creator override\n  const creator = stakeholders.find((s) => s.role === StakeholderRole.CREATOR);\n  if (decisionMode === DecisionMode.CREATOR_OVERRIDE && creator?.userId === proposedById) {\n    return { allowed: true };\n  }\n\n  // Check if proposed changes conflict with any stakeholder preferences\n  const conflicts = [];\n\n  for (const stakeholder of stakeholders) {\n    if (stakeholder.userId === proposedById) {\n      continue;\n    }\n\n    const prefs = stakeholder.privacySettings;\n\n    // Check if stakeholder has blocked reshare and change would allow it\n    if (prefs.canBlockReshare && proposedChanges.permissions?.canShare === true) {\n      conflicts.push({\n        stakeholderId: stakeholder.userId,\n        issue: 'share_permission_conflict',\n      });\n    }\n\n    // Check audience expansion\n    if (prefs.canSetAudienceLimit && proposedChanges.audience) {\n      // Would need to compare audience sizes\n      conflicts.push({\n        stakeholderId: stakeholder.userId,\n        issue: 'audience_expansion',\n      });\n    }\n  }\n\n  if (conflicts.length > 0) {\n    return {\n      allowed: false,\n      conflict: {\n        conflicts,\n        requiresConsensus: true,\n      },\n    };\n  }\n\n  return { allowed: true };\n}\n\n/**\n * Resolve privacy conflict with voting\n */\nexport async function resolvePrivacyConflict(contentId, proposedChanges, votes) {\n  try {\n    const prisma = getPrismaClient();\n\n    const policy = await prisma.sharingPolicy.findUnique({\n      where: { contentId },\n      include: { stakeholders: true },\n    });\n\n    if (!policy) {\n      return { success: false, error: 'Policy not found' };\n    }\n\n    const decisionMode = policy.collaborative?.decisionMode || DecisionMode.MAJORITY;\n    const { stakeholders } = policy;\n\n    let approved = false;\n    let finalDecision = null;\n\n    switch (decisionMode) {\n      case DecisionMode.UNANIMOUS:\n        approved = Object.values(votes).every((v) => v === 'approve');\n        break;\n\n      case DecisionMode.MAJORITY:\n        const approvals = Object.values(votes).filter((v) => v === 'approve').length;\n        approved = approvals > stakeholders.length / 2;\n        break;\n\n      case DecisionMode.CREATOR_OVERRIDE:\n        const creatorVote =\n          votes[stakeholders.find((s) => s.role === StakeholderRole.CREATOR)?.userId];\n        approved = creatorVote === 'approve';\n        break;\n\n      case DecisionMode.HIERARCHICAL:\n        // Most restrictive wins\n        const hasRejections = Object.values(votes).some((v) => v === 'reject');\n        approved = !hasRejections;\n        if (!approved) {\n          finalDecision = 'most_restrictive';\n        }\n        break;\n    }\n\n    if (approved) {\n      // Apply changes\n      await prisma.sharingPolicy.update({\n        where: { contentId },\n        data: proposedChanges,\n      });\n    }\n\n    // Record resolution\n    await prisma.privacyConflict.create({\n      data: {\n        contentId,\n        proposedChanges,\n        votes,\n        resolution: approved ? 'approved' : 'rejected',\n        finalDecision,\n        status: 'resolved',\n        resolvedAt: new Date(),\n      },\n    });\n\n    return {\n      success: true,\n      approved,\n      finalDecision,\n    };\n  } catch (error) {\n    log.error({ contentId, error: error.message }, 'Conflict resolution failed');\n    return { success: false, error: 'Resolution failed' };\n  }\n}\n\n// ============================================================================\n// Access Grants\n// ============================================================================\n\n/**\n * Create temporary access grant\n */\nexport async function createAccessGrant(policyId, grantedBy, grantedTo, options = {}) {\n  try {\n    const prisma = getPrismaClient();\n\n    const grant = await prisma.contentAccessGrant.create({\n      data: {\n        policyId,\n        grantedBy,\n        grantedTo,\n        grantedToType: options.grantedToType || 'user',\n        accessLevel: options.accessLevel || 'view',\n        permissions: options.permissions,\n        expiresAt: options.expiresAt,\n        maxViews: options.maxViews,\n      },\n    });\n\n    log.info({ grantId: grant.id, policyId, grantedTo }, 'Access grant created');\n    return { success: true, grant };\n  } catch (error) {\n    log.error({ policyId, error: error.message }, 'Failed to create access grant');\n    return { success: false, error: 'Failed to create grant' };\n  }\n}\n\n/**\n * Revoke access grant\n */\nexport async function revokeAccessGrant(grantId) {\n  try {\n    const prisma = getPrismaClient();\n\n    await prisma.contentAccessGrant.update({\n      where: { id: grantId },\n      data: {\n        status: 'revoked',\n        updatedAt: new Date(),\n      },\n    });\n\n    return { success: true };\n  } catch (error) {\n    log.error({ grantId, error: error.message }, 'Failed to revoke grant');\n    return { success: false, error: 'Failed to revoke grant' };\n  }\n}\n\n// ============================================================================\n// Access Logging\n// ============================================================================\n\n/**\n * Log content access\n */\nexport async function logContentAccess(policyId, accessorId, action, granted, context = {}) {\n  try {\n    const prisma = getPrismaClient();\n\n    await prisma.contentAccessLog.create({\n      data: {\n        policyId,\n        accessorId,\n        accessorType: context.accessorType || 'user',\n        action,\n        granted,\n        denialReason: context.denialReason,\n        viaCircleId: context.viaCircleId,\n        viaGrantId: context.viaGrantId,\n        ipAddress: context.ipAddress,\n        userAgent: context.userAgent,\n        deviceId: context.deviceId,\n        location: context.location,\n      },\n    });\n  } catch (error) {\n    log.error({ policyId, error: error.message }, 'Failed to log access');\n  }\n}\n\n/**\n * Get access log for content\n */\nexport async function getContentAccessLog(contentId, options = {}) {\n  try {\n    const prisma = getPrismaClient();\n    const { limit = 100, offset = 0 } = options;\n\n    const policy = await prisma.sharingPolicy.findUnique({\n      where: { contentId },\n    });\n\n    if (!policy) {\n      return { success: false, error: 'Policy not found' };\n    }\n\n    const logs = await prisma.contentAccessLog.findMany({\n      where: { policyId: policy.id },\n      orderBy: { timestamp: 'desc' },\n      take: limit,\n      skip: offset,\n    });\n\n    return { success: true, logs };\n  } catch (error) {\n    log.error({ contentId, error: error.message }, 'Failed to get access log');\n    return { success: false, error: 'Failed to get log' };\n  }\n}\n\n// ============================================================================\n// Export Service\n// ============================================================================\n\nexport const sharingPolicyService = {\n  // Policy CRUD\n  createSharingPolicy,\n  getSharingPolicy,\n  updateSharingPolicy,\n  deleteSharingPolicy,\n\n  // Access Control\n  checkAccess,\n\n  // Collaborative Privacy\n  addStakeholder,\n  resolvePrivacyConflict,\n\n  // Access Grants\n  createAccessGrant,\n  revokeAccessGrant,\n\n  // Logging\n  logContentAccess,\n  getContentAccessLog,\n\n  // Constants\n  Permission,\n  DecisionMode,\n  StakeholderRole,\n  DEFAULT_PERMISSIONS,\n};\n\nexport default sharingPolicyService;\n","usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\services\\storage-adapter.js","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\services\\sync-service.js","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\services\\ticketStore.js","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\services\\zai-mcp-service.js","messages":[{"ruleId":"no-unused-vars","severity":1,"message":"'ZAI_BASE_URL' is assigned a value but never used.","line":16,"column":7,"nodeType":"Identifier","messageId":"unusedVar","endLine":16,"endColumn":19,"suggestions":[{"messageId":"removeVar","data":{"varName":"ZAI_BASE_URL"},"fix":{"range":[342,390],"text":""},"desc":"Remove unused variable 'ZAI_BASE_URL'."}]},{"ruleId":"no-unused-vars","severity":1,"message":"'e' is defined but never used.","line":90,"column":20,"nodeType":"Identifier","messageId":"unusedVar","endLine":90,"endColumn":21}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":2,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * Z.AI MCP Service\n *\n * Provides MCP tool capabilities to VIVIM users:\n * - Web Search (!websearch)\n * - Web Reader (!read)\n * - GitHub/Zread (!github)\n * - Vision (!vision) - handled separately\n *\n * Uses Z.AI API key from environment (ZAI_API_KEY)\n */\n\nimport { logger } from '../lib/logger.js';\n\nconst { ZAI_API_KEY } = process.env;\nconst ZAI_BASE_URL = 'https://api.z.ai/api/mcp';\n\n// MCP Server endpoints\nconst MCP_ENDPOINTS = {\n  webSearch: 'https://api.z.ai/api/mcp/web_search_prime/mcp',\n  webReader: 'https://api.z.ai/api/mcp/web_reader/mcp',\n  zread: 'https://api.z.ai/api/mcp/zread/mcp',\n};\n\n/**\n * Make MCP request to Z.AI\n */\nasync function mcpRequest(endpoint, toolName, params) {\n  if (!ZAI_API_KEY) {\n    throw new Error('Z.AI API key not configured. Set ZAI_API_KEY environment variable.');\n  }\n\n  const response = await fetch(endpoint, {\n    method: 'POST',\n    headers: {\n      'Content-Type': 'application/json',\n      Accept: 'application/json, text/event-stream',\n      Authorization: `Bearer ${ZAI_API_KEY}`,\n    },\n    body: JSON.stringify({\n      jsonrpc: '2.0',\n      id: Date.now(),\n      method: 'tools/call',\n      params: {\n        name: toolName,\n        arguments: params,\n      },\n    }),\n  });\n\n  if (!response.ok) {\n    const error = await response.text();\n    logger.error({ endpoint, status: response.status, error }, 'Z.AI MCP request failed');\n    throw new Error(`Z.AI MCP error: ${response.status} ${error}`);\n  }\n\n  const contentType = response.headers.get('content-type') || '';\n\n  if (contentType.includes('text/event-stream')) {\n    let result = '';\n    const reader = response.body?.getReader();\n    if (!reader) {\n      throw new Error('No response body');\n    }\n\n    const decoder = new TextDecoder();\n    while (true) {\n      const { done, value } = await reader.read();\n      if (done) {\n        break;\n      }\n\n      const chunk = decoder.decode(value, { stream: true });\n      const lines = chunk.split('\\n');\n\n      for (const line of lines) {\n        if (line.startsWith('data: ')) {\n          const data = line.slice(6);\n          if (data === '[DONE]') {\n            break;\n          }\n\n          try {\n            const parsed = JSON.parse(data);\n            if (parsed.result?.content?.[0]?.text) {\n              result = parsed.result.content[0].text;\n            } else if (parsed.error?.message) {\n              throw new Error(parsed.error.message);\n            }\n          } catch (e) {\n            // Continue\n          }\n        }\n      }\n    }\n\n    try {\n      return JSON.parse(result);\n    } catch {\n      return { content: [{ text: result }] };\n    }\n  }\n\n  const data = await response.json();\n\n  if (data.error) {\n    throw new Error(`Z.AI MCP error: ${data.error.message}`);\n  }\n\n  return data.result;\n}\n\n/**\n * Web Search - Search the web for information\n * Usage: !websearch <query>\n */\nexport async function webSearch(query) {\n  logger.info({ query }, 'Z.AI Web Search');\n\n  const result = await mcpRequest(MCP_ENDPOINTS.webSearch, 'webSearchPrime', {\n    search_query: query,\n  });\n\n  // Parse and format results\n  const searchResults = result?.content?.[0]?.text ? JSON.parse(result.content[0].text) : result;\n\n  return {\n    tool: 'websearch',\n    query,\n    results: searchResults.results || [],\n    count: searchResults.results?.length || 0,\n  };\n}\n\n/**\n * Web Reader - Fetch and parse webpage content\n * Usage: !read <url>\n */\nexport async function webRead(url) {\n  logger.info({ url }, 'Z.AI Web Reader');\n\n  const result = await mcpRequest(MCP_ENDPOINTS.webReader, 'webReader', {\n    url,\n    include_content: true,\n  });\n\n  // Parse the result\n  const content = result?.content?.[0]?.text ? JSON.parse(result.content[0].text) : result;\n\n  return {\n    tool: 'webreader',\n    url,\n    title: content.title || 'Untitled',\n    content: content.content || content.text || '',\n    links: content.links || [],\n    summary: content.summary || '',\n  };\n}\n\n/**\n * GitHub/Zread - Search GitHub repositories\n * Usage: !github <owner/repo> <query>\n */\nexport async function githubSearch(repo, query) {\n  logger.info({ repo, query }, 'Z.AI GitHub Search (Zread)');\n\n  const result = await mcpRequest(MCP_ENDPOINTS.zread, 'search_doc', {\n    repo,\n    query,\n  });\n\n  // Parse the result\n  const searchResults = result?.content?.[0]?.text ? JSON.parse(result.content[0].text) : result;\n\n  return {\n    tool: 'github',\n    repo,\n    query,\n    results: searchResults.results || [],\n    count: searchResults.results?.length || 0,\n  };\n}\n\n/**\n * Get GitHub repository structure\n * Usage: !github <owner/repo>\n */\nexport async function githubRepoStructure(repo) {\n  logger.info({ repo }, 'Z.AI GitHub Repo Structure');\n\n  const result = await mcpRequest(MCP_ENDPOINTS.zread, 'get_repo_structure', {\n    repo,\n  });\n\n  const structure = result?.content?.[0]?.text ? JSON.parse(result.content[0].text) : result;\n\n  return {\n    tool: 'github',\n    repo,\n    structure: structure.tree || structure.files || [],\n  };\n}\n\n/**\n * Read file from GitHub repository\n * Usage: !githubfile <owner/repo> <file-path>\n */\nexport async function githubReadFile(repo, filePath) {\n  logger.info({ repo, filePath }, 'Z.AI GitHub Read File');\n\n  const result = await mcpRequest(MCP_ENDPOINTS.zread, 'read_file', {\n    repo,\n    path: filePath,\n  });\n\n  const content = result?.content?.[0]?.text ? JSON.parse(result.content[0].text) : result;\n\n  return {\n    tool: 'github',\n    repo,\n    file: filePath,\n    content: content.content || content,\n  };\n}\n\n/**\n * Process Vision request (image analysis)\n * This requires handling image upload first\n */\nexport async function visionAnalyze(imagePath, analysisType = 'general') {\n  logger.info({ imagePath, analysisType }, 'Z.AI Vision Analysis');\n\n  // For vision, we use the local MCP server\n  // This is a placeholder - actual implementation depends on how images are handled\n  // The Vision MCP is installed locally via @z_ai/mcp-server\n\n  return {\n    tool: 'vision',\n    status: 'not_implemented',\n    message:\n      'Vision analysis requires local MCP server setup. Use !read to analyze screenshots from URLs.',\n  };\n}\n\n/**\n * Execute Z.AI action based on trigger\n */\nexport async function executeZAIAction(action, params) {\n  switch (action) {\n    case 'websearch':\n      return webSearch(params.query);\n\n    case 'read':\n    case 'readurl':\n      return webRead(params.url);\n\n    case 'github':\n      if (params.file) {\n        return githubReadFile(params.repo, params.file);\n      }\n      if (params.structure) {\n        return githubRepoStructure(params.repo);\n      }\n      return githubSearch(params.repo, params.query);\n\n    case 'vision':\n      return visionAnalyze(params.image, params.type);\n\n    default:\n      throw new Error(`Unknown Z.AI action: ${action}`);\n  }\n}\n\n/**\n * Get available Z.AI MCP tools (for help/discovery)\n */\nexport function getAvailableTools() {\n  return [\n    {\n      id: 'websearch',\n      trigger: '!websearch',\n      label: 'Web Search',\n      description: 'Search the web for information',\n      usage: '!websearch <query>',\n      example: '!websearch latest AI developments 2026',\n    },\n    {\n      id: 'readurl',\n      trigger: '!read',\n      label: 'Web Reader',\n      description: 'Fetch and parse any webpage',\n      usage: '!read <url>',\n      example: '!read https://docs.z.ai',\n    },\n    {\n      id: 'github',\n      trigger: '!github',\n      label: 'GitHub Search',\n      description: 'Search GitHub repositories and docs',\n      usage: '!github <owner/repo> <query>',\n      example: '!github facebook/react hooks',\n    },\n    {\n      id: 'githubfile',\n      trigger: '!githubfile',\n      label: 'GitHub File',\n      description: 'Read file from GitHub repository',\n      usage: '!githubfile <owner/repo> <path>',\n      example: '!githubfile facebook/react README.md',\n    },\n    {\n      id: 'githubtree',\n      trigger: '!githubtree',\n      label: 'GitHub Tree',\n      description: 'Get repository structure',\n      usage: '!githubtree <owner/repo>',\n      example: '!githubtree facebook/react',\n    },\n  ];\n}\n\n/**\n * Check if Z.AI MCP is configured\n */\nexport function isMCPConfigured() {\n  return !!ZAI_API_KEY;\n}\n","usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\types\\ai.js","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\utils\\performance.js","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\utils\\server-error-reporting.js","messages":[{"ruleId":"no-nested-ternary","severity":1,"message":"Do not nest ternary expressions.","line":140,"column":18,"nodeType":"ConditionalExpression","messageId":"noNestedTernary","endLine":140,"endColumn":97},{"ruleId":"no-nested-ternary","severity":1,"message":"Do not nest ternary expressions.","line":146,"column":20,"nodeType":"ConditionalExpression","messageId":"noNestedTernary","endLine":146,"endColumn":99},{"ruleId":"no-nested-ternary","severity":1,"message":"Do not nest ternary expressions.","line":234,"column":18,"nodeType":"ConditionalExpression","messageId":"noNestedTernary","endLine":234,"endColumn":97},{"ruleId":"no-nested-ternary","severity":1,"message":"Do not nest ternary expressions.","line":328,"column":24,"nodeType":"ConditionalExpression","messageId":"noNestedTernary","endLine":332,"endColumn":24},{"ruleId":"no-unused-vars","severity":1,"message":"'requestId' is defined but never used. Allowed unused args must match /^_/u.","line":476,"column":87,"nodeType":"Identifier","messageId":"unusedVar","endLine":476,"endColumn":96,"suggestions":[{"messageId":"removeVar","data":{"varName":"requestId"},"fix":{"range":[13694,13705],"text":""},"desc":"Remove unused variable 'requestId'."}]}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":5,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * Enhanced Server-Side Error Reporting Module\n * Integrates with the centralized error reporting system\n * Provides comprehensive error tracking for all server operations\n *\n * Features:\n * - Database error context extraction\n * - Service contract violation detection\n * - Sync conflict logging\n * - Enhanced error categorization\n */\n\nimport { ErrorReporter, ErrorCategory } from '../../../common/error-reporting.js';\nimport { logger } from '../lib/logger.js';\n\nexport class ServerErrorReporter {\n  constructor() {\n    this.reporter = ErrorReporter.getInstance();\n    this.requestContexts = new Map();\n  }\n\n  /**\n   * Set request context for error correlation\n   */\n  setRequestContext(requestId, context) {\n    const existing = this.requestContexts.get(requestId) || {};\n    this.requestContexts.set(requestId, { ...existing, ...context });\n  }\n\n  /**\n   * Clear request context after response\n   */\n  clearRequestContext(requestId) {\n    this.requestContexts.delete(requestId);\n  }\n\n  /**\n   * Get request context for error correlation\n   */\n  getRequestContext(requestId) {\n    if (!requestId) {\n      return {};\n    }\n    return this.requestContexts.get(requestId) || {};\n  }\n\n  async reportContractViolation(\n    contractId,\n    violationType,\n    actualRequest,\n    actualResponse,\n    expectedContract,\n    deviation,\n    severity = 'medium',\n    requestId\n  ) {\n    try {\n      const requestContext = this.getRequestContext(requestId);\n\n      await this.reporter.report({\n        level: 'warning',\n        component: 'api',\n        category: ErrorCategory.CONTRACT_VIOLATION,\n        source: 'server',\n        message: `Contract violation: ${contractId} - ${violationType}`,\n        context: {\n          ...requestContext,\n          contract: {\n            contractId,\n            expectedParams: expectedContract.expectedParams,\n            actualParams: actualRequest,\n            expectedResponse: expectedContract.expectedResponse,\n            actualResponse,\n            deviation,\n          },\n        },\n        severity,\n        shouldAlert: severity === 'high' || severity === 'critical',\n      });\n\n      logger.warn({\n        msg: `[CONTRACT_VIOLATION] ${contractId}`,\n        violationType,\n        deviation,\n        requestId,\n      });\n    } catch (reportError) {\n      logger.error({\n        msg: 'Failed to report contract violation',\n        originalError: reportError?.message,\n      });\n    }\n  }\n\n  async reportDatabaseErrorWithContext(\n    message,\n    error = null,\n    context = {},\n    severity = 'critical',\n    requestId\n  ) {\n    try {\n      const requestContext = this.getRequestContext(requestId);\n      const {\n        model,\n        operation,\n        table,\n        query,\n        duration,\n        parameters,\n        errorCode,\n        constraint,\n        pgCode,\n      } = context;\n      const target = model || table || 'unknown';\n\n      let category = ErrorCategory.DATABASE_ERROR;\n      if (pgCode === '23505' || errorCode === 'UNIQUE_CONSTRAINT') {\n        category = ErrorCategory.CONSTRAINT_VIOLATION;\n      } else if (pgCode === '23503' || errorCode === 'FOREIGN_KEY_CONSTRAINT') {\n        category = ErrorCategory.CONSTRAINT_VIOLATION;\n      } else if (error?.message?.includes('timeout') || error?.message?.includes('canceling')) {\n        category = ErrorCategory.TRANSACTION_ROLLBACK;\n      }\n\n      const fullMessage = `DB_FAILURE [${operation} on ${target}]: ${message}${error ? ` (${error.message})` : ''}`;\n\n      await this.reporter.report({\n        level: 'error',\n        component: 'database',\n        category,\n        source: 'server',\n        message: fullMessage,\n        stack: error?.stack,\n        context: {\n          ...requestContext,\n          ...context,\n          operation: operation || 'unknown',\n          table: target,\n          query: query ? (typeof query === 'string' ? query : JSON.stringify(query)) : undefined,\n          parameters,\n          duration,\n          errorCode: errorCode || pgCode || error?.code,\n          constraint,\n          database: {\n            query: query ? (typeof query === 'string' ? query : JSON.stringify(query)) : undefined,\n            parameters,\n            errorCode: errorCode || pgCode || error?.code,\n            table: target,\n            constraint,\n          },\n        },\n        severity,\n        shouldAlert: severity === 'critical',\n      });\n\n      logger.error({\n        msg: fullMessage,\n        duration: `${duration}ms`,\n        query: query,\n        pgCode,\n        constraint,\n        context: { ...requestContext, ...context },\n        severity,\n        requestId,\n      });\n    } catch (reportError) {\n      logger.error({\n        msg: 'Failed to report database error with context',\n        originalError: reportError?.message,\n      });\n    }\n  }\n\n  async reportServerError(message, error = null, context = {}, severity = 'high', requestId) {\n    try {\n      const requestContext = this.getRequestContext(requestId);\n      const fullMessage = error?.message ? `${message}: ${error.message}` : message;\n\n      await this.reporter.report({\n        level: 'error',\n        component: 'server',\n        category: 'runtime',\n        source: 'server',\n        message: fullMessage,\n        stack: error?.stack,\n        context: {\n          ...requestContext,\n          ...context,\n          memoryUsage: process.memoryUsage?.().heapUsed,\n          cpuUsage: process.cpuUsage ? process.cpuUsage().user : undefined,\n          errorType: error?.name || 'Error',\n        },\n        severity,\n        shouldAlert: severity === 'critical' || severity === 'fatal',\n      });\n\n      logger.error({\n        msg: `[SERVER_ERROR] ${fullMessage}`,\n        error: error?.message,\n        stack: error?.stack,\n        context: { ...requestContext, ...context },\n        severity,\n        requestId,\n      });\n    } catch (reportError) {\n      logger.error({\n        msg: 'Failed to report server error to central system',\n        originalError: reportError?.message,\n        originalMessage: message,\n      });\n    }\n  }\n\n  async reportDatabaseError(message, error = null, context = {}, severity = 'critical', requestId) {\n    try {\n      const requestContext = this.getRequestContext(requestId);\n      const { model, operation, table, query, duration } = context;\n      const target = model || table || 'unknown';\n      const fullMessage = `DB_FAILURE [${operation} on ${target}]: ${message}${error ? ` (${error.message})` : ''}`;\n\n      await this.reporter.report({\n        level: 'error',\n        component: 'database',\n        category: 'database',\n        source: 'server',\n        message: fullMessage,\n        stack: error?.stack,\n        context: {\n          ...requestContext,\n          ...context,\n          operation: operation || 'unknown',\n          table: target,\n          query: query ? (typeof query === 'string' ? query : JSON.stringify(query)) : undefined,\n          duration,\n          errorCode: error?.code || context.errorCode,\n        },\n        severity,\n        shouldAlert: severity === 'critical',\n      });\n\n      logger.error({\n        msg: fullMessage,\n        duration: `${duration}ms`,\n        query: query,\n        context: { ...requestContext, ...context },\n        severity,\n        requestId,\n      });\n    } catch (reportError) {\n      logger.error({ msg: 'Failed to report database error', originalError: reportError?.message });\n    }\n  }\n\n  async reportAuthError(message, error = null, context = {}, severity = 'medium', requestId) {\n    try {\n      const requestContext = this.getRequestContext(requestId);\n\n      await this.reporter.report({\n        level: 'warning',\n        component: 'auth',\n        category: 'authentication',\n        source: 'server',\n        message,\n        stack: error?.stack,\n        context: {\n          ...requestContext,\n          ...context,\n          action: context.action || 'permission_check',\n          reason: context.reason || message,\n          ip: context.ip,\n          userAgent: context.userAgent,\n        },\n        severity,\n        shouldAlert: severity === 'critical',\n      });\n\n      logger.warn(\n        {\n          message,\n          error: error?.message,\n          context,\n          severity,\n          requestId,\n        },\n        'Auth error reported'\n      );\n    } catch (reportError) {\n      logger.error(\n        {\n          message: 'Failed to report auth error',\n          originalError: reportError?.message,\n        },\n        'Error reporting failed'\n      );\n    }\n  }\n\n  async reportAPIError(\n    endpoint,\n    method,\n    statusCode,\n    error = null,\n    context = {},\n    severity = statusCode >= 500 ? 'high' : 'medium',\n    requestId\n  ) {\n    try {\n      const requestContext = this.getRequestContext(requestId);\n      const isBottleneck = context.responseTime > 2000;\n      const bottleneckMsg = isBottleneck ? ` [SLOW: ${context.responseTime}ms]` : '';\n      const fullMessage = `API_FAILURE [${method} ${endpoint}] Status: ${statusCode}${bottleneckMsg}${error ? ` - ${error.message}` : ''}`;\n\n      await this.reporter.report({\n        level: statusCode >= 500 ? 'error' : 'warning',\n        component: 'api',\n        category: 'api',\n        source: 'server',\n        message: fullMessage,\n        stack: error?.stack,\n        context: {\n          ...requestContext,\n          ...context,\n          endpoint,\n          method,\n          statusCode,\n          responseTime: context.responseTime,\n          requestBody: context.requestBody\n            ? typeof context.requestBody === 'object'\n              ? JSON.stringify(context.requestBody)\n              : context.requestBody\n            : undefined,\n          isSlowResponse: isBottleneck,\n        },\n        severity,\n        shouldAlert: statusCode >= 500 || isBottleneck,\n      });\n\n      logger.error({\n        msg: fullMessage,\n        error: error?.message,\n        responseTime: context.responseTime,\n        context: { ...requestContext, ...context },\n        severity,\n        requestId,\n      });\n\n      if (isBottleneck) {\n        logger.warn({\n          msg: `PERFORMANCE_BOTTLENECK detected at ${method} ${endpoint}`,\n          duration: context.responseTime,\n          requestId,\n        });\n      }\n    } catch (reportError) {\n      logger.error({ msg: 'Failed to report API error', originalError: reportError?.message });\n    }\n  }\n\n  async reportSyncError(message, error = null, context = {}, severity = 'high', requestId) {\n    try {\n      const requestContext = this.getRequestContext(requestId);\n\n      let category = 'sync';\n      if (context.conflictType === 'version_mismatch') {\n        category = ErrorCategory.VERSION_MISMATCH;\n      } else if (context.conflictType === 'crdt_conflict') {\n        category = ErrorCategory.CRDT_CONFLICT;\n      } else if (context.conflictType === 'timeout') {\n        category = ErrorCategory.SYNC_TIMEOUT;\n      }\n\n      await this.reporter.report({\n        level: 'error',\n        component: 'sync',\n        category,\n        source: 'server',\n        message,\n        stack: error?.stack,\n        context: {\n          ...requestContext,\n          ...context,\n          operation: context.operation || 'unknown',\n          deviceId: context.deviceId,\n          localVersion: context.localVersion,\n          remoteVersion: context.remoteVersion,\n          conflictingFields: context.conflictingFields,\n          sync: {\n            entityType: context.entityType,\n            entityId: context.entityId,\n            operation: context.operation,\n            localVersion: context.localVersion,\n            remoteVersion: context.remoteVersion,\n            conflictData: context.conflictData,\n          },\n        },\n        severity,\n        shouldAlert: severity === 'critical',\n      });\n\n      logger.error(\n        {\n          message,\n          error: error?.message,\n          context,\n          severity,\n          requestId,\n        },\n        'Sync error reported'\n      );\n    } catch (reportError) {\n      logger.error(\n        {\n          message: 'Failed to report sync error',\n          originalError: reportError?.message,\n        },\n        'Error reporting failed'\n      );\n    }\n  }\n\n  async reportCRDTConflict(\n    entityType,\n    entityId,\n    localState,\n    remoteState,\n    conflictDetails,\n    resolution,\n    requestId\n  ) {\n    try {\n      const requestContext = this.getRequestContext(requestId);\n\n      await this.reporter.report({\n        level: 'warning',\n        component: 'sync',\n        category: ErrorCategory.CRDT_CONFLICT,\n        source: 'server',\n        message: `CRDT Conflict: ${entityType}:${entityId}`,\n        context: {\n          ...requestContext,\n          sync: {\n            entityType,\n            entityId,\n            operation: 'merge',\n            localVersion: localState?.version,\n            remoteVersion: remoteState?.version,\n            conflictData: {\n              localState,\n              remoteState,\n              conflictFields: conflictDetails?.conflictingFields,\n              mergeStrategy: resolution?.strategy,\n            },\n          },\n        },\n        severity: 'medium',\n        shouldAlert: false,\n      });\n\n      logger.warn({\n        msg: `[CRDT_CONFLICT] ${entityType}:${entityId}`,\n        localVersion: localState?.version,\n        remoteVersion: remoteState?.version,\n        conflictFields: conflictDetails?.conflictingFields,\n        resolution: resolution?.strategy,\n        requestId,\n      });\n    } catch (reportError) {\n      logger.error({\n        msg: 'Failed to report CRDT conflict',\n        originalError: reportError?.message,\n      });\n    }\n  }\n\n  trackSyncIssueViaReporter(issueType, source, target, entityType, entityId, details, requestId) {\n    try {\n      this.reporter.trackSyncIssue({\n        issueType,\n        source,\n        target,\n        entityType,\n        entityId,\n        details,\n      });\n    } catch (error) {\n      logger.error({\n        msg: 'Failed to track sync issue',\n        originalError: error?.message,\n      });\n    }\n  }\n\n  async reportValidationError(\n    resource,\n    fields,\n    error = null,\n    context = {},\n    severity = 'low',\n    requestId\n  ) {\n    try {\n      const requestContext = this.getRequestContext(requestId);\n\n      await this.reporter.report({\n        level: 'warning',\n        component: 'api',\n        category: 'validation',\n        source: 'server',\n        message: `Validation Error: ${resource}`,\n        stack: error?.stack,\n        context: {\n          ...requestContext,\n          ...context,\n          resource,\n          validationErrors: fields,\n          requestBody: context.requestBody,\n        },\n        severity,\n        shouldAlert: false,\n      });\n\n      logger.warn(\n        {\n          message: `Validation Error: ${resource}`,\n          fields,\n          context,\n          severity,\n          requestId,\n        },\n        'Validation error reported'\n      );\n    } catch (reportError) {\n      logger.error(\n        {\n          message: 'Failed to report validation error',\n          originalError: reportError?.message,\n        },\n        'Error reporting failed'\n      );\n    }\n  }\n\n  async reportSecurityIssue(type, details, error, requestId) {\n    try {\n      const requestContext = this.getRequestContext(requestId);\n\n      await this.reporter.report({\n        level: 'critical',\n        component: 'server',\n        category: 'security',\n        source: 'server',\n        message: `Security Issue: ${type}`,\n        stack: error?.stack,\n        context: {\n          ...requestContext,\n          ...details,\n          type,\n          ip: details.ip,\n          userAgent: details.userAgent,\n        },\n        severity: 'critical',\n        shouldAlert: true,\n        alertChannels: ['email', 'slack', 'webhook'],\n      });\n\n      logger.error(\n        {\n          message: `Security Issue: ${type}`,\n          details,\n          error: error?.message,\n        },\n        'Security issue reported'\n      );\n    } catch (reportError) {\n      logger.error(\n        {\n          message: 'Failed to report security issue',\n          originalError: reportError?.message,\n        },\n        'Error reporting failed'\n      );\n    }\n  }\n\n  async reportPerformanceIssue(\n    metric,\n    value,\n    threshold,\n    context = {},\n    severity = value > threshold * 2 ? 'medium' : 'low',\n    requestId\n  ) {\n    try {\n      const requestContext = this.getRequestContext(requestId);\n\n      await this.reporter.report({\n        level: 'warning',\n        component: 'server',\n        category: 'performance',\n        source: 'server',\n        message: `Performance Issue: ${metric}`,\n        context: {\n          ...requestContext,\n          ...context,\n          metric,\n          value,\n          threshold,\n          percentOver: ((value - threshold) / threshold) * 100,\n        },\n        severity,\n        shouldAlert: severity === 'medium',\n      });\n\n      logger.warn(\n        {\n          message: `Performance Issue: ${metric}`,\n          value,\n          threshold,\n          context,\n          severity,\n          requestId,\n        },\n        'Performance issue reported'\n      );\n    } catch (reportError) {\n      logger.error(\n        {\n          message: 'Failed to report performance issue',\n          originalError: reportError?.message,\n        },\n        'Error reporting failed'\n      );\n    }\n  }\n\n  async reportWarning(message, context = {}, requestId) {\n    try {\n      const requestContext = this.getRequestContext(requestId);\n\n      await this.reporter.report({\n        level: 'warning',\n        component: 'server',\n        category: 'general',\n        source: 'server',\n        message,\n        context: { ...requestContext, ...context },\n        severity: 'medium',\n        shouldAlert: false,\n      });\n\n      logger.warn({ message, context, requestId }, 'Server warning reported');\n    } catch (reportError) {\n      logger.error(\n        {\n          message: 'Failed to report warning',\n          originalError: reportError?.message,\n        },\n        'Warning reporting failed'\n      );\n    }\n  }\n\n  async reportInfo(message, context = {}, requestId) {\n    try {\n      const requestContext = this.getRequestContext(requestId);\n\n      await this.reporter.report({\n        level: 'info',\n        component: 'server',\n        category: 'general',\n        source: 'server',\n        message,\n        context: { ...requestContext, ...context },\n        severity: 'low',\n        shouldAlert: false,\n      });\n\n      logger.info({ message, context, requestId }, 'Server info reported');\n    } catch (reportError) {\n      logger.error(\n        {\n          message: 'Failed to report info',\n          originalError: reportError?.message,\n        },\n        'Info reporting failed'\n      );\n    }\n  }\n}\n\n// Singleton instance\nexport const serverErrorReporter = new ServerErrorReporter();\n\n// Express middleware for automatic error reporting and context tracking\nexport const errorReportingMiddleware = (req, res, next) => {\n  // Add request context\n  const requestId = req.id || req.headers['x-request-id'];\n  if (requestId) {\n    serverErrorReporter.setRequestContext(requestId, {\n      requestId,\n      endpoint: req.path,\n      method: req.method,\n      ip: req.ip,\n      userAgent: req.get('User-Agent'),\n      userId: req.user?.id || req.session?.userId,\n    });\n  }\n\n  // Add error reporting methods to request object\n  req.errorReporter = serverErrorReporter;\n\n  // Track response time\n  const startTime = Date.now();\n\n  // Override res.end to track response time\n  const originalEnd = res.end;\n  res.end = function (chunk, encoding, callback) {\n    const responseTime = Date.now() - startTime;\n\n    // Report slow responses\n    if (responseTime > 5000) {\n      // 5 seconds threshold\n      serverErrorReporter.reportPerformanceIssue(\n        'response_time',\n        responseTime,\n        5000,\n        { endpoint: req.path, method: req.method },\n        'medium',\n        requestId\n      );\n    }\n\n    return originalEnd.call(this, chunk, encoding, callback);\n  };\n\n  next();\n};\n\n// Global error handler that reports errors with full context\nexport const globalErrorHandler = (err, req, res, next) => {\n  const requestId = req.id || req.headers['x-request-id'];\n  const responseTime = res.locals?.responseTime || 0;\n\n  // Extract error information\n  const errorInfo = {\n    message: err.message,\n    stack: err.stack,\n    statusCode: err.statusCode || 500,\n    path: req.path,\n    method: req.method,\n    ip: req.ip,\n    userAgent: req.get('User-Agent'),\n    timestamp: new Date().toISOString(),\n    userId: req.user?.id || req.session?.userId || null,\n    responseTime,\n    requestBody: req.body,\n    query: req.query,\n  };\n\n  // Determine severity based on error type and status code\n  let severity = 'high';\n  if (err.statusCode >= 500) {\n    severity = 'critical';\n  } else if (err.statusCode >= 400) {\n    severity = 'medium';\n  }\n\n  // Report the error with full context\n  serverErrorReporter.reportServerError(\n    `Unhandled error in ${req.method} ${req.path}`,\n    err,\n    errorInfo,\n    severity,\n    requestId\n  );\n\n  // Continue with the default error handler\n  next(err);\n};\n","usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\validators\\ai.js","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\validators\\schemas.js","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"C:\\0-BlackBoxProject-0\\vivim-app-og\\vivim-app\\server\\src\\workers\\memory-worker.js","messages":[{"ruleId":"no-unused-vars","severity":1,"message":"'job' is defined but never used. Allowed unused args must match /^_/u.","line":74,"column":54,"nodeType":"Identifier","messageId":"unusedVar","endLine":74,"endColumn":57,"suggestions":[{"messageId":"removeVar","data":{"varName":"job"},"fix":{"range":[2301,2304],"text":""},"desc":"Remove unused variable 'job'."}]}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * Memory Consolidation Worker\n *\n * Consumes the 'consolidation' queue to:\n * 1. Summarize finished conversations\n * 2. Generate embeddings for Memories\n * 3. Store them in PostgreSQL with pgvector for semantic search\n */\n\nimport { queueService } from '../services/queue-service.js';\nimport { aiService } from '../services/ai-service.js';\nimport { getPrismaClient } from '../lib/database.js';\nimport { logger } from '../lib/logger.js';\nimport { v4 as uuidv4 } from 'uuid';\n\nconst prisma = getPrismaClient();\n\n// Worker logic: Process a 'Consolidate Conversation' job\nexport const processConsolidationJob = async (conversationId) => {\n  logger.info({ conversationId }, 'Processing consolidation job');\n\n  try {\n    // 1. Fetch Conversation\n    const conversation = await prisma.conversation.findUnique({\n      where: { id: conversationId },\n      include: { messages: true },\n    });\n\n    if (!conversation) {\n      throw new Error('Conversation not found');\n    }\n\n    // 2. Generate Summary (Episodic Memory)\n    const summary = await aiService.summarizeConversation(conversation);\n    logger.debug({ conversationId, summaryLen: summary.length }, 'Summary generated');\n\n    // 3. Generate Embedding\n    const embeddings = await aiService.generateEmbeddings(summary);\n    if (embeddings.length === 0) {\n      throw new Error('Failed to generate embedding');\n    }\n\n    // 4. Create Memory Record with embedding stored in PostgreSQL\n    const memory = await prisma.memory.create({\n      data: {\n        id: uuidv4(),\n        userId: conversation.ownerId || 'default-user',\n        content: summary,\n        type: 'EPISODIC',\n        category: null,\n        importance: 0.5,\n        embedding: embeddings[0],\n        sourceConversationIds: [conversationId],\n        isActive: true,\n        createdAt: new Date(),\n        updatedAt: new Date(),\n      },\n    });\n\n    // 5. Mark Conversation as 'Processed'\n    await prisma.conversation.update({\n      where: { id: conversationId },\n      data: { state: 'ARCHIVED' },\n    });\n\n    logger.info({ memoryId: memory.id }, 'Consolidation complete');\n  } catch (error) {\n    logger.error({ conversationId, error: error.message }, 'Consolidation failed');\n    throw error;\n  }\n};\n\n// Register the worker\nqueueService.getQueue('consolidation').on('active', (job) => {\n  // Logic handled in queue-service wrapper\n});\n\n// Helper to trigger consolidation\nexport const scheduleConsolidation = (conversationId) => {\n  return queueService.add('consolidation', () => processConsolidationJob(conversationId));\n};\n","usedDeprecatedRules":[]}]